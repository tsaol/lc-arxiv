{"2023-06-20T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2004.04243v4","updated":"2023-06-20T17:58:11Z","published":"2020-04-08T20:49:10Z","title":"Error correction and extraction in request dialogs","summary":"  We propose a dialog system utility component that gets the last two\nutterances of a user and can detect whether the last utterance is an error\ncorrection of the second last utterance. If yes, it corrects the second last\nutterance according to the error correction in the last utterance and outputs\nthe extracted pairs of reparandum and repair entity. This component offers two\nadvantages, learning the concept of corrections to avoid collecting corrections\nfor every new domain and extracting reparandum and repair pairs, which offers\nthe possibility to learn out of it.\n  For the error correction one sequence labeling and two sequence to sequence\napproaches are presented. For the error correction detection these three error\ncorrection approaches can also be used and in addition, we present a sequence\nclassification approach. One error correction detection and one error\ncorrection approach can be combined to a pipeline or the error correction\napproaches can be trained and used end-to-end to avoid two components. We\nmodified the EPIC-KITCHENS-100 dataset to evaluate the approaches for\ncorrecting entity phrases in request dialogs. For error correction detection\nand correction, we got an accuracy of 96.40 % on synthetic validation data and\nan accuracy of 77.81 % on human-created real-world test data.\n","authors":["Stefan Constantin","Alex Waibel"],"pdf_url":"https://arxiv.org/pdf/2004.04243v4.pdf","comment":"10 pages, 8 figures, 3 tables, presented at ICNLSP 2022"},{"id":"http://arxiv.org/abs/2306.11702v1","updated":"2023-06-20T17:30:02Z","published":"2023-06-20T17:30:02Z","title":"Lingua Manga: A Generic Large Language Model Centric System for Data\n  Curation","summary":"  Data curation is a wide-ranging area which contains many critical but\ntime-consuming data processing tasks. However, the diversity of such tasks\nmakes it challenging to develop a general-purpose data curation system. To\naddress this issue, we present Lingua Manga, a user-friendly and versatile\nsystem that utilizes pre-trained large language models. Lingua Manga offers\nautomatic optimization for achieving high performance and label efficiency\nwhile facilitating flexible and rapid development. Through three example\napplications with distinct objectives and users of varying levels of technical\nproficiency, we demonstrate that Lingua Manga can effectively assist both\nskilled programmers and low-code or even no-code users in addressing data\ncuration challenges.\n","authors":["Zui Chen","Lei Cao","Sam Madden"],"pdf_url":"https://arxiv.org/pdf/2306.11702v1.pdf","comment":"4 pages, 6 figures, VLDB 2023 Demo paper"},{"id":"http://arxiv.org/abs/2306.11698v1","updated":"2023-06-20T17:24:23Z","published":"2023-06-20T17:24:23Z","title":"DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT\n  Models","summary":"  Generative Pre-trained Transformer (GPT) models have exhibited exciting\nprogress in capabilities, capturing the interest of practitioners and the\npublic alike. Yet, while the literature on the trustworthiness of GPT models\nremains limited, practitioners have proposed employing capable GPT models for\nsensitive applications to healthcare and finance - where mistakes can be\ncostly. To this end, this work proposes a comprehensive trustworthiness\nevaluation for large language models with a focus on GPT-4 and GPT-3.5,\nconsidering diverse perspectives - including toxicity, stereotype bias,\nadversarial robustness, out-of-distribution robustness, robustness on\nadversarial demonstrations, privacy, machine ethics, and fairness. Based on our\nevaluations, we discover previously unpublished vulnerabilities to\ntrustworthiness threats. For instance, we find that GPT models can be easily\nmisled to generate toxic and biased outputs and leak private information in\nboth training data and conversation history. We also find that although GPT-4\nis usually more trustworthy than GPT-3.5 on standard benchmarks, GPT-4 is more\nvulnerable given jailbreaking system or user prompts, potentially due to the\nreason that GPT-4 follows the (misleading) instructions more precisely. Our\nwork illustrates a comprehensive trustworthiness evaluation of GPT models and\nsheds light on the trustworthiness gaps. Our benchmark is publicly available at\nhttps://decodingtrust.github.io/.\n","authors":["Boxin Wang","Weixin Chen","Hengzhi Pei","Chulin Xie","Mintong Kang","Chenhui Zhang","Chejian Xu","Zidi Xiong","Ritik Dutta","Rylan Schaeffer","Sang T. Truong","Simran Arora","Mantas Mazeika","Dan Hendrycks","Zinan Lin","Yu Cheng","Sanmi Koyejo","Dawn Song","Bo Li"],"pdf_url":"https://arxiv.org/pdf/2306.11698v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11695v1","updated":"2023-06-20T17:18:20Z","published":"2023-06-20T17:18:20Z","title":"A Simple and Effective Pruning Approach for Large Language Models","summary":"  As their size increases, Large Languages Models (LLMs) are natural candidates\nfor network pruning methods: approaches that drop a subset of network weights\nwhile striving to preserve performance. Existing methods, however, require\neither retraining, which is rarely affordable for billion-scale LLMs, or\nsolving a weight reconstruction problem reliant on second-order information,\nwhich may also be computationally expensive. In this paper, we introduce a\nnovel, straightforward yet effective pruning method, termed Wanda (Pruning by\nWeights and activations), designed to induce sparsity in pretrained LLMs.\nMotivated by the recent observation of emergent large magnitude features in\nLLMs, our approach prune weights with the smallest magnitudes multiplied by the\ncorresponding input activations, on a per-output basis. Notably, Wanda requires\nno retraining or weight update, and the pruned LLM can be used as is. We\nconduct a thorough evaluation of our method on LLaMA across various language\nbenchmarks. Wanda significantly outperforms the established baseline of\nmagnitude pruning and competes favorably against recent methods involving\nintensive weight update. Code is available at\nhttps://github.com/locuslab/wanda.\n","authors":["Mingjie Sun","Zhuang Liu","Anna Bair","J. Zico Kolter"],"pdf_url":"https://arxiv.org/pdf/2306.11695v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2305.19981v2","updated":"2023-06-20T16:52:56Z","published":"2023-05-31T16:06:07Z","title":"MedNgage: A Dataset for Understanding Engagement in Patient-Nurse\n  Conversations","summary":"  Patients who effectively manage their symptoms often demonstrate higher\nlevels of engagement in conversations and interventions with healthcare\npractitioners. This engagement is multifaceted, encompassing cognitive and\nsocio-affective dimensions. Consequently, it is crucial for AI systems to\nunderstand the engagement in natural conversations between patients and\npractitioners to better contribute toward patient care. In this paper, we\npresent a novel dataset (MedNgage), which consists of patient-nurse\nconversations about cancer symptom management. We manually annotate the dataset\nwith a novel framework of categories of patient engagement from two different\nangles, namely: i) socio-affective (3.1K spans), and ii) cognitive use of\nlanguage (1.8K spans). Through statistical analysis of the data that is\nannotated using our framework, we show a positive correlation between patient\nsymptom management outcomes and their engagement in conversations.\nAdditionally, we demonstrate that pre-trained transformer models fine-tuned on\nour dataset can reliably predict engagement classes in patient-nurse\nconversations. Lastly, we use LIME (Ribeiro et al., 2016) to analyze the\nunderlying challenges of the tasks that state-of-the-art transformer models\nencounter. The de-identified data is available for research purposes upon\nrequest.\n","authors":["Yan Wang","Heidi Ann Scharf Donovan","Sabit Hassan","Mailhe Alikhani"],"pdf_url":"https://arxiv.org/pdf/2305.19981v2.pdf","comment":"ACL Findings 2023"},{"id":"http://arxiv.org/abs/2306.11648v1","updated":"2023-06-20T16:16:56Z","published":"2023-06-20T16:16:56Z","title":"Harnessing the Power of Adversarial Prompting and Large Language Models\n  for Robust Hypothesis Generation in Astronomy","summary":"  This study investigates the application of Large Language Models (LLMs),\nspecifically GPT-4, within Astronomy. We employ in-context prompting, supplying\nthe model with up to 1000 papers from the NASA Astrophysics Data System, to\nexplore the extent to which performance can be improved by immersing the model\nin domain-specific literature. Our findings point towards a substantial boost\nin hypothesis generation when using in-context prompting, a benefit that is\nfurther accentuated by adversarial prompting. We illustrate how adversarial\nprompting empowers GPT-4 to extract essential details from a vast knowledge\nbase to produce meaningful hypotheses, signaling an innovative step towards\nemploying LLMs for scientific research in Astronomy.\n","authors":["Ioana Ciucă","Yuan-Sen Ting","Sandor Kruk","Kartheik Iyer"],"pdf_url":"https://arxiv.org/pdf/2306.11648v1.pdf","comment":"8 pages, 3 figures, accepted to ICML ML4Astro Workshop. Comments and\n  suggestions are welcome"},{"id":"http://arxiv.org/abs/2306.11646v1","updated":"2023-06-20T16:14:27Z","published":"2023-06-20T16:14:27Z","title":"Recent Advances in Direct Speech-to-text Translation","summary":"  Recently, speech-to-text translation has attracted more and more attention\nand many studies have emerged rapidly. In this paper, we present a\ncomprehensive survey on direct speech translation aiming to summarize the\ncurrent state-of-the-art techniques. First, we categorize the existing research\nwork into three directions based on the main challenges -- modeling burden,\ndata scarcity, and application issues. To tackle the problem of modeling\nburden, two main structures have been proposed, encoder-decoder framework\n(Transformer and the variants) and multitask frameworks. For the challenge of\ndata scarcity, recent work resorts to many sophisticated techniques, such as\ndata augmentation, pre-training, knowledge distillation, and multilingual\nmodeling. We analyze and summarize the application issues, which include\nreal-time, segmentation, named entity, gender bias, and code-switching.\nFinally, we discuss some promising directions for future work.\n","authors":["Chen Xu","Rong Ye","Qianqian Dong","Chengqi Zhao","Tom Ko","Mingxuan Wang","Tong Xiao","Jingbo Zhu"],"pdf_url":"https://arxiv.org/pdf/2306.11646v1.pdf","comment":"An expanded version of the paper accepted by IJCAI2023 survey track"},{"id":"http://arxiv.org/abs/2306.11644v1","updated":"2023-06-20T16:14:25Z","published":"2023-06-20T16:14:25Z","title":"Textbooks Are All You Need","summary":"  We introduce phi-1, a new large language model for code, with significantly\nsmaller size than competing models: phi-1 is a Transformer-based model with\n1.3B parameters, trained for 4 days on 8 A100s, using a selection of ``textbook\nquality\" data from the web (6B tokens) and synthetically generated textbooks\nand exercises with GPT-3.5 (1B tokens). Despite this small scale, phi-1 attains\npass@1 accuracy 50.6% on HumanEval and 55.5% on MBPP. It also displays\nsurprising emergent properties compared to phi-1-base, our model before our\nfinetuning stage on a dataset of coding exercises, and phi-1-small, a smaller\nmodel with 350M parameters trained with the same pipeline as phi-1 that still\nachieves 45% on HumanEval.\n","authors":["Suriya Gunasekar","Yi Zhang","Jyoti Aneja","Caio César Teodoro Mendes","Allie Del Giorno","Sivakanth Gopi","Mojan Javaheripi","Piero Kauffmann","Gustavo de Rosa","Olli Saarikivi","Adil Salim","Shital Shah","Harkirat Singh Behl","Xin Wang","Sébastien Bubeck","Ronen Eldan","Adam Tauman Kalai","Yin Tat Lee","Yuanzhi Li"],"pdf_url":"https://arxiv.org/pdf/2306.11644v1.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2305.06721v2","updated":"2023-06-20T15:22:58Z","published":"2023-05-11T10:56:20Z","title":"Advancing Neural Encoding of Portuguese with Transformer Albertina PT-*","summary":"  To advance the neural encoding of Portuguese (PT), and a fortiori the\ntechnological preparation of this language for the digital age, we developed a\nTransformer-based foundation model that sets a new state of the art in this\nrespect for two of its variants, namely European Portuguese from Portugal\n(PT-PT) and American Portuguese from Brazil (PT-BR).\n  To develop this encoder, which we named Albertina PT-*, a strong model was\nused as a starting point, DeBERTa, and its pre-training was done over data sets\nof Portuguese, namely over data sets we gathered for PT-PT and PT-BR, and over\nthe brWaC corpus for PT-BR. The performance of Albertina and competing models\nwas assessed by evaluating them on prominent downstream language processing\ntasks adapted for Portuguese.\n  Both Albertina PT-PT and PT-BR versions are distributed free of charge and\nunder the most permissive license possible and can be run on consumer-grade\nhardware, thus seeking to contribute to the advancement of research and\ninnovation in language technology for Portuguese.\n","authors":["João Rodrigues","Luís Gomes","João Silva","António Branco","Rodrigo Santos","Henrique Lopes Cardoso","Tomás Osório"],"pdf_url":"https://arxiv.org/pdf/2305.06721v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11593v1","updated":"2023-06-20T15:13:02Z","published":"2023-06-20T15:13:02Z","title":"Improving Image Captioning Descriptiveness by Ranking and LLM-based\n  Fusion","summary":"  State-of-The-Art (SoTA) image captioning models often rely on the Microsoft\nCOCO (MS-COCO) dataset for training. This dataset contains annotations provided\nby human annotators, who typically produce captions averaging around ten\ntokens. However, this constraint presents a challenge in effectively capturing\ncomplex scenes and conveying detailed information. Furthermore, captioning\nmodels tend to exhibit bias towards the ``average'' caption, which captures\nonly the more general aspects. What would happen if we were able to\nautomatically generate longer captions, thereby making them more detailed?\nWould these captions, evaluated by humans, be more or less representative of\nthe image content compared to the original MS-COCO captions? In this paper, we\npresent a novel approach to address previous challenges by showcasing how\ncaptions generated from different SoTA models can be effectively fused,\nresulting in richer captions. Our proposed method leverages existing models\nfrom the literature, eliminating the need for additional training. Instead, it\nutilizes an image-text based metric to rank the captions generated by SoTA\nmodels for a given image. Subsequently, the top two captions are fused using a\nLarge Language Model (LLM). Experimental results demonstrate the effectiveness\nof our approach, as the captions generated by our model exhibit higher\nconsistency with human judgment when evaluated on the MS-COCO test set. By\ncombining the strengths of various SoTA models, our method enhances the quality\nand appeal of image captions, bridging the gap between automated systems and\nthe rich, informative nature of human-generated descriptions. This advance\nopens up new possibilities for generating captions that are more suitable for\nthe training of both vision-language and captioning models.\n","authors":["Simone Bianco","Luigi Celona","Marco Donzella","Paolo Napoletano"],"pdf_url":"https://arxiv.org/pdf/2306.11593v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11585v1","updated":"2023-06-20T15:02:25Z","published":"2023-06-20T15:02:25Z","title":"FAIR: A Causal Framework for Accurately Inferring Judgments Reversals","summary":"  Artificial intelligence researchers have made significant advances in legal\nintelligence in recent years. However, the existing studies have not focused on\nthe important value embedded in judgments reversals, which limits the\nimprovement of the efficiency of legal intelligence. In this paper, we propose\na causal Framework for Accurately Inferring case Reversals (FAIR), which models\nthe problem of judgments reversals based on real Chinese judgments. We mine the\ncauses of judgments reversals by causal inference methods and inject the\nobtained causal relationships into the neural network as a priori knowledge.\nAnd then, our framework is validated on a challenging dataset as a legal\njudgment prediction task. The experimental results show that our framework can\ntap the most critical factors in judgments reversal, and the obtained causal\nrelationships can effectively improve the neural network's performance. In\naddition, we discuss the generalization ability of large language models for\nlegal intelligence tasks using ChatGPT as an example. Our experiment has found\nthat the generalization ability of large language models still has defects, and\nmining causal relationships can effectively improve the accuracy and explain\nability of model predictions.\n","authors":["Minghua He","Nanfei Gu","Yuntao Shi","Qionghui Zhang","Yaying Chen"],"pdf_url":"https://arxiv.org/pdf/2306.11585v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.15444v2","updated":"2023-06-20T14:41:38Z","published":"2023-05-24T07:38:24Z","title":"PromptNER: Prompting For Named Entity Recognition","summary":"  In a surprising turn, Large Language Models (LLMs) together with a growing\narsenal of prompt-based heuristics now offer powerful off-the-shelf approaches\nproviding few-shot solutions to myriad classic NLP problems. However, despite\npromising early results, these LLM-based few-shot methods remain far from the\nstate of the art in Named Entity Recognition (NER), where prevailing methods\ninclude learning representations via end-to-end structural understanding and\nfine-tuning on standard labeled corpora. In this paper, we introduce PromptNER,\na new state-of-the-art algorithm for few-Shot and cross-domain NER. To adapt to\nany new NER task PromptNER requires a set of entity definitions in addition to\nthe standard few-shot examples. Given a sentence, PromptNER prompts an LLM to\nproduce a list of potential entities along with corresponding explanations\njustifying their compatibility with the provided entity type definitions.\nRemarkably, PromptNER achieves state-of-the-art performance on few-shot NER,\nachieving a 4% (absolute) improvement in F1 score on the ConLL dataset, a 9%\n(absolute) improvement on the GENIA dataset, and a 4% (absolute) improvement on\nthe FewNERD dataset. PromptNER also moves the state of the art on Cross Domain\nNER, outperforming prior methods (including those not limited to the few-shot\nsetting), setting a new mark on 3/5 CrossNER target domains, with an average F1\ngain of 3%, despite using less than 2% of the available data.\n","authors":["Dhananjay Ashok","Zachary C. Lipton"],"pdf_url":"https://arxiv.org/pdf/2305.15444v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11559v1","updated":"2023-06-20T14:23:32Z","published":"2023-06-20T14:23:32Z","title":"The Ecological Fallacy in Annotation: Modelling Human Label Variation\n  goes beyond Sociodemographics","summary":"  Many NLP tasks exhibit human label variation, where different annotators give\ndifferent labels to the same texts. This variation is known to depend, at least\nin part, on the sociodemographics of annotators. Recent research aims to model\nindividual annotator behaviour rather than predicting aggregated labels, and we\nwould expect that sociodemographic information is useful for these models. On\nthe other hand, the ecological fallacy states that aggregate group behaviour,\nsuch as the behaviour of the average female annotator, does not necessarily\nexplain individual behaviour. To account for sociodemographics in models of\nindividual annotator behaviour, we introduce group-specific layers to\nmulti-annotator models. In a series of experiments for toxic content detection,\nwe find that explicitly accounting for sociodemographic attributes in this way\ndoes not significantly improve model performance. This result shows that\nindividual annotation behaviour depends on much more than just\nsociodemographics.\n","authors":["Matthias Orlikowski","Paul Röttger","Philipp Cimiano","Dirk Hovy"],"pdf_url":"https://arxiv.org/pdf/2306.11559v1.pdf","comment":"ACL2023 Camera-Ready"},{"id":"http://arxiv.org/abs/2306.08302v2","updated":"2023-06-20T14:18:49Z","published":"2023-06-14T07:15:26Z","title":"Unifying Large Language Models and Knowledge Graphs: A Roadmap","summary":"  Large language models (LLMs), such as ChatGPT and GPT4, are making new waves\nin the field of natural language processing and artificial intelligence, due to\ntheir emergent ability and generalizability. However, LLMs are black-box\nmodels, which often fall short of capturing and accessing factual knowledge. In\ncontrast, Knowledge Graphs (KGs), Wikipedia and Huapu for example, are\nstructured knowledge models that explicitly store rich factual knowledge. KGs\ncan enhance LLMs by providing external knowledge for inference and\ninterpretability. Meanwhile, KGs are difficult to construct and evolving by\nnature, which challenges the existing methods in KGs to generate new facts and\nrepresent unseen knowledge. Therefore, it is complementary to unify LLMs and\nKGs together and simultaneously leverage their advantages. In this article, we\npresent a forward-looking roadmap for the unification of LLMs and KGs. Our\nroadmap consists of three general frameworks, namely, 1) KG-enhanced LLMs,\nwhich incorporate KGs during the pre-training and inference phases of LLMs, or\nfor the purpose of enhancing understanding of the knowledge learned by LLMs; 2)\nLLM-augmented KGs, that leverage LLMs for different KG tasks such as embedding,\ncompletion, construction, graph-to-text generation, and question answering; and\n3) Synergized LLMs + KGs, in which LLMs and KGs play equal roles and work in a\nmutually beneficial way to enhance both LLMs and KGs for bidirectional\nreasoning driven by both data and knowledge. We review and summarize existing\nefforts within these three frameworks in our roadmap and pinpoint their future\nresearch directions.\n","authors":["Shirui Pan","Linhao Luo","Yufei Wang","Chen Chen","Jiapu Wang","Xindong Wu"],"pdf_url":"https://arxiv.org/pdf/2306.08302v2.pdf","comment":"29 pages, 25 figures"},{"id":"http://arxiv.org/abs/2207.01054v2","updated":"2023-06-20T13:32:02Z","published":"2022-07-03T14:31:32Z","title":"Multi-aspect Multilingual and Cross-lingual Parliamentary Speech\n  Analysis","summary":"  Parliamentary and legislative debate transcripts provide informative insight\ninto elected politicians' opinions, positions, and policy preferences. They are\ninteresting for political and social sciences as well as linguistics and\nnatural language processing (NLP) research. While existing research studied\nindividual parliaments, we apply advanced NLP methods to a joint and\ncomparative analysis of six national parliaments (Bulgarian, Czech, French,\nSlovene, Spanish, and United Kingdom) between 2017 and 2020. We analyze\nemotions and sentiment in the transcripts from the ParlaMint dataset collection\nand assess if the age, gender, and political orientation of speakers can be\ndetected from their speeches. The results show some commonalities and many\nsurprising differences among the analyzed countries.\n","authors":["Kristian Miok","Encarnacion Hidalgo-Tenorio","Petya Osenova","Miguel-Angel Benitez-Castro","Marko Robnik-Sikonja"],"pdf_url":"https://arxiv.org/pdf/2207.01054v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11520v1","updated":"2023-06-20T13:14:15Z","published":"2023-06-20T13:14:15Z","title":"Hallucination is the last thing you need","summary":"  The legal profession necessitates a multidimensional approach that involves\nsynthesizing an in-depth comprehension of a legal issue with insightful\ncommentary based on personal experience, combined with a comprehensive\nunderstanding of pertinent legislation, regulation, and case law, in order to\ndeliver an informed legal solution. The present offering with generative AI\npresents major obstacles in replicating this, as current models struggle to\nintegrate and navigate such a complex interplay of understanding, experience,\nand fact-checking procedures. It is noteworthy that where generative AI outputs\nunderstanding and experience, which reflect the aggregate of various subjective\nviews on similar topics, this often deflects the model's attention from the\ncrucial legal facts, thereby resulting in hallucination. Hence, this paper\ndelves into the feasibility of three independent LLMs, each focused on\nunderstanding, experience, and facts, synthesising as one single ensemble model\nto effectively counteract the current challenges posed by the existing\nmonolithic generative AI models. We introduce an idea of mutli-length\ntokenisation to protect key information assets like common law judgements, and\nfinally we interrogate the most advanced publicly available models for legal\nhallucination, with some interesting results.\n","authors":["Shawn Curran","Sam Lansley","Oliver Bethell"],"pdf_url":"https://arxiv.org/pdf/2306.11520v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11518v1","updated":"2023-06-20T13:12:58Z","published":"2023-06-20T13:12:58Z","title":"One model to rule them all: ranking Slovene summarizers","summary":"  Text summarization is an essential task in natural language processing, and\nresearchers have developed various approaches over the years, ranging from\nrule-based systems to neural networks. However, there is no single model or\napproach that performs well on every type of text. We propose a system that\nrecommends the most suitable summarization model for a given text. The proposed\nsystem employs a fully connected neural network that analyzes the input content\nand predicts which summarizer should score the best in terms of ROUGE score for\na given input. The meta-model selects among four different summarization\nmodels, developed for the Slovene language, using different properties of the\ninput, in particular its Doc2Vec document representation. The four Slovene\nsummarization models deal with different challenges associated with text\nsummarization in a less-resourced language. We evaluate the proposed SloMetaSum\nmodel performance automatically and parts of it manually. The results show that\nthe system successfully automates the step of manually selecting the best\nmodel.\n","authors":["Aleš Žagar","Marko Robnik-Šikonja"],"pdf_url":"https://arxiv.org/pdf/2306.11518v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11507v1","updated":"2023-06-20T12:53:39Z","published":"2023-06-20T12:53:39Z","title":"TrustGPT: A Benchmark for Trustworthy and Responsible Large Language\n  Models","summary":"  Large Language Models (LLMs) such as ChatGPT, have gained significant\nattention due to their impressive natural language processing capabilities. It\nis crucial to prioritize human-centered principles when utilizing these models.\nSafeguarding the ethical and moral compliance of LLMs is of utmost importance.\nHowever, individual ethical issues have not been well studied on the latest\nLLMs. Therefore, this study aims to address these gaps by introducing a new\nbenchmark -- TrustGPT. TrustGPT provides a comprehensive evaluation of LLMs in\nthree crucial areas: toxicity, bias, and value-alignment. Initially, TrustGPT\nexamines toxicity in language models by employing toxic prompt templates\nderived from social norms. It then quantifies the extent of bias in models by\nmeasuring quantifiable toxicity values across different groups. Lastly,\nTrustGPT assesses the value of conversation generation models from both active\nvalue-alignment and passive value-alignment tasks. Through the implementation\nof TrustGPT, this research aims to enhance our understanding of the performance\nof conversation generation models and promote the development of language\nmodels that are more ethical and socially responsible.\n","authors":["Yue Huang","Qihui Zhang","Philip S. Y","Lichao Sun"],"pdf_url":"https://arxiv.org/pdf/2306.11507v1.pdf","comment":"We are currently expanding this work and welcome collaborators!"},{"id":"http://arxiv.org/abs/2306.11489v1","updated":"2023-06-20T12:21:06Z","published":"2023-06-20T12:21:06Z","title":"ChatGPT is not Enough: Enhancing Large Language Models with Knowledge\n  Graphs for Fact-aware Language Modeling","summary":"  Recently, ChatGPT, a representative large language model (LLM), has gained\nconsiderable attention due to its powerful emergent abilities. Some researchers\nsuggest that LLMs could potentially replace structured knowledge bases like\nknowledge graphs (KGs) and function as parameterized knowledge bases. However,\nwhile LLMs are proficient at learning probabilistic language patterns based on\nlarge corpus and engaging in conversations with humans, they, like previous\nsmaller pre-trained language models (PLMs), still have difficulty in recalling\nfacts while generating knowledge-grounded contents. To overcome these\nlimitations, researchers have proposed enhancing data-driven PLMs with\nknowledge-based KGs to incorporate explicit factual knowledge into PLMs, thus\nimproving their performance to generate texts requiring factual knowledge and\nproviding more informed responses to user queries. This paper reviews the\nstudies on enhancing PLMs with KGs, detailing existing knowledge graph enhanced\npre-trained language models (KGPLMs) as well as their applications. Inspired by\nexisting studies on KGPLM, this paper proposes to enhance LLMs with KGs by\ndeveloping knowledge graph-enhanced large language models (KGLLMs). KGLLM\nprovides a solution to enhance LLMs' factual reasoning ability, opening up new\navenues for LLM research.\n","authors":["Linyao Yang","Hongyang Chen","Zhao Li","Xiao Ding","Xindong Wu"],"pdf_url":"https://arxiv.org/pdf/2306.11489v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11485v1","updated":"2023-06-20T12:16:31Z","published":"2023-06-20T12:16:31Z","title":"Explicit Syntactic Guidance for Neural Text Generation","summary":"  Most existing text generation models follow the sequence-to-sequence\nparadigm. Generative Grammar suggests that humans generate natural language\ntexts by learning language grammar. We propose a syntax-guided generation\nschema, which generates the sequence guided by a constituency parse tree in a\ntop-down direction. The decoding process can be decomposed into two parts: (1)\npredicting the infilling texts for each constituent in the lexicalized syntax\ncontext given the source sentence; (2) mapping and expanding each constituent\nto construct the next-level syntax context. Accordingly, we propose a\nstructural beam search method to find possible syntax structures\nhierarchically. Experiments on paraphrase generation and machine translation\nshow that the proposed method outperforms autoregressive baselines, while also\ndemonstrating effectiveness in terms of interpretability, controllability, and\ndiversity.\n","authors":["Yafu Li","Leyang Cui","Jianhao Yan","Yongjng Yin","Wei Bi","Shuming Shi","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.11485v1.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2306.11477v1","updated":"2023-06-20T12:02:26Z","published":"2023-06-20T12:02:26Z","title":"CATS: A Pragmatic Chinese Answer-to-Sequence Dataset with Large Scale\n  and High Quality","summary":"  There are three problems existing in the popular data-to-text datasets.\nFirst, the large-scale datasets either contain noise or lack real application\nscenarios. Second, the datasets close to real applications are relatively small\nin size. Last, current datasets bias in the English language while leaving\nother languages underexplored. To alleviate these limitations, in this paper,\nwe present CATS, a pragmatic Chinese answer-to-sequence dataset with large\nscale and high quality. The dataset aims to generate textual descriptions for\nthe answer in the practical TableQA system. Further, to bridge the structural\ngap between the input SQL and table and establish better semantic alignments,\nwe propose a Unified Graph Transformation approach to establish a joint\nencoding space for the two hybrid knowledge resources and convert this task to\na graph-to-text problem. The experiment results demonstrate the effectiveness\nof our proposed method. Further analysis on CATS attests to both the high\nquality and challenges of the dataset.\n","authors":["Liang Li","Ruiying Geng","Chengyang Fang","Bing Li","Can Ma","Rongyu Cao","Binhua Li","Fei Huang","Yongbin Li"],"pdf_url":"https://arxiv.org/pdf/2306.11477v1.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2306.11473v1","updated":"2023-06-20T11:53:43Z","published":"2023-06-20T11:53:43Z","title":"Timestamped Embedding-Matching Acoustic-to-Word CTC ASR","summary":"  In this work, we describe a novel method of training an embedding-matching\nword-level connectionist temporal classification (CTC) automatic speech\nrecognizer (ASR) such that it directly produces word start times and durations,\nrequired by many real-world applications, in addition to the transcription. The\nword timestamps enable the ASR to output word segmentations and word confusion\nnetworks without relying on a secondary model or forced alignment process when\ntesting. Our proposed system has similar word segmentation accuracy as a hybrid\nDNN-HMM (Deep Neural Network-Hidden Markov Model) system, with less than 3ms\ndifference in mean absolute error in word start times on TIMIT data. At the\nsame time, we observed less than 5% relative increase in the word error rate\ncompared to the non-timestamped system when using the same audio training data\nand nearly identical model size. We also contribute more rigorous analysis of\nmultiple-hypothesis embedding-matching ASR in general.\n","authors":["Woojay Jeon"],"pdf_url":"https://arxiv.org/pdf/2306.11473v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.19999v3","updated":"2023-06-20T11:50:33Z","published":"2023-05-31T16:20:04Z","title":"Beam Tree Recursive Cells","summary":"  We propose Beam Tree Recursive Cell (BT-Cell) - a backpropagation-friendly\nframework to extend Recursive Neural Networks (RvNNs) with beam search for\nlatent structure induction. We further extend this framework by proposing a\nrelaxation of the hard top-k operators in beam search for better propagation of\ngradient signals. We evaluate our proposed models in different\nout-of-distribution splits in both synthetic and realistic data. Our\nexperiments show that BTCell achieves near-perfect performance on several\nchallenging structure-sensitive synthetic tasks like ListOps and logical\ninference while maintaining comparable performance in realistic data against\nother RvNN-based models. Additionally, we identify a previously unknown failure\ncase for neural models in generalization to unseen number of arguments in\nListOps. The code is available at:\nhttps://github.com/JRC1995/BeamTreeRecursiveCells.\n","authors":["Jishnu Ray Chowdhury","Cornelia Caragea"],"pdf_url":"https://arxiv.org/pdf/2305.19999v3.pdf","comment":"Accepted in ICML 2023"},{"id":"http://arxiv.org/abs/2306.11444v1","updated":"2023-06-20T10:45:56Z","published":"2023-06-20T10:45:56Z","title":"Blackbird language matrices (BLM), a new task for rule-like\n  generalization in neural networks: Motivations and Formal Specifications","summary":"  We motivate and formally define a new task for fine-tuning rule-like\ngeneralization in large language models. It is conjectured that the\nshortcomings of current LLMs are due to a lack of ability to generalize. It has\nbeen argued that, instead, humans are better at generalization because they\nhave a tendency at extracting rules from complex data. We try to recreate this\ntendency to rule-based generalization. When exposed to tests of analytic\nintelligence, for example, the visual RAVEN IQ test, human problem-solvers\nidentify the relevant objects in the picture and their relevant attributes and\nreason based on rules applied to these objects and attributes. Based on the\ninduced rules, they are able to provide a solution to the test. We propose a\ntask that translates this IQ task into language. In this paper, we provide the\nformal specification for the task and the generative process of its datasets.\n","authors":["Paola Merlo"],"pdf_url":"https://arxiv.org/pdf/2306.11444v1.pdf","comment":"7pages, 6 figures. arXiv admin note: text overlap with\n  arXiv:2205.10866"},{"id":"http://arxiv.org/abs/2305.17680v3","updated":"2023-06-20T10:25:00Z","published":"2023-05-28T10:05:13Z","title":"Evaluating GPT-3 Generated Explanations for Hateful Content Moderation","summary":"  Recent research has focused on using large language models (LLMs) to generate\nexplanations for hate speech through fine-tuning or prompting. Despite the\ngrowing interest in this area, these generated explanations' effectiveness and\npotential limitations remain poorly understood. A key concern is that these\nexplanations, generated by LLMs, may lead to erroneous judgments about the\nnature of flagged content by both users and content moderators. For instance,\nan LLM-generated explanation might inaccurately convince a content moderator\nthat a benign piece of content is hateful. In light of this, we propose an\nanalytical framework for examining hate speech explanations and conducted an\nextensive survey on evaluating such explanations. Specifically, we prompted\nGPT-3 to generate explanations for both hateful and non-hateful content, and a\nsurvey was conducted with 2,400 unique respondents to evaluate the generated\nexplanations. Our findings reveal that (1) human evaluators rated the\nGPT-generated explanations as high quality in terms of linguistic fluency,\ninformativeness, persuasiveness, and logical soundness, (2) the persuasive\nnature of these explanations, however, varied depending on the prompting\nstrategy employed, and (3) this persuasiveness may result in incorrect\njudgments about the hatefulness of the content. Our study underscores the need\nfor caution in applying LLM-generated explanations for content moderation. Code\nand results are available at https://github.com/Social-AI-Studio/GPT3-HateEval.\n","authors":["Han Wang","Ming Shan Hee","Md Rabiul Awal","Kenny Tsu Wei Choo","Roy Ka-Wei Lee"],"pdf_url":"https://arxiv.org/pdf/2305.17680v3.pdf","comment":"9 pages, 2 figures, Accepted by International Joint Conference on\n  Artificial Intelligence(IJCAI)"},{"id":"http://arxiv.org/abs/2306.11432v1","updated":"2023-06-20T10:22:24Z","published":"2023-06-20T10:22:24Z","title":"Towards Theory-based Moral AI: Moral AI with Aggregating Models Based on\n  Normative Ethical Theory","summary":"  Moral AI has been studied in the fields of philosophy and artificial\nintelligence. Although most existing studies are only theoretical, recent\ndevelopments in AI have made it increasingly necessary to implement AI with\nmorality. On the other hand, humans are under the moral uncertainty of not\nknowing what is morally right. In this paper, we implement the Maximizing\nExpected Choiceworthiness (MEC) algorithm, which aggregates outputs of models\nbased on three normative theories of normative ethics to generate the most\nappropriate output. MEC is a method for making appropriate moral judgments\nunder moral uncertainty. Our experimental results suggest that the output of\nMEC correlates to some extent with commonsense morality and that MEC can\nproduce equally or more appropriate output than existing methods.\n","authors":["Masashi Takeshita","Rzepka Rafal","Kenji Araki"],"pdf_url":"https://arxiv.org/pdf/2306.11432v1.pdf","comment":"Accepted IJCAI 2023 Workshop of Ethics and Trust in Human-AI\n  Collaboration: Socio-Technical Approaches (EthAIcs 2023)"},{"id":"http://arxiv.org/abs/2306.11426v1","updated":"2023-06-20T10:15:01Z","published":"2023-06-20T10:15:01Z","title":"Exploring the Performance and Efficiency of Transformer Models for NLP\n  on Mobile Devices","summary":"  Deep learning (DL) is characterised by its dynamic nature, with new deep\nneural network (DNN) architectures and approaches emerging every few years,\ndriving the field's advancement. At the same time, the ever-increasing use of\nmobile devices (MDs) has resulted in a surge of DNN-based mobile applications.\nAlthough traditional architectures, like CNNs and RNNs, have been successfully\nintegrated into MDs, this is not the case for Transformers, a relatively new\nmodel family that has achieved new levels of accuracy across AI tasks, but\nposes significant computational challenges. In this work, we aim to make steps\ntowards bridging this gap by examining the current state of Transformers'\non-device execution. To this end, we construct a benchmark of representative\nmodels and thoroughly evaluate their performance across MDs with different\ncomputational capabilities. Our experimental results show that Transformers are\nnot accelerator-friendly and indicate the need for software and hardware\noptimisations to achieve efficient deployment.\n","authors":["Ioannis Panopoulos","Sokratis Nikolaidis","Stylianos I. Venieris","Iakovos S. Venieris"],"pdf_url":"https://arxiv.org/pdf/2306.11426v1.pdf","comment":"Accepted at the 3rd IEEE International Workshop on Distributed\n  Intelligent Systems (DistInSys), 2023"},{"id":"http://arxiv.org/abs/2306.11420v1","updated":"2023-06-20T10:03:57Z","published":"2023-06-20T10:03:57Z","title":"On Evaluating Multilingual Compositional Generalization with Translated\n  Datasets","summary":"  Compositional generalization allows efficient learning and human-like\ninductive biases. Since most research investigating compositional\ngeneralization in NLP is done on English, important questions remain\nunderexplored. Do the necessary compositional generalization abilities differ\nacross languages? Can models compositionally generalize cross-lingually? As a\nfirst step to answering these questions, recent work used neural machine\ntranslation to translate datasets for evaluating compositional generalization\nin semantic parsing. However, we show that this entails critical semantic\ndistortion. To address this limitation, we craft a faithful rule-based\ntranslation of the MCWQ dataset from English to Chinese and Japanese. Even with\nthe resulting robust benchmark, which we call MCWQ-R, we show that the\ndistribution of compositions still suffers due to linguistic divergences, and\nthat multilingual models still struggle with cross-lingual compositional\ngeneralization. Our dataset and methodology will be useful resources for the\nstudy of cross-lingual compositional generalization in other tasks.\n","authors":["Zi Wang","Daniel Hershcovich"],"pdf_url":"https://arxiv.org/pdf/2306.11420v1.pdf","comment":"ACL 2023 long paper"},{"id":"http://arxiv.org/abs/2306.11400v1","updated":"2023-06-20T09:15:52Z","published":"2023-06-20T09:15:52Z","title":"MuDPT: Multi-modal Deep-symphysis Prompt Tuning for Large Pre-trained\n  Vision-Language Models","summary":"  Prompt tuning, like CoOp, has recently shown promising vision recognizing and\ntransfer learning ability on various downstream tasks with the emergence of\nlarge pre-trained vision-language models like CLIP. However, we identify that\nexisting uni-modal prompt tuning approaches may result in sub-optimal\nperformance since this uni-modal design breaks the original alignment of\ntextual and visual representations in the pre-trained model. Inspired by the\nnature of pre-trained vision-language models, we aim to achieve completeness in\nprompt tuning and propose a novel approach called Multi-modal Deep-symphysis\nPrompt Tuning, dubbed as MuDPT, which extends independent multi-modal prompt\ntuning by additionally learning a model-agnostic transformative network to\nallow deep hierarchical bi-directional prompt fusion. We evaluate the\neffectiveness of MuDPT on few-shot vision recognition and out-of-domain\ngeneralization tasks. Compared with the state-of-the-art methods, MuDPT\nachieves better recognition and generalization ability with an apparent margin\nthanks to synergistic alignment of textual and visual representations. Our code\nis available at: https://github.com/Mechrev0/MuDPT.\n","authors":["Yongzhu Miao","Shasha Li","Jintao Tang","Ting Wang"],"pdf_url":"https://arxiv.org/pdf/2306.11400v1.pdf","comment":"The paper has been accepted by ICME 2023"},{"id":"http://arxiv.org/abs/2306.11386v1","updated":"2023-06-20T08:52:05Z","published":"2023-06-20T08:52:05Z","title":"Did the Models Understand Documents? Benchmarking Models for Language\n  Understanding in Document-Level Relation Extraction","summary":"  Document-level relation extraction (DocRE) attracts more research interest\nrecently. While models achieve consistent performance gains in DocRE, their\nunderlying decision rules are still understudied: Do they make the right\npredictions according to rationales? In this paper, we take the first step\ntoward answering this question and then introduce a new perspective on\ncomprehensively evaluating a model. Specifically, we first conduct annotations\nto provide the rationales considered by humans in DocRE. Then, we conduct\ninvestigations and reveal the fact that: In contrast to humans, the\nrepresentative state-of-the-art (SOTA) models in DocRE exhibit different\ndecision rules. Through our proposed RE-specific attacks, we next demonstrate\nthat the significant discrepancy in decision rules between models and humans\nseverely damages the robustness of models and renders them inapplicable to\nreal-world RE scenarios. After that, we introduce mean average precision (MAP)\nto evaluate the understanding and reasoning capabilities of models. According\nto the extensive experimental results, we finally appeal to future work to\nconsider evaluating both performance and the understanding ability of models\nfor the development of their applications. We make our annotations and code\npublicly available.\n","authors":["Haotian Chen","Bingsheng Chen","Xiangdong Zhou"],"pdf_url":"https://arxiv.org/pdf/2306.11386v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05698v3","updated":"2023-06-20T08:37:42Z","published":"2023-02-11T14:02:08Z","title":"Compositional Exemplars for In-context Learning","summary":"  Large pretrained language models (LMs) have shown impressive In-Context\nLearning (ICL) ability, where the model learns to do an unseen task via a\nprompt consisting of input-output examples as the demonstration, without any\nparameter updates. The performance of ICL is highly dominated by the quality of\nthe selected in-context examples. However, previous selection methods are\nmostly based on simple heuristics, leading to sub-optimal performance. In this\nwork, we formulate in-context example selection as a subset selection problem.\nWe propose CEIL (Compositional Exemplars for In-context Learning), which is\ninstantiated by Determinantal Point Processes (DPPs) to model the interaction\nbetween the given input and in-context examples, and optimized through a\ncarefully-designed contrastive learning objective to obtain preference from\nLMs. We validate CEIL on 12 classification and generation datasets from 7\ndistinct NLP tasks, including sentiment analysis, paraphrase detection, natural\nlanguage inference, commonsense reasoning, open-domain question answering, code\ngeneration, and semantic parsing. Extensive experiments demonstrate not only\nthe state-of-the-art performance but also the transferability and\ncompositionality of CEIL, shedding new light on effective and efficient\nin-context learning. Our code is released at\nhttps://github.com/HKUNLP/icl-ceil.\n","authors":["Jiacheng Ye","Zhiyong Wu","Jiangtao Feng","Tao Yu","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2302.05698v3.pdf","comment":"Accepted in ICML 2023"},{"id":"http://arxiv.org/abs/2306.11372v1","updated":"2023-06-20T08:27:47Z","published":"2023-06-20T08:27:47Z","title":"Democratizing LLMs for Low-Resource Languages by Leveraging their\n  English Dominant Abilities with Linguistically-Diverse Prompts","summary":"  Large language models (LLMs) are known to effectively perform tasks by simply\nobserving few exemplars. However, in low-resource languages, obtaining such\nhand-picked exemplars can still be challenging, where unsupervised techniques\nmay be necessary. Moreover, competent generative capabilities of LLMs are\nobserved only in high-resource languages, while their performances among\nunder-represented languages fall behind due to pre-training data imbalance. To\nelicit LLMs' ability onto low-resource languages without any supervised data,\nwe propose to assemble synthetic exemplars from a diverse set of high-resource\nlanguages to prompt the LLMs to translate from any language into English. These\nprompts are then used to create intra-lingual exemplars to perform tasks in the\ntarget languages. Our unsupervised prompting method performs on par with\nsupervised few-shot learning in LLMs of different sizes for translations\nbetween English and 13 Indic and 21 African low-resource languages. We also\nshow that fine-tuning a 7B model on data generated from our method helps it\nperform competitively with a 175B model. In non-English translation tasks, our\nmethod even outperforms supervised prompting by up to 3 chrF++ in many\nlow-resource languages. When evaluated on zero-shot multilingual summarization,\nour method surpasses other English-pivoting baselines by up to 4 ROUGE-L and is\nalso favored by GPT-4.\n","authors":["Xuan-Phi Nguyen","Sharifah Mahani Aljunied","Shafiq Joty","Lidong Bing"],"pdf_url":"https://arxiv.org/pdf/2306.11372v1.pdf","comment":"Pre-print"},{"id":"http://arxiv.org/abs/2306.11371v1","updated":"2023-06-20T08:27:42Z","published":"2023-06-20T08:27:42Z","title":"Visually grounded few-shot word learning in low-resource settings","summary":"  We propose a visually grounded speech model that learns new words and their\nvisual depictions from just a few word-image example pairs. Given a set of test\nimages and a spoken query, we ask the model which image depicts the query word.\nPrevious work has simplified this few-shot learning problem by either using an\nartificial setting with digit word-image pairs or by using a large number of\nexamples per class. Moreover, all previous studies were performed using English\nspeech-image data. We propose an approach that can work on natural word-image\npairs but with less examples, i.e. fewer shots, and then illustrate how this\napproach can be applied for multimodal few-shot learning in a real low-resource\nlanguage, Yoruba. Our approach involves using the given word-image example\npairs to mine new unsupervised word-image training pairs from large collections\nof unlabelledspeech and images. Additionally, we use a word-to-image attention\nmechanism to determine word-image similarity. With this new model, we achieve\nbetter performance with fewer shots than previous approaches on an existing\nEnglish benchmark. Many of the model's mistakes are due to confusion between\nvisual concepts co-occurring in similar contexts. The experiments on Yoruba\nshow the benefit of transferring knowledge from a multimodal model trained on a\nlarger set of English speech-image data\n","authors":["Leanne Nortje","Dan Oneata","Herman Kamper"],"pdf_url":"https://arxiv.org/pdf/2306.11371v1.pdf","comment":"Submitted to TALSP. arXiv admin note: substantial text overlap with\n  arXiv:2305.15937"},{"id":"http://arxiv.org/abs/2306.11345v1","updated":"2023-06-20T07:27:28Z","published":"2023-06-20T07:27:28Z","title":"KiUT: Knowledge-injected U-Transformer for Radiology Report Generation","summary":"  Radiology report generation aims to automatically generate a clinically\naccurate and coherent paragraph from the X-ray image, which could relieve\nradiologists from the heavy burden of report writing. Although various image\ncaption methods have shown remarkable performance in the natural image field,\ngenerating accurate reports for medical images requires knowledge of multiple\nmodalities, including vision, language, and medical terminology. We propose a\nKnowledge-injected U-Transformer (KiUT) to learn multi-level visual\nrepresentation and adaptively distill the information with contextual and\nclinical knowledge for word prediction. In detail, a U-connection schema\nbetween the encoder and decoder is designed to model interactions between\ndifferent modalities. And a symptom graph and an injected knowledge distiller\nare developed to assist the report generation. Experimentally, we outperform\nstate-of-the-art methods on two widely used benchmark datasets: IU-Xray and\nMIMIC-CXR. Further experimental results prove the advantages of our\narchitecture and the complementary benefits of the injected knowledge.\n","authors":["Zhongzhen Huang","Xiaofan Zhang","Shaoting Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.11345v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11341v1","updated":"2023-06-20T07:19:36Z","published":"2023-06-20T07:19:36Z","title":"MSVD-Indonesian: A Benchmark for Multimodal Video-Text Tasks in\n  Indonesian","summary":"  Multimodal learning on video and text data has been receiving growing\nattention from many researchers in various research tasks, including\ntext-to-video retrieval, video-to-text retrieval, and video captioning.\nAlthough many algorithms have been proposed for those challenging tasks, most\nof them are developed on English language datasets. Despite Indonesian being\none of the most spoken languages in the world, the research progress on the\nmultimodal video-text with Indonesian sentences is still under-explored, likely\ndue to the absence of the public benchmark dataset. To address this issue, we\nconstruct the first public Indonesian video-text dataset by translating English\nsentences from the MSVD dataset to Indonesian sentences. Using our dataset, we\nthen train neural network models which were developed for the English\nvideo-text dataset on three tasks, i.e., text-to-video retrieval, video-to-text\nretrieval, and video captioning. The recent neural network-based approaches to\nvideo-text tasks often utilized a feature extractor that is primarily\npretrained on an English vision-language dataset. Since the availability of the\npretraining resources with Indonesian sentences is relatively limited, the\napplicability of those approaches to our dataset is still questionable. To\novercome the lack of pretraining resources, we apply cross-lingual transfer\nlearning by utilizing the feature extractors pretrained on the English dataset,\nand we then fine-tune the models on our Indonesian dataset. Our experimental\nresults show that this approach can help to improve the performance for the\nthree tasks on all metrics. Finally, we discuss potential future works using\nour dataset, inspiring further research in the Indonesian multimodal video-text\ntasks. We believe that our dataset and our experimental results could provide\nvaluable contributions to the community. Our dataset is available on GitHub.\n","authors":["Willy Fitra Hendria"],"pdf_url":"https://arxiv.org/pdf/2306.11341v1.pdf","comment":"13 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2306.11309v1","updated":"2023-06-20T06:08:09Z","published":"2023-06-20T06:08:09Z","title":"Multi-pass Training and Cross-information Fusion for Low-resource\n  End-to-end Accented Speech Recognition","summary":"  Low-resource accented speech recognition is one of the important challenges\nfaced by current ASR technology in practical applications. In this study, we\npropose a Conformer-based architecture, called Aformer, to leverage both the\nacoustic information from large non-accented and limited accented training\ndata. Specifically, a general encoder and an accent encoder are designed in the\nAformer to extract complementary acoustic information. Moreover, we propose to\ntrain the Aformer in a multi-pass manner, and investigate three\ncross-information fusion methods to effectively combine the information from\nboth general and accent encoders. All experiments are conducted on both the\naccented English and Mandarin ASR tasks. Results show that our proposed methods\noutperform the strong Conformer baseline by relative 10.2% to 24.5%\nword/character error rate reduction on six in-domain and out-of-domain accented\ntest sets.\n","authors":["Xuefei Wang","Yanhua Long","Yijie Li","Haoran Wei"],"pdf_url":"https://arxiv.org/pdf/2306.11309v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11300v1","updated":"2023-06-20T05:30:59Z","published":"2023-06-20T05:30:59Z","title":"RS5M: A Large Scale Vision-Language Dataset for Remote Sensing\n  Vision-Language Foundation Model","summary":"  Pre-trained Vision-Language Foundation Models utilizing extensive image-text\npaired data have demonstrated unprecedented image-text association\ncapabilities, achieving remarkable results across various downstream tasks. A\ncritical challenge is how to make use of existing large-scale pre-trained VLMs,\nwhich are trained on common objects, to perform the domain-specific transfer\nfor accomplishing domain-related downstream tasks. In this paper, we propose a\nnew framework that includes the Domain Foundation Model (DFM), bridging the gap\nbetween the General Foundation Model (GFM) and domain-specific downstream\ntasks. Moreover, we present an image-text paired dataset in the field of remote\nsensing (RS), RS5M, which has 5 million RS images with English descriptions.\nThe dataset is obtained from filtering publicly available image-text paired\ndatasets and captioning label-only RS datasets with pre-trained VLM. These\nconstitute the first large-scale RS image-text paired dataset. Additionally, we\ntried several Parameter-Efficient Fine-Tuning methods on RS5M to implement the\nDFM. Experimental results show that our proposed dataset are highly effective\nfor various tasks, improving upon the baseline by $8 \\% \\sim 16 \\%$ in\nzero-shot classification tasks, and obtaining good results in both\nVision-Language Retrieval and Semantic Localization tasks. Finally, we show\nsuccessful results of training the RS Stable Diffusion model using the RS5M,\nuncovering more use cases of the dataset.\n","authors":["Zilun Zhang","Tiancheng Zhao","Yulong Guo","Jianwei Yin"],"pdf_url":"https://arxiv.org/pdf/2306.11300v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11296v1","updated":"2023-06-20T05:20:29Z","published":"2023-06-20T05:20:29Z","title":"ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF\n  Synthesis","summary":"  We use prompt engineering to guide ChatGPT in the automation of text mining\nof metal-organic frameworks (MOFs) synthesis conditions from diverse formats\nand styles of the scientific literature. This effectively mitigates ChatGPT's\ntendency to hallucinate information -- an issue that previously made the use of\nLarge Language Models (LLMs) in scientific fields challenging. Our approach\ninvolves the development of a workflow implementing three different processes\nfor text mining, programmed by ChatGPT itself. All of them enable parsing,\nsearching, filtering, classification, summarization, and data unification with\ndifferent tradeoffs between labor, speed, and accuracy. We deploy this system\nto extract 26,257 distinct synthesis parameters pertaining to approximately 800\nMOFs sourced from peer-reviewed research articles. This process incorporates\nour ChemPrompt Engineering strategy to instruct ChatGPT in text mining,\nresulting in impressive precision, recall, and F1 scores of 90-99%.\nFurthermore, with the dataset built by text mining, we constructed a\nmachine-learning model with over 86% accuracy in predicting MOF experimental\ncrystallization outcomes and preliminarily identifying important factors in MOF\ncrystallization. We also developed a reliable data-grounded MOF chatbot to\nanswer questions on chemical reactions and synthesis procedures. Given that the\nprocess of using ChatGPT reliably mines and tabulates diverse MOF synthesis\ninformation in a unified format, while using only narrative language requiring\nno coding expertise, we anticipate that our ChatGPT Chemistry Assistant will be\nvery useful across various other chemistry sub-disciplines.\n","authors":["Zhiling Zheng","Oufan Zhang","Christian Borgs","Jennifer T. Chayes","Omar M. Yaghi"],"pdf_url":"https://arxiv.org/pdf/2306.11296v1.pdf","comment":"97 pages (17-page manuscript, 80 pages of supporting information)"},{"id":"http://arxiv.org/abs/2306.09896v2","updated":"2023-06-20T04:38:43Z","published":"2023-06-16T15:13:17Z","title":"Demystifying GPT Self-Repair for Code Generation","summary":"  Large Language Models (LLMs) have shown remarkable aptitude in code\ngeneration but still struggle on challenging programming tasks. Self-repair --\nin which the model debugs and fixes mistakes in its own code -- has recently\nbecome a popular way to boost performance in these settings. However, only very\nlimited studies on how and when self-repair works effectively exist in the\nliterature, and one might wonder to what extent a model is really capable of\nproviding accurate feedback on why the code is wrong when that code was\ngenerated by the same model. In this paper, we analyze GPT-3.5 and GPT-4's\nability to perform self-repair on APPS, a challenging dataset consisting of\ndiverse coding challenges. To do so, we first establish a new evaluation\nstrategy dubbed pass@t that measures the pass rate of the tasks against the\ntotal number of tokens sampled from the model, enabling a fair comparison to\npurely sampling-based approaches. With this evaluation strategy, we find that\nthe effectiveness of self-repair is only seen in GPT-4. We also observe that\nself-repair is bottlenecked by the feedback stage; using GPT-4 to give feedback\non the programs generated by GPT-3.5 and using expert human programmers to give\nfeedback on the programs generated by GPT-4, we unlock significant performance\ngains.\n","authors":["Theo X. Olausson","Jeevana Priya Inala","Chenglong Wang","Jianfeng Gao","Armando Solar-Lezama"],"pdf_url":"https://arxiv.org/pdf/2306.09896v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11270v1","updated":"2023-06-20T03:48:51Z","published":"2023-06-20T03:48:51Z","title":"Evaluating the Zero-shot Robustness of Instruction-tuned Language Models","summary":"  Instruction fine-tuning has recently emerged as a promising approach for\nimproving the zero-shot capabilities of Large Language Models (LLMs) on new\ntasks. This technique has shown particular strength in improving the\nperformance of modestly sized LLMs, sometimes inducing performance competitive\nwith much larger model variants. In this paper we ask two questions: (1) How\nsensitive are instruction-tuned models to the particular phrasings of\ninstructions, and, (2) How can we make them more robust to such natural\nlanguage variation? To answer the former, we collect a set of 319 instructions\nmanually written by NLP practitioners for over 80 unique tasks included in\nwidely used benchmarks, and we evaluate the variance and average performance of\nthese instructions as compared to instruction phrasings observed during\ninstruction fine-tuning. We find that using novel (unobserved) but appropriate\ninstruction phrasings consistently degrades model performance, sometimes\nsubstantially so. Further, such natural instructions yield a wide variance in\ndownstream performance, despite their semantic equivalence. Put another way,\ninstruction-tuned models are not especially robust to instruction re-phrasings.\nWe propose a simple method to mitigate this issue by introducing ``soft\nprompt'' embedding parameters and optimizing these to maximize the similarity\nbetween representations of semantically equivalent instructions. We show that\nthis method consistently improves the robustness of instruction-tuned models.\n","authors":["Jiuding Sun","Chantal Shaib","Byron C. Wallace"],"pdf_url":"https://arxiv.org/pdf/2306.11270v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11260v1","updated":"2023-06-20T03:25:51Z","published":"2023-06-20T03:25:51Z","title":"A novel Counterfactual method for aspect-based sentiment analysis","summary":"  Aspect-based-sentiment-analysis (ABSA) is a fine-grained sentiment evaluation\ntask, which analyze the emotional polarity of the evaluation aspects.\nGenerally, the emotional polarity of an aspect exists in the corresponding\nopinion expression, whose diversity has great impacts on model's performance.\nTo mitigate this problem, we propose a novel and simple counterfactual data\naugmentation method that reverses the opinion expression of the aspects.\nSpecially, the integrated gradients are calculated to identify and mask the\nopinion expression. Then, a prompt with the reverse expression polarity is\ncombined to the original text, and a pre-trained language model (PLM), T5, is\nfinally was employed to predict the masks. The experimental results show the\nproposed counterfactual data augmentation method perform better than current\nmethods on three open-source datasets, i.e. Laptop, Restaurant and MAMS.\n","authors":["Dongming Wu","Lulu Wen","Chao Chen","Zhaoshu Shi"],"pdf_url":"https://arxiv.org/pdf/2306.11260v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11256v1","updated":"2023-06-20T03:21:10Z","published":"2023-06-20T03:21:10Z","title":"GUMSum: Multi-Genre Data and Evaluation for English Abstractive\n  Summarization","summary":"  Automatic summarization with pre-trained language models has led to\nimpressively fluent results, but is prone to 'hallucinations', low performance\non non-news genres, and outputs which are not exactly summaries. Targeting ACL\n2023's 'Reality Check' theme, we present GUMSum, a small but carefully crafted\ndataset of English summaries in 12 written and spoken genres for evaluation of\nabstractive summarization. Summaries are highly constrained, focusing on\nsubstitutive potential, factuality, and faithfulness. We present guidelines and\nevaluate human agreement as well as subjective judgments on recent system\noutputs, comparing general-domain untuned approaches, a fine-tuned one, and a\nprompt-based approach, to human performance. Results show that while GPT3\nachieves impressive scores, it still underperforms humans, with varying quality\nacross genres. Human judgments reveal different types of errors in supervised,\nprompted, and human-generated summaries, shedding light on the challenges of\nproducing a good summary.\n","authors":["Yang Janet Liu","Amir Zeldes"],"pdf_url":"https://arxiv.org/pdf/2306.11256v1.pdf","comment":"Accepted to the Findings of ACL 2023; camera-ready version"},{"id":"http://arxiv.org/abs/2304.05934v2","updated":"2023-06-20T03:20:18Z","published":"2023-04-12T15:52:53Z","title":"ASL Citizen: A Community-Sourced Dataset for Advancing Isolated Sign\n  Language Recognition","summary":"  Sign languages are used as a primary language by approximately 70 million\nD/deaf people world-wide. However, most communication technologies operate in\nspoken and written languages, creating inequities in access. To help tackle\nthis problem, we release ASL Citizen, the first crowdsourced Isolated Sign\nLanguage Recognition (ISLR) dataset, collected with consent and containing\n83,399 videos for 2,731 distinct signs filmed by 52 signers in a variety of\nenvironments. We propose that this dataset be used for sign language dictionary\nretrieval for American Sign Language (ASL), where a user demonstrates a sign to\ntheir webcam to retrieve matching signs from a dictionary. We show that\ntraining supervised machine learning classifiers with our dataset advances the\nstate-of-the-art on metrics relevant for dictionary retrieval, achieving 63%\naccuracy and a recall-at-10 of 91%, evaluated entirely on videos of users who\nare not present in the training or validation sets. An accessible PDF of this\narticle is available at the following link:\nhttps://aashakadesai.github.io/research/ASLCitizen_arxiv_updated.pdf\n","authors":["Aashaka Desai","Lauren Berger","Fyodor O. Minakov","Vanessa Milan","Chinmay Singh","Kriston Pumphrey","Richard E. Ladner","Hal Daumé III","Alex X. Lu","Naomi Caselli","Danielle Bragg"],"pdf_url":"https://arxiv.org/pdf/2304.05934v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11252v1","updated":"2023-06-20T03:09:32Z","published":"2023-06-20T03:09:32Z","title":"HK-LegiCoST: Leveraging Non-Verbatim Transcripts for Speech Translation","summary":"  We introduce HK-LegiCoST, a new three-way parallel corpus of\nCantonese-English translations, containing 600+ hours of Cantonese audio, its\nstandard traditional Chinese transcript, and English translation, segmented and\naligned at the sentence level. We describe the notable challenges in corpus\npreparation: segmentation, alignment of long audio recordings, and\nsentence-level alignment with non-verbatim transcripts. Such transcripts make\nthe corpus suitable for speech translation research when there are significant\ndifferences between the spoken and written forms of the source language. Due to\nits large size, we are able to demonstrate competitive speech translation\nbaselines on HK-LegiCoST and extend them to promising cross-corpus results on\nthe FLEURS Cantonese subset. These results deliver insights into speech\nrecognition and translation research in languages for which non-verbatim or\n``noisy'' transcription is common due to various factors, including vernacular\nand dialectal speech.\n","authors":["Cihan Xiao","Henry Li Xinyuan","Jinyi Yang","Dongji Gao","Matthew Wiesner","Kevin Duh","Sanjeev Khudanpur"],"pdf_url":"https://arxiv.org/pdf/2306.11252v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.15081v5","updated":"2023-06-20T01:55:28Z","published":"2022-03-28T20:41:17Z","title":"Word Discovery in Visually Grounded, Self-Supervised Speech Models","summary":"  We present a method for visually-grounded spoken term discovery. After\ntraining either a HuBERT or wav2vec2.0 model to associate spoken captions with\nnatural images, we show that powerful word segmentation and clustering\ncapability emerges within the model's self-attention heads. Our experiments\nreveal that this ability is not present to nearly the same extent in the base\nHuBERT and wav2vec2.0 models, suggesting that the visual grounding task is a\ncrucial component of the word discovery capability we observe. We also evaluate\nour method on the Buckeye word segmentation and ZeroSpeech spoken term\ndiscovery tasks, where we perform on par with or better than currently\npublished methods on several metrics. Code and model weights are available at\nhttps://github.com/jasonppy/word-discovery.\n","authors":["Puyuan Peng","David Harwath"],"pdf_url":"https://arxiv.org/pdf/2203.15081v5.pdf","comment":"Interspeech 2022 Oral. Update Table 5"},{"id":"http://arxiv.org/abs/2306.11232v1","updated":"2023-06-20T01:45:42Z","published":"2023-06-20T01:45:42Z","title":"Eight challenges in developing theory of intelligence","summary":"  A good theory of mathematical beauty is more practical than any current\nobservation, as new predictions of physical reality can be verified\nself-consistently. This belief applies to the current status of understanding\ndeep neural networks including large language models and even the biological\nintelligence. Toy models provide a metaphor of physical reality, allowing\nmathematically formulating that reality (i.e., the so-called theory), which can\nbe updated as more conjectures are justified or refuted. One does not need to\npack all details into a model, but rather, more abstract models are\nconstructed, as complex systems like brains or deep networks have many sloppy\ndimensions but much less stiff dimensions that strongly impact macroscopic\nobservables. This kind of bottom-up mechanistic modeling is still promising in\nthe modern era of understanding the natural or artificial intelligence. Here,\nwe shed light on eight challenges in developing theory of intelligence\nfollowing this theoretical paradigm.\n","authors":["Haiping Huang"],"pdf_url":"https://arxiv.org/pdf/2306.11232v1.pdf","comment":"19 pages, 103 references, no figures"},{"id":"http://arxiv.org/abs/2306.11222v1","updated":"2023-06-20T01:16:11Z","published":"2023-06-20T01:16:11Z","title":"LoSparse: Structured Compression of Large Language Models based on\n  Low-Rank and Sparse Approximation","summary":"  Transformer models have achieved remarkable results in various natural\nlanguage tasks, but they are often prohibitively large, requiring massive\nmemories and computational resources. To reduce the size and complexity of\nthese models, we propose LoSparse (Low-Rank and Sparse approximation), a novel\nmodel compression technique that approximates a weight matrix by the sum of a\nlow-rank matrix and a sparse matrix. Our method combines the advantages of both\nlow-rank approximations and pruning, while avoiding their limitations. Low-rank\napproximation compresses the coherent and expressive parts in neurons, while\npruning removes the incoherent and non-expressive parts in neurons. Pruning\nenhances the diversity of low-rank approximations, and low-rank approximation\nprevents pruning from losing too many expressive neurons. We evaluate our\nmethod on natural language understanding, question answering, and natural\nlanguage generation tasks. We show that it significantly outperforms existing\ncompression methods.\n","authors":["Yixiao Li","Yifan Yu","Qingru Zhang","Chen Liang","Pengcheng He","Weizhu Chen","Tuo Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.11222v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11207v1","updated":"2023-06-20T00:14:47Z","published":"2023-06-20T00:14:47Z","title":"Quilt-1M: One Million Image-Text Pairs for Histopathology","summary":"  Recent accelerations in multi-modal applications have been made possible with\nthe plethora of image and text data available online. However, the scarcity of\nanalogous data in the medical field, specifically in histopathology, has halted\ncomparable progress. To enable similar representation learning for\nhistopathology, we turn to YouTube, an untapped resource of videos, offering\n$1,087$ hours of valuable educational histopathology videos from expert\nclinicians. From YouTube, we curate Quilt: a large-scale vision-language\ndataset consisting of $768,826$ image and text pairs. Quilt was automatically\ncurated using a mixture of models, including large language models, handcrafted\nalgorithms, human knowledge databases, and automatic speech recognition. In\ncomparison, the most comprehensive datasets curated for histopathology amass\nonly around $200$K samples. We combine Quilt with datasets from other sources,\nincluding Twitter, research papers, and the internet in general, to create an\neven larger dataset: Quilt-1M, with $1$M paired image-text samples, marking it\nas the largest vision-language histopathology dataset to date. We demonstrate\nthe value of Quilt-1M by fine-tuning a pre-trained CLIP model. Our model\noutperforms state-of-the-art models on both zero-shot and linear probing tasks\nfor classifying new histopathology images across $13$ diverse patch-level\ndatasets of $8$ different sub-pathologies and cross-modal retrieval tasks.\n","authors":["Wisdom Oluchi Ikezogwo","Mehmet Saygin Seyfioglu","Fatemeh Ghezloo","Dylan Stefan Chan Geva","Fatwir Sheikh Mohammed","Pavan Kumar Anand","Ranjay Krishna","Linda Shapiro"],"pdf_url":"https://arxiv.org/pdf/2306.11207v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11943v1","updated":"2023-06-20T23:42:14Z","published":"2023-06-20T23:42:14Z","title":"Towards Understanding What Code Language Models Learned","summary":"  Pre-trained language models are effective in a variety of natural language\ntasks, but it has been argued their capabilities fall short of fully learning\nmeaning or understanding language. To understand the extent to which language\nmodels can learn some form of meaning, we investigate their ability to capture\nsemantics of code beyond superficial frequency and co-occurrence. In contrast\nto previous research on probing models for linguistic features, we study\npre-trained models in a setting that allows for objective and straightforward\nevaluation of a model's ability to learn semantics. In this paper, we examine\nwhether such models capture the semantics of code, which is precisely and\nformally defined. Through experiments involving the manipulation of code\nfragments, we show that code pre-trained models of code learn a robust\nrepresentation of the computational semantics of code that goes beyond\nsuperficial features of form alone\n","authors":["Toufique Ahmed","Dian Yu","Chengxuan Huang","Cathy Wang","Prem Devanbu","Kenji Sagae"],"pdf_url":"https://arxiv.org/pdf/2306.11943v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11932v1","updated":"2023-06-20T22:52:51Z","published":"2023-06-20T22:52:51Z","title":"Opportunities and Risks of LLMs for Scalable Deliberation with Polis","summary":"  Polis is a platform that leverages machine intelligence to scale up\ndeliberative processes. In this paper, we explore the opportunities and risks\nassociated with applying Large Language Models (LLMs) towards challenges with\nfacilitating, moderating and summarizing the results of Polis engagements. In\nparticular, we demonstrate with pilot experiments using Anthropic's Claude that\nLLMs can indeed augment human intelligence to help more efficiently run Polis\nconversations. In particular, we find that summarization capabilities enable\ncategorically new methods with immense promise to empower the public in\ncollective meaning-making exercises. And notably, LLM context limitations have\na significant impact on insight and quality of these results.\n  However, these opportunities come with risks. We discuss some of these risks,\nas well as principles and techniques for characterizing and mitigating them,\nand the implications for other deliberative or political systems that may\nemploy LLMs. Finally, we conclude with several open future research directions\nfor augmenting tools like Polis with LLMs.\n","authors":["Christopher T. Small","Ivan Vendrov","Esin Durmus","Hadjar Homaei","Elizabeth Barry","Julien Cornebise","Ted Suzman","Deep Ganguli","Colin Megill"],"pdf_url":"https://arxiv.org/pdf/2306.11932v1.pdf","comment":"31 pages (main body; 45 with Bibliography and Appendix), 6 figures"},{"id":"http://arxiv.org/abs/2211.15421v2","updated":"2023-06-20T21:34:44Z","published":"2022-11-15T03:17:07Z","title":"VRDU: A Benchmark for Visually-rich Document Understanding","summary":"  Understanding visually-rich business documents to extract structured data and\nautomate business workflows has been receiving attention both in academia and\nindustry. Although recent multi-modal language models have achieved impressive\nresults, we find that existing benchmarks do not reflect the complexity of real\ndocuments seen in industry. In this work, we identify the desiderata for a more\ncomprehensive benchmark and propose one we call Visually Rich Document\nUnderstanding (VRDU). VRDU contains two datasets that represent several\nchallenges: rich schema including diverse data types as well as hierarchical\nentities, complex templates including tables and multi-column layouts, and\ndiversity of different layouts (templates) within a single document type. We\ndesign few-shot and conventional experiment settings along with a carefully\ndesigned matching algorithm to evaluate extraction results. We report the\nperformance of strong baselines and offer three observations: (1) generalizing\nto new document templates is still very challenging, (2) few-shot performance\nhas a lot of headroom, and (3) models struggle with hierarchical fields such as\nline-items in an invoice. We plan to open source the benchmark and the\nevaluation toolkit. We hope this helps the community make progress on these\nchallenging tasks in extracting structured data from visually rich documents.\n","authors":["Zilong Wang","Yichao Zhou","Wei Wei","Chen-Yu Lee","Sandeep Tata"],"pdf_url":"https://arxiv.org/pdf/2211.15421v2.pdf","comment":"KDD 2023"},{"id":"http://arxiv.org/abs/2305.09770v3","updated":"2023-06-20T21:26:54Z","published":"2023-05-16T19:48:49Z","title":"ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to\n  Support Human-AI Scientific Writing","summary":"  Despite a surge collection of XAI methods, users still struggle to obtain\nrequired AI explanations. Previous research suggests chatbots as dynamic\nsolutions, but the effective design of conversational XAI agents for practical\nhuman needs remains under-explored. This paper focuses on Conversational XAI\nfor AI-assisted scientific writing tasks. Drawing from human linguistic\ntheories and formative studies, we identify four design rationales:\n\"multifaceted\", \"controllability\", \"mix-initiative\", \"context-aware\ndrill-down\". We incorporate them into an interactive prototype, ConvXAI, which\nfacilitates heterogeneous AI explanations for scientific writing through\ndialogue. In two studies with 21 users, ConvXAI outperforms a GUI-based\nbaseline on improving human-perceived understanding and writing improvement.\nThe paper further discusses the practical human usage patterns in interacting\nwith ConvXAI for scientific co-writing.\n","authors":["Hua Shen","Chieh-Yang Huang","Tongshuang Wu","Ting-Hao 'Kenneth' Huang"],"pdf_url":"https://arxiv.org/pdf/2305.09770v3.pdf","comment":"To appear in CSCW 2023 Demo. ConvXAI system code:\n  https://github.com/huashen218/convxai.git"},{"id":"http://arxiv.org/abs/2306.11900v1","updated":"2023-06-20T21:22:45Z","published":"2023-06-20T21:22:45Z","title":"Evaluation of Chinese-English Machine Translation of Emotion-Loaded\n  Microblog Texts: A Human Annotated Dataset for the Quality Assessment of\n  Emotion Translation","summary":"  In this paper, we focus on how current Machine Translation (MT) tools perform\non the translation of emotion-loaded texts by evaluating outputs from Google\nTranslate according to a framework proposed in this paper. We propose this\nevaluation framework based on the Multidimensional Quality Metrics (MQM) and\nperform a detailed error analysis of the MT outputs. From our analysis, we\nobserve that about 50% of the MT outputs fail to preserve the original emotion.\nAfter further analysis of the errors, we find that emotion carrying words and\nlinguistic phenomena such as polysemous words, negation, abbreviation etc., are\ncommon causes for these translation errors.\n","authors":["Shenbin Qian","Constantin Orasan","Felix do Carmo","Qiuliang Li","Diptesh Kanojia"],"pdf_url":"https://arxiv.org/pdf/2306.11900v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11892v1","updated":"2023-06-20T21:12:16Z","published":"2023-06-20T21:12:16Z","title":"Exploring New Frontiers in Agricultural NLP: Investigating the Potential\n  of Large Language Models for Food Applications","summary":"  This paper explores new frontiers in agricultural natural language processing\nby investigating the effectiveness of using food-related text corpora for\npretraining transformer-based language models. In particular, we focus on the\ntask of semantic matching, which involves establishing mappings between food\ndescriptions and nutrition data. To accomplish this, we fine-tune a pre-trained\ntransformer-based language model, AgriBERT, on this task, utilizing an external\nsource of knowledge, such as the FoodOn ontology. To advance the field of\nagricultural NLP, we propose two new avenues of exploration: (1) utilizing\nGPT-based models as a baseline and (2) leveraging ChatGPT as an external source\nof knowledge. ChatGPT has shown to be a strong baseline in many NLP tasks, and\nwe believe it has the potential to improve our model in the task of semantic\nmatching and enhance our model's understanding of food-related concepts and\nrelationships. Additionally, we experiment with other applications, such as\ncuisine prediction based on food ingredients, and expand the scope of our\nresearch to include other NLP tasks beyond semantic matching. Overall, this\npaper provides promising avenues for future research in this field, with\npotential implications for improving the performance of agricultural NLP\napplications.\n","authors":["Saed Rezayi","Zhengliang Liu","Zihao Wu","Chandra Dhakal","Bao Ge","Haixing Dai","Gengchen Mai","Ninghao Liu","Chen Zhen","Tianming Liu","Sheng Li"],"pdf_url":"https://arxiv.org/pdf/2306.11892v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11879v1","updated":"2023-06-20T20:37:54Z","published":"2023-06-20T20:37:54Z","title":"Open-Domain Text Evaluation via Meta Distribution Modeling","summary":"  Recent advances in open-domain text generation models powered by large\npre-trained language models (LLMs) have achieved remarkable performance.\nHowever, evaluating and controlling these models for desired attributes remains\na challenge, as traditional reference-based metrics such as BLEU, ROUGE, and\nMETEOR are insufficient for open-ended generation tasks. Similarly, while\ntrainable discriminator-based evaluation metrics show promise, obtaining\nhigh-quality training data is a non-trivial task. In this paper, we introduce a\nnovel approach to evaluate open-domain generation - the Meta-Distribution\nMethods (MDM). Drawing on the correlation between the rising parameter counts\nand the improving performance of LLMs, MDM creates a mapping from the contrast\nof two probabilistic distributions -- one known to be superior to the other --\nto quality measures, which can be viewed as a distribution of distributions\ni.e. Meta-Distribution. We investigate MDM for open-domain text generation\nevaluation under two paradigms: 1) \\emph{Generative} MDM, which leverages the\nMeta-Distribution Methods to generate in-domain negative samples for training\ndiscriminator-based metrics; 2) \\emph{Discriminative} MDM, which directly uses\ndistribution discrepancies between two language models for evaluation. Our\nexperiments on multi-turn dialogue and factuality in abstractive summarization\ndemonstrate that MDMs correlate better with human judgment than existing\nautomatic evaluation metrics on both tasks, highlighting the strong performance\nand generalizability of such methods.\n","authors":["Sidi Lu","Asli Celikyilmaz","Tianlu Wang","Nanyun Peng"],"pdf_url":"https://arxiv.org/pdf/2306.11879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.00887v2","updated":"2023-06-20T19:47:20Z","published":"2023-06-01T16:48:20Z","title":"OpenPI-C: A Better Benchmark and Stronger Baseline for Open-Vocabulary\n  State Tracking","summary":"  Open-vocabulary state tracking is a more practical version of state tracking\nthat aims to track state changes of entities throughout a process without\nrestricting the state space and entity space. OpenPI is to date the only\ndataset annotated for open-vocabulary state tracking. However, we identify\nissues with the dataset quality and evaluation metric. For the dataset, we\ncategorize 3 types of problems on the procedure level, step level and state\nchange level respectively, and build a clean dataset OpenPI-C using multiple\nrounds of human judgment. For the evaluation metric, we propose a cluster-based\nmetric to fix the original metric's preference for repetition.\n  Model-wise, we enhance the seq2seq generation baseline by reinstating two key\nproperties for state tracking: temporal dependency and entity awareness. The\nstate of the world after an action is inherently dependent on the previous\nstate. We model this dependency through a dynamic memory bank and allow the\nmodel to attend to the memory slots during decoding. On the other hand, the\nstate of the world is naturally a union of the states of involved entities.\nSince the entities are unknown in the open-vocabulary setting, we propose a\ntwo-stage model that refines the state change prediction conditioned on\nentities predicted from the first stage. Empirical results show the\neffectiveness of our proposed model especially on the cluster-based metric. The\ncode and data are released at https://github.com/shirley-wu/openpi-c\n","authors":["Xueqing Wu","Sha Li","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2306.00887v2.pdf","comment":"ACL 2023 findings (fix typo)"},{"id":"http://arxiv.org/abs/2306.11843v1","updated":"2023-06-20T18:51:21Z","published":"2023-06-20T18:51:21Z","title":"Retrieval-Based Transformer for Table Augmentation","summary":"  Data preparation, also called data wrangling, is considered one of the most\nexpensive and time-consuming steps when performing analytics or building\nmachine learning models. Preparing data typically involves collecting and\nmerging data from complex heterogeneous, and often large-scale data sources,\nsuch as data lakes. In this paper, we introduce a novel approach toward\nautomatic data wrangling in an attempt to alleviate the effort of end-users,\ne.g. data analysts, in structuring dynamic views from data lakes in the form of\ntabular data. We aim to address table augmentation tasks, including row/column\npopulation and data imputation. Given a corpus of tables, we propose a\nretrieval augmented self-trained transformer model. Our self-learning strategy\nconsists in randomly ablating tables from the corpus and training the\nretrieval-based model to reconstruct the original values or headers given the\npartial tables as input. We adopt this strategy to first train the dense neural\nretrieval model encoding table-parts to vectors, and then the end-to-end model\ntrained to perform table augmentation tasks. We test on EntiTables, the\nstandard benchmark for table augmentation, as well as introduce a new benchmark\nto advance further research: WebTables. Our model consistently and\nsubstantially outperforms both supervised statistical methods and the current\nstate-of-the-art transformer-based models.\n","authors":["Michael Glass","Xueqing Wu","Ankita Rajaram Naik","Gaetano Rossiello","Alfio Gliozzo"],"pdf_url":"https://arxiv.org/pdf/2306.11843v1.pdf","comment":"Findings of ACL 2023"},{"id":"http://arxiv.org/abs/2306.11838v1","updated":"2023-06-20T18:46:47Z","published":"2023-06-20T18:46:47Z","title":"Efficient Machine Translation Corpus Generation","summary":"  This paper proposes an efficient and semi-automated method for\nhuman-in-the-loop post-editing for machine translation (MT) corpus generation.\nThe method is based on online training of a custom MT quality estimation metric\non-the-fly as linguists perform post-edits. The online estimator is used to\nprioritize worse hypotheses for post-editing, and auto-close best hypotheses\nwithout post-editing. This way, significant improvements can be achieved in the\nresulting quality of post-edits at a lower cost due to reduced human\ninvolvement. The trained estimator can also provide an online sanity check\nmechanism for post-edits and remove the need for additional linguists to review\nthem or work on the same hypotheses. In this paper, the effect of prioritizing\nwith the proposed method on the resulting MT corpus quality is presented versus\nscheduling hypotheses randomly. As demonstrated by experiments, the proposed\nmethod improves the lifecycle of MT models by focusing the linguist effort on\nproduction samples and hypotheses, which matter most for expanding MT corpora\nto be used for re-training them.\n","authors":["Kamer Ali Yuksel","Ahmet Gunduz","Shreyas Sharma","Hassan Sawaf"],"pdf_url":"https://arxiv.org/pdf/2306.11838v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11832v1","updated":"2023-06-20T18:43:24Z","published":"2023-06-20T18:43:24Z","title":"QuOTeS: Query-Oriented Technical Summarization","summary":"  Abstract. When writing an academic paper, researchers often spend\nconsiderable time reviewing and summarizing papers to extract relevant\ncitations and data to compose the Introduction and Related Work sections. To\naddress this problem, we propose QuOTeS, an interactive system designed to\nretrieve sentences related to a summary of the research from a collection of\npotential references and hence assist in the composition of new papers. QuOTeS\nintegrates techniques from Query-Focused Extractive Summarization and\nHigh-Recall Information Retrieval to provide Interactive Query-Focused\nSummarization of scientific documents. To measure the performance of our\nsystem, we carried out a comprehensive user study where participants uploaded\npapers related to their research and evaluated the system in terms of its\nusability and the quality of the summaries it produces. The results show that\nQuOTeS provides a positive user experience and consistently provides\nquery-focused summaries that are relevant, concise, and complete. We share the\ncode of our system and the novel Query-Focused Summarization dataset collected\nduring our experiments at https://github.com/jarobyte91/quotes.\n","authors":["Juan Ramirez-Orta","Eduardo Xamena","Ana Maguitman","Axel J. Soto","Flavia P. Zanoto","Evangelos Milios"],"pdf_url":"https://arxiv.org/pdf/2306.11832v1.pdf","comment":"Accepted at ICDAR 2023"},{"id":"http://arxiv.org/abs/2306.11825v1","updated":"2023-06-20T18:36:52Z","published":"2023-06-20T18:36:52Z","title":"On Compositionality and Improved Training of NADO","summary":"  NeurAlly-Decomposed Oracle (NADO) is a powerful approach for controllable\ngeneration with large language models. Differentiating from finetuning/prompt\ntuning, it has the potential to avoid catastrophic forgetting of the large base\nmodel and achieve guaranteed convergence to an entropy-maximized closed-form\nsolution without significantly limiting the model capacity. Despite its\nsuccess, several challenges arise when applying NADO to more complex scenarios.\nFirst, the best practice of using NADO for the composition of multiple control\nsignals is under-explored. Second, vanilla NADO suffers from gradient vanishing\nfor low-probability control signals and is highly reliant on the\nforward-consistency regularization. In this paper, we study the aforementioned\nchallenges when using NADO theoretically and empirically. We show we can\nachieve guaranteed compositional generalization of NADO with a certain\npractice, and propose a novel alternative parameterization of NADO to perfectly\nguarantee the forward-consistency. We evaluate the improved training of NADO,\ni.e. NADO++, on CommonGen. Results show that NADO++ improves the effectiveness\nof the algorithm in multiple aspects.\n","authors":["Sidi Lu","Wenbo Zhao","Chenyang Tao","Arpit Gupta","Shanchan Wu","Tagyoung Chung","Nanyun Peng"],"pdf_url":"https://arxiv.org/pdf/2306.11825v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11823v1","updated":"2023-06-20T18:32:30Z","published":"2023-06-20T18:32:30Z","title":"EvolveMT: an Ensemble MT Engine Improving Itself with Usage Only","summary":"  This paper presents EvolveMT for efficiently combining multiple machine\ntranslation (MT) engines. The proposed system selects the output from a single\nengine for each segment by utilizing online learning techniques to predict the\nmost suitable system for every translation request. A neural quality estimation\nmetric supervises the method without requiring reference translations. The\nonline learning capability of this system allows for dynamic adaptation to\nalterations in the domain or machine translation engines, thereby obviating the\nnecessity for additional training. EvolveMT selects a subset of translation\nengines to be called based on the source sentence features. The degree of\nexploration is configurable according to the desired quality-cost trade-off.\nResults from custom datasets demonstrate that EvolveMT achieves similar\ntranslation accuracy at a lower cost than selecting the best translation of\neach segment from all translations using an MT quality estimator. To our\nknowledge, EvolveMT is the first meta MT system that adapts itself after\ndeployment to incoming translation requests from the production environment\nwithout needing costly retraining on human feedback.\n","authors":["Kamer Ali Yuksel","Ahmet Gunduz","Mohamed Al-Badrashiny","Shreyas Sharma","Hassan Sawaf"],"pdf_url":"https://arxiv.org/pdf/2306.11823v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11816v1","updated":"2023-06-20T18:19:17Z","published":"2023-06-20T18:19:17Z","title":"Learning to Generate Better Than Your LLM","summary":"  Reinforcement learning (RL) has emerged as a powerful paradigm for\nfine-tuning Large Language Models (LLMs) for conditional text generation. In\nparticular, recent LLMs such as ChatGPT and GPT-4 can engage in fluent\nconversations with users by incorporating RL and feedback from humans. Inspired\nby learning-to-search algorithms and capitalizing on key properties of text\ngeneration, we seek to investigate reinforcement learning algorithms beyond\ngeneral purpose algorithms such as Proximal policy optimization (PPO). In\nparticular, we extend RL algorithms to allow them to interact with a dynamic\nblack-box guide LLM such as GPT-3 and propose RL with guided feedback (RLGF), a\nsuite of RL algorithms for LLM fine-tuning. We experiment on the IMDB positive\nreview and CommonGen text generation task from the GRUE benchmark. We show that\nour RL algorithms achieve higher performance than supervised learning (SL) and\ndefault PPO baselines, demonstrating the benefit of interaction with the guide\nLLM. On CommonGen, we not only outperform our SL baselines but also improve\nbeyond PPO across a variety of lexical and semantic metrics beyond the one we\noptimized for. Notably, on the IMDB dataset, we show that our GPT-2 based\npolicy outperforms the zero-shot GPT-3 oracle, indicating that our algorithms\ncan learn from a powerful, black-box GPT-3 oracle with a simpler, cheaper, and\npublicly available GPT-2 model while gaining performance.\n","authors":["Jonathan D. Chang","Kiante Brantley","Rajkumar Ramamurthy","Dipendra Misra","Wen Sun"],"pdf_url":"https://arxiv.org/pdf/2306.11816v1.pdf","comment":"23 pages, 5 figures, 7 tables, 4 algorithms"},{"id":"http://arxiv.org/abs/2306.12443v1","updated":"2023-06-20T12:21:06Z","published":"2023-06-20T12:21:06Z","title":"DEPAC: a Corpus for Depression and Anxiety Detection from Speech","summary":"  Mental distress like depression and anxiety contribute to the largest\nproportion of the global burden of diseases. Automated diagnosis systems of\nsuch disorders, empowered by recent innovations in Artificial Intelligence, can\npave the way to reduce the sufferings of the affected individuals. Development\nof such systems requires information-rich and balanced corpora. In this work,\nwe introduce a novel mental distress analysis audio dataset DEPAC, labeled\nbased on established thresholds on depression and anxiety standard screening\ntools. This large dataset comprises multiple speech tasks per individual, as\nwell as relevant demographic information. Alongside, we present a feature set\nconsisting of hand-curated acoustic and linguistic features, which were found\neffective in identifying signs of mental illnesses in human speech. Finally, we\njustify the quality and effectiveness of our proposed audio corpus and feature\nset in predicting depression severity by comparing the performance of baseline\nmachine learning models built on this dataset with baseline models trained on\nother well-known depression corpora.\n","authors":["Mashrura Tasnim","Malikeh Ehghaghi","Brian Diep","Jekaterina Novikova"],"pdf_url":"https://arxiv.org/pdf/2306.12443v1.pdf","comment":"Accepted to the Eighth Workshop on Computational Linguistics and\n  Clinical Psychology (CLPsych) at NAACL 2022"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2306.11731v1","updated":"2023-06-20T17:59:46Z","published":"2023-06-20T17:59:46Z","title":"Learning Profitable NFT Image Diffusions via Multiple Visual-Policy\n  Guided Reinforcement Learning","summary":"  We study the task of generating profitable Non-Fungible Token (NFT) images\nfrom user-input texts. Recent advances in diffusion models have shown great\npotential for image generation. However, existing works can fall short in\ngenerating visually-pleasing and highly-profitable NFT images, mainly due to\nthe lack of 1) plentiful and fine-grained visual attribute prompts for an NFT\nimage, and 2) effective optimization metrics for generating high-quality NFT\nimages. To solve these challenges, we propose a Diffusion-based generation\nframework with Multiple Visual-Policies as rewards (i.e., Diffusion-MVP) for\nNFT images. The proposed framework consists of a large language model (LLM), a\ndiffusion-based image generator, and a series of visual rewards by design.\nFirst, the LLM enhances a basic human input (such as \"panda\") by generating\nmore comprehensive NFT-style prompts that include specific visual attributes,\nsuch as \"panda with Ninja style and green background.\" Second, the\ndiffusion-based image generator is fine-tuned using a large-scale NFT dataset\nto capture fine-grained image styles and accessory compositions of popular NFT\nelements. Third, we further propose to utilize multiple visual-policies as\noptimization goals, including visual rarity levels, visual aesthetic scores,\nand CLIP-based text-image relevances. This design ensures that our proposed\nDiffusion-MVP is capable of minting NFT images with high visual quality and\nmarket value. To facilitate this research, we have collected the largest\npublicly available NFT image dataset to date, consisting of 1.5 million\nhigh-quality images with corresponding texts and market values. Extensive\nexperiments including objective evaluations and user studies demonstrate that\nour framework can generate NFT images showing more visually engaging elements\nand higher market value, compared with SOTA approaches.\n","authors":["Huiguo He","Tianfu Wang","Huan Yang","Jianlong Fu","Nicholas Jing Yuan","Jian Yin","Hongyang Chao","Qi Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.11731v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11730v1","updated":"2023-06-20T17:59:14Z","published":"2023-06-20T17:59:14Z","title":"Segment Anything Model (SAM) for Radiation Oncology","summary":"  In this study, we evaluate the performance of the Segment Anything Model\n(SAM) model in clinical radiotherapy. We collected real clinical cases from\nfour regions at the Mayo Clinic: prostate, lung, gastrointestinal, and head \\&\nneck, which are typical treatment sites in radiation oncology. For each case,\nwe selected the OARs of concern in radiotherapy planning and compared the Dice\nand Jaccard outcomes between clinical manual delineation, automatic\nsegmentation using SAM's \"segment anything\" mode, and automatic segmentation\nusing SAM with box prompt. Our results indicate that SAM performs better in\nautomatic segmentation for the prostate and lung regions, while its performance\nin the gastrointestinal and head \\& neck regions was relatively inferior. When\nconsidering the size of the organ and the clarity of its boundary, SAM displays\nbetter performance for larger organs with clear boundaries, such as the lung\nand liver, and worse for smaller organs with unclear boundaries, like the\nparotid and cochlea. These findings align with the generally accepted\nvariations in difficulty level associated with manual delineation of different\norgans at different sites in clinical radiotherapy. Given that SAM, a single\ntrained model, could handle the delineation of OARs in four regions, these\nresults also demonstrate SAM's robust generalization capabilities in automatic\nsegmentation for radiotherapy, i.e., achieving delineation of different\nradiotherapy OARs using a generic automatic segmentation model. SAM's\ngeneralization capabilities across different regions make it technically\nfeasible to develop a generic model for automatic segmentation in radiotherapy.\n","authors":["Lian Zhang","Zhengliang Liu","Lu Zhang","Zihao Wu","Xiaowei Yu","Jason Holmes","Hongying Feng","Haixing Dai","Xiang Li","Quanzheng Li","Dajiang Zhu","Tianming Liu","Wei Liu"],"pdf_url":"https://arxiv.org/pdf/2306.11730v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.16952v2","updated":"2023-06-20T17:58:25Z","published":"2022-03-31T11:18:41Z","title":"Multimodal Fusion Transformer for Remote Sensing Image Classification","summary":"  Vision transformers (ViTs) have been trending in image classification tasks\ndue to their promising performance when compared to convolutional neural\nnetworks (CNNs). As a result, many researchers have tried to incorporate ViTs\nin hyperspectral image (HSI) classification tasks. To achieve satisfactory\nperformance, close to that of CNNs, transformers need fewer parameters. ViTs\nand other similar transformers use an external classification (CLS) token which\nis randomly initialized and often fails to generalize well, whereas other\nsources of multimodal datasets, such as light detection and ranging (LiDAR)\noffer the potential to improve these models by means of a CLS. In this paper,\nwe introduce a new multimodal fusion transformer (MFT) network which comprises\na multihead cross patch attention (mCrossPA) for HSI land-cover classification.\nOur mCrossPA utilizes other sources of complementary information in addition to\nthe HSI in the transformer encoder to achieve better generalization. The\nconcept of tokenization is used to generate CLS and HSI patch tokens, helping\nto learn a {distinctive representation} in a reduced and hierarchical feature\nspace. Extensive experiments are carried out on {widely used benchmark}\ndatasets {i.e.,} the University of Houston, Trento, University of Southern\nMississippi Gulfpark (MUUFL), and Augsburg. We compare the results of the\nproposed MFT model with other state-of-the-art transformers, classical CNNs,\nand conventional classifiers models. The superior performance achieved by the\nproposed model is due to the use of multihead cross patch attention. The source\ncode will be made available publicly at\n\\url{https://github.com/AnkurDeria/MFT}.}\n","authors":["Swalpa Kumar Roy","Ankur Deria","Danfeng Hong","Behnood Rasti","Antonio Plaza","Jocelyn Chanussot"],"pdf_url":"https://arxiv.org/pdf/2203.16952v2.pdf","comment":"Published in IEEE Transactions on Geoscience and Remote Sensing"},{"id":"http://arxiv.org/abs/2306.11729v1","updated":"2023-06-20T17:57:23Z","published":"2023-06-20T17:57:23Z","title":"Dense Video Object Captioning from Disjoint Supervision","summary":"  We propose a new task and model for dense video object captioning --\ndetecting, tracking, and captioning trajectories of all objects in a video.\nThis task unifies spatial and temporal understanding of the video, and requires\nfine-grained language description. Our model for dense video object captioning\nis trained end-to-end and consists of different modules for spatial\nlocalization, tracking, and captioning. As such, we can train our model with a\nmixture of disjoint tasks, and leverage diverse, large-scale datasets which\nsupervise different parts of our model. This results in noteworthy zero-shot\nperformance. Moreover, by finetuning a model from this initialization, we can\nfurther improve our performance, surpassing strong image-based baselines by a\nsignificant margin. Although we are not aware of other work performing this\ntask, we are able to repurpose existing video grounding datasets for our task,\nnamely VidSTG and VLN. We show our task is more general than grounding, and\nmodels trained on our task can directly be applied to grounding by finding the\nbounding box with the maximum likelihood of generating the query sentence. Our\nmodel outperforms dedicated, state-of-the-art models for spatial grounding on\nboth VidSTG and VLN.\n","authors":["Xingyi Zhou","Anurag Arnab","Chen Sun","Cordelia Schmid"],"pdf_url":"https://arxiv.org/pdf/2306.11729v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11726v1","updated":"2023-06-20T17:56:16Z","published":"2023-06-20T17:56:16Z","title":"How can objects help action recognition?","summary":"  Current state-of-the-art video models process a video clip as a long sequence\nof spatio-temporal tokens. However, they do not explicitly model objects, their\ninteractions across the video, and instead process all the tokens in the video.\nIn this paper, we investigate how we can use knowledge of objects to design\nbetter video models, namely to process fewer tokens and to improve recognition\naccuracy. This is in contrast to prior works which either drop tokens at the\ncost of accuracy, or increase accuracy whilst also increasing the computation\nrequired. First, we propose an object-guided token sampling strategy that\nenables us to retain a small fraction of the input tokens with minimal impact\non accuracy. And second, we propose an object-aware attention module that\nenriches our feature representation with object information and improves\noverall accuracy. Our resulting framework achieves better performance when\nusing fewer tokens than strong baselines. In particular, we match our baseline\nwith 30%, 40%, and 60% of the input tokens on SomethingElse,\nSomething-something v2, and Epic-Kitchens, respectively. When we use our model\nto process the same number of tokens as our baseline, we improve by 0.6 to 4.2\npoints on these datasets.\n","authors":["Xingyi Zhou","Anurag Arnab","Chen Sun","Cordelia Schmid"],"pdf_url":"https://arxiv.org/pdf/2306.11726v1.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2306.11724v1","updated":"2023-06-20T17:55:48Z","published":"2023-06-20T17:55:48Z","title":"Low-complexity Multidimensional DCT Approximations","summary":"  In this paper, we introduce low-complexity multidimensional discrete cosine\ntransform (DCT) approximations. Three dimensional DCT (3D DCT) approximations\nare formalized in terms of high-order tensor theory. The formulation is\nextended to higher dimensions with arbitrary lengths. Several multiplierless\n$8\\times 8\\times 8$ approximate methods are proposed and the computational\ncomplexity is discussed for the general multidimensional case. The proposed\nmethods complexity cost was assessed, presenting considerably lower arithmetic\noperations when compared with the exact 3D DCT. The proposed approximations\nwere embedded into 3D DCT-based video coding scheme and a modified quantization\nstep was introduced. The simulation results showed that the approximate 3D DCT\ncoding methods offer almost identical output visual quality when compared with\nexact 3D DCT scheme. The proposed 3D approximations were also employed as a\ntool for visual tracking. The approximate 3D DCT-based proposed system performs\nsimilarly to the original exact 3D DCT-based method. In general, the suggested\nmethods showed competitive performance at a considerably lower computational\ncost.\n","authors":["V. A. Coutinho","R. J. Cintra","F. M. Bayer"],"pdf_url":"https://arxiv.org/pdf/2306.11724v1.pdf","comment":"28 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2306.11719v1","updated":"2023-06-20T17:53:00Z","published":"2023-06-20T17:53:00Z","title":"Diffusion with Forward Models: Solving Stochastic Inverse Problems\n  Without Direct Supervision","summary":"  Denoising diffusion models are a powerful type of generative models used to\ncapture complex distributions of real-world signals. However, their\napplicability is limited to scenarios where training samples are readily\navailable, which is not always the case in real-world applications. For\nexample, in inverse graphics, the goal is to generate samples from a\ndistribution of 3D scenes that align with a given image, but ground-truth 3D\nscenes are unavailable and only 2D images are accessible. To address this\nlimitation, we propose a novel class of denoising diffusion probabilistic\nmodels that learn to sample from distributions of signals that are never\ndirectly observed. Instead, these signals are measured indirectly through a\nknown differentiable forward model, which produces partial observations of the\nunknown signal. Our approach involves integrating the forward model directly\ninto the denoising process. This integration effectively connects the\ngenerative modeling of observations with the generative modeling of the\nunderlying signals, allowing for end-to-end training of a conditional\ngenerative model over signals. During inference, our approach enables sampling\nfrom the distribution of underlying signals that are consistent with a given\npartial observation. We demonstrate the effectiveness of our method on three\nchallenging computer vision tasks. For instance, in the context of inverse\ngraphics, our model enables direct sampling from the distribution of 3D scenes\nthat align with a single 2D input image.\n","authors":["Ayush Tewari","Tianwei Yin","George Cazenavette","Semon Rezchikov","Joshua B. Tenenbaum","Frédo Durand","William T. Freeman","Vincent Sitzmann"],"pdf_url":"https://arxiv.org/pdf/2306.11719v1.pdf","comment":"Project page: https://diffusion-with-forward-models.github.io/"},{"id":"http://arxiv.org/abs/2212.03588v3","updated":"2023-06-20T17:50:05Z","published":"2022-12-07T12:05:00Z","title":"ZegCLIP: Towards Adapting CLIP for Zero-shot Semantic Segmentation","summary":"  Recently, CLIP has been applied to pixel-level zero-shot learning tasks via a\ntwo-stage scheme. The general idea is to first generate class-agnostic region\nproposals and then feed the cropped proposal regions to CLIP to utilize its\nimage-level zero-shot classification capability. While effective, such a scheme\nrequires two image encoders, one for proposal generation and one for CLIP,\nleading to a complicated pipeline and high computational cost. In this work, we\npursue a simpler-and-efficient one-stage solution that directly extends CLIP's\nzero-shot prediction capability from image to pixel level. Our investigation\nstarts with a straightforward extension as our baseline that generates semantic\nmasks by comparing the similarity between text and patch embeddings extracted\nfrom CLIP. However, such a paradigm could heavily overfit the seen classes and\nfail to generalize to unseen classes. To handle this issue, we propose three\nsimple-but-effective designs and figure out that they can significantly retain\nthe inherent zero-shot capacity of CLIP and improve pixel-level generalization\nability. Incorporating those modifications leads to an efficient zero-shot\nsemantic segmentation system called ZegCLIP. Through extensive experiments on\nthree public benchmarks, ZegCLIP demonstrates superior performance,\noutperforming the state-of-the-art methods by a large margin under both\n\"inductive\" and \"transductive\" zero-shot settings. In addition, compared with\nthe two-stage method, our one-stage ZegCLIP achieves a speedup of about 5 times\nfaster during inference. We release the code at\nhttps://github.com/ZiqinZhou66/ZegCLIP.git.\n","authors":["Ziqin Zhou","Bowen Zhang","Yinjie Lei","Lingqiao Liu","Yifan Liu"],"pdf_url":"https://arxiv.org/pdf/2212.03588v3.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2306.11714v1","updated":"2023-06-20T17:42:30Z","published":"2023-06-20T17:42:30Z","title":"Meta-Analysis of Transfer Learning for Segmentation of Brain Lesions","summary":"  A major challenge in stroke research and stroke recovery predictions is the\ndetermination of a stroke lesion's extent and its impact on relevant brain\nsystems. Manual segmentation of stroke lesions from 3D magnetic resonance (MR)\nimaging volumes, the current gold standard, is not only very time-consuming,\nbut its accuracy highly depends on the operator's experience. As a result,\nthere is a need for a fully automated segmentation method that can efficiently\nand objectively measure lesion extent and the impact of each lesion to predict\nimpairment and recovery potential which might be beneficial for clinical,\ntranslational, and research settings. We have implemented and tested a fully\nautomatic method for stroke lesion segmentation which was developed using eight\ndifferent 2D-model architectures trained via transfer learning (TL) and mixed\ndata approaches. Additionally, the final prediction was made using a novel\nensemble method involving stacking and agreement window. Our novel method was\nevaluated in a novel in-house dataset containing 22 T1w brain MR images, which\nwere challenging in various perspectives, but mostly because they included T1w\nMR images from the subacute (which typically less well defined T1 lesions) and\nchronic stroke phase (which typically means well defined T1-lesions).\nCross-validation results indicate that our new method can efficiently and\nautomatically segment lesions fast and with high accuracy compared to ground\ntruth. In addition to segmentation, we provide lesion volume and weighted\nlesion load of relevant brain systems based on the lesions' overlap with a\ncanonical structural motor system that stretches from the cortical motor region\nto the lowest end of the brain stem.\n","authors":["Sovesh Mohapatra","Advait Gosai","Anant Shinde","Aleksei Rutkovskii","Sirisha Nouduri","Gottfried Schlaug"],"pdf_url":"https://arxiv.org/pdf/2306.11714v1.pdf","comment":"13 Pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2306.11710v1","updated":"2023-06-20T17:39:24Z","published":"2023-06-20T17:39:24Z","title":"Data-Driven but Privacy-Conscious: Pedestrian Dataset De-identification\n  via Full-Body Person Synthesis","summary":"  The advent of data-driven technology solutions is accompanied by an\nincreasing concern with data privacy. This is of particular importance for\nhuman-centered image recognition tasks, such as pedestrian detection,\nre-identification, and tracking. To highlight the importance of privacy issues\nand motivate future research, we motivate and introduce the Pedestrian Dataset\nDe-Identification (PDI) task. PDI evaluates the degree of de-identification and\ndownstream task training performance for a given de-identification method. As a\nfirst baseline, we propose IncogniMOT, a two-stage full-body de-identification\npipeline based on image synthesis via generative adversarial networks. The\nfirst stage replaces target pedestrians with synthetic identities. To improve\ndownstream task performance, we then apply stage two, which blends and adapts\nthe synthetic image parts into the data. To demonstrate the effectiveness of\nIncogniMOT, we generate a fully de-identified version of the MOT17 pedestrian\ntracking dataset and analyze its application as training data for pedestrian\nre-identification, detection, and tracking models. Furthermore, we show how our\ndata is able to narrow the synthetic-to-real performance gap in a\nprivacy-conscious manner.\n","authors":["Maxim Maximov","Tim Meinhardt","Ismail Elezi","Zoe Papakipos","Caner Hazirbas","Cristian Canton","Laura Leal-Taixé"],"pdf_url":"https://arxiv.org/pdf/2306.11710v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.10008v2","updated":"2023-06-20T17:33:58Z","published":"2023-06-16T17:58:15Z","title":"CLIP2Protect: Protecting Facial Privacy using Text-Guided Makeup via\n  Adversarial Latent Search","summary":"  The success of deep learning based face recognition systems has given rise to\nserious privacy concerns due to their ability to enable unauthorized tracking\nof users in the digital world. Existing methods for enhancing privacy fail to\ngenerate naturalistic images that can protect facial privacy without\ncompromising user experience. We propose a novel two-step approach for facial\nprivacy protection that relies on finding adversarial latent codes in the\nlow-dimensional manifold of a pretrained generative model. The first step\ninverts the given face image into the latent space and finetunes the generative\nmodel to achieve an accurate reconstruction of the given image from its latent\ncode. This step produces a good initialization, aiding the generation of\nhigh-quality faces that resemble the given identity. Subsequently, user-defined\nmakeup text prompts and identity-preserving regularization are used to guide\nthe search for adversarial codes in the latent space. Extensive experiments\ndemonstrate that faces generated by our approach have stronger black-box\ntransferability with an absolute gain of 12.06% over the state-of-the-art\nfacial privacy protection approach under the face verification task. Finally,\nwe demonstrate the effectiveness of the proposed approach for commercial face\nrecognition systems. Our code is available at\nhttps://github.com/fahadshamshad/Clip2Protect.\n","authors":["Fahad Shamshad","Muzammal Naseer","Karthik Nandakumar"],"pdf_url":"https://arxiv.org/pdf/2306.10008v2.pdf","comment":"Accepted in CVPR 2023. Project page:\n  https://fahadshamshad.github.io/Clip2Protect/"},{"id":"http://arxiv.org/abs/2306.11699v1","updated":"2023-06-20T17:25:53Z","published":"2023-06-20T17:25:53Z","title":"GenPlot: Increasing the Scale and Diversity of Chart Derendering Data","summary":"  Vertical bars, horizontal bars, dot, scatter, and line plots provide a\ndiverse set of visualizations to represent data. To understand these plots, one\nmust be able to recognize textual components, locate data points in a plot, and\nprocess diverse visual contexts to extract information. In recent works such as\nPix2Struct, Matcha, and Deplot, OCR-free chart-to-text translation has achieved\nstate-of-the-art results on visual language tasks. These results outline the\nimportance of chart-derendering as a pre-training objective, yet existing\ndatasets provide a fixed set of training examples. In this paper, we propose\nGenPlot; a plot generator that can generate billions of additional plots for\nchart-derendering using synthetic data.\n","authors":["Brendan Artley"],"pdf_url":"https://arxiv.org/pdf/2306.11699v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11682v1","updated":"2023-06-20T16:58:51Z","published":"2023-06-20T16:58:51Z","title":"SkyGPT: Probabilistic Short-term Solar Forecasting Using Synthetic Sky\n  Videos from Physics-constrained VideoGPT","summary":"  In recent years, deep learning-based solar forecasting using all-sky images\nhas emerged as a promising approach for alleviating uncertainty in PV power\ngeneration. However, the stochastic nature of cloud movement remains a major\nchallenge for accurate and reliable solar forecasting. With the recent advances\nin generative artificial intelligence, the synthesis of visually plausible yet\ndiversified sky videos has potential for aiding in forecasts. In this study, we\nintroduce \\emph{SkyGPT}, a physics-informed stochastic video prediction model\nthat is able to generate multiple possible future images of the sky with\ndiverse cloud motion patterns, by using past sky image sequences as input.\nExtensive experiments and comparison with benchmark video prediction models\ndemonstrate the effectiveness of the proposed model in capturing cloud dynamics\nand generating future sky images with high realism and diversity. Furthermore,\nwe feed the generated future sky images from the video prediction models for\n15-minute-ahead probabilistic solar forecasting for a 30-kW roof-top PV system,\nand compare it with an end-to-end deep learning baseline model SUNSET and a\nsmart persistence model. Better PV output prediction reliability and sharpness\nis observed by using the predicted sky images generated with SkyGPT compared\nwith other benchmark models, achieving a continuous ranked probability score\n(CRPS) of 2.81 (13\\% better than SUNSET and 23\\% better than smart persistence)\nand a Winkler score of 26.70 for the test set. Although an arbitrary number of\nfutures can be generated from a historical sky image sequence, the results\nsuggest that 10 future scenarios is a good choice that balances probabilistic\nsolar forecasting performance and computational cost.\n","authors":["Yuhao Nie","Eric Zelikman","Andea Scott","Quentin Paletta","Adam Brandt"],"pdf_url":"https://arxiv.org/pdf/2306.11682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.04338v2","updated":"2023-06-20T16:38:13Z","published":"2022-09-09T14:51:13Z","title":"Bridging the Gap: Differentially Private Equivariant Deep Learning for\n  Medical Image Analysis","summary":"  Machine learning with formal privacy-preserving techniques like Differential\nPrivacy (DP) allows one to derive valuable insights from sensitive medical\nimaging data while promising to protect patient privacy, but it usually comes\nat a sharp privacy-utility trade-off. In this work, we propose to use steerable\nequivariant convolutional networks for medical image analysis with DP. Their\nimproved feature quality and parameter efficiency yield remarkable accuracy\ngains, narrowing the privacy-utility gap.\n","authors":["Florian A. Hölzl","Daniel Rueckert","Georgios Kaissis"],"pdf_url":"https://arxiv.org/pdf/2209.04338v2.pdf","comment":"Accepted as extended abstract at GeoMedIA Workshop 2022\n  (https://openreview.net/forum?id=rGYfMrMxI17)"},{"id":"http://arxiv.org/abs/2212.04488v2","updated":"2023-06-20T16:26:38Z","published":"2022-12-08T18:57:02Z","title":"Multi-Concept Customization of Text-to-Image Diffusion","summary":"  While generative models produce high-quality images of concepts learned from\na large-scale database, a user often wishes to synthesize instantiations of\ntheir own concepts (for example, their family, pets, or items). Can we teach a\nmodel to quickly acquire a new concept, given a few examples? Furthermore, can\nwe compose multiple new concepts together? We propose Custom Diffusion, an\nefficient method for augmenting existing text-to-image models. We find that\nonly optimizing a few parameters in the text-to-image conditioning mechanism is\nsufficiently powerful to represent new concepts while enabling fast tuning (~6\nminutes). Additionally, we can jointly train for multiple concepts or combine\nmultiple fine-tuned models into one via closed-form constrained optimization.\nOur fine-tuned model generates variations of multiple new concepts and\nseamlessly composes them with existing concepts in novel settings. Our method\noutperforms or performs on par with several baselines and concurrent works in\nboth qualitative and quantitative evaluations while being memory and\ncomputationally efficient.\n","authors":["Nupur Kumari","Bingliang Zhang","Richard Zhang","Eli Shechtman","Jun-Yan Zhu"],"pdf_url":"https://arxiv.org/pdf/2212.04488v2.pdf","comment":"Updated v2 with results on the new CustomConcept101 dataset\n  https://www.cs.cmu.edu/~custom-diffusion/dataset.html Project webpage:\n  https://www.cs.cmu.edu/~custom-diffusion"},{"id":"http://arxiv.org/abs/2305.13447v4","updated":"2023-06-20T16:18:45Z","published":"2023-05-22T19:44:57Z","title":"Regularization Through Simultaneous Learning: A Case Study on Plant\n  Classification","summary":"  In response to the prevalent challenge of overfitting in deep neural\nnetworks, this paper introduces Simultaneous Learning, a regularization\napproach drawing on principles of Transfer Learning and Multi-task Learning. We\nleverage auxiliary datasets with the target dataset, the UFOP-HVD, to\nfacilitate simultaneous classification guided by a customized loss function\nfeaturing an inter-group penalty. This experimental configuration allows for a\ndetailed examination of model performance across similar (PlantNet) and\ndissimilar (ImageNet) domains, thereby enriching the generalizability of\nConvolutional Neural Network models. Remarkably, our approach demonstrates\nsuperior performance over models without regularization and those applying\ndropout regularization exclusively, enhancing accuracy by 5 to 22 percentage\npoints. Moreover, when combined with dropout, the proposed approach improves\ngeneralization, securing state-of-the-art results for the UFOP-HVD challenge.\nThe method also showcases efficiency with significantly smaller sample sizes,\nsuggesting its broad applicability across a spectrum of related tasks. In\naddition, an interpretability approach is deployed to evaluate feature quality\nby analyzing class feature correlations within the network's convolutional\nlayers. The findings of this study provide deeper insights into the efficacy of\nSimultaneous Learning, particularly concerning its interaction with the\nauxiliary and target datasets.\n","authors":["Pedro Henrique Nascimento Castro","Gabriel Cássia Fortuna","Rafael Alves Bonfim de Queiroz","Gladston Juliano Prates Moreira","Eduardo José da Silva Luz"],"pdf_url":"https://arxiv.org/pdf/2305.13447v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11638v1","updated":"2023-06-20T16:05:24Z","published":"2023-06-20T16:05:24Z","title":"Collision Avoidance Detour for Multi-Agent Trajectory Forecasting","summary":"  We present our approach, Collision Avoidance Detour (CAD), which won the 3rd\nplace award in the 2023 Waymo Open Dataset Challenge - Sim Agents, held at the\n2023 CVPR Workshop on Autonomous Driving. To satisfy the motion prediction\nfactorization requirement, we partition all the valid objects into three\nmutually exclusive sets: Autonomous Driving Vehicle (ADV),\nWorld-tracks-to-predict, and World-others. We use different motion models to\nforecast their future trajectories independently. Furthermore, we also apply\ncollision avoidance detour resampling, additive Gaussian noise, and\nvelocity-based heading estimation to improve the realism of our simulation\nresult.\n","authors":["Hsu-kuang Chiu","Stephen F. Smith"],"pdf_url":"https://arxiv.org/pdf/2306.11638v1.pdf","comment":"3rd place award, 2023 Waymo Open Dataset Challenge - Sim Agents,\n  Workshop on Autonomous Driving of The IEEE/CVF Conference on Computer Vision\n  and Pattern Recognition (CVPR Workshop) 2023"},{"id":"http://arxiv.org/abs/2302.10289v7","updated":"2023-06-20T15:56:23Z","published":"2023-02-20T20:25:41Z","title":"Tackling Shortcut Learning in Deep Neural Networks: An Iterative\n  Approach with Interpretable Models","summary":"  We use concept-based interpretable models to mitigate shortcut learning.\nExisting methods lack interpretability. Beginning with a Blackbox, we\niteratively carve out a mixture of interpretable experts (MoIE) and a residual\nnetwork. Each expert explains a subset of data using First Order Logic (FOL).\nWhile explaining a sample, the FOL from biased BB-derived MoIE detects the\nshortcut effectively. Finetuning the BB with Metadata Normalization (MDN)\neliminates the shortcut. The FOLs from the finetuned-BB-derived MoIE verify the\nelimination of the shortcut. Our experiments show that MoIE does not hurt the\naccuracy of the original BB and eliminates shortcuts effectively.\n","authors":["Shantanu Ghosh","Ke Yu","Forough Arabshahi","Kayhan Batmanghelich"],"pdf_url":"https://arxiv.org/pdf/2302.10289v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11605v1","updated":"2023-06-20T15:33:24Z","published":"2023-06-20T15:33:24Z","title":"Annotation Cost Efficient Active Learning for Content Based Image\n  Retrieval","summary":"  Deep metric learning (DML) based methods have been found very effective for\ncontent-based image retrieval (CBIR) in remote sensing (RS). For accurately\nlearning the model parameters of deep neural networks, most of the DML methods\nrequire a high number of annotated training images, which can be costly to\ngather. To address this problem, in this paper we present an annotation cost\nefficient active learning (AL) method (denoted as ANNEAL). The proposed method\naims to iteratively enrich the training set by annotating the most informative\nimage pairs as similar or dissimilar, %answering a simple yes/no question,\nwhile accurately modelling a deep metric space. This is achieved by two\nconsecutive steps. In the first step the pairwise image similarity is modelled\nbased on the available training set. Then, in the second step the most\nuncertain and diverse (i.e., informative) image pairs are selected to be\nannotated. Unlike the existing AL methods for CBIR, at each AL iteration of\nANNEAL a human expert is asked to annotate the most informative image pairs as\nsimilar/dissimilar. This significantly reduces the annotation cost compared to\nannotating images with land-use/land cover class labels. Experimental results\nshow the effectiveness of our method. The code of ANNEAL is publicly available\nat https://git.tu-berlin.de/rsim/ANNEAL.\n","authors":["Julia Henkel","Genc Hoxha","Gencer Sumbul","Lars Möllenbrok","Begüm Demir"],"pdf_url":"https://arxiv.org/pdf/2306.11605v1.pdf","comment":"Accepted at IEEE International Geoscience and Remote Sensing\n  Symposium (IGARSS) 2023. Our code is available at\n  https://git.tu-berlin.de/rsim/ANNEAL"},{"id":"http://arxiv.org/abs/2306.11598v1","updated":"2023-06-20T15:16:35Z","published":"2023-06-20T15:16:35Z","title":"BEVScope: Enhancing Self-Supervised Depth Estimation Leveraging\n  Bird's-Eye-View in Dynamic Scenarios","summary":"  Depth estimation is a cornerstone of perception in autonomous driving and\nrobotic systems. The considerable cost and relatively sparse data acquisition\nof LiDAR systems have led to the exploration of cost-effective alternatives,\nnotably, self-supervised depth estimation. Nevertheless, current\nself-supervised depth estimation methods grapple with several limitations: (1)\nthe failure to adequately leverage informative multi-camera views. (2) the\nlimited capacity to handle dynamic objects effectively. To address these\nchallenges, we present BEVScope, an innovative approach to self-supervised\ndepth estimation that harnesses Bird's-Eye-View (BEV) features. Concurrently,\nwe propose an adaptive loss function, specifically designed to mitigate the\ncomplexities associated with moving objects. Empirical evaluations conducted on\nthe Nuscenes dataset validate our approach, demonstrating competitive\nperformance. Code will be released at https://github.com/myc634/BEVScope.\n","authors":["Yucheng Mao","Ruowen Zhao","Tianbao Zhang","Hang Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.11598v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11593v1","updated":"2023-06-20T15:13:02Z","published":"2023-06-20T15:13:02Z","title":"Improving Image Captioning Descriptiveness by Ranking and LLM-based\n  Fusion","summary":"  State-of-The-Art (SoTA) image captioning models often rely on the Microsoft\nCOCO (MS-COCO) dataset for training. This dataset contains annotations provided\nby human annotators, who typically produce captions averaging around ten\ntokens. However, this constraint presents a challenge in effectively capturing\ncomplex scenes and conveying detailed information. Furthermore, captioning\nmodels tend to exhibit bias towards the ``average'' caption, which captures\nonly the more general aspects. What would happen if we were able to\nautomatically generate longer captions, thereby making them more detailed?\nWould these captions, evaluated by humans, be more or less representative of\nthe image content compared to the original MS-COCO captions? In this paper, we\npresent a novel approach to address previous challenges by showcasing how\ncaptions generated from different SoTA models can be effectively fused,\nresulting in richer captions. Our proposed method leverages existing models\nfrom the literature, eliminating the need for additional training. Instead, it\nutilizes an image-text based metric to rank the captions generated by SoTA\nmodels for a given image. Subsequently, the top two captions are fused using a\nLarge Language Model (LLM). Experimental results demonstrate the effectiveness\nof our approach, as the captions generated by our model exhibit higher\nconsistency with human judgment when evaluated on the MS-COCO test set. By\ncombining the strengths of various SoTA models, our method enhances the quality\nand appeal of image captions, bridging the gap between automated systems and\nthe rich, informative nature of human-generated descriptions. This advance\nopens up new possibilities for generating captions that are more suitable for\nthe training of both vision-language and captioning models.\n","authors":["Simone Bianco","Luigi Celona","Marco Donzella","Paolo Napoletano"],"pdf_url":"https://arxiv.org/pdf/2306.11593v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11592v1","updated":"2023-06-20T15:10:35Z","published":"2023-06-20T15:10:35Z","title":"Deep Double Self-Expressive Subspace Clustering","summary":"  Deep subspace clustering based on auto-encoder has received wide attention.\nHowever, most subspace clustering based on auto-encoder does not utilize the\nstructural information in the self-expressive coefficient matrix, which limits\nthe clustering performance. In this paper, we propose a double self-expressive\nsubspace clustering algorithm. The key idea of our solution is to view the\nself-expressive coefficient as a feature representation of the example to get\nanother coefficient matrix. Then, we use the two coefficient matrices to\nconstruct the affinity matrix for spectral clustering. We find that it can\nreduce the subspace-preserving representation error and improve connectivity.\nTo further enhance the clustering performance, we proposed a self-supervised\nmodule based on contrastive learning, which can further improve the performance\nof the trained network. Experiments on several benchmark datasets demonstrate\nthat the proposed algorithm can achieve better clustering than state-of-the-art\nmethods.\n","authors":["Ling Zhao","Yunpeng Ma","Shanxiong Chen","Jun Zhou"],"pdf_url":"https://arxiv.org/pdf/2306.11592v1.pdf","comment":"5 pagees,4 figures,ICASSP2023, revised version"},{"id":"http://arxiv.org/abs/2306.08102v2","updated":"2023-06-20T15:04:31Z","published":"2023-06-13T19:46:40Z","title":"Domain-Aware Few-Shot Learning for Optical Coherence Tomography Noise\n  Reduction","summary":"  Speckle noise has long been an extensively studied problem in medical\nimaging. In recent years, there have been significant advances in leveraging\ndeep learning methods for noise reduction. Nevertheless, adaptation of\nsupervised learning models to unseen domains remains a challenging problem.\nSpecifically, deep neural networks (DNNs) trained for computational imaging\ntasks are vulnerable to changes in the acquisition system's physical\nparameters, such as: sampling space, resolution, and contrast. Even within the\nsame acquisition system, performance degrades across datasets of different\nbiological tissues. In this work, we propose a few-shot supervised learning\nframework for optical coherence tomography (OCT) noise reduction, that offers a\ndramatic increase in training speed and requires only a single image, or part\nof an image, and a corresponding speckle suppressed ground truth, for training.\nFurthermore, we formulate the domain shift problem for OCT diverse imaging\nsystems, and prove that the output resolution of a despeckling trained model is\ndetermined by the source domain resolution. We also provide possible remedies.\nWe propose different practical implementations of our approach, verify and\ncompare their applicability, robustness, and computational efficiency. Our\nresults demonstrate significant potential for generally improving sample\ncomplexity, generalization, and time efficiency, for coherent and non-coherent\nnoise reduction via supervised learning models, that can also be leveraged for\nother real-time computer vision applications.\n","authors":["Deborah Pereg"],"pdf_url":"https://arxiv.org/pdf/2306.08102v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11582v1","updated":"2023-06-20T14:56:02Z","published":"2023-06-20T14:56:02Z","title":"Computing a human-like reaction time metric from stable recurrent vision\n  models","summary":"  The meteoric rise in the adoption of deep neural networks as computational\nmodels of vision has inspired efforts to \"align\" these models with humans. One\ndimension of interest for alignment includes behavioral choices, but moving\nbeyond characterizing choice patterns to capturing temporal aspects of visual\ndecision-making has been challenging. Here, we sketch a general-purpose\nmethodology to construct computational accounts of reaction times from a\nstimulus-computable, task-optimized model. Specifically, we introduce a novel\nmetric leveraging insights from subjective logic theory summarizing evidence\naccumulation in recurrent vision models. We demonstrate that our metric aligns\nwith patterns of human reaction times for stimulus manipulations across four\ndisparate visual decision-making tasks spanning perceptual grouping, mental\nsimulation, and scene categorization. This work paves the way for exploring the\ntemporal alignment of model and human visual strategies in the context of\nvarious other cognitive tasks toward generating testable hypotheses for\nneuroscience.\n","authors":["Lore Goetschalckx","Lakshmi Narasimhan Govindarajan","Alekh Karkada Ashok","Aarit Ahuja","David L. Sheinberg","Thomas Serre"],"pdf_url":"https://arxiv.org/pdf/2306.11582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11576v1","updated":"2023-06-20T14:46:26Z","published":"2023-06-20T14:46:26Z","title":"Deep Learning Methods for Retinal Blood Vessel Segmentation: Evaluation\n  on Images with Retinopathy of Prematurity","summary":"  Automatic blood vessel segmentation from retinal images plays an important\nrole in the diagnosis of many systemic and eye diseases, including retinopathy\nof prematurity. Current state-of-the-art research in blood vessel segmentation\nfrom retinal images is based on convolutional neural networks. The solutions\nproposed so far are trained and tested on images from a few available retinal\nblood vessel segmentation datasets, which might limit their performance when\ngiven an image with retinopathy of prematurity signs. In this paper, we\nevaluate the performance of three high-performing convolutional neural networks\nfor retinal blood vessel segmentation in the context of blood vessel\nsegmentation on retinopathy of prematurity retinal images. The main motive\nbehind the study is to test if existing public datasets suffice to develop a\nhigh-performing predictor that could assist an ophthalmologist in retinopathy\nof prematurity diagnosis. To do so, we create a dataset consisting solely of\nretinopathy of prematurity images with retinal blood vessel annotations\nmanually labeled by two observers, where one is the ophthalmologist experienced\nin retinopathy of prematurity treatment. Experimental results show that all\nthree solutions have difficulties in detecting the retinal blood vessels of\ninfants due to a lower contrast compared to images from public datasets as\ndemonstrated by a significant drop in classification sensitivity. All three\nsolutions segment alongside retinal also choroidal blood vessels which are not\nused to diagnose retinopathy of prematurity, but instead represent noise and\nare confused with retinal blood vessels. By visual and numerical observations,\nwe observe that existing solutions for retinal blood vessel segmentation need\nimprovement toward more detailed datasets or deeper models in order to assist\nthe ophthalmologist in retinopathy of prematurity diagnosis.\n","authors":["Gorana Gojić","Veljko Petrović","Radovan Turović","Dinu Dragan","Ana Oros","Dušan Gajić","Nebojša Horvat"],"pdf_url":"https://arxiv.org/pdf/2306.11576v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11565v1","updated":"2023-06-20T14:30:32Z","published":"2023-06-20T14:30:32Z","title":"HomeRobot: Open-Vocabulary Mobile Manipulation","summary":"  HomeRobot (noun): An affordable compliant robot that navigates homes and\nmanipulates a wide range of objects in order to complete everyday tasks.\nOpen-Vocabulary Mobile Manipulation (OVMM) is the problem of picking any object\nin any unseen environment, and placing it in a commanded location. This is a\nfoundational challenge for robots to be useful assistants in human\nenvironments, because it involves tackling sub-problems from across robotics:\nperception, language understanding, navigation, and manipulation are all\nessential to OVMM. In addition, integration of the solutions to these\nsub-problems poses its own substantial challenges. To drive research in this\narea, we introduce the HomeRobot OVMM benchmark, where an agent navigates\nhousehold environments to grasp novel objects and place them on target\nreceptacles. HomeRobot has two components: a simulation component, which uses a\nlarge and diverse curated object set in new, high-quality multi-room home\nenvironments; and a real-world component, providing a software stack for the\nlow-cost Hello Robot Stretch to encourage replication of real-world experiments\nacross labs. We implement both reinforcement learning and heuristic\n(model-based) baselines and show evidence of sim-to-real transfer. Our\nbaselines achieve a 20% success rate in the real world; our experiments\nidentify ways future research work improve performance. See videos on our\nwebsite: https://ovmm.github.io/.\n","authors":["Sriram Yenamandra","Arun Ramachandran","Karmesh Yadav","Austin Wang","Mukul Khanna","Theophile Gervet","Tsung-Yen Yang","Vidhi Jain","Alexander William Clegg","John Turner","Zsolt Kira","Manolis Savva","Angel Chang","Devendra Singh Chaplot","Dhruv Batra","Roozbeh Mottaghi","Yonatan Bisk","Chris Paxton"],"pdf_url":"https://arxiv.org/pdf/2306.11565v1.pdf","comment":"35 pages, 20 figures, 8 tables"},{"id":"http://arxiv.org/abs/2306.11560v1","updated":"2023-06-20T14:26:53Z","published":"2023-06-20T14:26:53Z","title":"MILD: Modeling the Instance Learning Dynamics for Learning with Noisy\n  Labels","summary":"  Despite deep learning has achieved great success, it often relies on a large\namount of training data with accurate labels, which are expensive and\ntime-consuming to collect. A prominent direction to reduce the cost is to learn\nwith noisy labels, which are ubiquitous in the real-world applications. A\ncritical challenge for such a learning task is to reduce the effect of network\nmemorization on the falsely-labeled data. In this work, we propose an iterative\nselection approach based on the Weibull mixture model, which identifies clean\ndata by considering the overall learning dynamics of each data instance. In\ncontrast to the previous small-loss heuristics, we leverage the observation\nthat deep network is easy to memorize and hard to forget clean data. In\nparticular, we measure the difficulty of memorization and forgetting for each\ninstance via the transition times between being misclassified and being\nmemorized in training, and integrate them into a novel metric for selection.\nBased on the proposed metric, we retain a subset of identified clean data and\nrepeat the selection procedure to iteratively refine the clean subset, which is\nfinally used for model training. To validate our method, we perform extensive\nexperiments on synthetic noisy datasets and real-world web data, and our\nstrategy outperforms existing noisy-label learning methods.\n","authors":["Chuanyang Hu","Shipeng Yan","Zhitong Gao","Xuming He"],"pdf_url":"https://arxiv.org/pdf/2306.11560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11556v1","updated":"2023-06-20T14:18:20Z","published":"2023-06-20T14:18:20Z","title":"NeRF synthesis with shading guidance","summary":"  The emerging Neural Radiance Field (NeRF) shows great potential in\nrepresenting 3D scenes, which can render photo-realistic images from novel view\nwith only sparse views given. However, utilizing NeRF to reconstruct real-world\nscenes requires images from different viewpoints, which limits its practical\napplication. This problem can be even more pronounced for large scenes. In this\npaper, we introduce a new task called NeRF synthesis that utilizes the\nstructural content of a NeRF patch exemplar to construct a new radiance field\nof large size. We propose a two-phase method for synthesizing new scenes that\nare continuous in geometry and appearance. We also propose a boundary\nconstraint method to synthesize scenes of arbitrary size without artifacts.\nSpecifically, we control the lighting effects of synthesized scenes using\nshading guidance instead of decoupling the scene. We have demonstrated that our\nmethod can generate high-quality results with consistent geometry and\nappearance, even for scenes with complex lighting. We can also synthesize new\nscenes on curved surface with arbitrary lighting effects, which enhances the\npracticality of our proposed NeRF synthesis approach.\n","authors":["Chenbin Li","Yu Xin","Gaoyi Liu","Xiang Zeng","Ligang Liu"],"pdf_url":"https://arxiv.org/pdf/2306.11556v1.pdf","comment":"16 pages, 16 figures, accepted by CAD/Graphics 2023(poster)"},{"id":"http://arxiv.org/abs/2211.12514v2","updated":"2023-06-20T14:01:24Z","published":"2022-11-23T11:54:43Z","title":"AugOp: Inject Transformation into Neural Operator","summary":"  In this paper, we propose a simple and general approach to augment regular\nconvolution operator by injecting extra group-wise transformation during\ntraining and recover it during inference. Extra transformation is carefully\nselected to ensure it can be merged with regular convolution in each group and\nwill not change the topological structure of regular convolution during\ninference. Compared with regular convolution operator, our approach (AugConv)\ncan introduce larger learning capacity to improve model performance during\ntraining but will not increase extra computational overhead for model\ndeployment. Based on ResNet, we utilize AugConv to build convolutional neural\nnetworks named AugResNet. Result on image classification dataset Cifar-10 shows\nthat AugResNet outperforms its baseline in terms of model performance.\n","authors":["Longqing Ye"],"pdf_url":"https://arxiv.org/pdf/2211.12514v2.pdf","comment":"The results are greatly influenced by random seeds. The conclusion\n  may be wrong"},{"id":"http://arxiv.org/abs/2305.05344v2","updated":"2023-06-20T14:00:31Z","published":"2023-05-09T11:10:51Z","title":"Trustworthy Multi-phase Liver Tumor Segmentation via Evidence-based\n  Uncertainty","summary":"  Multi-phase liver contrast-enhanced computed tomography (CECT) images convey\nthe complementary multi-phase information for liver tumor segmentation (LiTS),\nwhich are crucial to assist the diagnosis of liver cancer clinically. However,\nthe performances of existing multi-phase liver tumor segmentation\n(MPLiTS)-based methods suffer from redundancy and weak interpretability, % of\nthe fused result, resulting in the implicit unreliability of clinical\napplications. In this paper, we propose a novel trustworthy multi-phase liver\ntumor segmentation (TMPLiTS), which is a unified framework jointly conducting\nsegmentation and uncertainty estimation. The trustworthy results could assist\nthe clinicians to make a reliable diagnosis. Specifically, Dempster-Shafer\nEvidence Theory (DST) is introduced to parameterize the segmentation and\nuncertainty as evidence following Dirichlet distribution. The reliability of\nsegmentation results among multi-phase CECT images is quantified explicitly.\nMeanwhile, a multi-expert mixture scheme (MEMS) is proposed to fuse the\nmulti-phase evidences, which can guarantee the effect of fusion procedure based\non theoretical analysis. Experimental results demonstrate the superiority of\nTMPLiTS compared with the state-of-the-art methods. Meanwhile, the robustness\nof TMPLiTS is verified, where the reliable performance can be guaranteed\nagainst the perturbations.\n","authors":["Chuanfei Hu","Tianyi Xia","Ying Cui","Quchen Zou","Yuancheng Wang","Wenbo Xiao","Shenghong Ju","Xinde Li"],"pdf_url":"https://arxiv.org/pdf/2305.05344v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11546v1","updated":"2023-06-20T13:59:20Z","published":"2023-06-20T13:59:20Z","title":"Bullying10K: A Neuromorphic Dataset towards Privacy-Preserving Bullying\n  Recognition","summary":"  The prevalence of violence in daily life poses significant threats to\nindividuals' physical and mental well-being. Using surveillance cameras in\npublic spaces has proven effective in proactively deterring and preventing such\nincidents. However, concerns regarding privacy invasion have emerged due to\ntheir widespread deployment. To address the problem, we leverage Dynamic Vision\nSensors (DVS) cameras to detect violent incidents and preserve privacy since it\ncaptures pixel brightness variations instead of static imagery. We introduce\nthe Bullying10K dataset, encompassing various actions, complex movements, and\nocclusions from real-life scenarios. It provides three benchmarks for\nevaluating different tasks: action recognition, temporal action localization,\nand pose estimation. With 10,000 event segments, totaling 12 billion events and\n255 GB of data, Bullying10K contributes significantly by balancing violence\ndetection and personal privacy persevering. And it also poses a challenge to\nthe neuromorphic dataset. It will serve as a valuable resource for training and\ndeveloping privacy-protecting video systems. The Bullying10K opens new\npossibilities for innovative approaches in these domains.\n","authors":["Yiting Dong","Yang Li","Dongcheng Zhao","Guobin Shen","Yi Zeng"],"pdf_url":"https://arxiv.org/pdf/2306.11546v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11541v1","updated":"2023-06-20T13:53:05Z","published":"2023-06-20T13:53:05Z","title":"Audio-Driven 3D Facial Animation from In-the-Wild Videos","summary":"  Given an arbitrary audio clip, audio-driven 3D facial animation aims to\ngenerate lifelike lip motions and facial expressions for a 3D head. Existing\nmethods typically rely on training their models using limited public 3D\ndatasets that contain a restricted number of audio-3D scan pairs. Consequently,\ntheir generalization capability remains limited. In this paper, we propose a\nnovel method that leverages in-the-wild 2D talking-head videos to train our 3D\nfacial animation model. The abundance of easily accessible 2D talking-head\nvideos equips our model with a robust generalization capability. By combining\nthese videos with existing 3D face reconstruction methods, our model excels in\ngenerating consistent and high-fidelity lip synchronization. Additionally, our\nmodel proficiently captures the speaking styles of different individuals,\nallowing it to generate 3D talking-heads with distinct personal styles.\nExtensive qualitative and quantitative experimental results demonstrate the\nsuperiority of our method.\n","authors":["Liying Lu","Tianke Zhang","Yunfei Liu","Xuangeng Chu","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2306.11541v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11536v1","updated":"2023-06-20T13:48:02Z","published":"2023-06-20T13:48:02Z","title":"Improving visual image reconstruction from human brain activity using\n  latent diffusion models via multiple decoded inputs","summary":"  The integration of deep learning and neuroscience has been advancing rapidly,\nwhich has led to improvements in the analysis of brain activity and the\nunderstanding of deep learning models from a neuroscientific perspective. The\nreconstruction of visual experience from human brain activity is an area that\nhas particularly benefited: the use of deep learning models trained on large\namounts of natural images has greatly improved its quality, and approaches that\ncombine the diverse information contained in visual experiences have\nproliferated rapidly in recent years. In this technical paper, by taking\nadvantage of the simple and generic framework that we proposed (Takagi and\nNishimoto, CVPR 2023), we examine the extent to which various additional\ndecoding techniques affect the performance of visual experience reconstruction.\nSpecifically, we combined our earlier work with the following three techniques:\nusing decoded text from brain activity, nonlinear optimization for structural\nimage reconstruction, and using decoded depth information from brain activity.\nWe confirmed that these techniques contributed to improving accuracy over the\nbaseline. We also discuss what researchers should consider when performing\nvisual reconstruction using deep generative models trained on large datasets.\nPlease check our webpage at\nhttps://sites.google.com/view/stablediffusion-with-brain/. Code is also\navailable at https://github.com/yu-takagi/StableDiffusionReconstruction.\n","authors":["Yu Takagi","Shinji Nishimoto"],"pdf_url":"https://arxiv.org/pdf/2306.11536v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11529v1","updated":"2023-06-20T13:32:01Z","published":"2023-06-20T13:32:01Z","title":"3D Keypoint Estimation Using Implicit Representation Learning","summary":"  In this paper, we tackle the challenging problem of 3D keypoint estimation of\ngeneral objects using a novel implicit representation. Previous works have\ndemonstrated promising results for keypoint prediction through direct\ncoordinate regression or heatmap-based inference. However, these methods are\ncommonly studied for specific subjects, such as human bodies and faces, which\npossess fixed keypoint structures. They also suffer in several practical\nscenarios where explicit or complete geometry is not given, including images\nand partial point clouds. Inspired by the recent success of advanced implicit\nrepresentation in reconstruction tasks, we explore the idea of using an\nimplicit field to represent keypoints. Specifically, our key idea is employing\nspheres to represent 3D keypoints, thereby enabling the learnability of the\ncorresponding signed distance field. Explicit keypoints can be extracted\nsubsequently by our algorithm based on the Hough transform. Quantitative and\nqualitative evaluations also show the superiority of our representation in\nterms of prediction accuracy.\n","authors":["Xiangyu Zhu","Dong Du","Haibin Huang","Chongyang Ma","Xiaoguang Han"],"pdf_url":"https://arxiv.org/pdf/2306.11529v1.pdf","comment":"Accepted by SGP 2023"},{"id":"http://arxiv.org/abs/2306.11528v1","updated":"2023-06-20T13:31:33Z","published":"2023-06-20T13:31:33Z","title":"TransRef: Multi-Scale Reference Embedding Transformer for\n  Reference-Guided Image Inpainting","summary":"  Image inpainting for completing complicated semantic environments and diverse\nhole patterns of corrupted images is challenging even for state-of-the-art\nlearning-based inpainting methods trained on large-scale data. A reference\nimage capturing the same scene of a corrupted image offers informative guidance\nfor completing the corrupted image as it shares similar texture and structure\npriors to that of the holes of the corrupted image. In this work, we propose a\ntransformer-based encoder-decoder network, named TransRef, for reference-guided\nimage inpainting. Specifically, the guidance is conducted progressively through\na reference embedding procedure, in which the referencing features are\nsubsequently aligned and fused with the features of the corrupted image. For\nprecise utilization of the reference features for guidance, a reference-patch\nalignment (Ref-PA) module is proposed to align the patch features of the\nreference and corrupted images and harmonize their style differences, while a\nreference-patch transformer (Ref-PT) module is proposed to refine the embedded\nreference feature. Moreover, to facilitate the research of reference-guided\nimage restoration tasks, we construct a publicly accessible benchmark dataset\ncontaining 50K pairs of input and reference images. Both quantitative and\nqualitative evaluations demonstrate the efficacy of the reference information\nand the proposed method over the state-of-the-art methods in completing complex\nholes. Code and dataset can be accessed at https://github.com/Cameltr/TransRef.\n","authors":["Liang Liao","Taorong Liu","Delin Chen","Jing Xiao","Zheng Wang","Chia-Wen Lin"],"pdf_url":"https://arxiv.org/pdf/2306.11528v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2306.11510v1","updated":"2023-06-20T13:01:19Z","published":"2023-06-20T13:01:19Z","title":"Pushing the Limits of 3D Shape Generation at Scale","summary":"  We present a significant breakthrough in 3D shape generation by scaling it to\nunprecedented dimensions. Through the adaptation of the Auto-Regressive model\nand the utilization of large language models, we have developed a remarkable\nmodel with an astounding 3.6 billion trainable parameters, establishing it as\nthe largest 3D shape generation model to date, named Argus-3D. Our approach\naddresses the limitations of existing methods by enhancing the quality and\ndiversity of generated 3D shapes. To tackle the challenges of high-resolution\n3D shape generation, our model incorporates tri-plane features as latent\nrepresentations, effectively reducing computational complexity. Additionally,\nwe introduce a discrete codebook for efficient quantization of these\nrepresentations. Leveraging the power of transformers, we enable multi-modal\nconditional generation, facilitating the production of diverse and visually\nimpressive 3D shapes. To train our expansive model, we leverage an ensemble of\npublicly-available 3D datasets, consisting of a comprehensive collection of\napproximately 900,000 objects from renowned repositories such as ModelNet40,\nShapeNet, Pix3D, 3D-Future, and Objaverse. This diverse dataset empowers our\nmodel to learn from a wide range of object variations, bolstering its ability\nto generate high-quality and diverse 3D shapes. Extensive experimentation\ndemonstrate the remarkable efficacy of our approach in significantly improving\nthe visual quality of generated 3D shapes. By pushing the boundaries of 3D\ngeneration, introducing novel methods for latent representation learning, and\nharnessing the power of transformers for multi-modal conditional generation,\nour contributions pave the way for substantial advancements in the field. Our\nwork unlocks new possibilities for applications in gaming, virtual reality,\nproduct design, and other domains that demand high-quality and diverse 3D\nobjects.\n","authors":["Wang Yu","Xuelin Qian","Jingyang Huo","Tiejun Huang","Bo Zhao","Yanwei Fu"],"pdf_url":"https://arxiv.org/pdf/2306.11510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11504v1","updated":"2023-06-20T12:50:49Z","published":"2023-06-20T12:50:49Z","title":"Align, Adapt and Inject: Sound-guided Unified Image Generation","summary":"  Text-guided image generation has witnessed unprecedented progress due to the\ndevelopment of diffusion models. Beyond text and image, sound is a vital\nelement within the sphere of human perception, offering vivid representations\nand naturally coinciding with corresponding scenes. Taking advantage of sound\ntherefore presents a promising avenue for exploration within image generation\nresearch. However, the relationship between audio and image supervision remains\nsignificantly underdeveloped, and the scarcity of related, high-quality\ndatasets brings further obstacles. In this paper, we propose a unified\nframework 'Align, Adapt, and Inject' (AAI) for sound-guided image generation,\nediting, and stylization. In particular, our method adapts input sound into a\nsound token, like an ordinary word, which can plug and play with existing\npowerful diffusion-based Text-to-Image (T2I) models. Specifically, we first\ntrain a multi-modal encoder to align audio representation with the pre-trained\ntextual manifold and visual manifold, respectively. Then, we propose the audio\nadapter to adapt audio representation into an audio token enriched with\nspecific semantics, which can be injected into a frozen T2I model flexibly. In\nthis way, we are able to extract the dynamic information of varied sounds,\nwhile utilizing the formidable capability of existing T2I models to facilitate\nsound-guided image generation, editing, and stylization in a convenient and\ncost-effective manner. The experiment results confirm that our proposed AAI\noutperforms other text and sound-guided state-of-the-art methods. And our\naligned multi-modal encoder is also competitive with other approaches in the\naudio-visual retrieval and audio-text retrieval tasks.\n","authors":["Yue Yang","Kaipeng Zhang","Yuying Ge","Wenqi Shao","Zeyue Xue","Yu Qiao","Ping Luo"],"pdf_url":"https://arxiv.org/pdf/2306.11504v1.pdf","comment":"Tech Report"},{"id":"http://arxiv.org/abs/2306.11496v1","updated":"2023-06-20T12:32:47Z","published":"2023-06-20T12:32:47Z","title":"EMoG: Synthesizing Emotive Co-speech 3D Gesture with Diffusion Model","summary":"  Although previous co-speech gesture generation methods are able to synthesize\nmotions in line with speech content, it is still not enough to handle diverse\nand complicated motion distribution. The key challenges are: 1) the one-to-many\nnature between the speech content and gestures; 2) the correlation modeling\nbetween the body joints. In this paper, we present a novel framework (EMoG) to\ntackle the above challenges with denoising diffusion models: 1) To alleviate\nthe one-to-many problem, we incorporate emotion clues to guide the generation\nprocess, making the generation much easier; 2) To model joint correlation, we\npropose to decompose the difficult gesture generation into two sub-problems:\njoint correlation modeling and temporal dynamics modeling. Then, the two\nsub-problems are explicitly tackled with our proposed Joint Correlation-aware\ntransFormer (JCFormer). Through extensive evaluations, we demonstrate that our\nproposed method surpasses previous state-of-the-art approaches, offering\nsubstantial superiority in gesture synthesis.\n","authors":["Lianying Yin","Yijun Wang","Tianyu He","Jinming Liu","Wei Zhao","Bohan Li","Xin Jin","Jianxin Lin"],"pdf_url":"https://arxiv.org/pdf/2306.11496v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2306.11490v1","updated":"2023-06-20T12:21:13Z","published":"2023-06-20T12:21:13Z","title":"UM-CAM: Uncertainty-weighted Multi-resolution Class Activation Maps for\n  Weakly-supervised Fetal Brain Segmentation","summary":"  Accurate segmentation of the fetal brain from Magnetic Resonance Image (MRI)\nis important for prenatal assessment of fetal development. Although deep\nlearning has shown the potential to achieve this task, it requires a large fine\nannotated dataset that is difficult to collect. To address this issue,\nweakly-supervised segmentation methods with image-level labels have gained\nattention, which are commonly based on class activation maps from a\nclassification network trained with image tags. However, most of these methods\nsuffer from incomplete activation regions, due to the low-resolution\nlocalization without detailed boundary cues. To this end, we propose a novel\nweakly-supervised method with image-level labels based on semantic features and\ncontext information exploration. We first propose an Uncertainty-weighted\nMulti-resolution Class Activation Map (UM-CAM) to generate high-quality\npixel-level supervision. Then, we design a Geodesic distance-based Seed\nExpansion (GSE) method to provide context information for rectifying the\nambiguous boundaries of UM-CAM. Extensive experiments on a fetal brain dataset\nshow that our UM-CAM can provide more accurate activation regions with fewer\nfalse positive regions than existing CAM variants, and our proposed method\noutperforms state-of-the-art weakly-supervised methods with image-level labels.\n","authors":["Jia Fu","Tao Lu","Shaoting Zhang","Guotai Wang"],"pdf_url":"https://arxiv.org/pdf/2306.11490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11414v1","updated":"2023-06-20T09:50:22Z","published":"2023-06-20T09:50:22Z","title":"Multi-Scale Occ: 4th Place Solution for CVPR 2023 3D Occupancy\n  Prediction Challenge","summary":"  In this report, we present the 4th place solution for CVPR 2023 3D occupancy\nprediction challenge. We propose a simple method called Multi-Scale Occ for\noccupancy prediction based on lift-splat-shoot framework, which introduces\nmulti-scale image features for generating better multi-scale 3D voxel features\nwith temporal fusion of multiple past frames. Post-processing including model\nensemble, test-time augmentation, and class-wise thresh are adopted to further\nboost the final performance. As shown on the leaderboard, our proposed\noccupancy prediction method ranks the 4th place with 49.36 mIoU.\n","authors":["Yangyang Ding","Luying Huang","Jiachen Zhong"],"pdf_url":"https://arxiv.org/pdf/2306.11414v1.pdf","comment":"The 4th place solution report for CVPR 2023 3D Occupancy Prediction\n  Challenge"},{"id":"http://arxiv.org/abs/2306.11406v1","updated":"2023-06-20T09:29:03Z","published":"2023-06-20T09:29:03Z","title":"Stable and Consistent Prediction of 3D Characteristic Orientation via\n  Invariant Residual Learning","summary":"  Learning to predict reliable characteristic orientations of 3D point clouds\nis an important yet challenging problem, as different point clouds of the same\nclass may have largely varying appearances. In this work, we introduce a novel\nmethod to decouple the shape geometry and semantics of the input point cloud to\nachieve both stability and consistency. The proposed method integrates\nshape-geometry-based SO(3)-equivariant learning and shape-semantics-based\nSO(3)-invariant residual learning, where a final characteristic orientation is\nobtained by calibrating an SO(3)-equivariant orientation hypothesis using an\nSO(3)-invariant residual rotation. In experiments, the proposed method not only\ndemonstrates superior stability and consistency but also exhibits\nstate-of-the-art performances when applied to point cloud part segmentation,\ngiven randomly rotated inputs.\n","authors":["Seungwook Kim","Chunghyun Park","Yoonwoo Jeong","Jaesik Park","Minsu Cho"],"pdf_url":"https://arxiv.org/pdf/2306.11406v1.pdf","comment":"Accepted to ICML 2023"},{"id":"http://arxiv.org/abs/2209.12221v4","updated":"2023-06-20T09:23:11Z","published":"2022-09-25T13:47:21Z","title":"Hand Hygiene Assessment via Joint Step Segmentation and Key Action\n  Scorer","summary":"  Hand hygiene is a standard six-step hand-washing action proposed by the World\nHealth Organization (WHO). However, there is no good way to supervise medical\nstaff to do hand hygiene, which brings the potential risk of disease spread.\nExisting action assessment works usually make an overall quality prediction on\nan entire video. However, the internal structures of hand hygiene action are\nimportant in hand hygiene assessment. Therefore, we propose a novel\nfine-grained learning framework to perform step segmentation and key action\nscorer in a joint manner for accurate hand hygiene assessment. Existing\ntemporal segmentation methods usually employ multi-stage convolutional network\nto improve the segmentation robustness, but easily lead to over-segmentation\ndue to the lack of the long-range dependence. To address this issue, we design\na multi-stage convolution-transformer network for step segmentation. Based on\nthe observation that each hand-washing step involves several key actions which\ndetermine the hand-washing quality, we design a set of key action scorers to\nevaluate the quality of key actions in each step. In addition, there lacks a\nunified dataset in hand hygiene assessment. Therefore, under the supervision of\nmedical staff, we contribute a video dataset that contains 300 video sequences\nwith fine-grained annotations. Extensive experiments on the dataset suggest\nthat our method well assesses hand hygiene videos and achieves outstanding\nperformance.\n","authors":["Chenglong Li","Qiwen Zhu","Tubiao Liu","Jin Tang","Yu Su"],"pdf_url":"https://arxiv.org/pdf/2209.12221v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11400v1","updated":"2023-06-20T09:15:52Z","published":"2023-06-20T09:15:52Z","title":"MuDPT: Multi-modal Deep-symphysis Prompt Tuning for Large Pre-trained\n  Vision-Language Models","summary":"  Prompt tuning, like CoOp, has recently shown promising vision recognizing and\ntransfer learning ability on various downstream tasks with the emergence of\nlarge pre-trained vision-language models like CLIP. However, we identify that\nexisting uni-modal prompt tuning approaches may result in sub-optimal\nperformance since this uni-modal design breaks the original alignment of\ntextual and visual representations in the pre-trained model. Inspired by the\nnature of pre-trained vision-language models, we aim to achieve completeness in\nprompt tuning and propose a novel approach called Multi-modal Deep-symphysis\nPrompt Tuning, dubbed as MuDPT, which extends independent multi-modal prompt\ntuning by additionally learning a model-agnostic transformative network to\nallow deep hierarchical bi-directional prompt fusion. We evaluate the\neffectiveness of MuDPT on few-shot vision recognition and out-of-domain\ngeneralization tasks. Compared with the state-of-the-art methods, MuDPT\nachieves better recognition and generalization ability with an apparent margin\nthanks to synergistic alignment of textual and visual representations. Our code\nis available at: https://github.com/Mechrev0/MuDPT.\n","authors":["Yongzhu Miao","Shasha Li","Jintao Tang","Ting Wang"],"pdf_url":"https://arxiv.org/pdf/2306.11400v1.pdf","comment":"The paper has been accepted by ICME 2023"},{"id":"http://arxiv.org/abs/2306.11378v1","updated":"2023-06-20T08:38:17Z","published":"2023-06-20T08:38:17Z","title":"Multi-task Collaborative Pre-training and Individual-adaptive-tokens\n  Fine-tuning: A Unified Framework for Brain Representation Learning","summary":"  Structural magnetic resonance imaging (sMRI) provides accurate estimates of\nthe brain's structural organization and learning invariant brain\nrepresentations from sMRI is an enduring issue in neuroscience. Previous deep\nrepresentation learning models ignore the fact that the brain, as the core of\nhuman cognitive activity, is distinct from other organs whose primary attribute\nis anatomy. Therefore, capturing the semantic structure that dominates\ninterindividual cognitive variability is key to accurately representing the\nbrain. Given that this high-level semantic information is subtle, distributed,\nand interdependently latent in the brain structure, sMRI-based models need to\ncapture fine-grained details and understand how they relate to the overall\nglobal structure. However, existing models are optimized by simple objectives,\nmaking features collapse into homogeneity and worsening simultaneous\nrepresentation of fine-grained information and holistic semantics, causing a\nlack of biological plausibility and interpretation of cognition. Here, we\npropose MCIAT, a unified framework that combines Multi-task Collaborative\npre-training and Individual-Adaptive-Tokens fine-tuning. Specifically, we first\nsynthesize restorative learning, age prediction auxiliary learning and\nadversarial learning as a joint proxy task for deep semantic representation\nlearning. Then, a mutual-attention-based token selection method is proposed to\nhighlight discriminative features. The proposed MCIAT achieves state-of-the-art\ndiagnosis performance on the ADHD-200 dataset compared with several sMRI-based\napproaches and shows superior generalization on the MCIC and OASIS datasets.\nMoreover, we studied 12 behavioral tasks and found significant associations\nbetween cognitive functions and MCIAT-established representations, which\nverifies the interpretability of our proposed framework.\n","authors":["Ning Jiang","Gongshu Wang","Tianyi Yan"],"pdf_url":"https://arxiv.org/pdf/2306.11378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11377v1","updated":"2023-06-20T08:36:08Z","published":"2023-06-20T08:36:08Z","title":"HabiCrowd: A High Performance Simulator for Crowd-Aware Visual\n  Navigation","summary":"  Visual navigation, a foundational aspect of Embodied AI (E-AI), has been\nsignificantly studied in the past few years. While many 3D simulators have been\nintroduced to support visual navigation tasks, scarcely works have been\ndirected towards combining human dynamics, creating the gap between simulation\nand real-world applications. Furthermore, current 3D simulators incorporating\nhuman dynamics have several limitations, particularly in terms of computational\nefficiency, which is a promise of E-AI simulators. To overcome these\nshortcomings, we introduce HabiCrowd, the first standard benchmark for\ncrowd-aware visual navigation that integrates a crowd dynamics model with\ndiverse human settings into photorealistic environments. Empirical evaluations\ndemonstrate that our proposed human dynamics model achieves state-of-the-art\nperformance in collision avoidance, while exhibiting superior computational\nefficiency compared to its counterparts. We leverage HabiCrowd to conduct\nseveral comprehensive studies on crowd-aware visual navigation tasks and\nhuman-robot interactions. The source code and data can be found at\nhttps://habicrowd.github.io/.\n","authors":["An Dinh Vuong","Toan Tien Nguyen","Minh Nhat VU","Baoru Huang","Dzung Nguyen","Huynh Thi Thanh Binh","Thieu Vo","Anh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2306.11377v1.pdf","comment":"14 pages, 10 figures"},{"id":"http://arxiv.org/abs/2206.00356v3","updated":"2023-06-20T08:28:38Z","published":"2022-06-01T09:43:10Z","title":"A Survey on Deep Learning for Skin Lesion Segmentation","summary":"  Skin cancer is a major public health problem that could benefit from\ncomputer-aided diagnosis to reduce the burden of this common disease. Skin\nlesion segmentation from images is an important step toward achieving this\ngoal. However, the presence of natural and artificial artifacts (e.g., hair and\nair bubbles), intrinsic factors (e.g., lesion shape and contrast), and\nvariations in image acquisition conditions make skin lesion segmentation a\nchallenging task. Recently, various researchers have explored the applicability\nof deep learning models to skin lesion segmentation. In this survey, we\ncross-examine 177 research papers that deal with deep learning-based\nsegmentation of skin lesions. We analyze these works along several dimensions,\nincluding input data (datasets, preprocessing, and synthetic data generation),\nmodel design (architecture, modules, and losses), and evaluation aspects (data\nannotation requirements and segmentation performance). We discuss these\ndimensions both from the viewpoint of select seminal works, and from a\nsystematic viewpoint, examining how those choices have influenced current\ntrends, and how their limitations should be addressed. To facilitate\ncomparisons, we summarize all examined works in a comprehensive table as well\nas an interactive table available online at\nhttps://github.com/sfu-mial/skin-lesion-segmentation-survey.\n","authors":["Zahra Mirikharaji","Kumar Abhishek","Alceu Bissoto","Catarina Barata","Sandra Avila","Eduardo Valle","M. Emre Celebi","Ghassan Hamarneh"],"pdf_url":"https://arxiv.org/pdf/2206.00356v3.pdf","comment":"Published in Medical Image Analysis (2023); 55 pages, 10 figures;\n  Mirikharaji and Abhishek: Joint first authors; Celebi and Hamarneh: Joint\n  senior authors"},{"id":"http://arxiv.org/abs/2304.04591v2","updated":"2023-06-20T08:23:01Z","published":"2023-04-10T13:52:19Z","title":"For Pre-Trained Vision Models in Motor Control, Not All Policy Learning\n  Methods are Created Equal","summary":"  In recent years, increasing attention has been directed to leveraging\npre-trained vision models for motor control. While existing works mainly\nemphasize the importance of this pre-training phase, the arguably equally\nimportant role played by downstream policy learning during control-specific\nfine-tuning is often neglected. It thus remains unclear if pre-trained vision\nmodels are consistent in their effectiveness under different control policies.\nTo bridge this gap in understanding, we conduct a comprehensive study on 14\npre-trained vision models using 3 distinct classes of policy learning methods,\nincluding reinforcement learning (RL), imitation learning through behavior\ncloning (BC), and imitation learning with a visual reward function (VRF). Our\nstudy yields a series of intriguing results, including the discovery that the\neffectiveness of pre-training is highly dependent on the choice of the\ndownstream policy learning algorithm. We show that conventionally accepted\nevaluation based on RL methods is highly variable and therefore unreliable, and\nfurther advocate for using more robust methods like VRF and BC. To facilitate\nmore universal evaluations of pre-trained models and their policy learning\nmethods in the future, we also release a benchmark of 21 tasks across 3\ndifferent environments alongside our work.\n","authors":["Yingdong Hu","Renhao Wang","Li Erran Li","Yang Gao"],"pdf_url":"https://arxiv.org/pdf/2304.04591v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.10950v2","updated":"2023-06-20T08:21:06Z","published":"2023-04-21T13:40:30Z","title":"Factored Neural Representation for Scene Understanding","summary":"  A long-standing goal in scene understanding is to obtain interpretable and\neditable representations that can be directly constructed from a raw monocular\nRGB-D video, without requiring specialized hardware setup or priors. The\nproblem is significantly more challenging in the presence of multiple moving\nand/or deforming objects. Traditional methods have approached the setup with a\nmix of simplifications, scene priors, pretrained templates, or known\ndeformation models. The advent of neural representations, especially neural\nimplicit representations and radiance fields, opens the possibility of\nend-to-end optimization to collectively capture geometry, appearance, and\nobject motion. However, current approaches produce global scene encoding,\nassume multiview capture with limited or no motion in the scenes, and do not\nfacilitate easy manipulation beyond novel view synthesis. In this work, we\nintroduce a factored neural scene representation that can directly be learned\nfrom a monocular RGB-D video to produce object-level neural presentations with\nan explicit encoding of object movement (e.g., rigid trajectory) and/or\ndeformations (e.g., nonrigid movement). We evaluate ours against a set of\nneural approaches on both synthetic and real data to demonstrate that the\nrepresentation is efficient, interpretable, and editable (e.g., change object\ntrajectory). Code and data are available at:\n$\\href{http://geometry.cs.ucl.ac.uk/projects/2023/factorednerf/}{\\text{http://geometry.cs.ucl.ac.uk/projects/2023/factorednerf/}}$.\n","authors":["Yu-Shiang Wong","Niloy J. Mitra"],"pdf_url":"https://arxiv.org/pdf/2304.10950v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11369v1","updated":"2023-06-20T08:19:51Z","published":"2023-06-20T08:19:51Z","title":"CrossKD: Cross-Head Knowledge Distillation for Dense Object Detection","summary":"  Knowledge Distillation (KD) has been validated as an effective model\ncompression technique for learning compact object detectors. Existing\nstate-of-the-art KD methods for object detection are mostly based on feature\nimitation, which is generally observed to be better than prediction mimicking.\nIn this paper, we show that the inconsistency of the optimization objectives\nbetween the ground-truth signals and distillation targets is the key reason for\nthe inefficiency of prediction mimicking. To alleviate this issue, we present a\nsimple yet effective distillation scheme, termed CrossKD, which delivers the\nintermediate features of the student's detection head to the teacher's\ndetection head. The resulting cross-head predictions are then forced to mimic\nthe teacher's predictions. Such a distillation manner relieves the student's\nhead from receiving contradictory supervision signals from the ground-truth\nannotations and the teacher's predictions, greatly improving the student's\ndetection performance. On MS COCO, with only prediction mimicking losses\napplied, our CrossKD boosts the average precision of GFL ResNet-50 with 1x\ntraining schedule from 40.2 to 43.7, outperforming all existing KD methods for\nobject detection. Code is available at https://github.com/jbwang1997/CrossKD.\n","authors":["Jiabao Wang","Yuming Chen","Zhaohui Zheng","Xiang Li","Ming-Ming Cheng","Qibin Hou"],"pdf_url":"https://arxiv.org/pdf/2306.11369v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11368v1","updated":"2023-06-20T08:16:25Z","published":"2023-06-20T08:16:25Z","title":"RoMe: Towards Large Scale Road Surface Reconstruction via Mesh\n  Representation","summary":"  Large-scale road surface reconstruction is becoming important to autonomous\ndriving systems, as it provides valuable training and testing data effectively.\nIn this paper, we introduce a simple yet efficient method, RoMe, for\nlarge-scale Road surface reconstruction via Mesh representations. To simplify\nthe problem, RoMe decomposes a 3D road surface into a triangle-mesh and a\nmultilayer perception network to model the road elevation implicitly. To retain\nfine surface details, each mesh vertex has two extra attributes, namely color\nand semantics. To improve the efficiency of RoMe in large-scale environments, a\nnovel waypoint sampling method is introduced. As such, RoMe can properly\npreserve road surface details, with only linear computational complexity to\nroad areas. In addition, to improve the accuracy of RoMe, extrinsics\noptimization is proposed to mitigate inaccurate extrinsic calibrations.\nExperimental results on popular public datasets also demonstrate the high\nefficiency and accuracy of RoMe.\n","authors":["Ruohong Mei","Wei Sui","Jiaxin Zhang","Qian Zhang","Tao Peng","Cong Yang"],"pdf_url":"https://arxiv.org/pdf/2306.11368v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.05661v2","updated":"2023-06-20T08:07:09Z","published":"2023-04-12T07:39:20Z","title":"SuperpixelGraph: Semi-automatic generation of building footprint through\n  semantic-sensitive superpixel and neural graph networks","summary":"  Most urban applications necessitate building footprints in the form of\nconcise vector graphics with sharp boundaries rather than pixel-wise raster\nimages. This need contrasts with the majority of existing methods, which\ntypically generate over-smoothed footprint polygons. Editing these\nautomatically produced polygons can be inefficient, if not more time-consuming\nthan manual digitization. This paper introduces a semi-automatic approach for\nbuilding footprint extraction through semantically-sensitive superpixels and\nneural graph networks. Drawing inspiration from object-based classification\ntechniques, we first learn to generate superpixels that are not only\nboundary-preserving but also semantically-sensitive. The superpixels respond\nexclusively to building boundaries rather than other natural objects, while\nsimultaneously producing semantic segmentation of the buildings. These\nintermediate superpixel representations can be naturally considered as nodes\nwithin a graph. Consequently, graph neural networks are employed to model the\nglobal interactions among all superpixels and enhance the representativeness of\nnode features for building segmentation. Classical approaches are utilized to\nextract and regularize boundaries for the vectorized building footprints.\nUtilizing minimal clicks and straightforward strokes, we efficiently accomplish\naccurate segmentation outcomes, eliminating the necessity for editing polygon\nvertices. Our proposed approach demonstrates superior precision and efficacy,\nas validated by experimental assessments on various public benchmark datasets.\nA significant improvement of 8% in AP50 was observed in vector graphics\nevaluation, surpassing established techniques. Additionally, we have devised an\noptimized and sophisticated pipeline for interactive editing, poised to further\naugment the overall quality of the results.\n","authors":["Haojia Yu","Han Hu","Bo Xu","Qisen Shang","Zhendong Wang","Qing Zhu"],"pdf_url":"https://arxiv.org/pdf/2304.05661v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.08309v2","updated":"2023-06-20T08:03:35Z","published":"2023-06-14T07:27:06Z","title":"Taming Reversible Halftoning via Predictive Luminance","summary":"  Traditional halftoning usually drops colors when dithering images with binary\ndots, which makes it difficult to recover the original color information. We\nproposed a novel halftoning technique that converts a color image into a binary\nhalftone with full restorability to its original version. Our novel base\nhalftoning technique consists of two convolutional neural networks (CNNs) to\nproduce the reversible halftone patterns, and a noise incentive block (NIB) to\nmitigate the flatness degradation issue of CNNs. Furthermore, to tackle the\nconflicts between the blue-noise quality and restoration accuracy in our novel\nbase method, we proposed a predictor-embedded approach to offload predictable\ninformation from the network, which in our case is the luminance information\nresembling from the halftone pattern. Such an approach allows the network to\ngain more flexibility to produce halftones with better blue-noise quality\nwithout compromising the restoration quality. Detailed studies on the\nmultiple-stage training method and loss weightings have been conducted. We have\ncompared our predictor-embedded method and our novel method regarding spectrum\nanalysis on halftone, halftone accuracy, restoration accuracy, and the data\nembedding studies. Our entropy evaluation evidences our halftone contains less\nencoding information than our novel base method. The experiments show our\npredictor-embedded method gains more flexibility to improve the blue-noise\nquality of halftones and maintains a comparable restoration quality with a\nhigher tolerance for disturbances.\n","authors":["Cheuk-Kit Lau","Menghan Xia","Tien-Tsin Wong"],"pdf_url":"https://arxiv.org/pdf/2306.08309v2.pdf","comment":"to be published in IEEE Transactions on Visualization and Computer\n  Graphics"},{"id":"http://arxiv.org/abs/2306.11363v1","updated":"2023-06-20T08:02:59Z","published":"2023-06-20T08:02:59Z","title":"Masked Diffusion Models are Fast Learners","summary":"  Diffusion models have emerged as the de-facto technique for image generation,\nyet they entail significant computational overhead, hindering the technique's\nbroader application in the research community. We propose a prior-based\ndenoising training framework, the first to incorporate the pre-train and\nfine-tune paradigm into the diffusion model training process, which\nsubstantially improves training efficiency and shows potential in facilitating\nvarious downstream tasks. Our approach centers on masking a high proportion\n(e.g., up to 90%) of the input image and employing masked score matching to\ndenoise the visible areas, thereby guiding the diffusion model to learn more\nsalient features from training data as prior knowledge. By utilizing this\nmasked learning process in a pre-training stage, we efficiently train the\nViT-based diffusion model on CelebA-HQ 256x256 in the pixel space, achieving a\n4x acceleration and enhancing the quality of generated images compared to DDPM.\nMoreover, our masked pre-training technique is universally applicable to\nvarious diffusion models that directly generate images in the pixel space and\nfacilitates learning pre-trained models with excellent generalizability: a\ndiffusion model pre-trained on VGGFace2 attains a 46% quality improvement\nthrough fine-tuning with merely 10% local data. Our code is available at\nhttps://github.com/jiachenlei/maskdm.\n","authors":["Jiachen Lei","Peng Cheng","Zhongjie Ba","Kui Ren"],"pdf_url":"https://arxiv.org/pdf/2306.11363v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11346v1","updated":"2023-06-20T07:28:40Z","published":"2023-06-20T07:28:40Z","title":"End-to-end 2D-3D Registration between Image and LiDAR Point Cloud for\n  Vehicle Localization","summary":"  Robot localization using a previously built map is essential for a variety of\ntasks including highly accurate navigation and mobile manipulation. A popular\napproach to robot localization is based on image-to-point cloud registration,\nwhich combines illumination-invariant LiDAR-based mapping with economical\nimage-based localization. However, the recent works for image-to-point cloud\nregistration either divide the registration into separate modules or project\nthe point cloud to the depth image to register the RGB and depth images. In\nthis paper, we present I2PNet, a novel end-to-end 2D-3D registration network.\nI2PNet directly registers the raw 3D point cloud with the 2D RGB image using\ndifferential modules with a unique target. The 2D-3D cost volume module for\ndifferential 2D-3D association is proposed to bridge feature extraction and\npose regression. 2D-3D cost volume module implicitly constructs the soft\npoint-to-pixel correspondence on the intrinsic-independent normalized plane of\nthe pinhole camera model. Moreover, we introduce an outlier mask prediction\nmodule to filter the outliers in the 2D-3D association before pose regression.\nFurthermore, we propose the coarse-to-fine 2D-3D registration architecture to\nincrease localization accuracy. We conduct extensive localization experiments\non the KITTI Odometry and nuScenes datasets. The results demonstrate that\nI2PNet outperforms the state-of-the-art by a large margin. In addition, I2PNet\nhas a higher efficiency than the previous works and can perform the\nlocalization in real-time. Moreover, we extend the application of I2PNet to the\ncamera-LiDAR online calibration and demonstrate that I2PNet outperforms recent\napproaches on the online calibration task.\n","authors":["Guangming Wang","Yu Zheng","Yanfeng Guo","Zhe Liu","Yixiang Zhu","Wolfram Burgard","Hesheng Wang"],"pdf_url":"https://arxiv.org/pdf/2306.11346v1.pdf","comment":"18 pages, 14 figures, under review"},{"id":"http://arxiv.org/abs/2306.11345v1","updated":"2023-06-20T07:27:28Z","published":"2023-06-20T07:27:28Z","title":"KiUT: Knowledge-injected U-Transformer for Radiology Report Generation","summary":"  Radiology report generation aims to automatically generate a clinically\naccurate and coherent paragraph from the X-ray image, which could relieve\nradiologists from the heavy burden of report writing. Although various image\ncaption methods have shown remarkable performance in the natural image field,\ngenerating accurate reports for medical images requires knowledge of multiple\nmodalities, including vision, language, and medical terminology. We propose a\nKnowledge-injected U-Transformer (KiUT) to learn multi-level visual\nrepresentation and adaptively distill the information with contextual and\nclinical knowledge for word prediction. In detail, a U-connection schema\nbetween the encoder and decoder is designed to model interactions between\ndifferent modalities. And a symptom graph and an injected knowledge distiller\nare developed to assist the report generation. Experimentally, we outperform\nstate-of-the-art methods on two widely used benchmark datasets: IU-Xray and\nMIMIC-CXR. Further experimental results prove the advantages of our\narchitecture and the complementary benefits of the injected knowledge.\n","authors":["Zhongzhen Huang","Xiaofan Zhang","Shaoting Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.11345v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11341v1","updated":"2023-06-20T07:19:36Z","published":"2023-06-20T07:19:36Z","title":"MSVD-Indonesian: A Benchmark for Multimodal Video-Text Tasks in\n  Indonesian","summary":"  Multimodal learning on video and text data has been receiving growing\nattention from many researchers in various research tasks, including\ntext-to-video retrieval, video-to-text retrieval, and video captioning.\nAlthough many algorithms have been proposed for those challenging tasks, most\nof them are developed on English language datasets. Despite Indonesian being\none of the most spoken languages in the world, the research progress on the\nmultimodal video-text with Indonesian sentences is still under-explored, likely\ndue to the absence of the public benchmark dataset. To address this issue, we\nconstruct the first public Indonesian video-text dataset by translating English\nsentences from the MSVD dataset to Indonesian sentences. Using our dataset, we\nthen train neural network models which were developed for the English\nvideo-text dataset on three tasks, i.e., text-to-video retrieval, video-to-text\nretrieval, and video captioning. The recent neural network-based approaches to\nvideo-text tasks often utilized a feature extractor that is primarily\npretrained on an English vision-language dataset. Since the availability of the\npretraining resources with Indonesian sentences is relatively limited, the\napplicability of those approaches to our dataset is still questionable. To\novercome the lack of pretraining resources, we apply cross-lingual transfer\nlearning by utilizing the feature extractors pretrained on the English dataset,\nand we then fine-tune the models on our Indonesian dataset. Our experimental\nresults show that this approach can help to improve the performance for the\nthree tasks on all metrics. Finally, we discuss potential future works using\nour dataset, inspiring further research in the Indonesian multimodal video-text\ntasks. We believe that our dataset and our experimental results could provide\nvaluable contributions to the community. Our dataset is available on GitHub.\n","authors":["Willy Fitra Hendria"],"pdf_url":"https://arxiv.org/pdf/2306.11341v1.pdf","comment":"13 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2306.11339v1","updated":"2023-06-20T07:17:38Z","published":"2023-06-20T07:17:38Z","title":"Augmenting Sub-model to Improve Main Model","summary":"  Image classification has improved with the development of training\ntechniques. However, these techniques often require careful parameter tuning to\nbalance the strength of regularization, limiting their potential benefits. In\nthis paper, we propose a novel way to use regularization called Augmenting\nSub-model (AugSub). AugSub consists of two models: the main model and the\nsub-model. While the main model employs conventional training recipes, the\nsub-model leverages the benefit of additional regularization. AugSub achieves\nthis by mitigating adverse effects through a relaxed loss function similar to\nself-distillation loss. We demonstrate the effectiveness of AugSub with three\ndrop techniques: dropout, drop-path, and random masking. Our analysis shows\nthat all AugSub improves performance, with the training loss converging even\nfaster than regular training. Among the three, AugMask is identified as the\nmost practical method due to its performance and cost efficiency. We further\nvalidate AugMask across diverse training recipes, including DeiT-III, ResNet,\nMAE fine-tuning, and Swin Transformer. The results show that AugMask\nconsistently provides significant performance gain. AugSub provides a practical\nand effective solution for introducing additional regularization under various\ntraining recipes. Code is available at\n\\url{https://github.com/naver-ai/augsub}.\n","authors":["Byeongho Heo","Taekyung Kim","Sangdoo Yun","Dongyoon Han"],"pdf_url":"https://arxiv.org/pdf/2306.11339v1.pdf","comment":"15 pages, 3 figures"},{"id":"http://arxiv.org/abs/2306.11335v1","updated":"2023-06-20T07:06:04Z","published":"2023-06-20T07:06:04Z","title":"RM-PRT: Realistic Robotic Manipulation Simulator and Benchmark with\n  Progressive Reasoning Tasks","summary":"  Recently, the advent of pre-trained large-scale language models (LLMs) like\nChatGPT and GPT-4 have significantly advanced the machine's natural language\nunderstanding capabilities. This breakthrough has allowed us to seamlessly\nintegrate these open-source LLMs into a unified robot simulator environment to\nhelp robots accurately understand and execute human natural language\ninstructions. To this end, in this work, we introduce a realistic robotic\nmanipulation simulator and build a Robotic Manipulation with Progressive\nReasoning Tasks (RM-PRT) benchmark on this basis. Specifically, the RM-PRT\nbenchmark builds a new high-fidelity digital twin scene based on Unreal Engine\n5, which includes 782 categories, 2023 objects, and 15K natural language\ninstructions generated by ChatGPT for a detailed evaluation of robot\nmanipulation. We propose a general pipeline for the RM-PRT benchmark that takes\nas input multimodal prompts containing natural language instructions and\nautomatically outputs actions containing the movement and position transitions.\nWe set four natural language understanding tasks with progressive reasoning\nlevels and evaluate the robot's ability to understand natural language\ninstructions in two modes of adsorption and grasping. In addition, we also\nconduct a comprehensive analysis and comparison of the differences and\nadvantages of 10 different LLMs in instruction understanding and generation\nquality. We hope the new simulator and benchmark will facilitate future\nresearch on language-guided robotic manipulation. Project website:\nhttps://necolizer.github.io/RM-PRT/ .\n","authors":["Pengzhen Ren","Kaidong Zhang","Hetao Zheng","Zixuan Li","Yuhang Wen","Fengda Zhu","Mas Ma","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2306.11335v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11334v1","updated":"2023-06-20T07:03:37Z","published":"2023-06-20T07:03:37Z","title":"Depth and DOF Cues Make A Better Defocus Blur Detector","summary":"  Defocus blur detection (DBD) separates in-focus and out-of-focus regions in\nan image. Previous approaches mistakenly mistook homogeneous areas in focus for\ndefocus blur regions, likely due to not considering the internal factors that\ncause defocus blur. Inspired by the law of depth, depth of field (DOF), and\ndefocus, we propose an approach called D-DFFNet, which incorporates depth and\nDOF cues in an implicit manner. This allows the model to understand the defocus\nphenomenon in a more natural way. Our method proposes a depth feature\ndistillation strategy to obtain depth knowledge from a pre-trained monocular\ndepth estimation model and uses a DOF-edge loss to understand the relationship\nbetween DOF and depth. Our approach outperforms state-of-the-art methods on\npublic benchmarks and a newly collected large benchmark dataset, EBD. Source\ncodes and EBD dataset are available at: https:github.com/yuxinjin-whu/D-DFFNet.\n","authors":["Yuxin Jin","Ming Qian","Jincheng Xiong","Nan Xue","Gui-Song Xia"],"pdf_url":"https://arxiv.org/pdf/2306.11334v1.pdf","comment":"Code: https://github.com/yuxinjin-whu/D-DFFNet"},{"id":"http://arxiv.org/abs/2306.11326v1","updated":"2023-06-20T06:50:50Z","published":"2023-06-20T06:50:50Z","title":"Meerkat Behaviour Recognition Dataset","summary":"  Recording animal behaviour is an important step in evaluating the well-being\nof animals and further understanding the natural world. Current methods for\ndocumenting animal behaviour within a zoo setting, such as scan sampling,\nrequire excessive human effort, are unfit for around-the-clock monitoring, and\nmay produce human-biased results. Several animal datasets already exist that\nfocus predominantly on wildlife interactions, with some extending to action or\nbehaviour recognition. However, there is limited data in a zoo setting or data\nfocusing on the group behaviours of social animals. We introduce a large\nmeerkat (Suricata Suricatta) behaviour recognition video dataset with diverse\nannotated behaviours, including group social interactions, tracking of\nindividuals within the camera view, skewed class distribution, and varying\nillumination conditions. This dataset includes videos from two positions within\nthe meerkat enclosure at the Wellington Zoo (Wellington, New Zealand), with\n848,400 annotated frames across 20 videos and 15 unannotated videos.\n","authors":["Mitchell Rogers","Gaël Gendron","David Arturo Soriano Valdez","Mihailo Azhar","Yang Chen","Shahrokh Heidari","Caleb Perelini","Padriac O'Leary","Kobe Knowles","Izak Tait","Simon Eyre","Michael Witbrock","Patrice Delmas"],"pdf_url":"https://arxiv.org/pdf/2306.11326v1.pdf","comment":"Presented as a poster for the CV4Animals Workshop, CVPR 2023. For\n  associated dataset see: https://meerkat-dataset.github.io/"},{"id":"http://arxiv.org/abs/2211.14813v2","updated":"2023-06-20T06:36:09Z","published":"2022-11-27T12:38:52Z","title":"SegCLIP: Patch Aggregation with Learnable Centers for Open-Vocabulary\n  Semantic Segmentation","summary":"  Recently, the contrastive language-image pre-training, e.g., CLIP, has\ndemonstrated promising results on various downstream tasks. The pre-trained\nmodel can capture enriched visual concepts for images by learning from a large\nscale of text-image data. However, transferring the learned visual knowledge to\nopen-vocabulary semantic segmentation is still under-explored. In this paper,\nwe propose a CLIP-based model named SegCLIP for the topic of open-vocabulary\nsegmentation in an annotation-free manner. The SegCLIP achieves segmentation\nbased on ViT and the main idea is to gather patches with learnable centers to\nsemantic regions through training on text-image pairs. The gathering operation\ncan dynamically capture the semantic groups, which can be used to generate the\nfinal segmentation results. We further propose a reconstruction loss on masked\npatches and a superpixel-based KL loss with pseudo-labels to enhance the visual\nrepresentation. Experimental results show that our model achieves comparable or\nsuperior segmentation accuracy on the PASCAL VOC 2012 (+0.3% mIoU), PASCAL\nContext (+2.3% mIoU), and COCO (+2.2% mIoU) compared with baselines. We release\nthe code at https://github.com/ArrowLuo/SegCLIP.\n","authors":["Huaishao Luo","Junwei Bao","Youzheng Wu","Xiaodong He","Tianrui Li"],"pdf_url":"https://arxiv.org/pdf/2211.14813v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2103.07073v2","updated":"2023-06-20T06:26:31Z","published":"2021-03-12T04:02:23Z","title":"DP-Image: Differential Privacy for Image Data in Feature Space","summary":"  The excessive use of images in social networks, government databases, and\nindustrial applications has posed great privacy risks and raised serious\nconcerns from the public. Even though differential privacy (DP) is a widely\naccepted criterion that can provide a provable privacy guarantee, the\napplication of DP on unstructured data such as images is not trivial due to the\nlack of a clear qualification on the meaningful difference between any two\nimages. In this paper, for the first time, we introduce a novel notion of\nimage-aware differential privacy, referred to as DP-image, that can protect\nuser's personal information in images, from both human and AI adversaries. The\nDP-Image definition is formulated as an extended version of traditional\ndifferential privacy, considering the distance measurements between feature\nspace vectors of images. Then we propose a mechanism to achieve DP-Image by\nadding noise to an image feature vector. Finally, we conduct experiments with a\ncase study on face image privacy. Our results show that the proposed DP-Image\nmethod provides excellent DP protection on images, with a controllable\ndistortion to faces.\n","authors":["Hanyu Xue","Bo Liu","Ming Ding","Tianqing Zhu","Dayong Ye","Li Song","Wanlei Zhou"],"pdf_url":"https://arxiv.org/pdf/2103.07073v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11316v1","updated":"2023-06-20T06:25:48Z","published":"2023-06-20T06:25:48Z","title":"Unfolding Framework with Prior of Convolution-Transformer Mixture and\n  Uncertainty Estimation for Video Snapshot Compressive Imaging","summary":"  We consider the problem of video snapshot compressive imaging (SCI), where\nsequential high-speed frames are modulated by different masks and captured by a\nsingle measurement. The underlying principle of reconstructing multi-frame\nimages from only one single measurement is to solve an ill-posed problem. By\ncombining optimization algorithms and neural networks, deep unfolding networks\n(DUNs) score tremendous achievements in solving inverse problems. In this\npaper, our proposed model is under the DUN framework and we propose a 3D\nConvolution-Transformer Mixture (CTM) module with a 3D efficient and scalable\nattention model plugged in, which helps fully learn the correlation between\ntemporal and spatial dimensions by virtue of Transformer. To our best\nknowledge, this is the first time that Transformer is employed to video SCI\nreconstruction. Besides, to further investigate the high-frequency information\nduring the reconstruction process which are neglected in previous studies, we\nintroduce variance estimation characterizing the uncertainty on a\npixel-by-pixel basis. Extensive experimental results demonstrate that our\nproposed method achieves state-of-the-art (SOTA) (with a 1.2dB gain in PSNR\nover previous SOTA algorithm) results. We will release the code.\n","authors":["Siming Zheng","Xin Yuan"],"pdf_url":"https://arxiv.org/pdf/2306.11316v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.09682v2","updated":"2023-06-20T06:06:55Z","published":"2023-06-16T08:26:57Z","title":"OCTScenes: A Versatile Real-World Dataset of Tabletop Scenes for\n  Object-Centric Learning","summary":"  Humans possess the cognitive ability to comprehend scenes in a compositional\nmanner. To empower AI systems with similar abilities, object-centric\nrepresentation learning aims to acquire representations of individual objects\nfrom visual scenes without any supervision. Although recent advancements in\nobject-centric representation learning have achieved remarkable progress on\ncomplex synthesis datasets, there is a huge challenge for application in\ncomplex real-world scenes. One of the essential reasons is the scarcity of\nreal-world datasets specifically tailored to object-centric representation\nlearning methods. To solve this problem, we propose a versatile real-world\ndataset of tabletop scenes for object-centric learning called OCTScenes, which\nis meticulously designed to serve as a benchmark for comparing, evaluating and\nanalyzing object-centric representation learning methods. OCTScenes contains\n5000 tabletop scenes with a total of 15 everyday objects. Each scene is\ncaptured in 60 frames covering a 360-degree perspective. Consequently,\nOCTScenes is a versatile benchmark dataset that can simultaneously satisfy the\nevaluation of object-centric representation learning methods across static\nscenes, dynamic scenes, and multi-view scenes tasks. Extensive experiments of\nobject-centric representation learning methods for static, dynamic and\nmulti-view scenes are conducted on OCTScenes. The results demonstrate the\nshortcomings of state-of-the-art methods for learning meaningful\nrepresentations from real-world data, despite their impressive performance on\ncomplex synthesis datasets. Furthermore, OCTScenes can serves as a catalyst for\nadvancing existing state-of-the-art methods, inspiring them to adapt to\nreal-world scenes. Dataset and code are available at\nhttps://huggingface.co/datasets/Yinxuan/OCTScenes.\n","authors":["Yinxuan Huang","Tonglin Chen","Zhimeng Shen","Jinghao Huang","Bin Li","Xiangyang Xue"],"pdf_url":"https://arxiv.org/pdf/2306.09682v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11305v1","updated":"2023-06-20T06:02:19Z","published":"2023-06-20T06:02:19Z","title":"Progressive Neural Representation for Sequential Video Compilation","summary":"  Neural Implicit Representations (NIR) have gained significant attention\nrecently due to their ability to represent complex and high-dimensional data.\nUnlike explicit representations, which require storing and manipulating\nindividual data points, implicit representations capture information through a\nlearned mapping function without explicitly representing the data points\nthemselves. They often prune or quantize neural networks after training to\naccelerate encoding/decoding speed, yet we find that conventional methods fail\nto transfer learned representations to new videos. This work studies the\ncontinuous expansion of implicit video representations as videos arrive\nsequentially over time, where the model can only access the videos from the\ncurrent session. We propose a novel neural video representation, Progressive\nNeural Representation (PNR), that finds an adaptive substructure from the\nsupernet for a given video based on Lottery Ticket Hypothesis. At each training\nsession, our PNR transfers the learned knowledge of the previously obtained\nsubnetworks to learn the representation of the current video while keeping the\npast subnetwork weights intact. Therefore it can almost perfectly preserve the\ndecoding ability (i.e., catastrophic forgetting) of the NIR on previous videos.\nWe demonstrate the effectiveness of our proposed PNR on the neural sequential\nvideo representation compilation on the novel UVG8/17 video sequence\nbenchmarks.\n","authors":["Haeyong Kang","DaHyun Kim","Jaehong Yoon","Sung Ju Hwang","Chang D Yoo"],"pdf_url":"https://arxiv.org/pdf/2306.11305v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11300v1","updated":"2023-06-20T05:30:59Z","published":"2023-06-20T05:30:59Z","title":"RS5M: A Large Scale Vision-Language Dataset for Remote Sensing\n  Vision-Language Foundation Model","summary":"  Pre-trained Vision-Language Foundation Models utilizing extensive image-text\npaired data have demonstrated unprecedented image-text association\ncapabilities, achieving remarkable results across various downstream tasks. A\ncritical challenge is how to make use of existing large-scale pre-trained VLMs,\nwhich are trained on common objects, to perform the domain-specific transfer\nfor accomplishing domain-related downstream tasks. In this paper, we propose a\nnew framework that includes the Domain Foundation Model (DFM), bridging the gap\nbetween the General Foundation Model (GFM) and domain-specific downstream\ntasks. Moreover, we present an image-text paired dataset in the field of remote\nsensing (RS), RS5M, which has 5 million RS images with English descriptions.\nThe dataset is obtained from filtering publicly available image-text paired\ndatasets and captioning label-only RS datasets with pre-trained VLM. These\nconstitute the first large-scale RS image-text paired dataset. Additionally, we\ntried several Parameter-Efficient Fine-Tuning methods on RS5M to implement the\nDFM. Experimental results show that our proposed dataset are highly effective\nfor various tasks, improving upon the baseline by $8 \\% \\sim 16 \\%$ in\nzero-shot classification tasks, and obtaining good results in both\nVision-Language Retrieval and Semantic Localization tasks. Finally, we show\nsuccessful results of training the RS Stable Diffusion model using the RS5M,\nuncovering more use cases of the dataset.\n","authors":["Zilun Zhang","Tiancheng Zhao","Yulong Guo","Jianwei Yin"],"pdf_url":"https://arxiv.org/pdf/2306.11300v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11290v1","updated":"2023-06-20T05:07:23Z","published":"2023-06-20T05:07:23Z","title":"Habitat Synthetic Scenes Dataset (HSSD-200): An Analysis of 3D Scene\n  Scale and Realism Tradeoffs for ObjectGoal Navigation","summary":"  We contribute the Habitat Synthetic Scene Dataset, a dataset of 211\nhigh-quality 3D scenes, and use it to test navigation agent generalization to\nrealistic 3D environments. Our dataset represents real interiors and contains a\ndiverse set of 18,656 models of real-world objects. We investigate the impact\nof synthetic 3D scene dataset scale and realism on the task of training\nembodied agents to find and navigate to objects (ObjectGoal navigation). By\ncomparing to synthetic 3D scene datasets from prior work, we find that scale\nhelps in generalization, but the benefits quickly saturate, making visual\nfidelity and correlation to real-world scenes more important. Our experiments\nshow that agents trained on our smaller-scale dataset can match or outperform\nagents trained on much larger datasets. Surprisingly, we observe that agents\ntrained on just 122 scenes from our dataset outperform agents trained on 10,000\nscenes from the ProcTHOR-10K dataset in terms of zero-shot generalization in\nreal-world scanned environments.\n","authors":["Mukul Khanna","Yongsen Mao","Hanxiao Jiang","Sanjay Haresh","Brennan Schacklett","Dhruv Batra","Alexander Clegg","Eric Undersander","Angel X. Chang","Manolis Savva"],"pdf_url":"https://arxiv.org/pdf/2306.11290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11287v1","updated":"2023-06-20T04:59:09Z","published":"2023-06-20T04:59:09Z","title":"Spatiotemporal Pyramidal CNN with Depth-Wise Separable Convolution for\n  Eye Blinking Detection in the Wild","summary":"  Eye blinking detection in the wild plays an essential role in deception\ndetection, driving fatigue detection, etc. Despite the fact that numerous\nattempts have already been made, the majority of them have encountered\ndifficulties, such as the derived eye images having different resolutions as\nthe distance between the face and the camera changes; or the requirement of a\nlightweight detection model to obtain a short inference time in order to\nperform in real-time. In this research, two problems are addressed: how the eye\nblinking detection model can learn efficiently from different resolutions of\neye pictures in diverse conditions; and how to reduce the size of the detection\nmodel for faster inference time. We propose to utilize upsampling and\ndownsampling the input eye images to the same resolution as one potential\nsolution for the first problem, then find out which interpolation method can\nresult in the highest performance of the detection model. For the second\nproblem, although a recent spatiotemporal convolutional neural network used for\neye blinking detection has a strong capacity to extract both spatial and\ntemporal characteristics, it remains having a high number of network\nparameters, leading to high inference time. Therefore, using Depth-wise\nSeparable Convolution rather than conventional convolution layers inside each\nbranch is considered in this paper as a feasible solution.\n","authors":["Lan Anh Thi Nguy","Bach Nguyen Gia","Thanh Tu Thi Nguyen","Kamioka Eiji","Tan Xuan Phan"],"pdf_url":"https://arxiv.org/pdf/2306.11287v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.10275v2","updated":"2023-06-20T04:30:42Z","published":"2022-10-19T03:38:57Z","title":"Towards Explaining Distribution Shifts","summary":"  A distribution shift can have fundamental consequences such as signaling a\nchange in the operating environment or significantly reducing the accuracy of\ndownstream models. Thus, understanding distribution shifts is critical for\nexamining and hopefully mitigating the effect of such a shift. Most prior work\nfocuses on merely detecting if a shift has occurred and assumes any detected\nshift can be understood and handled appropriately by a human operator. We hope\nto aid in these manual mitigation tasks by explaining the distribution shift\nusing interpretable transportation maps from the original distribution to the\nshifted one. We derive our interpretable mappings from a relaxation of optimal\ntransport, where the candidate mappings are restricted to a set of\ninterpretable mappings. We then inspect multiple quintessential use-cases of\ndistribution shift in real-world tabular, text, and image datasets to showcase\nhow our explanatory mappings provide a better balance between detail and\ninterpretability than baseline explanations by both visual inspection and our\nPercentExplained metric.\n","authors":["Sean Kulinski","David I. Inouye"],"pdf_url":"https://arxiv.org/pdf/2210.10275v2.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2205.03562v3","updated":"2023-06-20T03:50:38Z","published":"2022-05-07T05:47:22Z","title":"Graph Fusion Network for Multi-Oriented Object Detection","summary":"  In object detection, non-maximum suppression (NMS) methods are extensively\nadopted to remove horizontal duplicates of detected dense boxes for generating\nfinal object instances. However, due to the degraded quality of dense detection\nboxes and not explicit exploration of the context information, existing NMS\nmethods via simple intersection-over-union (IoU) metrics tend to underperform\non multi-oriented and long-size objects detection. Distinguishing with general\nNMS methods via duplicate removal, we propose a novel graph fusion network,\nnamed GFNet, for multi-oriented object detection. Our GFNet is extensible and\nadaptively fuse dense detection boxes to detect more accurate and holistic\nmulti-oriented object instances. Specifically, we first adopt a locality-aware\nclustering algorithm to group dense detection boxes into different clusters. We\nwill construct an instance sub-graph for the detection boxes belonging to one\ncluster. Then, we propose a graph-based fusion network via Graph Convolutional\nNetwork (GCN) to learn to reason and fuse the detection boxes for generating\nfinal instance boxes. Extensive experiments both on public available\nmulti-oriented text datasets (including MSRA-TD500, ICDAR2015, ICDAR2017-MLT)\nand multi-oriented object datasets (DOTA) verify the effectiveness and\nrobustness of our method against general NMS methods in multi-oriented object\ndetection.\n","authors":["Shi-Xue Zhang","Xiaobin Zhu","Jie-Bo Hou","Xu-Cheng Yin"],"pdf_url":"https://arxiv.org/pdf/2205.03562v3.pdf","comment":"Accepted by Applied Intelligence (APIN 2022)"},{"id":"http://arxiv.org/abs/2306.11261v1","updated":"2023-06-20T03:29:05Z","published":"2023-06-20T03:29:05Z","title":"Comparative Evaluation of Recent Universal Adversarial Perturbations in\n  Image Classification","summary":"  The vulnerability of Convolutional Neural Networks (CNNs) to adversarial\nsamples has recently garnered significant attention in the machine learning\ncommunity. Furthermore, recent studies have unveiled the existence of universal\nadversarial perturbations (UAPs) that are image-agnostic and highly\ntransferable across different CNN models. In this survey, our primary focus\nrevolves around the recent advancements in UAPs specifically within the image\nclassification task. We categorize UAPs into two distinct categories, i.e.,\nnoise-based attacks and generator-based attacks, thereby providing a\ncomprehensive overview of representative methods within each category. By\npresenting the computational details of these methods, we summarize various\nloss functions employed for learning UAPs. Furthermore, we conduct a\ncomprehensive evaluation of different loss functions within consistent training\nframeworks, including noise-based and generator-based. The evaluation covers a\nwide range of attack settings, including black-box and white-box attacks,\ntargeted and untargeted attacks, as well as the examination of defense\nmechanisms.\n  Our quantitative evaluation results yield several important findings\npertaining to the effectiveness of different loss functions, the selection of\nsurrogate CNN models, the impact of training data and data size, and the\ntraining frameworks involved in crafting universal attackers. Finally, to\nfurther promote future research on universal adversarial attacks, we provide\nsome visualizations of the perturbations and discuss the potential research\ndirections.\n","authors":["Juanjuan Weng","Zhiming Luo","Dazhen Lin","Shaozi Li"],"pdf_url":"https://arxiv.org/pdf/2306.11261v1.pdf","comment":"18 pages,8 figures, 7 tables"},{"id":"http://arxiv.org/abs/2304.05934v2","updated":"2023-06-20T03:20:18Z","published":"2023-04-12T15:52:53Z","title":"ASL Citizen: A Community-Sourced Dataset for Advancing Isolated Sign\n  Language Recognition","summary":"  Sign languages are used as a primary language by approximately 70 million\nD/deaf people world-wide. However, most communication technologies operate in\nspoken and written languages, creating inequities in access. To help tackle\nthis problem, we release ASL Citizen, the first crowdsourced Isolated Sign\nLanguage Recognition (ISLR) dataset, collected with consent and containing\n83,399 videos for 2,731 distinct signs filmed by 52 signers in a variety of\nenvironments. We propose that this dataset be used for sign language dictionary\nretrieval for American Sign Language (ASL), where a user demonstrates a sign to\ntheir webcam to retrieve matching signs from a dictionary. We show that\ntraining supervised machine learning classifiers with our dataset advances the\nstate-of-the-art on metrics relevant for dictionary retrieval, achieving 63%\naccuracy and a recall-at-10 of 91%, evaluated entirely on videos of users who\nare not present in the training or validation sets. An accessible PDF of this\narticle is available at the following link:\nhttps://aashakadesai.github.io/research/ASLCitizen_arxiv_updated.pdf\n","authors":["Aashaka Desai","Lauren Berger","Fyodor O. Minakov","Vanessa Milan","Chinmay Singh","Kriston Pumphrey","Richard E. Ladner","Hal Daumé III","Alex X. Lu","Naomi Caselli","Danielle Bragg"],"pdf_url":"https://arxiv.org/pdf/2304.05934v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.06410v2","updated":"2023-06-20T03:18:52Z","published":"2022-03-12T11:02:32Z","title":"Kernel Proposal Network for Arbitrary Shape Text Detection","summary":"  Segmentation-based methods have achieved great success for arbitrary shape\ntext detection. However, separating neighboring text instances is still one of\nthe most challenging problems due to the complexity of texts in scene images.\nIn this paper, we propose an innovative Kernel Proposal Network (dubbed KPN)\nfor arbitrary shape text detection. The proposed KPN can separate neighboring\ntext instances by classifying different texts into instance-independent feature\nmaps, meanwhile avoiding the complex aggregation process existing in\nsegmentation-based arbitrary shape text detection methods. To be concrete, our\nKPN will predict a Gaussian center map for each text image, which will be used\nto extract a series of candidate kernel proposals (i.e., dynamic convolution\nkernel) from the embedding feature maps according to their corresponding\nkeypoint positions. To enforce the independence between kernel proposals, we\npropose a novel orthogonal learning loss (OLL) via orthogonal constraints.\nSpecifically, our kernel proposals contain important self-information learned\nby network and location information by position embedding. Finally, kernel\nproposals will individually convolve all embedding feature maps for generating\nindividual embedded maps of text instances. In this way, our KPN can\neffectively separate neighboring text instances and improve the robustness\nagainst unclear boundaries. To our knowledge, our work is the first to\nintroduce the dynamic convolution kernel strategy to efficiently and\neffectively tackle the adhesion problem of neighboring text instances in text\ndetection. Experimental results on challenging datasets verify the impressive\nperformance and efficiency of our method. The code and model are available at\nhttps://github.com/GXYM/KPN.\n","authors":["Shi-Xue Zhang","Xiaobin Zhu","Jie-Bo Hou","Chun Yang","Xu-Cheng Yin"],"pdf_url":"https://arxiv.org/pdf/2203.06410v2.pdf","comment":"This paper was completed in 2020-11.It was first submitted to CVPR\n  2021 and then ICCV 2021. Finally, it has been accepted by TNNLS in 2022-02\n  after major revision. Here, I thank Dr.Hou for his important contributions"},{"id":"http://arxiv.org/abs/2306.11251v1","updated":"2023-06-20T03:05:28Z","published":"2023-06-20T03:05:28Z","title":"Eliminating Lipschitz Singularities in Diffusion Models","summary":"  Diffusion models, which employ stochastic differential equations to sample\nimages through integrals, have emerged as a dominant class of generative\nmodels. However, the rationality of the diffusion process itself receives\nlimited attention, leaving the question of whether the problem is well-posed\nand well-conditioned. In this paper, we uncover a vexing propensity of\ndiffusion models: they frequently exhibit the infinite Lipschitz near the zero\npoint of timesteps. This poses a threat to the stability and accuracy of the\ndiffusion process, which relies on integral operations. We provide a\ncomprehensive evaluation of the issue from both theoretical and empirical\nperspectives. To address this challenge, we propose a novel approach, dubbed\nE-TSDM, which eliminates the Lipschitz singularity of the diffusion model near\nzero. Remarkably, our technique yields a substantial improvement in\nperformance, e.g., on the high-resolution FFHQ dataset ($256\\times256$).\nMoreover, as a byproduct of our method, we manage to achieve a dramatic\nreduction in the Frechet Inception Distance of other acceleration methods\nrelying on network Lipschitz, including DDIM and DPM-Solver, by over 33$\\%$. We\nconduct extensive experiments on diverse datasets to validate our theory and\nmethod. Our work not only advances the understanding of the general diffusion\nprocess, but also provides insights for the design of diffusion models.\n","authors":["Zhantao Yang","Ruili Feng","Han Zhang","Yujun Shen","Kai Zhu","Lianghua Huang","Yifei Zhang","Yu Liu","Deli Zhao","Jingren Zhou","Fan Cheng"],"pdf_url":"https://arxiv.org/pdf/2306.11251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11249v1","updated":"2023-06-20T03:02:14Z","published":"2023-06-20T03:02:14Z","title":"OpenSTL: A Comprehensive Benchmark of Spatio-Temporal Predictive\n  Learning","summary":"  Spatio-temporal predictive learning is a learning paradigm that enables\nmodels to learn spatial and temporal patterns by predicting future frames from\ngiven past frames in an unsupervised manner. Despite remarkable progress in\nrecent years, a lack of systematic understanding persists due to the diverse\nsettings, complex implementation, and difficult reproducibility. Without\nstandardization, comparisons can be unfair and insights inconclusive. To\naddress this dilemma, we propose OpenSTL, a comprehensive benchmark for\nspatio-temporal predictive learning that categorizes prevalent approaches into\nrecurrent-based and recurrent-free models. OpenSTL provides a modular and\nextensible framework implementing various state-of-the-art methods. We conduct\nstandard evaluations on datasets across various domains, including synthetic\nmoving object trajectory, human motion, driving scenes, traffic flow and\nweather forecasting. Based on our observations, we provide a detailed analysis\nof how model architecture and dataset properties affect spatio-temporal\npredictive learning performance. Surprisingly, we find that recurrent-free\nmodels achieve a good balance between efficiency and performance than recurrent\nmodels. Thus, we further extend the common MetaFormers to boost recurrent-free\nspatial-temporal predictive learning. We open-source the code and models at\nhttps://github.com/chengtan9907/OpenSTL.\n","authors":["Cheng Tan","Siyuan Li","Zhangyang Gao","Wenfei Guan","Zedong Wang","Zicheng Liu","Lirong Wu","Stan Z. Li"],"pdf_url":"https://arxiv.org/pdf/2306.11249v1.pdf","comment":"33 pages, 17 figures, 19 tables. Under review. For more details,\n  please refer to https://github.com/chengtan9907/OpenSTL"},{"id":"http://arxiv.org/abs/2205.05320v4","updated":"2023-06-20T03:00:29Z","published":"2022-05-11T07:59:13Z","title":"Arbitrary Shape Text Detection via Boundary Transformer","summary":"  In arbitrary shape text detection, locating accurate text boundaries is\nchallenging and non-trivial. Existing methods often suffer from indirect text\nboundary modeling or complex post-processing. In this paper, we systematically\npresent a unified coarse-to-fine framework via boundary learning for arbitrary\nshape text detection, which can accurately and efficiently locate text\nboundaries without post-processing. In our method, we explicitly model the text\nboundary via an innovative iterative boundary transformer in a coarse-to-fine\nmanner. In this way, our method can directly gain accurate text boundaries and\nabandon complex post-processing to improve efficiency. Specifically, our method\nmainly consists of a feature extraction backbone, a boundary proposal module,\nand an iteratively optimized boundary transformer module. The boundary proposal\nmodule consisting of multi-layer dilated convolutions will compute important\nprior information (including classification map, distance field, and direction\nfield) for generating coarse boundary proposals while guiding the boundary\ntransformer's optimization. The boundary transformer module adopts an\nencoder-decoder structure, in which the encoder is constructed by multi-layer\ntransformer blocks with residual connection while the decoder is a simple\nmulti-layer perceptron network (MLP). Under the guidance of prior information,\nthe boundary transformer module will gradually refine the coarse boundary\nproposals via iterative boundary deformation. Furthermore, we propose a novel\nboundary energy loss (BEL) which introduces an energy minimization constraint\nand an energy monotonically decreasing constraint to further optimize and\nstabilize the learning of boundary refinement. Extensive experiments on\npublicly available and challenging datasets demonstrate the state-of-the-art\nperformance and promising efficiency of our method.\n","authors":["Shi-Xue Zhang","Chun Yang","Xiaobin Zhu","Xu-Cheng Yin"],"pdf_url":"https://arxiv.org/pdf/2205.05320v4.pdf","comment":"It is an extend version (TextBPN++) to our preliminary conference\n  version TextBPN(ICCV 2021) [arXiv:2107.12664], which has been accepted by\n  IEEE Transactions on Multimedia (T-MM 2023)"},{"id":"http://arxiv.org/abs/2306.11248v1","updated":"2023-06-20T03:00:22Z","published":"2023-06-20T03:00:22Z","title":"Dynamic Perceiver for Efficient Visual Recognition","summary":"  Early exiting has become a promising approach to improving the inference\nefficiency of deep networks. By structuring models with multiple classifiers\n(exits), predictions for ``easy'' samples can be generated at earlier exits,\nnegating the need for executing deeper layers. Current multi-exit networks\ntypically implement linear classifiers at intermediate layers, compelling\nlow-level features to encapsulate high-level semantics. This sub-optimal design\ninvariably undermines the performance of later exits. In this paper, we propose\nDynamic Perceiver (Dyn-Perceiver) to decouple the feature extraction procedure\nand the early classification task with a novel dual-branch architecture. A\nfeature branch serves to extract image features, while a classification branch\nprocesses a latent code assigned for classification tasks. Bi-directional\ncross-attention layers are established to progressively fuse the information of\nboth branches. Early exits are placed exclusively within the classification\nbranch, thus eliminating the need for linear separability in low-level\nfeatures. Dyn-Perceiver constitutes a versatile and adaptable framework that\ncan be built upon various architectures. Experiments on image classification,\naction recognition, and object detection demonstrate that our method\nsignificantly improves the inference efficiency of different backbones,\noutperforming numerous competitive approaches across a broad range of\ncomputational budgets. Evaluation on both CPU and GPU platforms substantiate\nthe superior practical efficiency of Dyn-Perceiver. Code is available at\nhttps://www.github.com/LeapLabTHU/Dynamic_Perceiver.\n","authors":["Yizeng Han","Dongchen Han","Zeyu Liu","Yulin Wang","Xuran Pan","Yifan Pu","Chao Deng","Junlan Feng","Shiji Song","Gao Huang"],"pdf_url":"https://arxiv.org/pdf/2306.11248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.11478v3","updated":"2023-06-20T02:35:51Z","published":"2022-11-21T14:12:53Z","title":"Background-Mixed Augmentation for Weakly Supervised Change Detection","summary":"  Change detection (CD) is to decouple object changes (i.e., object missing or\nappearing) from background changes (i.e., environment variations) like light\nand season variations in two images captured in the same scene over a long time\nspan, presenting critical applications in disaster management, urban\ndevelopment, etc. In particular, the endless patterns of background changes\nrequire detectors to have a high generalization against unseen environment\nvariations, making this task significantly challenging. Recent deep\nlearning-based methods develop novel network architectures or optimization\nstrategies with paired-training examples, which do not handle the\ngeneralization issue explicitly and require huge manual pixel-level annotation\nefforts. In this work, for the first attempt in the CD community, we study the\ngeneralization issue of CD from the perspective of data augmentation and\ndevelop a novel weakly supervised training algorithm that only needs\nimage-level labels. Different from general augmentation techniques for\nclassification, we propose the background-mixed augmentation that is\nspecifically designed for change detection by augmenting examples under the\nguidance of a set of background-changing images and letting deep CD models see\ndiverse environment variations. Moreover, we propose the augmented & real data\nconsistency loss that encourages the generalization increase significantly. Our\nmethod as a general framework can enhance a wide range of existing deep\nlearning-based detectors. We conduct extensive experiments in two public\ndatasets and enhance four state-of-the-art methods, demonstrating the\nadvantages of our method. We release the code at\nhttps://github.com/tsingqguo/bgmix.\n","authors":["Rui Huang","Ruofei Wang","Qing Guo","Jieda Wei","Yuxiang Zhang","Wei Fan","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2211.11478v3.pdf","comment":"AAAI 2023 Accepted"},{"id":"http://arxiv.org/abs/2306.11238v1","updated":"2023-06-20T02:21:45Z","published":"2023-06-20T02:21:45Z","title":"CAMP-Net: Context-Aware Multi-Prior Network for Accelerated MRI\n  Reconstruction","summary":"  Despite promising advances in deep learning-based MRI reconstruction methods,\nrestoring high-frequency image details and textures remains a challenging\nproblem for accelerated MRI. To tackle this challenge, we propose a novel\ncontext-aware multi-prior network (CAMP-Net) for MRI reconstruction. CAMP-Net\nleverages the complementary nature of multiple prior knowledge and explores\ndata redundancy between adjacent slices in the hybrid domain to improve image\nquality. It incorporates three interleaved modules respectively for image\nenhancement, k-space restoration, and calibration consistency to jointly learn\ncontext-aware multiple priors in an end-to-end fashion. The image enhancement\nmodule learns a coil-combined image prior to suppress noise-like artifacts,\nwhile the k-space restoration module explores multi-coil k-space correlations\nto recover high-frequency details. The calibration consistency module embeds\nthe known physical properties of MRI acquisition to ensure consistency of\nk-space correlations extracted from measurements and the artifact-free image\nintermediate. The resulting low- and high-frequency reconstructions are\nhierarchically aggregated in a frequency fusion module and iteratively refined\nto progressively reconstruct the final image. We evaluated the generalizability\nand robustness of our method on three large public datasets with various\naccelerations and sampling patterns. Comprehensive experiments demonstrate that\nCAMP-Net outperforms state-of-the-art methods in terms of reconstruction\nquality and quantitative $T_2$ mapping.\n","authors":["Liping Zhang","Xiaobo Li","Weitian Chen"],"pdf_url":"https://arxiv.org/pdf/2306.11238v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11207v1","updated":"2023-06-20T00:14:47Z","published":"2023-06-20T00:14:47Z","title":"Quilt-1M: One Million Image-Text Pairs for Histopathology","summary":"  Recent accelerations in multi-modal applications have been made possible with\nthe plethora of image and text data available online. However, the scarcity of\nanalogous data in the medical field, specifically in histopathology, has halted\ncomparable progress. To enable similar representation learning for\nhistopathology, we turn to YouTube, an untapped resource of videos, offering\n$1,087$ hours of valuable educational histopathology videos from expert\nclinicians. From YouTube, we curate Quilt: a large-scale vision-language\ndataset consisting of $768,826$ image and text pairs. Quilt was automatically\ncurated using a mixture of models, including large language models, handcrafted\nalgorithms, human knowledge databases, and automatic speech recognition. In\ncomparison, the most comprehensive datasets curated for histopathology amass\nonly around $200$K samples. We combine Quilt with datasets from other sources,\nincluding Twitter, research papers, and the internet in general, to create an\neven larger dataset: Quilt-1M, with $1$M paired image-text samples, marking it\nas the largest vision-language histopathology dataset to date. We demonstrate\nthe value of Quilt-1M by fine-tuning a pre-trained CLIP model. Our model\noutperforms state-of-the-art models on both zero-shot and linear probing tasks\nfor classifying new histopathology images across $13$ diverse patch-level\ndatasets of $8$ different sub-pathologies and cross-modal retrieval tasks.\n","authors":["Wisdom Oluchi Ikezogwo","Mehmet Saygin Seyfioglu","Fatemeh Ghezloo","Dylan Stefan Chan Geva","Fatwir Sheikh Mohammed","Pavan Kumar Anand","Ranjay Krishna","Linda Shapiro"],"pdf_url":"https://arxiv.org/pdf/2306.11207v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.08407v2","updated":"2023-06-20T22:33:48Z","published":"2022-08-17T17:03:48Z","title":"Self-Supervised Depth Estimation in Laparoscopic Image using 3D\n  Geometric Consistency","summary":"  Depth estimation is a crucial step for image-guided intervention in robotic\nsurgery and laparoscopic imaging system. Since per-pixel depth ground truth is\ndifficult to acquire for laparoscopic image data, it is rarely possible to\napply supervised depth estimation to surgical applications. As an alternative,\nself-supervised methods have been introduced to train depth estimators using\nonly synchronized stereo image pairs. However, most recent work focused on the\nleft-right consistency in 2D and ignored valuable inherent 3D information on\nthe object in real world coordinates, meaning that the left-right 3D geometric\nstructural consistency is not fully utilized. To overcome this limitation, we\npresent M3Depth, a self-supervised depth estimator to leverage 3D geometric\nstructural information hidden in stereo pairs while keeping monocular\ninference. The method also removes the influence of border regions unseen in at\nleast one of the stereo images via masking, to enhance the correspondences\nbetween left and right images in overlapping areas. Intensive experiments show\nthat our method outperforms previous self-supervised approaches on both a\npublic dataset and a newly acquired dataset by a large margin, indicating a\ngood generalization across different samples and laparoscopes. Code and data\nare available at https://github.com/br0202/M3Depth.\n","authors":["Baoru Huang","Jian-Qing Zheng","Anh Nguyen","Chi Xu","Ioannis Gkouzionis","Kunal Vyas","David Tuch","Stamatia Giannarou","Daniel S. Elson"],"pdf_url":"https://arxiv.org/pdf/2208.08407v2.pdf","comment":"Accepted by MICCAI2022"},{"id":"http://arxiv.org/abs/2306.11925v1","updated":"2023-06-20T22:21:34Z","published":"2023-06-20T22:21:34Z","title":"LVM-Med: Learning Large-Scale Self-Supervised Vision Models for Medical\n  Imaging via Second-order Graph Matching","summary":"  Obtaining large pre-trained models that can be fine-tuned to new tasks with\nlimited annotated samples has remained an open challenge for medical imaging\ndata. While pre-trained deep networks on ImageNet and vision-language\nfoundation models trained on web-scale data are prevailing approaches, their\neffectiveness on medical tasks is limited due to the significant domain shift\nbetween natural and medical images. To bridge this gap, we introduce LVM-Med,\nthe first family of deep networks trained on large-scale medical datasets. We\nhave collected approximately 1.3 million medical images from 55 publicly\navailable datasets, covering a large number of organs and modalities such as\nCT, MRI, X-ray, and Ultrasound. We benchmark several state-of-the-art\nself-supervised algorithms on this dataset and propose a novel self-supervised\ncontrastive learning algorithm using a graph-matching formulation. The proposed\napproach makes three contributions: (i) it integrates prior pair-wise image\nsimilarity metrics based on local and global information; (ii) it captures the\nstructural constraints of feature embeddings through a loss function\nconstructed via a combinatorial graph-matching objective; and (iii) it can be\ntrained efficiently end-to-end using modern gradient-estimation techniques for\nblack-box solvers. We thoroughly evaluate the proposed LVM-Med on 15 downstream\nmedical tasks ranging from segmentation and classification to object detection,\nand both for the in and out-of-distribution settings. LVM-Med empirically\noutperforms a number of state-of-the-art supervised, self-supervised, and\nfoundation models. For challenging tasks such as Brain Tumor Classification or\nDiabetic Retinopathy Grading, LVM-Med improves previous vision-language models\ntrained on 1 billion masks by 6-7% while using only a ResNet-50.\n","authors":["Duy M. H. Nguyen","Hoang Nguyen","Nghiem T. Diep","Tan N. Pham","Tri Cao","Binh T. Nguyen","Paul Swoboda","Nhat Ho","Shadi Albarqouni","Pengtao Xie","Daniel Sonntag","Mathias Niepert"],"pdf_url":"https://arxiv.org/pdf/2306.11925v1.pdf","comment":"First version"},{"id":"http://arxiv.org/abs/2306.11920v1","updated":"2023-06-20T22:06:39Z","published":"2023-06-20T22:06:39Z","title":"NILUT: Conditional Neural Implicit 3D Lookup Tables for Image\n  Enhancement","summary":"  3D lookup tables (3D LUTs) are a key component for image enhancement. Modern\nimage signal processors (ISPs) have dedicated support for these as part of the\ncamera rendering pipeline. Cameras typically provide multiple options for\npicture styles, where each style is usually obtained by applying a unique\nhandcrafted 3D LUT. Current approaches for learning and applying 3D LUTs are\nnotably fast, yet not so memory-efficient, as storing multiple 3D LUTs is\nrequired. For this reason and other implementation limitations, their use on\nmobile devices is less popular. In this work, we propose a Neural Implicit LUT\n(NILUT), an implicitly defined continuous 3D color transformation parameterized\nby a neural network. We show that NILUTs are capable of accurately emulating\nreal 3D LUTs. Moreover, a NILUT can be extended to incorporate multiple styles\ninto a single network with the ability to blend styles implicitly. Our novel\napproach is memory-efficient, controllable and can complement previous methods,\nincluding learned ISPs. Code, models and dataset available at:\nhttps://github.com/mv-lab/nilut\n","authors":["Marcos V. Conde","Javier Vazquez-Corral","Michael S. Brown","Radu Timofte"],"pdf_url":"https://arxiv.org/pdf/2306.11920v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11911v1","updated":"2023-06-20T21:49:16Z","published":"2023-06-20T21:49:16Z","title":"LNL+K: Learning with Noisy Labels and Noise Source Distribution\n  Knowledge","summary":"  Learning with noisy labels (LNL) is challenging as the model tends to\nmemorize noisy labels, which can lead to overfitting. Many LNL methods detect\nclean samples by maximizing the similarity between samples in each category,\nwhich does not make any assumptions about likely noise sources. However, we\noften have some knowledge about the potential source(s) of noisy labels. For\nexample, an image mislabeled as a cheetah is more likely a leopard than a\nhippopotamus due to their visual similarity. Thus, we introduce a new task\ncalled Learning with Noisy Labels and noise source distribution Knowledge\n(LNL+K), which assumes we have some knowledge about likely source(s) of label\nnoise that we can take advantage of. By making this presumption, methods are\nbetter equipped to distinguish hard negatives between categories from label\nnoise. In addition, this enables us to explore datasets where the noise may\nrepresent the majority of samples, a setting that breaks a critical premise of\nmost methods developed for the LNL task. We explore several baseline LNL+K\napproaches that integrate noise source knowledge into state-of-the-art LNL\nmethods across three diverse datasets and three types of noise, where we report\na 5-15% boost in performance compared with the unadapted methods. Critically,\nwe find that LNL methods do not generalize well in every setting, highlighting\nthe importance of directly exploring our LNL+K task.\n","authors":["Siqi Wang","Bryan A. Plummer"],"pdf_url":"https://arxiv.org/pdf/2306.11911v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.05622v3","updated":"2023-06-20T21:23:10Z","published":"2023-04-12T05:39:38Z","title":"SAMM (Segment Any Medical Model): A 3D Slicer Integration to SAM","summary":"  The Segment Anything Model (SAM) is a new image segmentation tool trained\nwith the largest available segmentation dataset. The model has demonstrated\nthat, with efficient prompting, it can create high-quality, generalized masks\nfor image segmentation. However, the performance of the model on medical images\nrequires further validation. To assist with the development, assessment, and\napplication of SAM on medical images, we introduce Segment Any Medical Model\n(SAMM), an extension of SAM on 3D Slicer - an open-source image processing and\nvisualization software extensively used by the medical imaging community. This\nopen-source extension to 3D Slicer and its demonstrations are posted on GitHub\n(https://github.com/bingogome/samm). SAMM achieves 0.6-second latency of a\ncomplete cycle and can infer image masks in nearly real-time.\n","authors":["Yihao Liu","Jiaming Zhang","Zhangcong She","Amir Kheradmand","Mehran Armand"],"pdf_url":"https://arxiv.org/pdf/2304.05622v3.pdf","comment":"6 pages, 4 figures"},{"id":"http://arxiv.org/abs/2306.11876v1","updated":"2023-06-20T20:23:46Z","published":"2023-06-20T20:23:46Z","title":"BMAD: Benchmarks for Medical Anomaly Detection","summary":"  Anomaly detection (AD) is a fundamental research problem in machine learning\nand computer vision, with practical applications in industrial inspection,\nvideo surveillance, and medical diagnosis. In medical imaging, AD is especially\nvital for detecting and diagnosing anomalies that may indicate rare diseases or\nconditions. However, there is a lack of a universal and fair benchmark for\nevaluating AD methods on medical images, which hinders the development of more\ngeneralized and robust AD methods in this specific domain. To bridge this gap,\nwe introduce a comprehensive evaluation benchmark for assessing anomaly\ndetection methods on medical images. This benchmark encompasses six reorganized\ndatasets from five medical domains (i.e. brain MRI, liver CT, retinal OCT,\nchest X-ray, and digital histopathology) and three key evaluation metrics, and\nincludes a total of fourteen state-of-the-art AD algorithms. This standardized\nand well-curated medical benchmark with the well-structured codebase enables\ncomprehensive comparisons among recently proposed anomaly detection methods. It\nwill facilitate the community to conduct a fair comparison and advance the\nfield of AD on medical imaging. More information on BMAD is available in our\nGitHub repository: https://github.com/DorisBao/BMAD\n","authors":["Jinan Bao","Hanshi Sun","Hanqiu Deng","Yinsheng He","Zhaoxiang Zhang","Xingyu Li"],"pdf_url":"https://arxiv.org/pdf/2306.11876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11868v1","updated":"2023-06-20T20:01:07Z","published":"2023-06-20T20:01:07Z","title":"Multiverse Transformer: 1st Place Solution for Waymo Open Sim Agents\n  Challenge 2023","summary":"  This technical report presents our 1st place solution for the Waymo Open Sim\nAgents Challenge (WOSAC) 2023. Our proposed MultiVerse Transformer for Agent\nsimulation (MVTA) effectively leverages transformer-based motion prediction\napproaches, and is tailored for closed-loop simulation of agents. In order to\nproduce simulations with a high degree of realism, we design novel training and\nsampling methods, and implement a receding horizon prediction mechanism. In\naddition, we introduce a variable-length history aggregation method to mitigate\nthe compounding error that can arise during closed-loop autoregressive\nexecution. On the WOSAC, our MVTA and its enhanced version MVTE reach a realism\nmeta-metric of 0.5091 and 0.5168, respectively, outperforming all the other\nmethods on the leaderboard.\n","authors":["Yu Wang","Tiebiao Zhao","Fan Yi"],"pdf_url":"https://arxiv.org/pdf/2306.11868v1.pdf","comment":"Technical report for the 1st place solution of Waymo Open Sim Agents\n  Challenge 2023. Project page:\n  https://multiverse-transformer.github.io/sim-agents/. CVPR 2023 workshop on\n  Autonomous Driving: https://cvpr2023.wad.vision/"},{"id":"http://arxiv.org/abs/2301.03198v3","updated":"2023-06-20T19:47:21Z","published":"2023-01-09T08:27:36Z","title":"The Algonauts Project 2023 Challenge: How the Human Brain Makes Sense of\n  Natural Scenes","summary":"  The sciences of biological and artificial intelligence are ever more\nintertwined. Neural computational principles inspire new intelligent machines,\nwhich are in turn used to advance theoretical understanding of the brain. To\npromote further exchange of ideas and collaboration between biological and\nartificial intelligence researchers, we introduce the 2023 installment of the\nAlgonauts Project challenge: How the Human Brain Makes Sense of Natural Scenes\n(http://algonauts.csail.mit.edu). This installment prompts the fields of\nartificial and biological intelligence to come together towards building\ncomputational models of the visual brain using the largest and richest dataset\nof fMRI responses to visual scenes, the Natural Scenes Dataset (NSD). NSD\nprovides high-quality fMRI responses to ~73,000 different naturalistic colored\nscenes, making it the ideal candidate for data-driven model building approaches\npromoted by the 2023 challenge. The challenge is open to all and makes results\ndirectly comparable and transparent through a public leaderboard automatically\nupdated after each submission, thus allowing for rapid model development. We\nbelieve that the 2023 installment will spark symbiotic collaborations between\nbiological and artificial intelligence scientists, leading to a deeper\nunderstanding of the brain through cutting-edge computational models and to\nnovel ways of engineering artificial intelligent agents through inductive\nbiases from biological systems.\n","authors":["A. T. Gifford","B. Lahner","S. Saba-Sadiya","M. G. Vilas","A. Lascelles","A. Oliva","K. Kay","G. Roig","R. M. Cichy"],"pdf_url":"https://arxiv.org/pdf/2301.03198v3.pdf","comment":"5 pages, 2 figures"},{"id":"http://arxiv.org/abs/2306.11848v1","updated":"2023-06-20T18:59:27Z","published":"2023-06-20T18:59:27Z","title":"Using super-resolution for enhancing visual perception and segmentation\n  performance in veterinary cytology","summary":"  The primary objective of this research was to enhance the quality of semantic\nsegmentation in cytology images by incorporating super-resolution (SR)\narchitectures. An additional contribution was the development of a novel\ndataset aimed at improving imaging quality in the presence of inaccurate focus.\nOur experimental results demonstrate that the integration of SR techniques into\nthe segmentation pipeline can lead to a significant improvement of up to 25% in\nthe mean average precision (mAP) segmentation metric. These findings suggest\nthat leveraging SR architectures holds great promise for advancing the state of\nthe art in cytology image analysis.\n","authors":["Jakub Caputa","Maciej Wielgosz","Daria Łukasik","Paweł Russek","Jakub Grzeszczyk","Michał Karwatowski","Szymon Mazurek","Rafał Frączek","Anna Śmiech","Ernest Jamro","Sebastian Koryciak","Agnieszka Dąbrowska-Boruch","Marcin Pietroń","Kazimierz Wiatr"],"pdf_url":"https://arxiv.org/pdf/2306.11848v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11837v1","updated":"2023-06-20T18:45:49Z","published":"2023-06-20T18:45:49Z","title":"Brain Anatomy Prior Modeling to Forecast Clinical Progression of\n  Cognitive Impairment with Structural MRI","summary":"  Brain structural MRI has been widely used to assess the future progression of\ncognitive impairment (CI). Previous learning-based studies usually suffer from\nthe issue of small-sized labeled training data, while there exist a huge amount\nof structural MRIs in large-scale public databases. Intuitively, brain\nanatomical structures derived from these public MRIs (even without\ntask-specific label information) can be used to boost CI progression trajectory\nprediction. However, previous studies seldom take advantage of such brain\nanatomy prior. To this end, this paper proposes a brain anatomy prior modeling\n(BAPM) framework to forecast the clinical progression of cognitive impairment\nwith small-sized target MRIs by exploring anatomical brain structures.\nSpecifically, the BAPM consists of a pretext model and a downstream model, with\na shared brain anatomy-guided encoder to model brain anatomy prior explicitly.\nBesides the encoder, the pretext model also contains two decoders for two\nauxiliary tasks (i.e., MRI reconstruction and brain tissue segmentation), while\nthe downstream model relies on a predictor for classification. The brain\nanatomy-guided encoder is pre-trained with the pretext model on 9,344 auxiliary\nMRIs without diagnostic labels for anatomy prior modeling. With this encoder\nfrozen, the downstream model is then fine-tuned on limited target MRIs for\nprediction. We validate the BAPM on two CI-related studies with T1-weighted\nMRIs from 448 subjects. Experimental results suggest the effectiveness of BAPM\nin (1) four CI progression prediction tasks, (2) MR image reconstruction, and\n(3) brain tissue segmentation, compared with several state-of-the-art methods.\n","authors":["Lintao Zhang","Jinjian Wu","Lihong Wang","Li Wang","David C. Steffens","Shijun Qiu","Guy G. Potter","Mingxia Liu"],"pdf_url":"https://arxiv.org/pdf/2306.11837v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11822v1","updated":"2023-06-20T18:31:32Z","published":"2023-06-20T18:31:32Z","title":"Self-supervised Multi-task Learning Framework for Safety and\n  Health-Oriented Connected Driving Environment Perception using Onboard Camera","summary":"  Cutting-edge connected vehicle (CV) technologies have drawn much attention in\nrecent years. The real-time traffic data captured by a CV can be shared with\nother CVs and data centers so as to open new possibilities for solving diverse\ntransportation problems. However, imagery captured by onboard cameras in a\nconnected environment, are not sufficiently investigated, especially for safety\nand health-oriented visual perception. In this paper, a bidirectional process\nof image synthesis and decomposition (BPISD) approach is proposed, and thus a\nnovel self-supervised multi-task learning framework, to simultaneously estimate\ndepth map, atmospheric visibility, airlight, and PM2.5 mass concentration, in\nwhich depth map and visibility are considered highly associated with traffic\nsafety, while airlight and PM2.5 mass concentration are directly correlated\nwith human health. Both the training and testing phases of the proposed system\nsolely require a single image as input. Due to the innovative training\npipeline, the depth estimation network can manage various levels of visibility\nconditions and overcome inherent problems in current image-synthesis-based\ndepth estimation, thereby generating high-quality depth maps even in\nlow-visibility situations and further benefiting accurate estimations of\nvisibility, airlight, and PM2.5 mass concentration. Extensive experiments on\nthe synthesized data from the KITTI and real-world data collected in Beijing\ndemonstrate that the proposed method can (1) achieve performance competitive in\ndepth estimation as compared with state-of-the-art methods when taking clear\nimages as input; (2) predict vivid depth map for images contaminated by various\nlevels of haze; and (3) accurately estimate visibility, airlight, and PM2.5\nmass concentrations. Beneficial applications can be developed based on the\npresented work to improve traffic safety, air quality, and public health.\n","authors":["Shaocheng Jia","Wei Yao"],"pdf_url":"https://arxiv.org/pdf/2306.11822v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11763v1","updated":"2023-06-20T09:46:01Z","published":"2023-06-20T09:46:01Z","title":"Exploring the Effectiveness of Dataset Synthesis: An application of\n  Apple Detection in Orchards","summary":"  Deep object detection models have achieved notable successes in recent years,\nbut one major obstacle remains: the requirement for a large amount of training\ndata. Obtaining such data is a tedious process and is mainly time consuming,\nleading to the exploration of new research avenues like synthetic data\ngeneration techniques. In this study, we explore the usability of Stable\nDiffusion 2.1-base for generating synthetic datasets of apple trees for object\ndetection and compare it to a baseline model trained on real-world data. After\ncreating a dataset of realistic apple trees with prompt engineering and\nutilizing a previously trained Stable Diffusion model, the custom dataset was\nannotated and evaluated by training a YOLOv5m object detection model to predict\napples in a real-world apple detection dataset. YOLOv5m was chosen for its\nrapid inference time and minimal hardware demands. Results demonstrate that the\nmodel trained on generated data is slightly underperforming compared to a\nbaseline model trained on real-world images when evaluated on a set of\nreal-world images. However, these findings remain highly promising, as the\naverage precision difference is only 0.09 and 0.06, respectively. Qualitative\nresults indicate that the model can accurately predict the location of apples,\nexcept in cases of heavy shading. These findings illustrate the potential of\nsynthetic data generation techniques as a viable alternative to the collection\nof extensive training data for object detection models.\n","authors":["Alexander van Meekeren","Maya Aghaei","Klaas Dijkstra"],"pdf_url":"https://arxiv.org/pdf/2306.11763v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11762v1","updated":"2023-06-20T09:10:06Z","published":"2023-06-20T09:10:06Z","title":"MultiEarth 2023 Deforestation Challenge -- Team FOREVER","summary":"  It is important problem to accurately estimate deforestation of satellite\nimagery since this approach can analyse extensive area without direct human\naccess. However, it is not simple problem because of difficulty in observing\nthe clear ground surface due to extensive cloud cover during long rainy season.\nIn this paper, we present a multi-view learning strategy to predict\ndeforestation status in the Amazon rainforest area with latest deep neural\nnetwork models. Multi-modal dataset consists of three types of different\nsatellites imagery, Sentinel-1, Sentinel-2 and Landsat 8 is utilized to train\nand predict deforestation status. MMsegmentation framework is selected to apply\ncomprehensive data augmentation and diverse networks. The proposed method\neffectively and accurately predicts the deforestation status of new queries.\n","authors":["Seunghan Park","Dongoo Lee","Yeonju Choi","SungTae Moon"],"pdf_url":"https://arxiv.org/pdf/2306.11762v1.pdf","comment":"CVPR 2023, MultiEarth 2023, Deforestation Estimation Challenge"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2306.08650v2","updated":"2023-06-20T16:47:08Z","published":"2023-06-14T17:30:02Z","title":"Learning to Rank when Grades Matter","summary":"  Graded labels are ubiquitous in real-world learning-to-rank applications,\nespecially in human rated relevance data. Traditional learning-to-rank\ntechniques aim to optimize the ranked order of documents. They typically,\nhowever, ignore predicting actual grades. This prevents them from being adopted\nin applications where grades matter, such as filtering out ``poor'' documents.\nAchieving both good ranking performance and good grade prediction performance\nis still an under-explored problem. Existing research either focuses only on\nranking performance by not calibrating model outputs, or treats grades as\nnumerical values, assuming labels are on a linear scale and failing to leverage\nthe ordinal grade information. In this paper, we conduct a rigorous study of\nlearning to rank with grades, where both ranking performance and grade\nprediction performance are important. We provide a formal discussion on how to\nperform ranking with non-scalar predictions for grades, and propose a\nmultiobjective formulation to jointly optimize both ranking and grade\npredictions. In experiments, we verify on several public datasets that our\nmethods are able to push the Pareto frontier of the tradeoff between ranking\nand grade prediction performance, showing the benefit of leveraging ordinal\ngrade information.\n","authors":["Le Yan","Zhen Qin","Gil Shamir","Dong Lin","Xuanhui Wang","Mike Bendersky"],"pdf_url":"https://arxiv.org/pdf/2306.08650v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11612v1","updated":"2023-06-20T15:41:44Z","published":"2023-06-20T15:41:44Z","title":"Visual Analysis of Large Multi-Field AMR Data on GPUs Using Interactive\n  Volume Lines","summary":"  To visually compare ensembles of volumes, dynamic volume lines (DVLs)\nrepresent each ensemble member as a 1D polyline. To compute these, the volume\ncells are sorted on a space-filling curve and scaled by the ensemble's local\nvariation. The resulting 1D plot can augment or serve as an alternative to a 3D\nvolume visualization free of visual clutter and occlusion. Interactively\ncomputing DVLs is challenging when the data is large, and the volume grid is\nnot structured/regular, as is often the case with computational fluid dynamics\nsimulations. We extend DVLs to support large-scale, multi-field adaptive mesh\nrefinement (AMR) data that can be explored interactively. Our GPU-based system\nupdates the DVL representation whenever the data or the alpha transfer function\nchanges. We demonstrate and evaluate our interactive prototype using large AMR\nvolumes from astrophysics simulations.\n","authors":["Stefan Zellmann","Serkan Demirci","Uğur Güdükbay"],"pdf_url":"https://arxiv.org/pdf/2306.11612v1.pdf","comment":"IEEE VIS 2023 Short Paper"},{"id":"http://arxiv.org/abs/2306.11610v1","updated":"2023-06-20T15:39:24Z","published":"2023-06-20T15:39:24Z","title":"Mining Interest Trends and Adaptively Assigning SampleWeight for\n  Session-based Recommendation","summary":"  Session-based Recommendation (SR) aims to predict users' next click based on\ntheir behavior within a short period, which is crucial for online platforms.\nHowever, most existing SR methods somewhat ignore the fact that user preference\nis not necessarily strongly related to the order of interactions. Moreover,\nthey ignore the differences in importance between different samples, which\nlimits the model-fitting performance. To tackle these issues, we put forward\nthe method, Mining Interest Trends and Adaptively Assigning Sample Weight,\nabbreviated as MTAW. Specifically, we model users' instant interest based on\ntheir present behavior and all their previous behaviors. Meanwhile, we\ndiscriminatively integrate instant interests to capture the changing trend of\nuser interest to make more personalized recommendations. Furthermore, we devise\na novel loss function that dynamically weights the samples according to their\nprediction difficulty in the current epoch. Extensive experimental results on\ntwo benchmark datasets demonstrate the effectiveness and superiority of our\nmethod.\n","authors":["Kai Ouyang","Xianghong Xu","Miaoxin Chen","Zuotong Xie","Hai-Tao Zheng","Shuangyong Song","Yu Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.11610v1.pdf","comment":"This work has been accepted by SIGIR 2023"},{"id":"http://arxiv.org/abs/2306.11553v1","updated":"2023-06-20T14:15:19Z","published":"2023-06-20T14:15:19Z","title":"Polytope: An Algorithm for Efficient Feature Extraction on Hypercubes","summary":"  Data extraction algorithms on data hypercubes, or datacubes, are\ntraditionally only capable of cutting boxes of data along the datacube axes.\nFor many use cases however, this is not a sufficient approach and returns more\ndata than users might actually need. This not only forces users to apply\npost-processing after extraction, but more importantly this consumes more I/O\nresources than is necessary. When considering very large datacubes from which\nusers only want to extract small non-rectangular subsets, the box approach does\nnot scale well. Indeed, with this traditional approach, I/O systems quickly\nreach capacity, trying to read and return unwanted data to users. In this\npaper, we propose a novel technique, based on computational geometry concepts,\nwhich instead carefully pre-selects the precise bytes of data which the user\nneeds in order to then only read those from the datacube. As we discuss later\non, this novel extraction method will considerably help scale access to large\npetabyte size data hypercubes in a variety of scientific fields.\n","authors":["Mathilde Leuridan","James Hawkes","Simon Smart","Emanuele Danovaro","Tiago Quintino"],"pdf_url":"https://arxiv.org/pdf/2306.11553v1.pdf","comment":"10 pages, 13 figures"},{"id":"http://arxiv.org/abs/2303.06016v2","updated":"2023-06-20T09:20:39Z","published":"2023-03-09T12:13:46Z","title":"Probe: Learning Users' Personalized Projection Bias in Intertemporal\n  Bundle Choices","summary":"  Intertemporal choices involve making decisions that require weighing the\ncosts in the present against the benefits in the future. One specific type of\nintertemporal choice is the decision between purchasing an individual item or\nopting for a bundle that includes that item. Previous research assumes that\nindividuals have accurate expectations of the factors involved in these\nchoices. However, in reality, users' perceptions of these factors are often\nbiased, leading to irrational and suboptimal decision-making. In this work, we\nspecifically focus on two commonly observed biases: projection bias and the\nreference-point effect. To address these biases, we propose a novel\nbias-embedded preference model called Probe. The Probe incorporates a weight\nfunction to capture users' projection bias and a value function to account for\nthe reference-point effect, and introduce prospect theory from behavioral\neconomics to combine the weight and value functions. This allows us to\ndetermine the probability of users selecting the bundle or a single item. We\nprovide a thorough theoretical analysis to demonstrate the impact of projection\nbias on the design of bundle sales strategies. Through experimental results, we\nshow that the proposed Probe model outperforms existing methods and contributes\nto a better understanding of users' irrational behaviors in bundle purchases.\nThis investigation can facilitate a deeper comprehension of users'\ndecision-making mechanisms, enable the provision of personalized services, and\nassist users in making more rational and optimal decisions.\n","authors":["Qingming Li","H. Vicky Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.06016v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11397v1","updated":"2023-06-20T09:04:06Z","published":"2023-06-20T09:04:06Z","title":"Generative Retrieval as Dense Retrieval","summary":"  Generative retrieval is a promising new neural retrieval paradigm that aims\nto optimize the retrieval pipeline by performing both indexing and retrieval\nwith a single transformer model. However, this new paradigm faces challenges\nwith updating the index and scaling to large collections. In this paper, we\nanalyze two prominent variants of generative retrieval and show that they can\nbe conceptually viewed as bi-encoders for dense retrieval. Specifically, we\nanalytically demonstrate that the generative retrieval process can be\ndecomposed into dot products between query and document vectors, similar to\ndense retrieval. This analysis leads us to propose a new variant of generative\nretrieval, called Tied-Atomic, which addresses the updating and scaling issues\nby incorporating techniques from dense retrieval. In experiments on two\ndatasets, NQ320k and the full MSMARCO, we confirm that this approach does not\nreduce retrieval effectiveness while enabling the model to scale to large\ncollections.\n","authors":["Thong Nguyen","Andrew Yates"],"pdf_url":"https://arxiv.org/pdf/2306.11397v1.pdf","comment":"GenIR@SIGIR2023"},{"id":"http://arxiv.org/abs/2306.11395v1","updated":"2023-06-20T09:03:24Z","published":"2023-06-20T09:03:24Z","title":"CAPRI: Context-Aware Interpretable Point-of-Interest Recommendation\n  Framework","summary":"  Point-of-Interest (POI ) recommendation systems have gained popularity for\ntheir unique ability to suggest geographical destinations with the\nincorporation of contextual information such as time, location, and user-item\ninteraction. Existing recommendation frameworks lack the contextual fusion\nrequired for POI systems. This paper presents CAPRI, a novel POI recommendation\nframework that effectively integrates context-aware models, such as GeoSoCa,\nLORE, and USG, and introduces a novel strategy for the efficient merging of\ncontextual information. CAPRI integrates an evaluation module that expands the\nevaluation scope beyond accuracy to include novelty, personalization,\ndiversity, and fairness. With an aim to establish a new industry standard for\nreproducible results in the realm of POI recommendation systems, we have made\nCAPRI openly accessible on GitHub, facilitating easy access and contribution to\nthe continued development and refinement of this innovative framework.\n","authors":["Ali Tourani","Hossein A. Rahmani","Mohammadmehdi Naghiaei","Yashar Deldjoo"],"pdf_url":"https://arxiv.org/pdf/2306.11395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11296v1","updated":"2023-06-20T05:20:29Z","published":"2023-06-20T05:20:29Z","title":"ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF\n  Synthesis","summary":"  We use prompt engineering to guide ChatGPT in the automation of text mining\nof metal-organic frameworks (MOFs) synthesis conditions from diverse formats\nand styles of the scientific literature. This effectively mitigates ChatGPT's\ntendency to hallucinate information -- an issue that previously made the use of\nLarge Language Models (LLMs) in scientific fields challenging. Our approach\ninvolves the development of a workflow implementing three different processes\nfor text mining, programmed by ChatGPT itself. All of them enable parsing,\nsearching, filtering, classification, summarization, and data unification with\ndifferent tradeoffs between labor, speed, and accuracy. We deploy this system\nto extract 26,257 distinct synthesis parameters pertaining to approximately 800\nMOFs sourced from peer-reviewed research articles. This process incorporates\nour ChemPrompt Engineering strategy to instruct ChatGPT in text mining,\nresulting in impressive precision, recall, and F1 scores of 90-99%.\nFurthermore, with the dataset built by text mining, we constructed a\nmachine-learning model with over 86% accuracy in predicting MOF experimental\ncrystallization outcomes and preliminarily identifying important factors in MOF\ncrystallization. We also developed a reliable data-grounded MOF chatbot to\nanswer questions on chemical reactions and synthesis procedures. Given that the\nprocess of using ChatGPT reliably mines and tabulates diverse MOF synthesis\ninformation in a unified format, while using only narrative language requiring\nno coding expertise, we anticipate that our ChatGPT Chemistry Assistant will be\nvery useful across various other chemistry sub-disciplines.\n","authors":["Zhiling Zheng","Oufan Zhang","Christian Borgs","Jennifer T. Chayes","Omar M. Yaghi"],"pdf_url":"https://arxiv.org/pdf/2306.11296v1.pdf","comment":"97 pages (17-page manuscript, 80 pages of supporting information)"},{"id":"http://arxiv.org/abs/2306.11293v1","updated":"2023-06-20T05:18:55Z","published":"2023-06-20T05:18:55Z","title":"Representation Sparsification with Hybrid Thresholding for Fast\n  SPLADE-based Document Retrieval","summary":"  Learned sparse document representations using a transformer-based neural\nmodel has been found to be attractive in both relevance effectiveness and time\nefficiency. This paper describes a representation sparsification scheme based\non hard and soft thresholding with an inverted index approximation for faster\nSPLADE-based document retrieval. It provides analytical and experimental\nresults on the impact of this learnable hybrid thresholding scheme.\n","authors":["Yifan Qiao","Yingrui Yang","Shanxiu He","Tao Yang"],"pdf_url":"https://arxiv.org/pdf/2306.11293v1.pdf","comment":"This paper is published in SIGIR'23"},{"id":"http://arxiv.org/abs/2306.11279v1","updated":"2023-06-20T04:16:53Z","published":"2023-06-20T04:16:53Z","title":"Less Can Be More: Exploring Population Rating Dispositions with\n  Partitioned Models in Recommender Systems","summary":"  In this study, we partition users by rating disposition - looking first at\ntheir percentage of negative ratings, and then at the general use of the rating\nscale. We hypothesize that users with different rating dispositions may use the\nrecommender system differently and therefore the agreement with their past\nratings may be less predictive of the future agreement.\n  We use data from a large movie rating website to explore whether users should\nbe grouped by disposition, focusing on identifying their various rating\ndistributions that may hurt recommender effectiveness. We find that such\npartitioning not only improves computational efficiency but also improves top-k\nperformance and predictive accuracy. Though such effects are largest for the\nuser-based KNN CF, smaller for item-based KNN CF, and smallest for latent\nfactor algorithms such as SVD.\n","authors":["Ruixuan Sun","Ruoyan Kong","Qiao Jin","Joseph A. Konstan"],"pdf_url":"https://arxiv.org/pdf/2306.11279v1.pdf","comment":"Ruixuan Sun, Ruoyan Kong, Qiao Jin, and Joseph A. Konstan. 2023. Less\n  Can Be More: Exploring Population Rating Dispositions with Partitioned Models\n  in Recommender Systems. In UMAP 23 Adjunct: Adjunct Proceedings of the 31st\n  ACM Conference on User Modeling, Adaptation and Personalization (UMAP 23\n  Adjunct), June 26-29, 2023, Limassol, Cyprus. ACM, New York, NY, USA, 5 pages"},{"id":"http://arxiv.org/abs/2301.12197v2","updated":"2023-06-20T02:59:32Z","published":"2023-01-28T13:38:48Z","title":"Mutual Wasserstein Discrepancy Minimization for Sequential\n  Recommendation","summary":"  Self-supervised sequential recommendation significantly improves\nrecommendation performance by maximizing mutual information with well-designed\ndata augmentations. However, the mutual information estimation is based on the\ncalculation of Kullback Leibler divergence with several limitations, including\nasymmetrical estimation, the exponential need of the sample size, and training\ninstability. Also, existing data augmentations are mostly stochastic and can\npotentially break sequential correlations with random modifications. These two\nissues motivate us to investigate an alternative robust mutual information\nmeasurement capable of modeling uncertainty and alleviating KL divergence\nlimitations. To this end, we propose a novel self-supervised learning framework\nbased on Mutual WasserStein discrepancy minimization MStein for the sequential\nrecommendation. We propose the Wasserstein Discrepancy Measurement to measure\nthe mutual information between augmented sequences. Wasserstein Discrepancy\nMeasurement builds upon the 2-Wasserstein distance, which is more robust, more\nefficient in small batch sizes, and able to model the uncertainty of stochastic\naugmentation processes. We also propose a novel contrastive learning loss based\non Wasserstein Discrepancy Measurement. Extensive experiments on four benchmark\ndatasets demonstrate the effectiveness of MStein over baselines. More\nquantitative analyses show the robustness against perturbations and training\nefficiency in batch size. Finally, improvements analysis indicates better\nrepresentations of popular users or items with significant uncertainty. The\nsource code is at https://github.com/zfan20/MStein.\n","authors":["Ziwei Fan","Zhiwei Liu","Hao Peng","Philip S Yu"],"pdf_url":"https://arxiv.org/pdf/2301.12197v2.pdf","comment":"Updated with the correction of the asymmetric mistake on the mutual\n  information connection"},{"id":"http://arxiv.org/abs/2306.11233v1","updated":"2023-06-20T01:47:25Z","published":"2023-06-20T01:47:25Z","title":"Hybrid Multi-Criteria Preference Ranking by Subsorting","summary":"  Multi-criteria recommender systems can improve the quality of recommendations\nby considering user preferences on multiple criteria. One promising approach\nproposed recently is multi-criteria ranking, which uses Pareto ranking to\nassign a ranking score based on the dominance relationship between predicted\nratings across criteria. However, applying Pareto ranking to all criteria may\nresult in non-differentiable ranking scores. To alleviate this issue, we\nproposed a hybrid multi-criteria ranking method by using subsorting. More\nspecifically, we utilize one ranking method as the major sorting approach,\nwhile we apply another preference ordering method as subsorting. Our\nexperimental results on the OpenTable and Yahoo!Movies data present the\nadvantages of this hybrid ranking approach. In addition, the experiments also\nreveal more insights about the sustainability of the multi-criteria ranking for\ntop-N item recommendations.\n","authors":["Yong Zheng","David Xuejun Wang"],"pdf_url":"https://arxiv.org/pdf/2306.11233v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11843v1","updated":"2023-06-20T18:51:21Z","published":"2023-06-20T18:51:21Z","title":"Retrieval-Based Transformer for Table Augmentation","summary":"  Data preparation, also called data wrangling, is considered one of the most\nexpensive and time-consuming steps when performing analytics or building\nmachine learning models. Preparing data typically involves collecting and\nmerging data from complex heterogeneous, and often large-scale data sources,\nsuch as data lakes. In this paper, we introduce a novel approach toward\nautomatic data wrangling in an attempt to alleviate the effort of end-users,\ne.g. data analysts, in structuring dynamic views from data lakes in the form of\ntabular data. We aim to address table augmentation tasks, including row/column\npopulation and data imputation. Given a corpus of tables, we propose a\nretrieval augmented self-trained transformer model. Our self-learning strategy\nconsists in randomly ablating tables from the corpus and training the\nretrieval-based model to reconstruct the original values or headers given the\npartial tables as input. We adopt this strategy to first train the dense neural\nretrieval model encoding table-parts to vectors, and then the end-to-end model\ntrained to perform table augmentation tasks. We test on EntiTables, the\nstandard benchmark for table augmentation, as well as introduce a new benchmark\nto advance further research: WebTables. Our model consistently and\nsubstantially outperforms both supervised statistical methods and the current\nstate-of-the-art transformer-based models.\n","authors":["Michael Glass","Xueqing Wu","Ankita Rajaram Naik","Gaetano Rossiello","Alfio Gliozzo"],"pdf_url":"https://arxiv.org/pdf/2306.11843v1.pdf","comment":"Findings of ACL 2023"},{"id":"http://arxiv.org/abs/2306.11832v1","updated":"2023-06-20T18:43:24Z","published":"2023-06-20T18:43:24Z","title":"QuOTeS: Query-Oriented Technical Summarization","summary":"  Abstract. When writing an academic paper, researchers often spend\nconsiderable time reviewing and summarizing papers to extract relevant\ncitations and data to compose the Introduction and Related Work sections. To\naddress this problem, we propose QuOTeS, an interactive system designed to\nretrieve sentences related to a summary of the research from a collection of\npotential references and hence assist in the composition of new papers. QuOTeS\nintegrates techniques from Query-Focused Extractive Summarization and\nHigh-Recall Information Retrieval to provide Interactive Query-Focused\nSummarization of scientific documents. To measure the performance of our\nsystem, we carried out a comprehensive user study where participants uploaded\npapers related to their research and evaluated the system in terms of its\nusability and the quality of the summaries it produces. The results show that\nQuOTeS provides a positive user experience and consistently provides\nquery-focused summaries that are relevant, concise, and complete. We share the\ncode of our system and the novel Query-Focused Summarization dataset collected\nduring our experiments at https://github.com/jarobyte91/quotes.\n","authors":["Juan Ramirez-Orta","Eduardo Xamena","Ana Maguitman","Axel J. Soto","Flavia P. Zanoto","Evangelos Milios"],"pdf_url":"https://arxiv.org/pdf/2306.11832v1.pdf","comment":"Accepted at ICDAR 2023"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2306.11730v1","updated":"2023-06-20T17:59:14Z","published":"2023-06-20T17:59:14Z","title":"Segment Anything Model (SAM) for Radiation Oncology","summary":"  In this study, we evaluate the performance of the Segment Anything Model\n(SAM) model in clinical radiotherapy. We collected real clinical cases from\nfour regions at the Mayo Clinic: prostate, lung, gastrointestinal, and head \\&\nneck, which are typical treatment sites in radiation oncology. For each case,\nwe selected the OARs of concern in radiotherapy planning and compared the Dice\nand Jaccard outcomes between clinical manual delineation, automatic\nsegmentation using SAM's \"segment anything\" mode, and automatic segmentation\nusing SAM with box prompt. Our results indicate that SAM performs better in\nautomatic segmentation for the prostate and lung regions, while its performance\nin the gastrointestinal and head \\& neck regions was relatively inferior. When\nconsidering the size of the organ and the clarity of its boundary, SAM displays\nbetter performance for larger organs with clear boundaries, such as the lung\nand liver, and worse for smaller organs with unclear boundaries, like the\nparotid and cochlea. These findings align with the generally accepted\nvariations in difficulty level associated with manual delineation of different\norgans at different sites in clinical radiotherapy. Given that SAM, a single\ntrained model, could handle the delineation of OARs in four regions, these\nresults also demonstrate SAM's robust generalization capabilities in automatic\nsegmentation for radiotherapy, i.e., achieving delineation of different\nradiotherapy OARs using a generic automatic segmentation model. SAM's\ngeneralization capabilities across different regions make it technically\nfeasible to develop a generic model for automatic segmentation in radiotherapy.\n","authors":["Lian Zhang","Zhengliang Liu","Lu Zhang","Zihao Wu","Xiaowei Yu","Jason Holmes","Hongying Feng","Haixing Dai","Xiang Li","Quanzheng Li","Dajiang Zhu","Tianming Liu","Wei Liu"],"pdf_url":"https://arxiv.org/pdf/2306.11730v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.16952v2","updated":"2023-06-20T17:58:25Z","published":"2022-03-31T11:18:41Z","title":"Multimodal Fusion Transformer for Remote Sensing Image Classification","summary":"  Vision transformers (ViTs) have been trending in image classification tasks\ndue to their promising performance when compared to convolutional neural\nnetworks (CNNs). As a result, many researchers have tried to incorporate ViTs\nin hyperspectral image (HSI) classification tasks. To achieve satisfactory\nperformance, close to that of CNNs, transformers need fewer parameters. ViTs\nand other similar transformers use an external classification (CLS) token which\nis randomly initialized and often fails to generalize well, whereas other\nsources of multimodal datasets, such as light detection and ranging (LiDAR)\noffer the potential to improve these models by means of a CLS. In this paper,\nwe introduce a new multimodal fusion transformer (MFT) network which comprises\na multihead cross patch attention (mCrossPA) for HSI land-cover classification.\nOur mCrossPA utilizes other sources of complementary information in addition to\nthe HSI in the transformer encoder to achieve better generalization. The\nconcept of tokenization is used to generate CLS and HSI patch tokens, helping\nto learn a {distinctive representation} in a reduced and hierarchical feature\nspace. Extensive experiments are carried out on {widely used benchmark}\ndatasets {i.e.,} the University of Houston, Trento, University of Southern\nMississippi Gulfpark (MUUFL), and Augsburg. We compare the results of the\nproposed MFT model with other state-of-the-art transformers, classical CNNs,\nand conventional classifiers models. The superior performance achieved by the\nproposed model is due to the use of multihead cross patch attention. The source\ncode will be made available publicly at\n\\url{https://github.com/AnkurDeria/MFT}.}\n","authors":["Swalpa Kumar Roy","Ankur Deria","Danfeng Hong","Behnood Rasti","Antonio Plaza","Jocelyn Chanussot"],"pdf_url":"https://arxiv.org/pdf/2203.16952v2.pdf","comment":"Published in IEEE Transactions on Geoscience and Remote Sensing"},{"id":"http://arxiv.org/abs/2306.11719v1","updated":"2023-06-20T17:53:00Z","published":"2023-06-20T17:53:00Z","title":"Diffusion with Forward Models: Solving Stochastic Inverse Problems\n  Without Direct Supervision","summary":"  Denoising diffusion models are a powerful type of generative models used to\ncapture complex distributions of real-world signals. However, their\napplicability is limited to scenarios where training samples are readily\navailable, which is not always the case in real-world applications. For\nexample, in inverse graphics, the goal is to generate samples from a\ndistribution of 3D scenes that align with a given image, but ground-truth 3D\nscenes are unavailable and only 2D images are accessible. To address this\nlimitation, we propose a novel class of denoising diffusion probabilistic\nmodels that learn to sample from distributions of signals that are never\ndirectly observed. Instead, these signals are measured indirectly through a\nknown differentiable forward model, which produces partial observations of the\nunknown signal. Our approach involves integrating the forward model directly\ninto the denoising process. This integration effectively connects the\ngenerative modeling of observations with the generative modeling of the\nunderlying signals, allowing for end-to-end training of a conditional\ngenerative model over signals. During inference, our approach enables sampling\nfrom the distribution of underlying signals that are consistent with a given\npartial observation. We demonstrate the effectiveness of our method on three\nchallenging computer vision tasks. For instance, in the context of inverse\ngraphics, our model enables direct sampling from the distribution of 3D scenes\nthat align with a single 2D input image.\n","authors":["Ayush Tewari","Tianwei Yin","George Cazenavette","Semon Rezchikov","Joshua B. Tenenbaum","Frédo Durand","William T. Freeman","Vincent Sitzmann"],"pdf_url":"https://arxiv.org/pdf/2306.11719v1.pdf","comment":"Project page: https://diffusion-with-forward-models.github.io/"},{"id":"http://arxiv.org/abs/2306.11715v1","updated":"2023-06-20T17:43:42Z","published":"2023-06-20T17:43:42Z","title":"Multi-Fidelity Active Learning with GFlowNets","summary":"  In the last decades, the capacity to generate large amounts of data in\nscience and engineering applications has been growing steadily. Meanwhile, the\nprogress in machine learning has turned it into a suitable tool to process and\nutilise the available data. Nonetheless, many relevant scientific and\nengineering problems present challenges where current machine learning methods\ncannot yet efficiently leverage the available data and resources. For example,\nin scientific discovery, we are often faced with the problem of exploring very\nlarge, high-dimensional spaces, where querying a high fidelity, black-box\nobjective function is very expensive. Progress in machine learning methods that\ncan efficiently tackle such problems would help accelerate currently crucial\nareas such as drug and materials discovery. In this paper, we propose the use\nof GFlowNets for multi-fidelity active learning, where multiple approximations\nof the black-box function are available at lower fidelity and cost. GFlowNets\nare recently proposed methods for amortised probabilistic inference that have\nproven efficient for exploring large, high-dimensional spaces and can hence be\npractical in the multi-fidelity setting too. Here, we describe our algorithm\nfor multi-fidelity active learning with GFlowNets and evaluate its performance\nin both well-studied synthetic tasks and practically relevant applications of\nmolecular discovery. Our results show that multi-fidelity active learning with\nGFlowNets can efficiently leverage the availability of multiple oracles with\ndifferent costs and fidelities to accelerate scientific discovery and\nengineering design.\n","authors":["Alex Hernandez-Garcia","Nikita Saxena","Moksh Jain","Cheng-Hao Liu","Yoshua Bengio"],"pdf_url":"https://arxiv.org/pdf/2306.11715v1.pdf","comment":"Code: https://github.com/nikita-0209/mf-al-gfn"},{"id":"http://arxiv.org/abs/2306.11714v1","updated":"2023-06-20T17:42:30Z","published":"2023-06-20T17:42:30Z","title":"Meta-Analysis of Transfer Learning for Segmentation of Brain Lesions","summary":"  A major challenge in stroke research and stroke recovery predictions is the\ndetermination of a stroke lesion's extent and its impact on relevant brain\nsystems. Manual segmentation of stroke lesions from 3D magnetic resonance (MR)\nimaging volumes, the current gold standard, is not only very time-consuming,\nbut its accuracy highly depends on the operator's experience. As a result,\nthere is a need for a fully automated segmentation method that can efficiently\nand objectively measure lesion extent and the impact of each lesion to predict\nimpairment and recovery potential which might be beneficial for clinical,\ntranslational, and research settings. We have implemented and tested a fully\nautomatic method for stroke lesion segmentation which was developed using eight\ndifferent 2D-model architectures trained via transfer learning (TL) and mixed\ndata approaches. Additionally, the final prediction was made using a novel\nensemble method involving stacking and agreement window. Our novel method was\nevaluated in a novel in-house dataset containing 22 T1w brain MR images, which\nwere challenging in various perspectives, but mostly because they included T1w\nMR images from the subacute (which typically less well defined T1 lesions) and\nchronic stroke phase (which typically means well defined T1-lesions).\nCross-validation results indicate that our new method can efficiently and\nautomatically segment lesions fast and with high accuracy compared to ground\ntruth. In addition to segmentation, we provide lesion volume and weighted\nlesion load of relevant brain systems based on the lesions' overlap with a\ncanonical structural motor system that stretches from the cortical motor region\nto the lowest end of the brain stem.\n","authors":["Sovesh Mohapatra","Advait Gosai","Anant Shinde","Aleksei Rutkovskii","Sirisha Nouduri","Gottfried Schlaug"],"pdf_url":"https://arxiv.org/pdf/2306.11714v1.pdf","comment":"13 Pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2306.09633v2","updated":"2023-06-20T17:39:24Z","published":"2023-06-16T05:32:24Z","title":"The False Dawn: Reevaluating Google's Reinforcement Learning for Chip\n  Macro Placement","summary":"  Reinforcement learning (RL) for physical design of silicon chips in a Google\n2021 Nature paper stirred controversy due to poorly documented claims that\nraised eyebrows and attracted critical media coverage. The Nature paper\nwithheld most inputs needed to produce reported results and some critical steps\nin the methodology. But two separate evaluations filled in the gaps and\ndemonstrated that Google RL lags behind human designers, behind a well-known\nalgorithm (Simulated Annealing), and also behind generally-available commercial\nsoftware. Crosschecked data indicate that the integrity of the Nature paper is\nsubstantially undermined owing to errors in the conduct, analysis and\nreporting.\n","authors":["Igor L. Markov"],"pdf_url":"https://arxiv.org/pdf/2306.09633v2.pdf","comment":"14 pages, 1 figure, 3 tables"},{"id":"http://arxiv.org/abs/2306.11706v1","updated":"2023-06-20T17:35:20Z","published":"2023-06-20T17:35:20Z","title":"RoboCat: A Self-Improving Foundation Agent for Robotic Manipulation","summary":"  The ability to leverage heterogeneous robotic experience from different\nrobots and tasks to quickly master novel skills and embodiments has the\npotential to transform robot learning. Inspired by recent advances in\nfoundation models for vision and language, we propose a foundation agent for\nrobotic manipulation. This agent, named RoboCat, is a visual goal-conditioned\ndecision transformer capable of consuming multi-embodiment action-labelled\nvisual experience. This data spans a large repertoire of motor control skills\nfrom simulated and real robotic arms with varying sets of observations and\nactions. With RoboCat, we demonstrate the ability to generalise to new tasks\nand robots, both zero-shot as well as through adaptation using only 100--1000\nexamples for the target task. We also show how a trained model itself can be\nused to generate data for subsequent training iterations, thus providing a\nbasic building block for an autonomous improvement loop. We investigate the\nagent's capabilities, with large-scale evaluations both in simulation and on\nthree different real robot embodiments. We find that as we grow and diversify\nits training data, RoboCat not only shows signs of cross-task transfer, but\nalso becomes more efficient at adapting to new tasks.\n","authors":["Konstantinos Bousmalis","Giulia Vezzani","Dushyant Rao","Coline Devin","Alex X. Lee","Maria Bauza","Todor Davchev","Yuxiang Zhou","Agrim Gupta","Akhil Raju","Antoine Laurens","Claudio Fantacci","Valentin Dalibard","Martina Zambelli","Murilo Martins","Rugile Pevceviciute","Michiel Blokzijl","Misha Denil","Nathan Batchelor","Thomas Lampe","Emilio Parisotto","Konrad Żołna","Scott Reed","Sergio Gómez Colmenarejo","Jon Scholz","Abbas Abdolmaleki","Oliver Groth","Jean-Baptiste Regli","Oleg Sushkov","Tom Rothörl","José Enrique Chen","Yusuf Aytar","Dave Barker","Joy Ortiz","Martin Riedmiller","Jost Tobias Springenberg","Raia Hadsell","Francesco Nori","Nicolas Heess"],"pdf_url":"https://arxiv.org/pdf/2306.11706v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.10008v2","updated":"2023-06-20T17:33:58Z","published":"2023-06-16T17:58:15Z","title":"CLIP2Protect: Protecting Facial Privacy using Text-Guided Makeup via\n  Adversarial Latent Search","summary":"  The success of deep learning based face recognition systems has given rise to\nserious privacy concerns due to their ability to enable unauthorized tracking\nof users in the digital world. Existing methods for enhancing privacy fail to\ngenerate naturalistic images that can protect facial privacy without\ncompromising user experience. We propose a novel two-step approach for facial\nprivacy protection that relies on finding adversarial latent codes in the\nlow-dimensional manifold of a pretrained generative model. The first step\ninverts the given face image into the latent space and finetunes the generative\nmodel to achieve an accurate reconstruction of the given image from its latent\ncode. This step produces a good initialization, aiding the generation of\nhigh-quality faces that resemble the given identity. Subsequently, user-defined\nmakeup text prompts and identity-preserving regularization are used to guide\nthe search for adversarial codes in the latent space. Extensive experiments\ndemonstrate that faces generated by our approach have stronger black-box\ntransferability with an absolute gain of 12.06% over the state-of-the-art\nfacial privacy protection approach under the face verification task. Finally,\nwe demonstrate the effectiveness of the proposed approach for commercial face\nrecognition systems. Our code is available at\nhttps://github.com/fahadshamshad/Clip2Protect.\n","authors":["Fahad Shamshad","Muzammal Naseer","Karthik Nandakumar"],"pdf_url":"https://arxiv.org/pdf/2306.10008v2.pdf","comment":"Accepted in CVPR 2023. Project page:\n  https://fahadshamshad.github.io/Clip2Protect/"},{"id":"http://arxiv.org/abs/2306.11700v1","updated":"2023-06-20T17:27:31Z","published":"2023-06-20T17:27:31Z","title":"Last-Iterate Convergent Policy Gradient Primal-Dual Methods for\n  Constrained MDPs","summary":"  We study the problem of computing an optimal policy of an infinite-horizon\ndiscounted constrained Markov decision process (constrained MDP). Despite the\npopularity of Lagrangian-based policy search methods used in practice, the\noscillation of policy iterates in these methods has not been fully understood,\nbringing out issues such as violation of constraints and sensitivity to\nhyper-parameters. To fill this gap, we employ the Lagrangian method to cast a\nconstrained MDP into a constrained saddle-point problem in which max/min\nplayers correspond to primal/dual variables, respectively, and develop two\nsingle-time-scale policy-based primal-dual algorithms with non-asymptotic\nconvergence of their policy iterates to an optimal constrained policy.\nSpecifically, we first propose a regularized policy gradient primal-dual\n(RPG-PD) method that updates the policy using an entropy-regularized policy\ngradient, and the dual via a quadratic-regularized gradient ascent,\nsimultaneously. We prove that the policy primal-dual iterates of RPG-PD\nconverge to a regularized saddle point with a sublinear rate, while the policy\niterates converge sublinearly to an optimal constrained policy. We further\ninstantiate RPG-PD in large state or action spaces by including function\napproximation in policy parametrization, and establish similar sublinear\nlast-iterate policy convergence. Second, we propose an optimistic policy\ngradient primal-dual (OPG-PD) method that employs the optimistic gradient\nmethod to update primal/dual variables, simultaneously. We prove that the\npolicy primal-dual iterates of OPG-PD converge to a saddle point that contains\nan optimal constrained policy, with a linear rate. To the best of our\nknowledge, this work appears to be the first non-asymptotic policy last-iterate\nconvergence result for single-time-scale algorithms in constrained MDPs.\n","authors":["Dongsheng Ding","Chen-Yu Wei","Kaiqing Zhang","Alejandro Ribeiro"],"pdf_url":"https://arxiv.org/pdf/2306.11700v1.pdf","comment":"78 pages, 17 figures, and 1 table"},{"id":"http://arxiv.org/abs/2306.11697v1","updated":"2023-06-20T17:22:23Z","published":"2023-06-20T17:22:23Z","title":"Individual Treatment Effects in Extreme Regimes","summary":"  Understanding individual treatment effects in extreme regimes is important\nfor characterizing risks associated with different interventions. This is\nhindered by the fact that extreme regime data may be hard to collect, as it is\nscarcely observed in practice. In addressing this issue, we propose a new\nframework for estimating the individual treatment effect in extreme regimes\n(ITE$_2$). Specifically, we quantify this effect by the changes in the tail\ndecay rates of potential outcomes in the presence or absence of the treatment.\nSubsequently, we establish conditions under which ITE$_2$ may be calculated and\ndevelop algorithms for its computation. We demonstrate the efficacy of our\nproposed method on various synthetic and semi-synthetic datasets.\n","authors":["Ahmed Aloui","Ali Hasan","Yuting Ng","Miroslav Pajic","Vahid Tarokh"],"pdf_url":"https://arxiv.org/pdf/2306.11697v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11696v1","updated":"2023-06-20T17:19:39Z","published":"2023-06-20T17:19:39Z","title":"RoTaR: Efficient Row-Based Table Representation Learning via\n  Teacher-Student Training","summary":"  We propose RoTaR, a row-based table representation learning method, to\naddress the efficiency and scalability issues faced by existing table\nrepresentation learning methods. The key idea of RoTaR is to generate\nquery-agnostic row representations that could be re-used via query-specific\naggregation. In addition to the row-based architecture, we introduce several\ntechniques: cell-aware position embedding, teacher-student training paradigm,\nand selective backward to improve the performance of RoTaR model.\n","authors":["Zui Chen","Lei Cao","Sam Madden"],"pdf_url":"https://arxiv.org/pdf/2306.11696v1.pdf","comment":"6 pages, 3 figures, NeurIPS 2022 Table Representation Learning\n  workshop"},{"id":"http://arxiv.org/abs/2306.11695v1","updated":"2023-06-20T17:18:20Z","published":"2023-06-20T17:18:20Z","title":"A Simple and Effective Pruning Approach for Large Language Models","summary":"  As their size increases, Large Languages Models (LLMs) are natural candidates\nfor network pruning methods: approaches that drop a subset of network weights\nwhile striving to preserve performance. Existing methods, however, require\neither retraining, which is rarely affordable for billion-scale LLMs, or\nsolving a weight reconstruction problem reliant on second-order information,\nwhich may also be computationally expensive. In this paper, we introduce a\nnovel, straightforward yet effective pruning method, termed Wanda (Pruning by\nWeights and activations), designed to induce sparsity in pretrained LLMs.\nMotivated by the recent observation of emergent large magnitude features in\nLLMs, our approach prune weights with the smallest magnitudes multiplied by the\ncorresponding input activations, on a per-output basis. Notably, Wanda requires\nno retraining or weight update, and the pruned LLM can be used as is. We\nconduct a thorough evaluation of our method on LLaMA across various language\nbenchmarks. Wanda significantly outperforms the established baseline of\nmagnitude pruning and competes favorably against recent methods involving\nintensive weight update. Code is available at\nhttps://github.com/locuslab/wanda.\n","authors":["Mingjie Sun","Zhuang Liu","Anna Bair","J. Zico Kolter"],"pdf_url":"https://arxiv.org/pdf/2306.11695v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2306.11681v1","updated":"2023-06-20T16:58:19Z","published":"2023-06-20T16:58:19Z","title":"MoleCLUEs: Optimizing Molecular Conformers by Minimization of\n  Differentiable Uncertainty","summary":"  Structure-based models in the molecular sciences can be highly sensitive to\ninput geometries and give predictions with large variance under subtle\ncoordinate perturbations. We present an approach to mitigate this failure mode\nby generating conformations that explicitly minimize uncertainty in a\npredictive model. To achieve this, we compute differentiable estimates of\naleatoric \\textit{and} epistemic uncertainties directly from learned\nembeddings. We then train an optimizer that iteratively samples embeddings to\nreduce these uncertainties according to their gradients. As our predictive\nmodel is constructed as a variational autoencoder, the new embeddings can be\ndecoded to their corresponding inputs, which we call \\textit{MoleCLUEs}, or\n(molecular) counterfactual latent uncertainty explanations\n\\citep{antoran2020getting}. We provide results of our algorithm for the task of\npredicting drug properties with maximum confidence as well as analysis of the\ndifferentiable structure simulations.\n","authors":["Michael Maser","Natasa Tagasovska","Jae Hyeon Lee","Andrew Watkins"],"pdf_url":"https://arxiv.org/pdf/2306.11681v1.pdf","comment":"Submitted to the Differentiable Almost Everything Workshop, ICML 2023"},{"id":"http://arxiv.org/abs/2306.11680v1","updated":"2023-06-20T16:58:00Z","published":"2023-06-20T16:58:00Z","title":"The Implicit Bias of Batch Normalization in Linear Models and Two-layer\n  Linear Convolutional Neural Networks","summary":"  We study the implicit bias of batch normalization trained by gradient\ndescent. We show that when learning a linear model with batch normalization for\nbinary classification, gradient descent converges to a uniform margin\nclassifier on the training data with an $\\exp(-\\Omega(\\log^2 t))$ convergence\nrate. This distinguishes linear models with batch normalization from those\nwithout batch normalization in terms of both the type of implicit bias and the\nconvergence rate. We further extend our result to a class of two-layer,\nsingle-filter linear convolutional neural networks, and show that batch\nnormalization has an implicit bias towards a patch-wise uniform margin. Based\non two examples, we demonstrate that patch-wise uniform margin classifiers can\noutperform the maximum margin classifiers in certain learning problems. Our\nresults contribute to a better theoretical understanding of batch\nnormalization.\n","authors":["Yuan Cao","Difan Zou","Yuanzhi Li","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2306.11680v1.pdf","comment":"53 pages, 2 figures"},{"id":"http://arxiv.org/abs/2301.07210v3","updated":"2023-06-20T16:57:52Z","published":"2023-01-17T22:18:53Z","title":"Causal Falsification of Digital Twins","summary":"  Digital twins hold substantial promise in many applications, but rigorous\nprocedures for assessing their accuracy are essential for their widespread\ndeployment in safety-critical settings. By formulating this task within the\nframework of causal inference, we show that attempts to certify the correctness\nof a twin using real-world observational data are unsound unless potentially\ntenuous assumptions are made about the data-generating process. To avoid these\nassumptions, we propose an assessment strategy that instead aims to find cases\nwhere the twin is not correct, and present a general-purpose statistical\nprocedure for doing so that may be used across a wide variety of applications\nand twin models. Our approach yields reliable and actionable information about\nthe twin under minimal assumptions about the twin and the real-world process of\ninterest. We demonstrate the effectiveness of our methodology via a large-scale\ncase study involving sepsis modelling within the Pulse Physiology Engine, which\nwe assess using the MIMIC-III dataset of ICU patients.\n","authors":["Rob Cornish","Muhammad Faaiz Taufiq","Arnaud Doucet","Chris Holmes"],"pdf_url":"https://arxiv.org/pdf/2301.07210v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.13005v2","updated":"2023-06-20T16:53:06Z","published":"2022-05-25T18:35:11Z","title":"QGNN: Value Function Factorisation with Graph Neural Networks","summary":"  In multi-agent reinforcement learning, the use of a global objective is a\npowerful tool for incentivising cooperation. Unfortunately, it is not\nsample-efficient to train individual agents with a global reward, because it\ndoes not necessarily correlate with an agent's individual actions. This problem\ncan be solved by factorising the global value function into local value\nfunctions. Early work in this domain performed factorisation by conditioning\nlocal value functions purely on local information. Recently, it has been shown\nthat providing both local information and an encoding of the global state can\npromote cooperative behaviour. In this paper we propose QGNN, the first value\nfactorisation method to use a graph neural network (GNN) based model. The\nmulti-layer message passing architecture of QGNN provides more representational\ncomplexity than models in prior work, allowing it to produce a more effective\nfactorisation. QGNN also introduces a permutation invariant mixer which is able\nto match the performance of other methods, even with significantly fewer\nparameters. We evaluate our method against several baselines, including\nQMIX-Att, GraphMIX, QMIX, VDN, and hybrid architectures. Our experiments\ninclude Starcraft, the standard benchmark for credit assignment; Estimate Game,\na custom environment that explicitly models inter-agent dependencies; and\nCoalition Structure Generation, a foundational problem with real-world\napplications. The results show that QGNN outperforms state-of-the-art value\nfactorisation baselines consistently.\n","authors":["Ryan Kortvelesy","Amanda Prorok"],"pdf_url":"https://arxiv.org/pdf/2205.13005v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.08650v2","updated":"2023-06-20T16:47:08Z","published":"2023-06-14T17:30:02Z","title":"Learning to Rank when Grades Matter","summary":"  Graded labels are ubiquitous in real-world learning-to-rank applications,\nespecially in human rated relevance data. Traditional learning-to-rank\ntechniques aim to optimize the ranked order of documents. They typically,\nhowever, ignore predicting actual grades. This prevents them from being adopted\nin applications where grades matter, such as filtering out ``poor'' documents.\nAchieving both good ranking performance and good grade prediction performance\nis still an under-explored problem. Existing research either focuses only on\nranking performance by not calibrating model outputs, or treats grades as\nnumerical values, assuming labels are on a linear scale and failing to leverage\nthe ordinal grade information. In this paper, we conduct a rigorous study of\nlearning to rank with grades, where both ranking performance and grade\nprediction performance are important. We provide a formal discussion on how to\nperform ranking with non-scalar predictions for grades, and propose a\nmultiobjective formulation to jointly optimize both ranking and grade\npredictions. In experiments, we verify on several public datasets that our\nmethods are able to push the Pareto frontier of the tradeoff between ranking\nand grade prediction performance, showing the benefit of leveraging ordinal\ngrade information.\n","authors":["Le Yan","Zhen Qin","Gil Shamir","Dong Lin","Xuanhui Wang","Mike Bendersky"],"pdf_url":"https://arxiv.org/pdf/2306.08650v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11670v1","updated":"2023-06-20T16:43:38Z","published":"2023-06-20T16:43:38Z","title":"GIO: Gradient Information Optimization for Training Dataset Selection","summary":"  It is often advantageous to train models on a subset of the available train\nexamples, because the examples are of variable quality or because one would\nlike to train with fewer examples, without sacrificing performance. We present\nGradient Information Optimization (GIO), a scalable, task-agnostic approach to\nthis data selection problem that requires only a small set of (unlabeled)\nexamples representing a target distribution. GIO begins from a natural,\ninformation-theoretic objective that is intractable in practice. Our\ncontribution is in showing that it can be made highly scalable through a simple\nrelaxation of the objective and a highly efficient implementation. In\nexperiments with machine translation, spelling correction, and image\nrecognition, we show that GIO delivers outstanding results with very small\ntrain sets. These findings are robust to different representation models and\nhyperparameters for GIO itself. GIO is task- and domain-agnostic and can be\napplied out-of-the-box to new datasets and domains.\n","authors":["Dante Everaert","Christopher Potts"],"pdf_url":"https://arxiv.org/pdf/2306.11670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11668v1","updated":"2023-06-20T16:40:41Z","published":"2023-06-20T16:40:41Z","title":"Principles for Initialization and Architecture Selection in Graph Neural\n  Networks with ReLU Activations","summary":"  This article derives and validates three principles for initialization and\narchitecture selection in finite width graph neural networks (GNNs) with ReLU\nactivations. First, we theoretically derive what is essentially the unique\ngeneralization to ReLU GNNs of the well-known He-initialization. Our\ninitialization scheme guarantees that the average scale of network outputs and\ngradients remains order one at initialization. Second, we prove in finite width\nvanilla ReLU GNNs that oversmoothing is unavoidable at large depth when using\nfixed aggregation operator, regardless of initialization. We then prove that\nusing residual aggregation operators, obtained by interpolating a fixed\naggregation operator with the identity, provably alleviates oversmoothing at\ninitialization. Finally, we show that the common practice of using residual\nconnections with a fixup-type initialization provably avoids correlation\ncollapse in final layer features at initialization. Through ablation studies we\nfind that using the correct initialization, residual aggregation operators, and\nresidual connections in the forward pass significantly and reliably speeds up\nearly training dynamics in deep ReLU GNNs on a variety of tasks.\n","authors":["Gage DeZoort","Boris Hanin"],"pdf_url":"https://arxiv.org/pdf/2306.11668v1.pdf","comment":"Comments appreciated"},{"id":"http://arxiv.org/abs/2306.11667v1","updated":"2023-06-20T16:39:27Z","published":"2023-06-20T16:39:27Z","title":"G-NM: A Group of Numerical Time Series Prediction Models","summary":"  In this study, we focus on the development and implementation of a\ncomprehensive ensemble of numerical time series forecasting models,\ncollectively referred to as the Group of Numerical Time Series Prediction Model\n(G-NM). This inclusive set comprises traditional models such as Autoregressive\nIntegrated Moving Average (ARIMA), Holt-Winters' method, and Support Vector\nRegression (SVR), in addition to modern neural network models including\nRecurrent Neural Network (RNN) and Long Short-Term Memory (LSTM). G-NM is\nexplicitly constructed to augment our predictive capabilities related to\npatterns and trends inherent in complex natural phenomena. By utilizing time\nseries data relevant to these events, G-NM facilitates the prediction of such\nphenomena over extended periods. The primary objective of this research is to\nboth advance our understanding of such occurrences and to significantly enhance\nthe accuracy of our forecasts. G-NM encapsulates both linear and non-linear\ndependencies, seasonalities, and trends present in time series data. Each of\nthese models contributes distinct strengths, from ARIMA's resilience in\nhandling linear trends and seasonality, SVR's proficiency in capturing\nnon-linear patterns, to LSTM's adaptability in modeling various components of\ntime series data. Through the exploitation of the G-NM potential, we strive to\nadvance the state-of-the-art in large-scale time series forecasting models. We\nanticipate that this research will represent a significant stepping stone in\nour ongoing endeavor to comprehend and forecast the complex events that\nconstitute the natural world.\n","authors":["Juyoung Yun"],"pdf_url":"https://arxiv.org/pdf/2306.11667v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.04338v2","updated":"2023-06-20T16:38:13Z","published":"2022-09-09T14:51:13Z","title":"Bridging the Gap: Differentially Private Equivariant Deep Learning for\n  Medical Image Analysis","summary":"  Machine learning with formal privacy-preserving techniques like Differential\nPrivacy (DP) allows one to derive valuable insights from sensitive medical\nimaging data while promising to protect patient privacy, but it usually comes\nat a sharp privacy-utility trade-off. In this work, we propose to use steerable\nequivariant convolutional networks for medical image analysis with DP. Their\nimproved feature quality and parameter efficiency yield remarkable accuracy\ngains, narrowing the privacy-utility gap.\n","authors":["Florian A. Hölzl","Daniel Rueckert","Georgios Kaissis"],"pdf_url":"https://arxiv.org/pdf/2209.04338v2.pdf","comment":"Accepted as extended abstract at GeoMedIA Workshop 2022\n  (https://openreview.net/forum?id=rGYfMrMxI17)"},{"id":"http://arxiv.org/abs/2306.11666v1","updated":"2023-06-20T16:37:57Z","published":"2023-06-20T16:37:57Z","title":"Neural Astrophysical Wind Models","summary":"  The bulk kinematics and thermodynamics of hot supernovae-driven galactic\nwinds is critically dependent on both the amount of swept up cool clouds and\nnon-spherical collimated flow geometry. However, accurately parameterizing\nthese physics is difficult because their functional forms are often unknown,\nand because the coupled non-linear flow equations contain singularities. We\nshow that deep neural networks embedded as individual terms in the governing\ncoupled ordinary differential equations (ODEs) can robustly discover both of\nthese physics, without any prior knowledge of the true function structure, as a\nsupervised learning task. We optimize a loss function based on the Mach number,\nrather than the explicitly solved-for 3 conserved variables, and apply a\npenalty term towards near-diverging solutions. The same neural network\narchitecture is used for learning both the hidden mass-loading and surface area\nexpansion rates. This work further highlights the feasibility of neural ODEs as\na promising discovery tool with mechanistic interpretability for non-linear\ninverse problems.\n","authors":["Dustin D. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2306.11666v1.pdf","comment":"7 Pages, 4 Figures, Accepted at the ICML 2023 Workshop on Machine\n  Learning for Astrophysics"},{"id":"http://arxiv.org/abs/2212.04488v2","updated":"2023-06-20T16:26:38Z","published":"2022-12-08T18:57:02Z","title":"Multi-Concept Customization of Text-to-Image Diffusion","summary":"  While generative models produce high-quality images of concepts learned from\na large-scale database, a user often wishes to synthesize instantiations of\ntheir own concepts (for example, their family, pets, or items). Can we teach a\nmodel to quickly acquire a new concept, given a few examples? Furthermore, can\nwe compose multiple new concepts together? We propose Custom Diffusion, an\nefficient method for augmenting existing text-to-image models. We find that\nonly optimizing a few parameters in the text-to-image conditioning mechanism is\nsufficiently powerful to represent new concepts while enabling fast tuning (~6\nminutes). Additionally, we can jointly train for multiple concepts or combine\nmultiple fine-tuned models into one via closed-form constrained optimization.\nOur fine-tuned model generates variations of multiple new concepts and\nseamlessly composes them with existing concepts in novel settings. Our method\noutperforms or performs on par with several baselines and concurrent works in\nboth qualitative and quantitative evaluations while being memory and\ncomputationally efficient.\n","authors":["Nupur Kumari","Bingliang Zhang","Richard Zhang","Eli Shechtman","Jun-Yan Zhu"],"pdf_url":"https://arxiv.org/pdf/2212.04488v2.pdf","comment":"Updated v2 with results on the new CustomConcept101 dataset\n  https://www.cs.cmu.edu/~custom-diffusion/dataset.html Project webpage:\n  https://www.cs.cmu.edu/~custom-diffusion"},{"id":"http://arxiv.org/abs/2305.13447v4","updated":"2023-06-20T16:18:45Z","published":"2023-05-22T19:44:57Z","title":"Regularization Through Simultaneous Learning: A Case Study on Plant\n  Classification","summary":"  In response to the prevalent challenge of overfitting in deep neural\nnetworks, this paper introduces Simultaneous Learning, a regularization\napproach drawing on principles of Transfer Learning and Multi-task Learning. We\nleverage auxiliary datasets with the target dataset, the UFOP-HVD, to\nfacilitate simultaneous classification guided by a customized loss function\nfeaturing an inter-group penalty. This experimental configuration allows for a\ndetailed examination of model performance across similar (PlantNet) and\ndissimilar (ImageNet) domains, thereby enriching the generalizability of\nConvolutional Neural Network models. Remarkably, our approach demonstrates\nsuperior performance over models without regularization and those applying\ndropout regularization exclusively, enhancing accuracy by 5 to 22 percentage\npoints. Moreover, when combined with dropout, the proposed approach improves\ngeneralization, securing state-of-the-art results for the UFOP-HVD challenge.\nThe method also showcases efficiency with significantly smaller sample sizes,\nsuggesting its broad applicability across a spectrum of related tasks. In\naddition, an interpretability approach is deployed to evaluate feature quality\nby analyzing class feature correlations within the network's convolutional\nlayers. The findings of this study provide deeper insights into the efficacy of\nSimultaneous Learning, particularly concerning its interaction with the\nauxiliary and target datasets.\n","authors":["Pedro Henrique Nascimento Castro","Gabriel Cássia Fortuna","Rafael Alves Bonfim de Queiroz","Gladston Juliano Prates Moreira","Eduardo José da Silva Luz"],"pdf_url":"https://arxiv.org/pdf/2305.13447v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11650v1","updated":"2023-06-20T16:18:14Z","published":"2023-06-20T16:18:14Z","title":"FedNoisy: Federated Noisy Label Learning Benchmark","summary":"  Federated learning has gained popularity for distributed learning without\naggregating sensitive data from clients. But meanwhile, the distributed and\nisolated nature of data isolation may be complicated by data quality, making it\nmore vulnerable to noisy labels. Many efforts exist to defend against the\nnegative impacts of noisy labels in centralized or federated settings. However,\nthere is a lack of a benchmark that comprehensively considers the impact of\nnoisy labels in a wide variety of typical FL settings. In this work, we serve\nthe first standardized benchmark that can help researchers fully explore\npotential federated noisy settings. Also, we conduct comprehensive experiments\nto explore the characteristics of these data settings and unravel challenging\nscenarios on the federated noisy label learning, which may guide method\ndevelopment in the future. We highlight the 20 basic settings for more than 5\ndatasets proposed in our benchmark and standardized simulation pipeline for\nfederated noisy label learning. We hope this benchmark can facilitate idea\nverification in federated learning with noisy labels. \\texttt{FedNoisy} is\navailable at \\codeword{https://github.com/SMILELab-FL/FedNoisy}.\n","authors":["Siqi Liang","Jintao Huang","Dun Zeng","Junyuan Hong","Jiayu Zhou","Zenglin Xu"],"pdf_url":"https://arxiv.org/pdf/2306.11650v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11644v1","updated":"2023-06-20T16:14:25Z","published":"2023-06-20T16:14:25Z","title":"Textbooks Are All You Need","summary":"  We introduce phi-1, a new large language model for code, with significantly\nsmaller size than competing models: phi-1 is a Transformer-based model with\n1.3B parameters, trained for 4 days on 8 A100s, using a selection of ``textbook\nquality\" data from the web (6B tokens) and synthetically generated textbooks\nand exercises with GPT-3.5 (1B tokens). Despite this small scale, phi-1 attains\npass@1 accuracy 50.6% on HumanEval and 55.5% on MBPP. It also displays\nsurprising emergent properties compared to phi-1-base, our model before our\nfinetuning stage on a dataset of coding exercises, and phi-1-small, a smaller\nmodel with 350M parameters trained with the same pipeline as phi-1 that still\nachieves 45% on HumanEval.\n","authors":["Suriya Gunasekar","Yi Zhang","Jyoti Aneja","Caio César Teodoro Mendes","Allie Del Giorno","Sivakanth Gopi","Mojan Javaheripi","Piero Kauffmann","Gustavo de Rosa","Olli Saarikivi","Adil Salim","Shital Shah","Harkirat Singh Behl","Xin Wang","Sébastien Bubeck","Ronen Eldan","Adam Tauman Kalai","Yin Tat Lee","Yuanzhi Li"],"pdf_url":"https://arxiv.org/pdf/2306.11644v1.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2206.02670v4","updated":"2023-06-20T16:07:31Z","published":"2022-06-06T15:16:10Z","title":"Robust Adversarial Attacks Detection based on Explainable Deep\n  Reinforcement Learning For UAV Guidance and Planning","summary":"  The dangers of adversarial attacks on Uncrewed Aerial Vehicle (UAV) agents\noperating in public are increasing. Adopting AI-based techniques and, more\nspecifically, Deep Learning (DL) approaches to control and guide these UAVs can\nbe beneficial in terms of performance but can add concerns regarding the safety\nof those techniques and their vulnerability against adversarial attacks.\nConfusion in the agent's decision-making process caused by these attacks can\nseriously affect the safety of the UAV. This paper proposes an innovative\napproach based on the explainability of DL methods to build an efficient\ndetector that will protect these DL schemes and the UAVs adopting them from\nattacks. The agent adopts a Deep Reinforcement Learning (DRL) scheme for\nguidance and planning. The agent is trained with a Deep Deterministic Policy\nGradient (DDPG) with Prioritised Experience Replay (PER) DRL scheme that\nutilises Artificial Potential Field (APF) to improve training times and\nobstacle avoidance performance. A simulated environment for UAV explainable\nDRL-based planning and guidance, including obstacles and adversarial attacks,\nis built. The adversarial attacks are generated by the Basic Iterative Method\n(BIM) algorithm and reduced obstacle course completion rates from 97\\% to 35\\%.\nTwo adversarial attack detectors are proposed to counter this reduction. The\nfirst one is a Convolutional Neural Network Adversarial Detector (CNN-AD),\nwhich achieves accuracy in the detection of 80\\%. The second detector utilises\na Long Short Term Memory (LSTM) network. It achieves an accuracy of 91\\% with\nfaster computing times compared to the CNN-AD, allowing for real-time\nadversarial detection.\n","authors":["Thomas Hickling","Nabil Aouf","Phillippa Spencer"],"pdf_url":"https://arxiv.org/pdf/2206.02670v4.pdf","comment":"13 pages, 16 figures"},{"id":"http://arxiv.org/abs/2306.11636v1","updated":"2023-06-20T16:02:56Z","published":"2023-06-20T16:02:56Z","title":"SeFNet: Bridging Tabular Datasets with Semantic Feature Nets","summary":"  Machine learning applications cover a wide range of predictive tasks in which\ntabular datasets play a significant role. However, although they often address\nsimilar problems, tabular datasets are typically treated as standalone tasks.\nThe possibilities of using previously solved problems are limited due to the\nlack of structured contextual information about their features and the lack of\nunderstanding of the relations between them. To overcome this limitation, we\npropose a new approach called Semantic Feature Net (SeFNet), capturing the\nsemantic meaning of the analyzed tabular features. By leveraging existing\nontologies and domain knowledge, SeFNet opens up new opportunities for sharing\ninsights between diverse predictive tasks. One such opportunity is the Dataset\nOntology-based Semantic Similarity (DOSS) measure, which quantifies the\nsimilarity between datasets using relations across their features. In this\npaper, we present an example of SeFNet prepared for a collection of predictive\ntasks in healthcare, with the features' relations derived from the SNOMED-CT\nontology. The proposed SeFNet framework and the accompanying DOSS measure\naddress the issue of limited contextual information in tabular datasets. By\nincorporating domain knowledge and establishing semantic relations between\nfeatures, we enhance the potential for meta-learning and enable valuable\ninsights to be shared across different predictive tasks.\n","authors":["Katarzyna Woźnica","Piotr Wilczyński","Przemysław Biecek"],"pdf_url":"https://arxiv.org/pdf/2306.11636v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10289v7","updated":"2023-06-20T15:56:23Z","published":"2023-02-20T20:25:41Z","title":"Tackling Shortcut Learning in Deep Neural Networks: An Iterative\n  Approach with Interpretable Models","summary":"  We use concept-based interpretable models to mitigate shortcut learning.\nExisting methods lack interpretability. Beginning with a Blackbox, we\niteratively carve out a mixture of interpretable experts (MoIE) and a residual\nnetwork. Each expert explains a subset of data using First Order Logic (FOL).\nWhile explaining a sample, the FOL from biased BB-derived MoIE detects the\nshortcut effectively. Finetuning the BB with Metadata Normalization (MDN)\neliminates the shortcut. The FOLs from the finetuned-BB-derived MoIE verify the\nelimination of the shortcut. Our experiments show that MoIE does not hurt the\naccuracy of the original BB and eliminates shortcuts effectively.\n","authors":["Shantanu Ghosh","Ke Yu","Forough Arabshahi","Kayhan Batmanghelich"],"pdf_url":"https://arxiv.org/pdf/2302.10289v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12020v2","updated":"2023-06-20T15:53:49Z","published":"2022-11-22T05:24:30Z","title":"PhAST: Physics-Aware, Scalable, and Task-specific GNNs for Accelerated\n  Catalyst Design","summary":"  Mitigating the climate crisis requires a rapid transition towards lower\ncarbon energy. Catalyst materials play a crucial role in the electrochemical\nreactions involved in a great number of industrial processes key to this\ntransition, such as renewable energy storage and electrofuel synthesis. To\nreduce the amount of energy spent on such processes, we must quickly discover\nmore efficient catalysts to drive the electrochemical reactions. Machine\nlearning (ML) holds the potential to efficiently model the properties of\nmaterials from large amounts of data, and thus to accelerate electrocatalyst\ndesign. The Open Catalyst Project OC20 data set was constructed to that end.\nHowever, most existing ML models trained on OC20 are still neither scalable nor\naccurate enough for practical applications. Here, we propose several\ntask-specific innovations, applicable to most architectures, which increase\nboth computational efficiency and accuracy. In particular, we propose\nimprovements in (1) the graph creation step, (2) atom representations and (3)\nthe energy prediction head. We describe these contributions and evaluate them\non several architectures, showing up to 5$\\times$ reduction in inference time\nwithout sacrificing accuracy.\n","authors":["Alexandre Duval","Victor Schmidt","Santiago Miret","Yoshua Bengio","Alex Hernández-García","David Rolnick"],"pdf_url":"https://arxiv.org/pdf/2211.12020v2.pdf","comment":"Accepted at the NeurIPS 2022 AI for Accelerated Materials Design\n  Workshop. Under submission at JMLR"},{"id":"http://arxiv.org/abs/2306.11626v1","updated":"2023-06-20T15:51:25Z","published":"2023-06-20T15:51:25Z","title":"Regularized Robust MDPs and Risk-Sensitive MDPs: Equivalence, Policy\n  Gradient, and Sample Complexity","summary":"  This paper focuses on reinforcement learning for the regularized robust\nMarkov decision process (MDP) problem, an extension of the robust MDP\nframework. We first introduce the risk-sensitive MDP and establish the\nequivalence between risk-sensitive MDP and regularized robust MDP. This\nequivalence offers an alternative perspective for addressing the regularized\nRMDP and enables the design of efficient learning algorithms. Given this\nequivalence, we further derive the policy gradient theorem for the regularized\nrobust MDP problem and prove the global convergence of the exact policy\ngradient method under the tabular setting with direct parameterization. We also\npropose a sample-based offline learning algorithm, namely the robust fitted-Z\niteration (RFZI), for a specific regularized robust MDP problem with a\nKL-divergence regularization term and analyze the sample complexity of the\nalgorithm. Our results are also supported by numerical simulations.\n","authors":["Runyu Zhang","Yang Hu","Na Li"],"pdf_url":"https://arxiv.org/pdf/2306.11626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.15239v2","updated":"2023-06-20T15:50:48Z","published":"2023-05-24T15:24:19Z","title":"Deep Learning and Ethics","summary":"  This article appears as chapter 21 of Prince (2023, Understanding Deep\nLearning); a complete draft of the textbook is available here:\nhttp://udlbook.com. This chapter considers potential harms arising from the\ndesign and use of AI systems. These include algorithmic bias, lack of\nexplainability, data privacy violations, militarization, fraud, and\nenvironmental concerns. The aim is not to provide advice on being more ethical.\nInstead, the goal is to express ideas and start conversations in key areas that\nhave received attention in philosophy, political science, and the broader\nsocial sciences.\n","authors":["Travis LaCroix","Simon J. D. Prince"],"pdf_url":"https://arxiv.org/pdf/2305.15239v2.pdf","comment":"Copyright in this Work has been licensed exclusively to The MIT\n  Press, https://mitpress.mit.edu, which will be releasing the final version to\n  the public in 2023. All inquiries regarding rights should be addressed to The\n  MIT Press, Rights and Permissions Department"},{"id":"http://arxiv.org/abs/2306.11623v1","updated":"2023-06-20T15:49:09Z","published":"2023-06-20T15:49:09Z","title":"Mean-field Analysis of Generalization Errors","summary":"  We propose a novel framework for exploring weak and $L_2$ generalization\nerrors of algorithms through the lens of differential calculus on the space of\nprobability measures. Specifically, we consider the KL-regularized empirical\nrisk minimization problem and establish generic conditions under which the\ngeneralization error convergence rate, when training on a sample of size $n$,\nis $\\mathcal{O}(1/n)$. In the context of supervised learning with a one-hidden\nlayer neural network in the mean-field regime, these conditions are reflected\nin suitable integrability and regularity assumptions on the loss and activation\nfunctions.\n","authors":["Gholamali Aminian","Samuel N. Cohen","Łukasz Szpruch"],"pdf_url":"https://arxiv.org/pdf/2306.11623v1.pdf","comment":"49 pages"},{"id":"http://arxiv.org/abs/2305.08950v2","updated":"2023-06-20T15:43:32Z","published":"2023-05-15T18:37:24Z","title":"Causal Analysis for Robust Interpretability of Neural Networks","summary":"  Interpreting the inner function of neural networks is crucial for the\ntrustworthy development and deployment of these black-box models. Prior\ninterpretability methods focus on correlation-based measures to attribute model\ndecisions to individual examples. However, these measures are susceptible to\nnoise and spurious correlations encoded in the model during the training phase\n(e.g., biased inputs, model overfitting, or misspecification). Moreover, this\nprocess has proven to result in noisy and unstable attributions that prevent\nany transparent understanding of the model's behavior. In this paper, we\ndevelop a robust interventional-based method grounded by causal analysis to\ncapture cause-effect mechanisms in pre-trained neural networks and their\nrelation to the prediction. Our novel approach relies on path interventions to\ninfer the causal mechanisms within hidden layers and isolate relevant and\nnecessary information (to model prediction), avoiding noisy ones. The result is\ntask-specific causal explanatory graphs that can audit model behavior and\nexpress the actual causes underlying its performance. We apply our method to\nvision models trained on classification tasks. On image classification tasks,\nwe provide extensive quantitative experiments to show that our approach can\ncapture more stable and faithful explanations than standard attribution-based\nmethods. Furthermore, the underlying causal graphs reveal the neural\ninteractions in the model, making it a valuable tool in other applications\n(e.g., model repair).\n","authors":["Ola Ahmad","Nicolas Bereux","Loïc Baret","Vahid Hashemi","Freddy Lecue"],"pdf_url":"https://arxiv.org/pdf/2305.08950v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06994v2","updated":"2023-06-20T15:29:51Z","published":"2023-06-12T09:42:16Z","title":"Correlated Time Series Self-Supervised Representation Learning via\n  Spatiotemporal Bootstrapping","summary":"  Correlated time series analysis plays an important role in many real-world\nindustries. Learning an efficient representation of this large-scale data for\nfurther downstream tasks is necessary but challenging. In this paper, we\npropose a time-step-level representation learning framework for individual\ninstances via bootstrapped spatiotemporal representation prediction. We\nevaluated the effectiveness and flexibility of our representation learning\nframework on correlated time series forecasting and cold-start transferring the\nforecasting model to new instances with limited data. A linear regression model\ntrained on top of the learned representations demonstrates our model performs\nbest in most cases. Especially compared to representation learning models, we\nreduce the RMSE, MAE, and MAPE by 37%, 49%, and 48% on the PeMS-BAY dataset,\nrespectively. Furthermore, in real-world metro passenger flow data, our\nframework demonstrates the ability to transfer to infer future information of\nnew cold-start instances, with gains of 15%, 19%, and 18%. The source code will\nbe released under the GitHub\nhttps://github.com/bonaldli/Spatiotemporal-TS-Representation-Learning\n","authors":["Luxuan Wang","Lei Bai","Ziyue Li","Rui Zhao","Fugee Tsung"],"pdf_url":"https://arxiv.org/pdf/2306.06994v2.pdf","comment":"Accepted to IEEE CASE 2023"},{"id":"http://arxiv.org/abs/2306.11593v1","updated":"2023-06-20T15:13:02Z","published":"2023-06-20T15:13:02Z","title":"Improving Image Captioning Descriptiveness by Ranking and LLM-based\n  Fusion","summary":"  State-of-The-Art (SoTA) image captioning models often rely on the Microsoft\nCOCO (MS-COCO) dataset for training. This dataset contains annotations provided\nby human annotators, who typically produce captions averaging around ten\ntokens. However, this constraint presents a challenge in effectively capturing\ncomplex scenes and conveying detailed information. Furthermore, captioning\nmodels tend to exhibit bias towards the ``average'' caption, which captures\nonly the more general aspects. What would happen if we were able to\nautomatically generate longer captions, thereby making them more detailed?\nWould these captions, evaluated by humans, be more or less representative of\nthe image content compared to the original MS-COCO captions? In this paper, we\npresent a novel approach to address previous challenges by showcasing how\ncaptions generated from different SoTA models can be effectively fused,\nresulting in richer captions. Our proposed method leverages existing models\nfrom the literature, eliminating the need for additional training. Instead, it\nutilizes an image-text based metric to rank the captions generated by SoTA\nmodels for a given image. Subsequently, the top two captions are fused using a\nLarge Language Model (LLM). Experimental results demonstrate the effectiveness\nof our approach, as the captions generated by our model exhibit higher\nconsistency with human judgment when evaluated on the MS-COCO test set. By\ncombining the strengths of various SoTA models, our method enhances the quality\nand appeal of image captions, bridging the gap between automated systems and\nthe rich, informative nature of human-generated descriptions. This advance\nopens up new possibilities for generating captions that are more suitable for\nthe training of both vision-language and captioning models.\n","authors":["Simone Bianco","Luigi Celona","Marco Donzella","Paolo Napoletano"],"pdf_url":"https://arxiv.org/pdf/2306.11593v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11589v1","updated":"2023-06-20T15:07:37Z","published":"2023-06-20T15:07:37Z","title":"Sampling from Gaussian Process Posteriors using Stochastic Gradient\n  Descent","summary":"  Gaussian processes are a powerful framework for quantifying uncertainty and\nfor sequential decision-making but are limited by the requirement of solving\nlinear systems. In general, this has a cubic cost in dataset size and is\nsensitive to conditioning. We explore stochastic gradient algorithms as a\ncomputationally efficient method of approximately solving these linear systems:\nwe develop low-variance optimization objectives for sampling from the posterior\nand extend these to inducing points. Counterintuitively, stochastic gradient\ndescent often produces accurate predictions, even in cases where it does not\nconverge quickly to the optimum. We explain this through a spectral\ncharacterization of the implicit bias from non-convergence. We show that\nstochastic gradient descent produces predictive distributions close to the true\nposterior both in regions with sufficient data coverage, and in regions\nsufficiently far away from the data. Experimentally, stochastic gradient\ndescent achieves state-of-the-art performance on sufficiently large-scale or\nill-conditioned regression tasks. Its uncertainty estimates match the\nperformance of significantly more expensive baselines on a large-scale\nBayesian~optimization~task.\n","authors":["Jihao Andreas Lin","Javier Antorán","Shreyas Padhy","David Janz","José Miguel Hernández-Lobato","Alexander Terenin"],"pdf_url":"https://arxiv.org/pdf/2306.11589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.08102v2","updated":"2023-06-20T15:04:31Z","published":"2023-06-13T19:46:40Z","title":"Domain-Aware Few-Shot Learning for Optical Coherence Tomography Noise\n  Reduction","summary":"  Speckle noise has long been an extensively studied problem in medical\nimaging. In recent years, there have been significant advances in leveraging\ndeep learning methods for noise reduction. Nevertheless, adaptation of\nsupervised learning models to unseen domains remains a challenging problem.\nSpecifically, deep neural networks (DNNs) trained for computational imaging\ntasks are vulnerable to changes in the acquisition system's physical\nparameters, such as: sampling space, resolution, and contrast. Even within the\nsame acquisition system, performance degrades across datasets of different\nbiological tissues. In this work, we propose a few-shot supervised learning\nframework for optical coherence tomography (OCT) noise reduction, that offers a\ndramatic increase in training speed and requires only a single image, or part\nof an image, and a corresponding speckle suppressed ground truth, for training.\nFurthermore, we formulate the domain shift problem for OCT diverse imaging\nsystems, and prove that the output resolution of a despeckling trained model is\ndetermined by the source domain resolution. We also provide possible remedies.\nWe propose different practical implementations of our approach, verify and\ncompare their applicability, robustness, and computational efficiency. Our\nresults demonstrate significant potential for generally improving sample\ncomplexity, generalization, and time efficiency, for coherent and non-coherent\nnoise reduction via supervised learning models, that can also be leveraged for\nother real-time computer vision applications.\n","authors":["Deborah Pereg"],"pdf_url":"https://arxiv.org/pdf/2306.08102v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11586v1","updated":"2023-06-20T15:03:31Z","published":"2023-06-20T15:03:31Z","title":"Provably Powerful Graph Neural Networks for Directed Multigraphs","summary":"  This paper proposes a set of simple adaptations to transform standard\nmessage-passing Graph Neural Networks (GNN) into provably powerful directed\nmultigraph neural networks. The adaptations include multigraph port numbering,\nego IDs, and reverse message passing. We prove that the combination of these\ntheoretically enables the detection of any directed subgraph pattern. To\nvalidate the effectiveness of our proposed adaptations in practice, we conduct\nexperiments on synthetic subgraph detection tasks, which demonstrate\noutstanding performance with almost perfect results.\n  Moreover, we apply our proposed adaptations to two financial crime analysis\ntasks. We observe dramatic improvements in detecting money laundering\ntransactions, improving the minority-class F1 score of a standard\nmessage-passing GNN by up to 45%, and clearly outperforming tree-based and GNN\nbaselines. Similarly impressive results are observed on a real-world phishing\ndetection dataset, boosting a standard GNN's F1 score by over 15% and\noutperforming all baselines.\n","authors":["Béni Egressy","Luc von Niederhäusern","Jovan Blanusa","Erik Altman","Roger Wattenhofer","Kubilay Atasu"],"pdf_url":"https://arxiv.org/pdf/2306.11586v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08839v6","updated":"2023-06-20T14:52:47Z","published":"2023-01-21T00:48:18Z","title":"A Trustworthiness Score to Evaluate DNN Predictions","summary":"  Due to the black box nature of deep neural networks (DNN), the continuous\nvalidation of DNN during operation is challenging with the absence of a human\nmonitor. As a result this makes it difficult for developers and regulators to\ngain confidence in the deployment of autonomous systems employing DNN. It is\ncritical for safety during operation to know when DNN's predictions are\ntrustworthy or suspicious. With the absence of a human monitor, the basic\napproach is to use the model's output confidence score to assess if predictions\nare trustworthy or suspicious. However, the model's confidence score is a\nresult of computations coming from a black box, therefore lacks transparency\nand makes it challenging to automatedly credit trustworthiness to predictions.\nWe introduce the trustworthiness score (TS), a simple metric that provides a\nmore transparent and effective way of providing confidence in DNN predictions\ncompared to model's confidence score. The metric quantifies the trustworthiness\nin a prediction by checking for the existence of certain features in the\npredictions made by the DNN. We also use the underlying idea of the TS metric,\nto provide a suspiciousness score (SS) in the overall input frame to help in\nthe detection of suspicious frames where false negatives exist. We conduct a\ncase study using YOLOv5 on persons detection to demonstrate our method and\nusage of TS and SS. The case study shows that using our method consistently\nimproves the precision of predictions compared to relying on model confidence\nscore alone, for both 1) approving of trustworthy predictions (~20%\nimprovement) and 2) detecting suspicious frames (~5% improvement).\n","authors":["Abanoub Ghobrial","Darryl Hond","Hamid Asgari","Kerstin Eder"],"pdf_url":"https://arxiv.org/pdf/2301.08839v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11576v1","updated":"2023-06-20T14:46:26Z","published":"2023-06-20T14:46:26Z","title":"Deep Learning Methods for Retinal Blood Vessel Segmentation: Evaluation\n  on Images with Retinopathy of Prematurity","summary":"  Automatic blood vessel segmentation from retinal images plays an important\nrole in the diagnosis of many systemic and eye diseases, including retinopathy\nof prematurity. Current state-of-the-art research in blood vessel segmentation\nfrom retinal images is based on convolutional neural networks. The solutions\nproposed so far are trained and tested on images from a few available retinal\nblood vessel segmentation datasets, which might limit their performance when\ngiven an image with retinopathy of prematurity signs. In this paper, we\nevaluate the performance of three high-performing convolutional neural networks\nfor retinal blood vessel segmentation in the context of blood vessel\nsegmentation on retinopathy of prematurity retinal images. The main motive\nbehind the study is to test if existing public datasets suffice to develop a\nhigh-performing predictor that could assist an ophthalmologist in retinopathy\nof prematurity diagnosis. To do so, we create a dataset consisting solely of\nretinopathy of prematurity images with retinal blood vessel annotations\nmanually labeled by two observers, where one is the ophthalmologist experienced\nin retinopathy of prematurity treatment. Experimental results show that all\nthree solutions have difficulties in detecting the retinal blood vessels of\ninfants due to a lower contrast compared to images from public datasets as\ndemonstrated by a significant drop in classification sensitivity. All three\nsolutions segment alongside retinal also choroidal blood vessels which are not\nused to diagnose retinopathy of prematurity, but instead represent noise and\nare confused with retinal blood vessels. By visual and numerical observations,\nwe observe that existing solutions for retinal blood vessel segmentation need\nimprovement toward more detailed datasets or deeper models in order to assist\nthe ophthalmologist in retinopathy of prematurity diagnosis.\n","authors":["Gorana Gojić","Veljko Petrović","Radovan Turović","Dinu Dragan","Ana Oros","Dušan Gajić","Nebojša Horvat"],"pdf_url":"https://arxiv.org/pdf/2306.11576v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.15444v2","updated":"2023-06-20T14:41:38Z","published":"2023-05-24T07:38:24Z","title":"PromptNER: Prompting For Named Entity Recognition","summary":"  In a surprising turn, Large Language Models (LLMs) together with a growing\narsenal of prompt-based heuristics now offer powerful off-the-shelf approaches\nproviding few-shot solutions to myriad classic NLP problems. However, despite\npromising early results, these LLM-based few-shot methods remain far from the\nstate of the art in Named Entity Recognition (NER), where prevailing methods\ninclude learning representations via end-to-end structural understanding and\nfine-tuning on standard labeled corpora. In this paper, we introduce PromptNER,\na new state-of-the-art algorithm for few-Shot and cross-domain NER. To adapt to\nany new NER task PromptNER requires a set of entity definitions in addition to\nthe standard few-shot examples. Given a sentence, PromptNER prompts an LLM to\nproduce a list of potential entities along with corresponding explanations\njustifying their compatibility with the provided entity type definitions.\nRemarkably, PromptNER achieves state-of-the-art performance on few-shot NER,\nachieving a 4% (absolute) improvement in F1 score on the ConLL dataset, a 9%\n(absolute) improvement on the GENIA dataset, and a 4% (absolute) improvement on\nthe FewNERD dataset. PromptNER also moves the state of the art on Cross Domain\nNER, outperforming prior methods (including those not limited to the few-shot\nsetting), setting a new mark on 3/5 CrossNER target domains, with an average F1\ngain of 3%, despite using less than 2% of the available data.\n","authors":["Dhananjay Ashok","Zachary C. Lipton"],"pdf_url":"https://arxiv.org/pdf/2305.15444v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.12021v2","updated":"2023-06-20T14:35:14Z","published":"2023-03-21T16:55:18Z","title":"Graph Kalman Filters","summary":"  The well-known Kalman filters model dynamical systems by relying on\nstate-space representations with the next state updated, and its uncertainty\ncontrolled, by fresh information associated with newly observed system outputs.\nThis paper generalizes, for the first time in the literature, Kalman and\nextended Kalman filters to discrete-time settings where inputs, states, and\noutputs are represented as attributed graphs whose topology and attributes can\nchange with time. The setup allows us to adapt the framework to cases where the\noutput is a vector or a scalar too (node/graph level tasks). Within the\nproposed theoretical framework, the unknown state-transition and the readout\nfunctions are learned end-to-end along with the downstream prediction task.\n","authors":["Cesare Alippi","Daniele Zambon"],"pdf_url":"https://arxiv.org/pdf/2303.12021v2.pdf","comment":"Added empirical validation"},{"id":"http://arxiv.org/abs/2306.11560v1","updated":"2023-06-20T14:26:53Z","published":"2023-06-20T14:26:53Z","title":"MILD: Modeling the Instance Learning Dynamics for Learning with Noisy\n  Labels","summary":"  Despite deep learning has achieved great success, it often relies on a large\namount of training data with accurate labels, which are expensive and\ntime-consuming to collect. A prominent direction to reduce the cost is to learn\nwith noisy labels, which are ubiquitous in the real-world applications. A\ncritical challenge for such a learning task is to reduce the effect of network\nmemorization on the falsely-labeled data. In this work, we propose an iterative\nselection approach based on the Weibull mixture model, which identifies clean\ndata by considering the overall learning dynamics of each data instance. In\ncontrast to the previous small-loss heuristics, we leverage the observation\nthat deep network is easy to memorize and hard to forget clean data. In\nparticular, we measure the difficulty of memorization and forgetting for each\ninstance via the transition times between being misclassified and being\nmemorized in training, and integrate them into a novel metric for selection.\nBased on the proposed metric, we retain a subset of identified clean data and\nrepeat the selection procedure to iteratively refine the clean subset, which is\nfinally used for model training. To validate our method, we perform extensive\nexperiments on synthetic noisy datasets and real-world web data, and our\nstrategy outperforms existing noisy-label learning methods.\n","authors":["Chuanyang Hu","Shipeng Yan","Zhitong Gao","Xuming He"],"pdf_url":"https://arxiv.org/pdf/2306.11560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.00369v2","updated":"2023-06-20T14:23:39Z","published":"2022-12-01T08:59:21Z","title":"Deep neural network techniques for monaural speech enhancement: state of\n  the art analysis","summary":"  Deep neural networks (DNN) techniques have become pervasive in domains such\nas natural language processing and computer vision. They have achieved great\nsuccess in these domains in task such as machine translation and image\ngeneration. Due to their success, these data driven techniques have been\napplied in audio domain. More specifically, DNN models have been applied in\nspeech enhancement domain to achieve denosing, dereverberation and\nmulti-speaker separation in monaural speech enhancement. In this paper, we\nreview some dominant DNN techniques being employed to achieve speech\nseparation. The review looks at the whole pipeline of speech enhancement from\nfeature extraction, how DNN based tools are modelling both global and local\nfeatures of speech and model training (supervised and unsupervised). We also\nreview the use of speech-enhancement pre-trained models to boost speech\nenhancement process. The review is geared towards covering the dominant trends\nwith regards to DNN application in speech enhancement in speech obtained via a\nsingle speaker.\n","authors":["Peter Ochieng"],"pdf_url":"https://arxiv.org/pdf/2212.00369v2.pdf","comment":"conference"},{"id":"http://arxiv.org/abs/2306.03775v2","updated":"2023-06-20T14:20:48Z","published":"2023-06-06T15:32:30Z","title":"Matched Pair Calibration for Ranking Fairness","summary":"  We propose a test of fairness in score-based ranking systems called matched\npair calibration. Our approach constructs a set of matched item pairs with\nminimal confounding differences between subgroups before computing an\nappropriate measure of ranking error over the set. The matching step ensures\nthat we compare subgroup outcomes between identically scored items so that\nmeasured performance differences directly imply unfairness in subgroup-level\nexposures. We show how our approach generalizes the fairness intuitions of\ncalibration from a binary classification setting to ranking and connect our\napproach to other proposals for ranking fairness measures. Moreover, our\nstrategy shows how the logic of marginal outcome tests extends to cases where\nthe analyst has access to model scores. Lastly, we provide an example of\napplying matched pair calibration to a real-word ranking data set to\ndemonstrate its efficacy in detecting ranking bias.\n","authors":["Hannah Korevaar","Chris McConnell","Edmund Tong","Erik Brinkman","Alana Shine","Misam Abbas","Blossom Metevier","Sam Corbett-Davies","Khalid El-Arini"],"pdf_url":"https://arxiv.org/pdf/2306.03775v2.pdf","comment":"19 pages, 8 figures"},{"id":"http://arxiv.org/abs/2306.11552v1","updated":"2023-06-20T14:14:59Z","published":"2023-06-20T14:14:59Z","title":"Inter-Cell Network Slicing With Transfer Learning Empowered Multi-Agent\n  Deep Reinforcement Learning","summary":"  Network slicing enables operators to efficiently support diverse applications\non a common physical infrastructure. The ever-increasing densification of\nnetwork deployment leads to complex and non-trivial inter-cell interference,\nwhich requires more than inaccurate analytic models to dynamically optimize\nresource management for network slices. In this paper, we develop a DIRP\nalgorithm with multiple deep reinforcement learning (DRL) agents to\ncooperatively optimize resource partition in individual cells to fulfill the\nrequirements of each slice, based on two alternative reward functions.\nNevertheless, existing DRL approaches usually tie the pretrained model\nparameters to specific network environments with poor transferability, which\nraises practical deployment concerns in large-scale mobile networks. Hence, we\ndesign a novel transfer learning-aided DIRP (TL-DIRP) algorithm to ease the\ntransfer of DIRP agents across different network environments in terms of\nsample efficiency, model reproducibility, and algorithm scalability. The\nTL-DIRP algorithm first centrally trains a generalized model and then transfers\nthe \"generalist\" to each local agent as \"specialist\" with distributed\nfinetuning and execution. TL-DIRP consists of two steps: 1) centralized\ntraining of a generalized distributed model, 2) transferring the \"generalist\"\nto each \"specialist\" with distributed finetuning and execution. The numerical\nresults show that not only DIRP outperforms existing baseline approaches in\nterms of faster convergence and higher reward, but more importantly, TL-DIRP\nsignificantly improves the service performance, with reduced exploration cost,\naccelerated convergence rate, and enhanced model reproducibility. As compared\nto a traffic-aware baseline, TL-DIRP provides about 15% less violation ratio of\nthe quality of service (QoS) for the worst slice service and 8.8% less\nviolation on the average service QoS.\n","authors":["Tianlun Hu","Qi Liao","Qiang Liu","Georg Carle"],"pdf_url":"https://arxiv.org/pdf/2306.11552v1.pdf","comment":"14 pages, 14 figures, IEEE Open Journal of the Communications Society"},{"id":"http://arxiv.org/abs/2306.11551v1","updated":"2023-06-20T14:12:29Z","published":"2023-06-20T14:12:29Z","title":"IMP-MARL: a Suite of Environments for Large-scale Infrastructure\n  Management Planning via MARL","summary":"  We introduce IMP-MARL, an open-source suite of multi-agent reinforcement\nlearning (MARL) environments for large-scale Infrastructure Management Planning\n(IMP), offering a platform for benchmarking the scalability of cooperative MARL\nmethods in real-world engineering applications. In IMP, a multi-component\nengineering system is subject to a risk of failure due to its components'\ndamage condition. Specifically, each agent plans inspections and repairs for a\nspecific system component, aiming to minimise maintenance costs while\ncooperating to minimise system failure risk. With IMP-MARL, we release several\nenvironments including one related to offshore wind structural systems, in an\neffort to meet today's needs to improve management strategies to support\nsustainable and reliable energy systems. Supported by IMP practical engineering\nenvironments featuring up to 100 agents, we conduct a benchmark campaign, where\nthe scalability and performance of state-of-the-art cooperative MARL methods\nare compared against expert-based heuristic policies. The results reveal that\ncentralised training with decentralised execution methods scale better with the\nnumber of agents than fully centralised or decentralised RL approaches, while\nalso outperforming expert-based heuristic policies in most IMP environments.\nBased on our findings, we additionally outline remaining cooperation and\nscalability challenges that future MARL methods should still address. Through\nIMP-MARL, we encourage the implementation of new environments and the further\ndevelopment of MARL methods.\n","authors":["Pascal Leroy","Pablo G. Morato","Jonathan Pisane","Athanasios Kolios","Damien Ernst"],"pdf_url":"https://arxiv.org/pdf/2306.11551v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2105.11213v2","updated":"2023-06-20T14:03:48Z","published":"2021-05-24T11:44:08Z","title":"A Low-Delay MAC for IoT Applications: Decentralized Optimal Scheduling\n  of Queues without Explicit State Information Sharing","summary":"  We consider a system of several collocated nodes sharing a time slotted\nwireless channel, and seek a MAC (medium access control) that (i) provides low\nmean delay, (ii) has distributed control (i.e., there is no central scheduler),\nand (iii) does not require explicit exchange of state information or control\nsignals. The design of such MAC protocols must keep in mind the need for\ncontention access at light traffic, and scheduled access in heavy traffic,\nleading to the long-standing interest in hybrid, adaptive MACs.\n  Working in the discrete time setting, for the distributed MAC design, we\nconsider a practical information structure where each node has local\ninformation and some common information obtained from overhearing. In this\nsetting, \"ZMAC\" is an existing protocol that is hybrid and adaptive. We\napproach the problem via two steps (1) We show that it is sufficient for the\npolicy to be \"greedy\" and \"exhaustive\". Limiting the policy to this class\nreduces the problem to obtaining a queue switching policy at queue emptiness\ninstants. (2) Formulating the delay optimal scheduling as a POMDP (partially\nobserved Markov decision process), we show that the optimal switching rule is\nStochastic Largest Queue (SLQ).\n  Using this theory as the basis, we then develop a practical distributed\nscheduler, QZMAC, which is also tunable. We implement QZMAC on standard\noff-the-shelf TelosB motes and also use simulations to compare QZMAC with the\nfull-knowledge centralized scheduler, and with ZMAC. We use our implementation\nto study the impact of false detection while overhearing the common\ninformation, and the efficiency of QZMAC. Our simulation results show that the\nmean delay with QZMAC is close that of the full-knowledge centralized\nscheduler.\n","authors":["Avinash Mohan","Arpan Chattopadhyay","Shivam Vinayak Vatsa","Anurag Kumar"],"pdf_url":"https://arxiv.org/pdf/2105.11213v2.pdf","comment":"28 pages, 19 figures"},{"id":"http://arxiv.org/abs/2306.11547v1","updated":"2023-06-20T14:01:29Z","published":"2023-06-20T14:01:29Z","title":"Event Stream GPT: A Data Pre-processing and Modeling Library for\n  Generative, Pre-trained Transformers over Continuous-time Sequences of\n  Complex Events","summary":"  Generative, pre-trained transformers (GPTs, a.k.a. \"Foundation Models\") have\nreshaped natural language processing (NLP) through their versatility in diverse\ndownstream tasks. However, their potential extends far beyond NLP. This paper\nprovides a software utility to help realize this potential, extending the\napplicability of GPTs to continuous-time sequences of complex events with\ninternal dependencies, such as medical record datasets. Despite their\npotential, the adoption of foundation models in these domains has been hampered\nby the lack of suitable tools for model construction and evaluation. To bridge\nthis gap, we introduce Event Stream GPT (ESGPT), an open-source library\ndesigned to streamline the end-to-end process for building GPTs for\ncontinuous-time event sequences. ESGPT allows users to (1) build flexible,\nfoundation-model scale input datasets by specifying only a minimal\nconfiguration file, (2) leverage a Hugging Face compatible modeling API for\nGPTs over this modality that incorporates intra-event causal dependency\nstructures and autoregressive generation capabilities, and (3) evaluate models\nvia standardized processes that can assess few and even zero-shot performance\nof pre-trained models on user-specified fine-tuning tasks.\n","authors":["Matthew B. A. McDermott","Bret Nestor","Peniel Argaw","Isaac Kohane"],"pdf_url":"https://arxiv.org/pdf/2306.11547v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12514v2","updated":"2023-06-20T14:01:24Z","published":"2022-11-23T11:54:43Z","title":"AugOp: Inject Transformation into Neural Operator","summary":"  In this paper, we propose a simple and general approach to augment regular\nconvolution operator by injecting extra group-wise transformation during\ntraining and recover it during inference. Extra transformation is carefully\nselected to ensure it can be merged with regular convolution in each group and\nwill not change the topological structure of regular convolution during\ninference. Compared with regular convolution operator, our approach (AugConv)\ncan introduce larger learning capacity to improve model performance during\ntraining but will not increase extra computational overhead for model\ndeployment. Based on ResNet, we utilize AugConv to build convolutional neural\nnetworks named AugResNet. Result on image classification dataset Cifar-10 shows\nthat AugResNet outperforms its baseline in terms of model performance.\n","authors":["Longqing Ye"],"pdf_url":"https://arxiv.org/pdf/2211.12514v2.pdf","comment":"The results are greatly influenced by random seeds. The conclusion\n  may be wrong"},{"id":"http://arxiv.org/abs/2306.09890v2","updated":"2023-06-20T13:47:17Z","published":"2023-06-16T14:59:17Z","title":"Studying Generalization on Memory-Based Methods in Continual Learning","summary":"  One of the objectives of Continual Learning is to learn new concepts\ncontinually over a stream of experiences and at the same time avoid\ncatastrophic forgetting. To mitigate complete knowledge overwriting,\nmemory-based methods store a percentage of previous data distributions to be\nused during training. Although these methods produce good results, few studies\nhave tested their out-of-distribution generalization properties, as well as\nwhether these methods overfit the replay memory. In this work, we show that\nalthough these methods can help in traditional in-distribution generalization,\nthey can strongly impair out-of-distribution generalization by learning\nspurious features and correlations. Using a controlled environment, the Synbol\nbenchmark generator (Lacoste et al., 2020), we demonstrate that this lack of\nout-of-distribution generalization mainly occurs in the linear classifier.\n","authors":["Felipe del Rio","Julio Hurtado","Cristian Buc","Alvaro Soto","Vincenzo Lomonaco"],"pdf_url":"https://arxiv.org/pdf/2306.09890v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.10536v2","updated":"2023-06-20T13:45:49Z","published":"2023-05-17T19:46:34Z","title":"Online List Labeling with Predictions","summary":"  A growing line of work shows how learned predictions can be used to break\nthrough worst-case barriers to improve the running time of an algorithm.\nHowever, incorporating predictions into data structures with strong theoretical\nguarantees remains underdeveloped. This paper takes a step in this direction by\nshowing that predictions can be leveraged in the fundamental online list\nlabeling problem. In the problem, n items arrive over time and must be stored\nin sorted order in an array of size Theta(n). The array slot of an element is\nits label and the goal is to maintain sorted order while minimizing the total\nnumber of elements moved (i.e., relabeled). We design a new list labeling data\nstructure and bound its performance in two models. In the worst-case\nlearning-augmented model, we give guarantees in terms of the error in the\npredictions. Our data structure provides strong guarantees: it is optimal for\nany prediction error and guarantees the best-known worst-case bound even when\nthe predictions are entirely erroneous. We also consider a stochastic error\nmodel and bound the performance in terms of the expectation and variance of the\nerror. Finally, the theoretical results are demonstrated empirically. In\nparticular, we show that our data structure has strong performance on real\ntemporal data sets where predictions are constructed from elements that arrived\nin the past, as is typically done in a practical use case.\n","authors":["Samuel McCauley","Benjamin Moseley","Aidin Niaparast","Shikha Singh"],"pdf_url":"https://arxiv.org/pdf/2305.10536v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11526v1","updated":"2023-06-20T13:28:27Z","published":"2023-06-20T13:28:27Z","title":"Understanding Contrastive Learning Through the Lens of Margins","summary":"  Self-supervised learning, or SSL, holds the key to expanding the usage of\nmachine learning in real-world tasks by alleviating heavy human supervision.\nContrastive learning and its varieties have been SSL strategies in various\nfields. We use margins as a stepping stone for understanding how contrastive\nlearning works at a deeper level and providing potential directions to improve\nrepresentation learning. Through gradient analysis, we found that margins scale\ngradients in three different ways: emphasizing positive samples, de-emphasizing\npositive samples when angles of positive samples are wide, and attenuating the\ndiminishing gradients as the estimated probability approaches the target\nprobability. We separately analyze each and provide possible directions for\nimproving SSL frameworks. Our experimental results demonstrate that these\nproperties can contribute to acquiring better representations, which can\nenhance performance in both seen and unseen datasets.\n","authors":["Daniel Rho","TaeSoo Kim","Sooill Park","Jaehyun Park","JaeHan Park"],"pdf_url":"https://arxiv.org/pdf/2306.11526v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.05223v2","updated":"2023-06-20T13:21:09Z","published":"2023-04-11T13:46:59Z","title":"Inhomogeneous graph trend filtering via a l2,0 cardinality penalty","summary":"  We study estimation of piecewise smooth signals over a graph. We propose a\n$\\ell_{2,0}$-norm penalized Graph Trend Filtering (GTF) model to estimate\npiecewise smooth graph signals that exhibit inhomogeneous levels of smoothness\nacross the nodes. We prove that the proposed GTF model is simultaneously a\nk-means clustering on the signal over the nodes and a minimum graph cut on the\nedges of the graph, where the clustering and the cut share the same assignment\nmatrix. We propose two methods to solve the proposed GTF model: a spectral\ndecomposition method and a method based on simulated annealing. In the\nexperiment on synthetic and real-world datasets, we show that the proposed GTF\nmodel has a better performances compared with existing approaches on the tasks\nof denoising, support recovery and semi-supervised classification. We also show\nthat the proposed GTF model can be solved more efficiently than existing models\nfor the dataset with a large edge set.\n","authors":["Xiaoqing Huang","Andersen Ang","Kun Huang","Jie Zhang","Yijie Wang"],"pdf_url":"https://arxiv.org/pdf/2304.05223v2.pdf","comment":"12 pages, 3 figures, 4 tables"},{"id":"http://arxiv.org/abs/2211.10420v3","updated":"2023-06-20T13:01:54Z","published":"2022-11-18T18:35:14Z","title":"Mirror Sinkhorn: Fast Online Optimization on Transport Polytopes","summary":"  Optimal transport is an important tool in machine learning, allowing to\ncapture geometric properties of the data through a linear program on transport\npolytopes. We present a single-loop optimization algorithm for minimizing\ngeneral convex objectives on these domains, utilizing the principles of\nSinkhorn matrix scaling and mirror descent. The proposed algorithm is robust to\nnoise, and can be used in an online setting. We provide theoretical guarantees\nfor convex objectives and experimental results showcasing it effectiveness on\nboth synthetic and real-world data.\n","authors":["Marin Ballu","Quentin Berthet"],"pdf_url":"https://arxiv.org/pdf/2211.10420v3.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2306.11509v1","updated":"2023-06-20T13:01:00Z","published":"2023-06-20T13:01:00Z","title":"Implicit neural representation with physics-informed neural networks for\n  the reconstruction of the early part of room impulse responses","summary":"  Recently deep learning and machine learning approaches have been widely\nemployed for various applications in acoustics. Nonetheless, in the area of\nsound field processing and reconstruction classic methods based on the\nsolutions of wave equation are still widespread. Recently, physics-informed\nneural networks have been proposed as a deep learning paradigm for solving\npartial differential equations which govern physical phenomena, bridging the\ngap between purely data-driven and model based methods. Here, we exploit\nphysics-informed neural networks to reconstruct the early part of missing room\nimpulse responses in an uniform linear array. This methodology allows us to\nexploit the underlying law of acoustics, i.e., the wave equation, forcing the\nneural network to generate physically meaningful solutions given only a limited\nnumber of data points. The results on real measurements show that the proposed\nmodel achieves accurate reconstruction and performance in line with respect to\nstate-of-the-art deep-learning and compress sensing techniques while\nmaintaining a lightweight architecture.\n","authors":["Mirco Pezzoli","Fabio Antonacci","Augusto Sarti"],"pdf_url":"https://arxiv.org/pdf/2306.11509v1.pdf","comment":"Accepted for publication at Forum Acusticum 2023"},{"id":"http://arxiv.org/abs/2306.11497v1","updated":"2023-06-20T12:36:28Z","published":"2023-06-20T12:36:28Z","title":"Convergence and concentration properties of constant step-size SGD\n  through Markov chains","summary":"  We consider the optimization of a smooth and strongly convex objective using\nconstant step-size stochastic gradient descent (SGD) and study its properties\nthrough the prism of Markov chains. We show that, for unbiased gradient\nestimates with mildly controlled variance, the iteration converges to an\ninvariant distribution in total variation distance. We also establish this\nconvergence in Wasserstein-2 distance under a relaxed assumption on the\ngradient noise distribution compared to previous work. Thanks to the invariance\nproperty of the limit distribution, our analysis shows that the latter inherits\nsub-Gaussian or sub-exponential concentration properties when these hold true\nfor the gradient. This allows the derivation of high-confidence bounds for the\nfinal estimate. Finally, under such conditions in the linear case, we obtain a\ndimension-free deviation bound for the Polyak-Ruppert average of a tail\nsequence. All our results are non-asymptotic and their consequences are\ndiscussed through a few applications.\n","authors":["Ibrahim Merad","Stéphane Gaïffas"],"pdf_url":"https://arxiv.org/pdf/2306.11497v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.15253v2","updated":"2023-06-20T12:32:43Z","published":"2022-11-28T12:09:06Z","title":"Lipschitz constant estimation for 1D convolutional neural networks","summary":"  In this work, we propose a dissipativity-based method for Lipschitz constant\nestimation of 1D convolutional neural networks (CNNs). In particular, we\nanalyze the dissipativity properties of convolutional, pooling, and fully\nconnected layers making use of incremental quadratic constraints for nonlinear\nactivation functions and pooling operations. The Lipschitz constant of the\nconcatenation of these mappings is then estimated by solving a semidefinite\nprogram which we derive from dissipativity theory. To make our method as\nefficient as possible, we exploit the structure of convolutional layers by\nrealizing these finite impulse response filters as causal dynamical systems in\nstate space and carrying out the dissipativity analysis for the state space\nrealizations. The examples we provide show that our Lipschitz bounds are\nadvantageous in terms of accuracy and scalability.\n","authors":["Patricia Pauli","Dennis Gramlich","Frank Allgöwer"],"pdf_url":"https://arxiv.org/pdf/2211.15253v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.06203v5","updated":"2023-06-20T12:24:53Z","published":"2022-09-13T17:56:13Z","title":"Normalizing Flows for Interventional Density Estimation","summary":"  Existing machine learning methods for causal inference usually estimate\nquantities expressed via the mean of potential outcomes (e.g., average\ntreatment effect). However, such quantities do not capture the full information\nabout the distribution of potential outcomes. In this work, we estimate the\ndensity of potential outcomes after interventions from observational data. For\nthis, we propose a novel, fully-parametric deep learning method called\nInterventional Normalizing Flows. Specifically, we combine two normalizing\nflows, namely (i) a nuisance flow for estimating nuisance parameters and (ii) a\ntarget flow for parametric estimation of the density of potential outcomes. We\nfurther develop a tractable optimization objective based on a one-step bias\ncorrection for efficient and doubly robust estimation of the target flow\nparameters. As a result, our Interventional Normalizing Flows offer a properly\nnormalized density estimator. Across various experiments, we demonstrate that\nour Interventional Normalizing Flows are expressive and highly effective, and\nscale well with both sample size and high-dimensional confounding. To the best\nof our knowledge, our Interventional Normalizing Flows are the first proper\nfully-parametric, deep learning method for density estimation of potential\noutcomes.\n","authors":["Valentyn Melnychuk","Dennis Frauen","Stefan Feuerriegel"],"pdf_url":"https://arxiv.org/pdf/2209.06203v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.04470v4","updated":"2023-06-20T12:21:58Z","published":"2022-10-10T07:47:56Z","title":"Actor-Critic or Critic-Actor? A Tale of Two Time Scales","summary":"  We revisit the standard formulation of tabular actor-critic algorithm as a\ntwo time-scale stochastic approximation with value function computed on a\nfaster time-scale and policy computed on a slower time-scale. This emulates\npolicy iteration. We observe that reversal of the time scales will in fact\nemulate value iteration and is a legitimate algorithm. We provide a proof of\nconvergence and compare the two empirically with and without function\napproximation (with both linear and nonlinear function approximators) and\nobserve that our proposed critic-actor algorithm performs on par with\nactor-critic in terms of both accuracy and computational effort.\n","authors":["Shalabh Bhatnagar","Vivek S. Borkar","Soumyajit Guin"],"pdf_url":"https://arxiv.org/pdf/2210.04470v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11488v1","updated":"2023-06-20T12:20:23Z","published":"2023-06-20T12:20:23Z","title":"Informed POMDP: Leveraging Additional Information in Model-Based RL","summary":"  In this work, we generalize the problem of learning through interaction in a\nPOMDP by accounting for eventual additional information available at training\ntime. First, we introduce the informed POMDP, a new learning paradigm offering\na clear distinction between the training information and the execution\nobservation. Next, we propose an objective for learning a sufficient statistic\nfrom the history for the optimal control that leverages this information. We\nthen show that this informed objective consists of learning an environment\nmodel from which we can sample latent trajectories. Finally, we show for the\nDreamer algorithm that the convergence speed of the policies is sometimes\ngreatly improved on several environments by using this informed environment\nmodel. Those results and the simplicity of the proposed adaptation advocate for\na systematic consideration of eventual additional information when learning in\na POMDP using model-based RL.\n","authors":["Gaspard Lambrechts","Adrien Bolland","Damien Ernst"],"pdf_url":"https://arxiv.org/pdf/2306.11488v1.pdf","comment":"8 pages, 13 pages total, 8 figures"},{"id":"http://arxiv.org/abs/2306.11487v1","updated":"2023-06-20T12:17:46Z","published":"2023-06-20T12:17:46Z","title":"Efficient Large-scale Nonstationary Spatial Covariance Function\n  Estimation Using Convolutional Neural Networks","summary":"  Spatial processes observed in various fields, such as climate and\nenvironmental science, often occur on a large scale and demonstrate spatial\nnonstationarity. Fitting a Gaussian process with a nonstationary Mat\\'ern\ncovariance is challenging. Previous studies in the literature have tackled this\nchallenge by employing spatial partitioning techniques to estimate the\nparameters that vary spatially in the covariance function. The selection of\npartitions is an important consideration, but it is often subjective and lacks\na data-driven approach. To address this issue, in this study, we utilize the\npower of Convolutional Neural Networks (ConvNets) to derive subregions from the\nnonstationary data. We employ a selection mechanism to identify subregions that\nexhibit similar behavior to stationary fields. In order to distinguish between\nstationary and nonstationary random fields, we conducted training on ConvNet\nusing various simulated data. These simulations are generated from Gaussian\nprocesses with Mat\\'ern covariance models under a wide range of parameter\nsettings, ensuring adequate representation of both stationary and nonstationary\nspatial data. We assess the performance of the proposed method with synthetic\nand real datasets at a large scale. The results revealed enhanced accuracy in\nparameter estimations when relying on ConvNet-based partition compared to\ntraditional user-defined approaches.\n","authors":["Pratik Nag","Yiping Hong","Sameh Abdulah","Ghulam A. Qadir","Marc G. Genton","Ying Sun"],"pdf_url":"https://arxiv.org/pdf/2306.11487v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11483v1","updated":"2023-06-20T12:12:16Z","published":"2023-06-20T12:12:16Z","title":"Int-HRL: Towards Intention-based Hierarchical Reinforcement Learning","summary":"  While deep reinforcement learning (RL) agents outperform humans on an\nincreasing number of tasks, training them requires data equivalent to decades\nof human gameplay. Recent hierarchical RL methods have increased sample\nefficiency by incorporating information inherent to the structure of the\ndecision problem but at the cost of having to discover or use human-annotated\nsub-goals that guide the learning process. We show that intentions of human\nplayers, i.e. the precursor of goal-oriented decisions, can be robustly\npredicted from eye gaze even for the long-horizon sparse rewards task of\nMontezuma's Revenge - one of the most challenging RL tasks in the Atari2600\ngame suite. We propose Int-HRL: Hierarchical RL with intention-based sub-goals\nthat are inferred from human eye gaze. Our novel sub-goal extraction pipeline\nis fully automatic and replaces the need for manual sub-goal annotation by\nhuman experts. Our evaluations show that replacing hand-crafted sub-goals with\nautomatically extracted intentions leads to a HRL agent that is significantly\nmore sample efficient than previous methods.\n","authors":["Anna Penzkofer","Simon Schaefer","Florian Strohm","Mihai Bâce","Stefan Leutenegger","Andreas Bulling"],"pdf_url":"https://arxiv.org/pdf/2306.11483v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13728v2","updated":"2023-06-20T12:11:50Z","published":"2023-01-31T16:06:54Z","title":"Convolutional autoencoder for the spatiotemporal latent representation\n  of turbulence","summary":"  Turbulence is characterised by chaotic dynamics and a high-dimensional state\nspace, which make this phenomenon challenging to predict. However, turbulent\nflows are often characterised by coherent spatiotemporal structures, such as\nvortices or large-scale modes, which can help obtain a latent description of\nturbulent flows. However, current approaches are often limited by either the\nneed to use some form of thresholding on quantities defining the isosurfaces to\nwhich the flow structures are associated or the linearity of traditional modal\nflow decomposition approaches, such as those based on proper orthogonal\ndecomposition. This problem is exacerbated in flows that exhibit extreme\nevents, which are rare and sudden changes in a turbulent state. The goal of\nthis paper is to obtain an efficient and accurate reduced-order latent\nrepresentation of a turbulent flow that exhibits extreme events. Specifically,\nwe employ a three-dimensional multiscale convolutional autoencoder (CAE) to\nobtain such latent representation. We apply it to a three-dimensional turbulent\nflow. We show that the Multiscale CAE is efficient, requiring less than 10%\ndegrees of freedom than proper orthogonal decomposition for compressing the\ndata and is able to accurately reconstruct flow states related to extreme\nevents. The proposed deep learning architecture opens opportunities for\nnonlinear reduced-order modeling of turbulent flows from data.\n","authors":["Nguyen Anh Khoa Doan","Alberto Racca","Luca Magri"],"pdf_url":"https://arxiv.org/pdf/2301.13728v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11481v1","updated":"2023-06-20T12:06:56Z","published":"2023-06-20T12:06:56Z","title":"Learning Locally Interpretable Rule Ensemble","summary":"  This paper proposes a new framework for learning a rule ensemble model that\nis both accurate and interpretable. A rule ensemble is an interpretable model\nbased on the linear combination of weighted rules. In practice, we often face\nthe trade-off between the accuracy and interpretability of rule ensembles. That\nis, a rule ensemble needs to include a sufficiently large number of weighted\nrules to maintain its accuracy, which harms its interpretability for human\nusers. To avoid this trade-off and learn an interpretable rule ensemble without\ndegrading accuracy, we introduce a new concept of interpretability, named local\ninterpretability, which is evaluated by the total number of rules necessary to\nexpress individual predictions made by the model, rather than to express the\nmodel itself. Then, we propose a regularizer that promotes local\ninterpretability and develop an efficient algorithm for learning a rule\nensemble with the proposed regularizer by coordinate descent with local search.\nExperimental results demonstrated that our method learns rule ensembles that\ncan explain individual predictions with fewer rules than the existing methods,\nincluding RuleFit, while maintaining comparable accuracy.\n","authors":["Kentaro Kanamori"],"pdf_url":"https://arxiv.org/pdf/2306.11481v1.pdf","comment":"23 pages, 12 figures, to appear in the 2023 European Conference on\n  Machine Learning and Principles and Practice of Knowledge Discovery in\n  Databases (ECMLPKDD 2023)"},{"id":"http://arxiv.org/abs/2306.11475v1","updated":"2023-06-20T11:59:03Z","published":"2023-06-20T11:59:03Z","title":"Delegated Classification","summary":"  When machine learning is outsourced to a rational agent, conflicts of\ninterest might arise and severely impact predictive performance. In this work,\nwe propose a theoretical framework for incentive-aware delegation of machine\nlearning tasks. We model delegation as a principal-agent game, in which\naccurate learning can be incentivized by the principal using performance-based\ncontracts. Adapting the economic theory of contract design to this setting, we\ndefine budget-optimal contracts and prove they take a simple threshold form\nunder reasonable assumptions. In the binary-action case, the optimality of such\ncontracts is shown to be equivalent to the classic Neyman-Pearson lemma,\nestablishing a formal connection between contract design and statistical\nhypothesis testing. Empirically, we demonstrate that budget-optimal contracts\ncan be constructed using small-scale data, leveraging recent advances in the\nstudy of learning curves and scaling laws. Performance and economic outcomes\nare evaluated using synthetic and real-world classification tasks.\n","authors":["Eden Saig","Inbal Talgam-Cohen","Nir Rosenfeld"],"pdf_url":"https://arxiv.org/pdf/2306.11475v1.pdf","comment":"Comments are welcome"},{"id":"http://arxiv.org/abs/2306.11474v1","updated":"2023-06-20T11:54:36Z","published":"2023-06-20T11:54:36Z","title":"A Passivity-Based Method for Accelerated Convex Optimisation","summary":"  This study presents a constructive methodology for designing accelerated\nconvex optimisation algorithms in continuous-time domain. The two key enablers\nare the classical concept of passivity in control theory and the time-dependent\nchange of variables that maps the output of the internal dynamic system to the\noptimisation variables. The Lyapunov function associated with the optimisation\ndynamics is obtained as a natural consequence of specifying the internal\ndynamics that drives the state evolution as a passive linear time-invariant\nsystem. The passivity-based methodology provides a general framework that has\nthe flexibility to generate convex optimisation algorithms with the guarantee\nof different convergence rate bounds on the objective function value. The same\nprinciple applies to the design of online parameter update algorithms for\nadaptive control by re-defining the output of internal dynamics to allow for\nthe feedback interconnection with tracking error dynamics.\n","authors":["Namhoon Cho","Hyo-Sang Shin"],"pdf_url":"https://arxiv.org/pdf/2306.11474v1.pdf","comment":"10 pages, 1 figure"},{"id":"http://arxiv.org/abs/2305.04225v2","updated":"2023-06-20T11:53:04Z","published":"2023-05-07T09:06:11Z","title":"LSGNN: Towards General Graph Neural Network in Node Classification by\n  Local Similarity","summary":"  Heterophily has been considered as an issue that hurts the performance of\nGraph Neural Networks (GNNs). To address this issue, some existing work uses a\ngraph-level weighted fusion of the information of multi-hop neighbors to\ninclude more nodes with homophily. However, the heterophily might differ among\nnodes, which requires to consider the local topology. Motivated by it, we\npropose to use the local similarity (LocalSim) to learn node-level weighted\nfusion, which can also serve as a plug-and-play module. For better fusion, we\npropose a novel and efficient Initial Residual Difference Connection (IRDC) to\nextract more informative multi-hop information. Moreover, we provide\ntheoretical analysis on the effectiveness of LocalSim representing node\nhomophily on synthetic graphs. Extensive evaluations over real benchmark\ndatasets show that our proposed method, namely Local Similarity Graph Neural\nNetwork (LSGNN), can offer comparable or superior state-of-the-art performance\non both homophilic and heterophilic graphs. Meanwhile, the plug-and-play model\ncan significantly boost the performance of existing GNNs. Our code is provided\nat https://github.com/draym28/LSGNN.\n","authors":["Yuhan Chen","Yihong Luo","Jing Tang","Liang Yang","Siya Qiu","Chuan Wang","Xiaochun Cao"],"pdf_url":"https://arxiv.org/pdf/2305.04225v2.pdf","comment":"The first two authors contributed equally to this work; IJCAI23"},{"id":"http://arxiv.org/abs/2306.11472v1","updated":"2023-06-20T11:51:44Z","published":"2023-06-20T11:51:44Z","title":"Spatio-temporal DeepKriging for Interpolation and Probabilistic\n  Forecasting","summary":"  Gaussian processes (GP) and Kriging are widely used in traditional\nspatio-temporal mod-elling and prediction. These techniques typically\npresuppose that the data are observed from a stationary GP with parametric\ncovariance structure. However, processes in real-world applications often\nexhibit non-Gaussianity and nonstationarity. Moreover, likelihood-based\ninference for GPs is computationally expensive and thus prohibitive for large\ndatasets. In this paper we propose a deep neural network (DNN) based two-stage\nmodel for spatio-temporal interpolation and forecasting. Interpolation is\nperformed in the first step, which utilizes a dependent DNN with the embedding\nlayer constructed with spatio-temporal basis functions. For the second stage,\nwe use Long-Short Term Memory (LSTM) and convolutional LSTM to forecast future\nobservations at a given location. We adopt the quantile-based loss function in\nthe DNN to provide probabilistic forecasting. Compared to Kriging, the proposed\nmethod does not require specifying covariance functions or making stationarity\nassumption, and is computationally efficient. Therefore, it is suitable for\nlarge-scale prediction of complex spatio-temporal processes. We apply our\nmethod to monthly $PM_{2.5}$ data at more than $200,000$ space-time locations\nfrom January 1999 to December 2022 for fast imputation of missing values and\nforecasts with uncertainties.\n","authors":["Pratik Nag","Ying Sun","Brian J Reich"],"pdf_url":"https://arxiv.org/pdf/2306.11472v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.19999v3","updated":"2023-06-20T11:50:33Z","published":"2023-05-31T16:20:04Z","title":"Beam Tree Recursive Cells","summary":"  We propose Beam Tree Recursive Cell (BT-Cell) - a backpropagation-friendly\nframework to extend Recursive Neural Networks (RvNNs) with beam search for\nlatent structure induction. We further extend this framework by proposing a\nrelaxation of the hard top-k operators in beam search for better propagation of\ngradient signals. We evaluate our proposed models in different\nout-of-distribution splits in both synthetic and realistic data. Our\nexperiments show that BTCell achieves near-perfect performance on several\nchallenging structure-sensitive synthetic tasks like ListOps and logical\ninference while maintaining comparable performance in realistic data against\nother RvNN-based models. Additionally, we identify a previously unknown failure\ncase for neural models in generalization to unseen number of arguments in\nListOps. The code is available at:\nhttps://github.com/JRC1995/BeamTreeRecursiveCells.\n","authors":["Jishnu Ray Chowdhury","Cornelia Caragea"],"pdf_url":"https://arxiv.org/pdf/2305.19999v3.pdf","comment":"Accepted in ICML 2023"},{"id":"http://arxiv.org/abs/2306.11466v1","updated":"2023-06-20T11:41:01Z","published":"2023-06-20T11:41:01Z","title":"Comprehensive Training and Evaluation on Deep Reinforcement Learning for\n  Automated Driving in Various Simulated Driving Maneuvers","summary":"  Developing and testing automated driving models in the real world might be\nchallenging and even dangerous, while simulation can help with this, especially\nfor challenging maneuvers. Deep reinforcement learning (DRL) has the potential\nto tackle complex decision-making and controlling tasks through learning and\ninteracting with the environment, thus it is suitable for developing automated\ndriving while not being explored in detail yet. This study carried out a\ncomprehensive study by implementing, evaluating, and comparing the two DRL\nalgorithms, Deep Q-networks (DQN) and Trust Region Policy Optimization (TRPO),\nfor training automated driving on the highway-env simulation platform.\nEffective and customized reward functions were developed and the implemented\nalgorithms were evaluated in terms of onlane accuracy (how well the car drives\non the road within the lane), efficiency (how fast the car drives), safety (how\nlikely the car is to crash into obstacles), and comfort (how much the car makes\njerks, e.g., suddenly accelerates or brakes). Results show that the TRPO-based\nmodels with modified reward functions delivered the best performance in most\ncases. Furthermore, to train a uniform driving model that can tackle various\ndriving maneuvers besides the specific ones, this study expanded the\nhighway-env and developed an extra customized training environment, namely,\nComplexRoads, integrating various driving maneuvers and multiple road scenarios\ntogether. Models trained on the designed ComplexRoads environment can adapt\nwell to other driving maneuvers with promising overall performance. Lastly,\nseveral functionalities were added to the highway-env to implement this work.\nThe codes are open on GitHub at https://github.com/alaineman/drlcarsim.\n","authors":["Yongqi Dong","Tobias Datema","Vincent Wassenaar","Joris van de Weg","Cahit Tolga Kopar","Harim Suleman"],"pdf_url":"https://arxiv.org/pdf/2306.11466v1.pdf","comment":"6 pages, 3 figures, under review by the 26th IEEE International\n  Conference on Intelligent Transportation Systems (ITSC 2023)"},{"id":"http://arxiv.org/abs/2306.11465v1","updated":"2023-06-20T11:39:55Z","published":"2023-06-20T11:39:55Z","title":"Safe, Efficient, Comfort, and Energy-saving Automated Driving through\n  Roundabout Based on Deep Reinforcement Learning","summary":"  Traffic scenarios in roundabouts pose substantial complexity for automated\ndriving. Manually mapping all possible scenarios into a state space is\nlabor-intensive and challenging. Deep reinforcement learning (DRL) with its\nability to learn from interacting with the environment emerges as a promising\nsolution for training such automated driving models. This study explores,\nemploys, and implements various DRL algorithms, namely Deep Deterministic\nPolicy Gradient (DDPG), Proximal Policy Optimization (PPO), and Trust Region\nPolicy Optimization (TRPO) to instruct automated vehicles' driving through\nroundabouts. The driving state space, action space, and reward function are\ndesigned. The reward function considers safety, efficiency, comfort, and energy\nconsumption to align with real-world requirements. All three tested DRL\nalgorithms succeed in enabling automated vehicles to drive through the\nroundabout. To holistically evaluate the performance of these algorithms, this\nstudy establishes an evaluation methodology considering multiple indicators\nsuch as safety, efficiency, and comfort level. A method employing the Analytic\nHierarchy Process is also developed to weigh these evaluation indicators.\nExperimental results on various testing scenarios reveal that the TRPO\nalgorithm outperforms DDPG and PPO in terms of safety and efficiency, and PPO\nperforms best in terms of comfort level. Lastly, to verify the model's\nadaptability and robustness regarding other driving scenarios, this study also\ndeploys the model trained by TRPO to a range of different testing scenarios,\ne.g., highway driving and merging. Experimental results demonstrate that the\nTRPO model trained on only roundabout driving scenarios exhibits a certain\ndegree of proficiency in highway driving and merging scenarios. This study\nprovides a foundation for the application of automated driving with DRL in real\ntraffic environments.\n","authors":["Henan Yuan","Penghui Li","Bart van Arem","Liujiang Kang","Yongqi Dong"],"pdf_url":"https://arxiv.org/pdf/2306.11465v1.pdf","comment":"6 pages, 3 figures, under review by the 26th IEEE International\n  Conference on Intelligent Transportation Systems (ITSC 2023)"},{"id":"http://arxiv.org/abs/2304.03338v2","updated":"2023-06-20T11:22:11Z","published":"2023-04-06T19:26:03Z","title":"Maximal Ordinal Two-Factorizations","summary":"  Given a formal context, an ordinal factor is a subset of its incidence\nrelation that forms a chain in the concept lattice, i.e., a part of the dataset\nthat corresponds to a linear order. To visualize the data in a formal context,\nGanter and Glodeanu proposed a biplot based on two ordinal factors. For the\nbiplot to be useful, it is important that these factors comprise as much data\npoints as possible, i.e., that they cover a large part of the incidence\nrelation. In this work, we investigate such ordinal two-factorizations. First,\nwe investigate for formal contexts that omit ordinal two-factorizations the\ndisjointness of the two factors. Then, we show that deciding on the existence\nof two-factorizations of a given size is an NP-complete problem which makes\ncomputing maximal factorizations computationally expensive. Finally, we provide\nthe algorithm Ord2Factor that allows us to compute large ordinal\ntwo-factorizations.\n","authors":["Dominik Dürrschnabel","Gerd Stumme"],"pdf_url":"https://arxiv.org/pdf/2304.03338v2.pdf","comment":"15 pages, 6 figures, 2 algorithms, 28th International Conference on\n  Conceptual Structures"},{"id":"http://arxiv.org/abs/2306.11455v1","updated":"2023-06-20T11:12:21Z","published":"2023-06-20T11:12:21Z","title":"Provably Robust Temporal Difference Learning for Heavy-Tailed Rewards","summary":"  In a broad class of reinforcement learning applications, stochastic rewards\nhave heavy-tailed distributions, which lead to infinite second-order moments\nfor stochastic (semi)gradients in policy evaluation and direct policy\noptimization. In such instances, the existing RL methods may fail miserably due\nto frequent statistical outliers. In this work, we establish that temporal\ndifference (TD) learning with a dynamic gradient clipping mechanism, and\ncorrespondingly operated natural actor-critic (NAC), can be provably\nrobustified against heavy-tailed reward distributions. It is shown in the\nframework of linear function approximation that a favorable tradeoff between\nbias and variability of the stochastic gradients can be achieved with this\ndynamic gradient clipping mechanism. In particular, we prove that robust\nversions of TD learning achieve sample complexities of order\n$\\mathcal{O}(\\varepsilon^{-\\frac{1}{p}})$ and\n$\\mathcal{O}(\\varepsilon^{-1-\\frac{1}{p}})$ with and without the full-rank\nassumption on the feature matrix, respectively, under heavy-tailed rewards with\nfinite moments of order $(1+p)$ for some $p\\in(0,1]$, both in expectation and\nwith high probability. We show that a robust variant of NAC based on Robust TD\nlearning achieves $\\tilde{\\mathcal{O}}(\\varepsilon^{-4-\\frac{2}{p}})$ sample\ncomplexity. We corroborate our theoretical results with numerical experiments.\n","authors":["Semih Cayci","Atilla Eryilmaz"],"pdf_url":"https://arxiv.org/pdf/2306.11455v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02709v2","updated":"2023-06-20T11:02:59Z","published":"2023-06-05T09:01:38Z","title":"Comparative Study on Semi-supervised Learning Applied for Anomaly\n  Detection in Hydraulic Condition Monitoring System","summary":"  Condition-based maintenance is becoming increasingly important in hydraulic\nsystems. However, anomaly detection for these systems remains challenging,\nespecially since that anomalous data is scarce and labeling such data is\ntedious and even dangerous. Therefore, it is advisable to make use of\nunsupervised or semi-supervised methods, especially for semi-supervised\nlearning which utilizes unsupervised learning as a feature extraction mechanism\nto aid the supervised part when only a small number of labels are available.\nThis study systematically compares semi-supervised learning methods applied for\nanomaly detection in hydraulic condition monitoring systems. Firstly, thorough\ndata analysis and feature learning were carried out to understand the\nopen-sourced hydraulic condition monitoring dataset. Then, various methods were\nimplemented and evaluated including traditional stand-alone semi-supervised\nlearning models (e.g., one-class SVM, Robust Covariance), ensemble models\n(e.g., Isolation Forest), and deep neural network based models (e.g.,\nautoencoder, Hierarchical Extreme Learning Machine (HELM)). Typically, this\nstudy customized and implemented an extreme learning machine based\nsemi-supervised HELM model and verified its superiority over other\nsemi-supervised methods. Extensive experiments show that the customized HELM\nmodel obtained state-of-the-art performance with the highest accuracy (99.5%),\nthe lowest false positive rate (0.015), and the best F1-score (0.985) beating\nother semi-supervised methods.\n","authors":["Yongqi Dong","Kejia Chen","Zhiyuan Ma"],"pdf_url":"https://arxiv.org/pdf/2306.02709v2.pdf","comment":"7 pages, 8 figures, accepted by 2023 IEEE International Conference on\n  Systems, Man, and Cybernetics (SMC 2023) https://ieeesmc2023.org/"},{"id":"http://arxiv.org/abs/2106.00563v3","updated":"2023-06-20T10:56:28Z","published":"2021-06-01T15:20:34Z","title":"IID-GAN: an IID Sampling Perspective for Regularizing Mode Collapse","summary":"  Despite its success, generative adversarial networks (GANs) still suffer from\nmode collapse, i.e., the generator can only map latent variables to a partial\nset of modes in the target distribution. In this paper, we analyze and seek to\nregularize this issue with an independent and identically distributed (IID)\nsampling perspective and emphasize that holding the IID property referring to\nthe target distribution for generation can naturally avoid mode collapse. This\nis based on the basic IID assumption for real data in machine learning.\nHowever, though the source samples {z} obey IID, the generations {G(z)} may not\nnecessarily be IID sampling from the target distribution. Based on this\nobservation, considering a necessary condition of IID generation that the\ninverse samples from target data should also be IID in the source distribution,\nwe propose a new loss to encourage the closeness between inverse samples of\nreal data and the Gaussian source in latent space to regularize the generation\nto be IID from the target distribution. Experiments on both synthetic and\nreal-world data show the effectiveness of our model.\n","authors":["Yang Li","Liangliang Shi","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2106.00563v3.pdf","comment":"Accepted in IJCAI 2023"},{"id":"http://arxiv.org/abs/2306.11443v1","updated":"2023-06-20T10:40:53Z","published":"2023-06-20T10:40:53Z","title":"UUKG: Unified Urban Knowledge Graph Dataset for Urban Spatiotemporal\n  Prediction","summary":"  Accurate Urban SpatioTemporal Prediction (USTP) is of great importance to the\ndevelopment and operation of the smart city. As an emerging building block,\nmulti-sourced urban data are usually integrated as urban knowledge graphs\n(UrbanKGs) to provide critical knowledge for urban spatiotemporal prediction\nmodels. However, existing UrbanKGs are often tailored for specific downstream\nprediction tasks and are not publicly available, which limits the potential\nadvancement. This paper presents UUKG, the unified urban knowledge graph\ndataset for knowledge-enhanced urban spatiotemporal predictions. Specifically,\nwe first construct UrbanKGs consisting of millions of triplets for two\nmetropolises by connecting heterogeneous urban entities such as administrative\nboroughs, POIs, and road segments. Moreover, we conduct qualitative and\nquantitative analysis on constructed UrbanKGs and uncover diverse high-order\nstructural patterns, such as hierarchies and cycles, that can be leveraged to\nbenefit downstream USTP tasks. To validate and facilitate the use of UrbanKGs,\nwe implement and evaluate 15 KG embedding methods on the KG completion task and\nintegrate the learned KG embeddings into 9 spatiotemporal models for five\ndifferent USTP tasks. The extensive experimental results not only provide\nbenchmarks of knowledge-enhanced USTP models under different task settings but\nalso highlight the potential of state-of-the-art high-order structure-aware\nUrbanKG embedding methods. We hope the proposed UUKG fosters research on urban\nknowledge graphs and broad smart city applications. The dataset and source code\nare available at https://github.com/usail-hkust/UUKG/.\n","authors":["Yansong Ning","Hao Liu","Hao Wang","Zhenyu Zeng","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2306.11443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11435v1","updated":"2023-06-20T10:30:46Z","published":"2023-06-20T10:30:46Z","title":"Graph Neural Stochastic Differential Equations for Learning Brownian\n  Dynamics","summary":"  Neural networks (NNs) that exploit strong inductive biases based on physical\nlaws and symmetries have shown remarkable success in learning the dynamics of\nphysical systems directly from their trajectory. However, these works focus\nonly on the systems that follow deterministic dynamics, for instance, Newtonian\nor Hamiltonian dynamics. Here, we propose a framework, namely Brownian graph\nneural networks (BROGNET), combining stochastic differential equations (SDEs)\nand GNNs to learn Brownian dynamics directly from the trajectory. We\ntheoretically show that BROGNET conserves the linear momentum of the system,\nwhich in turn, provides superior performance on learning dynamics as revealed\nempirically. We demonstrate this approach on several systems, namely, linear\nspring, linear spring with binary particle types, and non-linear spring\nsystems, all following Brownian dynamics at finite temperatures. We show that\nBROGNET significantly outperforms proposed baselines across all the benchmarked\nBrownian systems. In addition, we demonstrate zero-shot generalizability of\nBROGNET to simulate unseen system sizes that are two orders of magnitude larger\nand to different temperatures than those used during training. Altogether, our\nstudy contributes to advancing the understanding of the intricate dynamics of\nBrownian motion and demonstrates the effectiveness of graph neural networks in\nmodeling such complex systems.\n","authors":["Suresh Bishnoi"," Jayadeva","Sayan Ranu","N. M. Anoop Krishnan"],"pdf_url":"https://arxiv.org/pdf/2306.11435v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11426v1","updated":"2023-06-20T10:15:01Z","published":"2023-06-20T10:15:01Z","title":"Exploring the Performance and Efficiency of Transformer Models for NLP\n  on Mobile Devices","summary":"  Deep learning (DL) is characterised by its dynamic nature, with new deep\nneural network (DNN) architectures and approaches emerging every few years,\ndriving the field's advancement. At the same time, the ever-increasing use of\nmobile devices (MDs) has resulted in a surge of DNN-based mobile applications.\nAlthough traditional architectures, like CNNs and RNNs, have been successfully\nintegrated into MDs, this is not the case for Transformers, a relatively new\nmodel family that has achieved new levels of accuracy across AI tasks, but\nposes significant computational challenges. In this work, we aim to make steps\ntowards bridging this gap by examining the current state of Transformers'\non-device execution. To this end, we construct a benchmark of representative\nmodels and thoroughly evaluate their performance across MDs with different\ncomputational capabilities. Our experimental results show that Transformers are\nnot accelerator-friendly and indicate the need for software and hardware\noptimisations to achieve efficient deployment.\n","authors":["Ioannis Panopoulos","Sokratis Nikolaidis","Stylianos I. Venieris","Iakovos S. Venieris"],"pdf_url":"https://arxiv.org/pdf/2306.11426v1.pdf","comment":"Accepted at the 3rd IEEE International Workshop on Distributed\n  Intelligent Systems (DistInSys), 2023"},{"id":"http://arxiv.org/abs/2306.11418v1","updated":"2023-06-20T09:59:45Z","published":"2023-06-20T09:59:45Z","title":"Computing large deviation prefactors of stochastic dynamical systems\n  based on machine learning","summary":"  In this paper, we present large deviation theory that characterizes the\nexponential estimate for rare events of stochastic dynamical systems in the\nlimit of weak noise. We aim to consider next-to-leading-order approximation for\nmore accurate calculation of mean exit time via computing large deviation\nprefactors with the research efforts of machine learning. More specifically, we\ndesign a neural network framework to compute quasipotential, most probable\npaths and prefactors based on the orthogonal decomposition of vector field. We\ncorroborate the higher effectiveness and accuracy of our algorithm with a\npractical example. Numerical experiments demonstrate its powerful function in\nexploring internal mechanism of rare events triggered by weak random\nfluctuations.\n","authors":["Yang Li","Shenglan Yuan","Linghongzhi Lu","Xianbin Liu"],"pdf_url":"https://arxiv.org/pdf/2306.11418v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13545v2","updated":"2023-06-20T09:58:12Z","published":"2023-01-31T10:46:46Z","title":"Holistic Graph-based Motion Prediction","summary":"  Motion prediction for automated vehicles in complex environments is a\ndifficult task that is to be mastered when automated vehicles are to be used in\narbitrary situations. Many factors influence the future motion of traffic\nparticipants starting with traffic rules and reaching from the interaction\nbetween each other to personal habits of human drivers. Therefore we present a\nnovel approach for a graph-based prediction based on a heterogeneous holistic\ngraph representation that combines temporal information, properties and\nrelations between traffic participants as well as relations with static\nelements like the road network. The information are encoded through different\ntypes of nodes and edges that both are enriched with arbitrary features. We\nevaluated the approach on the INTERACTION and the Argoverse dataset and\nconducted an informative ablation study to demonstrate the benefit of different\ntypes of information for the motion prediction quality.\n","authors":["Daniel Grimm","Philip Schörner","Moritz Dreßler","J. -Marius Zöllner"],"pdf_url":"https://arxiv.org/pdf/2301.13545v2.pdf","comment":"Accepted on ICRA 2023"},{"id":"http://arxiv.org/abs/2306.11417v1","updated":"2023-06-20T09:55:10Z","published":"2023-06-20T09:55:10Z","title":"PyRCA: A Library for Metric-based Root Cause Analysis","summary":"  We introduce PyRCA, an open-source Python machine learning library of Root\nCause Analysis (RCA) for Artificial Intelligence for IT Operations (AIOps). It\nprovides a holistic framework to uncover the complicated metric causal\ndependencies and automatically locate root causes of incidents. It offers a\nunified interface for multiple commonly used RCA models, encompassing both\ngraph construction and scoring tasks. This library aims to provide IT\noperations staff, data scientists, and researchers a one-step solution to rapid\nmodel development, model evaluation and deployment to online applications. In\nparticular, our library includes various causal discovery methods to support\ncausal graph construction, and multiple types of root cause scoring methods\ninspired by Bayesian analysis, graph analysis and causal analysis, etc. Our GUI\ndashboard offers practitioners an intuitive point-and-click interface,\nempowering them to easily inject expert knowledge through human interaction.\nWith the ability to visualize causal graphs and the root cause of incidents,\npractitioners can quickly gain insights and improve their workflow efficiency.\nThis technical report introduces PyRCA's architecture and major\nfunctionalities, while also presenting benchmark performance numbers in\ncomparison to various baseline models. Additionally, we demonstrate PyRCA's\ncapabilities through several example use cases.\n","authors":["Chenghao Liu","Wenzhuo Yang","Himanshu Mittal","Manpreet Singh","Doyen Sahoo","Steven C. H. Hoi"],"pdf_url":"https://arxiv.org/pdf/2306.11417v1.pdf","comment":"Github repo: https://github.com/salesforce/PyRCA"},{"id":"http://arxiv.org/abs/2302.09125v3","updated":"2023-06-20T09:51:14Z","published":"2023-02-17T20:17:21Z","title":"JANA: Jointly Amortized Neural Approximation of Complex Bayesian Models","summary":"  This work proposes ``jointly amortized neural approximation'' (JANA) of\nintractable likelihood functions and posterior densities arising in Bayesian\nsurrogate modeling and simulation-based inference. We train three complementary\nnetworks in an end-to-end fashion: 1) a summary network to compress individual\ndata points, sets, or time series into informative embedding vectors; 2) a\nposterior network to learn an amortized approximate posterior; and 3) a\nlikelihood network to learn an amortized approximate likelihood. Their\ninteraction opens a new route to amortized marginal likelihood and posterior\npredictive estimation -- two important ingredients of Bayesian workflows that\nare often too expensive for standard methods. We benchmark the fidelity of JANA\non a variety of simulation models against state-of-the-art Bayesian methods and\npropose a powerful and interpretable diagnostic for joint calibration. In\naddition, we investigate the ability of recurrent likelihood networks to\nemulate complex time series models without resorting to hand-crafted summary\nstatistics.\n","authors":["Stefan T. Radev","Marvin Schmitt","Valentin Pratz","Umberto Picchini","Ullrich Köthe","Paul-Christian Bürkner"],"pdf_url":"https://arxiv.org/pdf/2302.09125v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11412v1","updated":"2023-06-20T09:40:32Z","published":"2023-06-20T09:40:32Z","title":"Hierarchical GNNs for Large Graph Generation","summary":"  Large graphs are present in a variety of domains, including social networks,\ncivil infrastructure, and the physical sciences to name a few. Graph generation\nis similarly widespread, with applications in drug discovery, network analysis\nand synthetic datasets among others. While GNN (Graph Neural Network) models\nhave been applied in these domains their high in-memory costs restrict them to\nsmall graphs. Conversely less costly rule-based methods struggle to reproduce\ncomplex structures. We propose HIGGS (Hierarchical Generation of Graphs) as a\nmodel-agnostic framework of producing large graphs with realistic local\nstructures. HIGGS uses GNN models with conditional generation capabilities to\nsample graphs in hierarchies of resolution. As a result HIGGS has the capacity\nto extend the scale of generated graphs from a given GNN model by quadratic\norder. As a demonstration we implement HIGGS using DiGress, a recent\ngraph-diffusion model, including a novel edge-predictive-diffusion variant\nedge-DiGress. We use this implementation to generate categorically attributed\ngraphs with tens of thousands of nodes. These HIGGS generated graphs are far\nlarger than any previously produced using GNNs. Despite this jump in scale we\ndemonstrate that the graphs produced by HIGGS are, on the local scale, more\nrealistic than those from the rule-based model BTER.\n","authors":["Alex O. Davies","Nirav S. Ajmeri","Telmo M. Silva Filho"],"pdf_url":"https://arxiv.org/pdf/2306.11412v1.pdf","comment":"In submission for NeurIPS 23"},{"id":"http://arxiv.org/abs/2305.18394v3","updated":"2023-06-20T09:36:29Z","published":"2023-05-28T12:34:07Z","title":"On Optimal Regularization Parameters via Bilevel Learning","summary":"  Variational regularization is commonly used to solve linear inverse problems,\nand involves augmenting a data fidelity by a regularizer. The regularizer is\nused to promote a priori information, and is weighted by a regularization\nparameter. Selection of an appropriate regularization parameter is critical,\nwith various choices leading to very different reconstructions. Existing\nstrategies such as the discrepancy principle and L-curve can be used to\ndetermine a suitable parameter value, but in recent years a supervised machine\nlearning approach called bilevel learning has been employed. Bilevel learning\nis a powerful framework to determine optimal parameters, and involves solving a\nnested optimisation problem. While previous strategies enjoy various\ntheoretical results, the well-posedness of bilevel learning in this setting is\nstill a developing field. One necessary property is positivity of the\ndetermined regularization parameter. In this work, we provide a new condition\nthat better characterises positivity of optimal regularization parameters than\nthe existing theory. Numerical results verify and explore this new condition\nfor both small and large dimensional problems.\n","authors":["Matthias J. Ehrhardt","Silvia Gazzola","Sebastian J. Scott"],"pdf_url":"https://arxiv.org/pdf/2305.18394v3.pdf","comment":"26 pages, 6 figures. Fixed typos in the header and Lemma 3. Fixed\n  error in Proposition 5. Fixed typos"},{"id":"http://arxiv.org/abs/2306.11406v1","updated":"2023-06-20T09:29:03Z","published":"2023-06-20T09:29:03Z","title":"Stable and Consistent Prediction of 3D Characteristic Orientation via\n  Invariant Residual Learning","summary":"  Learning to predict reliable characteristic orientations of 3D point clouds\nis an important yet challenging problem, as different point clouds of the same\nclass may have largely varying appearances. In this work, we introduce a novel\nmethod to decouple the shape geometry and semantics of the input point cloud to\nachieve both stability and consistency. The proposed method integrates\nshape-geometry-based SO(3)-equivariant learning and shape-semantics-based\nSO(3)-invariant residual learning, where a final characteristic orientation is\nobtained by calibrating an SO(3)-equivariant orientation hypothesis using an\nSO(3)-invariant residual rotation. In experiments, the proposed method not only\ndemonstrates superior stability and consistency but also exhibits\nstate-of-the-art performances when applied to point cloud part segmentation,\ngiven randomly rotated inputs.\n","authors":["Seungwook Kim","Chunghyun Park","Yoonwoo Jeong","Jaesik Park","Minsu Cho"],"pdf_url":"https://arxiv.org/pdf/2306.11406v1.pdf","comment":"Accepted to ICML 2023"},{"id":"http://arxiv.org/abs/2112.09036v5","updated":"2023-06-20T09:26:58Z","published":"2021-12-16T17:27:29Z","title":"The Dual PC Algorithm and the Role of Gaussianity for Structure Learning\n  of Bayesian Networks","summary":"  Learning the graphical structure of Bayesian networks is key to describing\ndata-generating mechanisms in many complex applications but poses considerable\ncomputational challenges. Observational data can only identify the equivalence\nclass of the directed acyclic graph underlying a Bayesian network model, and a\nvariety of methods exist to tackle the problem. Under certain assumptions, the\npopular PC algorithm can consistently recover the correct equivalence class by\nreverse-engineering the conditional independence (CI) relationships holding in\nthe variable distribution. The dual PC algorithm is a novel scheme to carry out\nthe CI tests within the PC algorithm by leveraging the inverse relationship\nbetween covariance and precision matrices. By exploiting block matrix\ninversions we can also perform tests on partial correlations of complementary\n(or dual) conditioning sets. The multiple CI tests of the dual PC algorithm\nproceed by first considering marginal and full-order CI relationships and\nprogressively moving to central-order ones. Simulation studies show that the\ndual PC algorithm outperforms the classic PC algorithm both in terms of run\ntime and in recovering the underlying network structure, even in the presence\nof deviations from Gaussianity. Additionally, we show that the dual PC\nalgorithm applies for Gaussian copula models, and demonstrate its performance\nin that setting.\n","authors":["Enrico Giudice","Jack Kuipers","Giusi Moffa"],"pdf_url":"https://arxiv.org/pdf/2112.09036v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.07218v2","updated":"2023-06-20T09:01:22Z","published":"2023-06-12T16:24:01Z","title":"A Protocol for Continual Explanation of SHAP","summary":"  Continual Learning trains models on a stream of data, with the aim of\nlearning new information without forgetting previous knowledge. Given the\ndynamic nature of such environments, explaining the predictions of these models\ncan be challenging. We study the behavior of SHAP values explanations in\nContinual Learning and propose an evaluation protocol to robustly assess the\nchange of explanations in Class-Incremental scenarios. We observed that, while\nReplay strategies enforce the stability of SHAP values in\nfeedforward/convolutional models, they are not able to do the same with\nfully-trained recurrent models. We show that alternative recurrent approaches,\nlike randomized recurrent models, are more effective in keeping the\nexplanations stable over time.\n","authors":["Andrea Cossu","Francesco Spinnato","Riccardo Guidotti","Davide Bacciu"],"pdf_url":"https://arxiv.org/pdf/2306.07218v2.pdf","comment":"ESANN 2023, 6 pages, added link to code"},{"id":"http://arxiv.org/abs/2207.11708v3","updated":"2023-06-20T08:56:29Z","published":"2022-07-24T10:22:28Z","title":"Towards an Improved Understanding of Software Vulnerability Assessment\n  Using Data-Driven Approaches","summary":"  The thesis advances the field of software security by providing knowledge and\nautomation support for software vulnerability assessment using data-driven\napproaches. Software vulnerability assessment provides important and\nmultifaceted information to prevent and mitigate dangerous cyber-attacks in the\nwild. The key contributions include a systematisation of knowledge, along with\na suite of novel data-driven techniques and practical recommendations for\nresearchers and practitioners in the area. The thesis results help improve the\nunderstanding and inform the practice of assessing ever-increasing\nvulnerabilities in real-world software systems. This in turn enables more\nthorough and timely fixing prioritisation and planning of these critical\nsecurity issues.\n","authors":["Triet H. M. Le"],"pdf_url":"https://arxiv.org/pdf/2207.11708v3.pdf","comment":"A thesis submitted for the degree of Doctor of Philosophy at The\n  University of Adelaide. The official version of the thesis can be found at\n  the institutional repository: https://hdl.handle.net/2440/135914"},{"id":"http://arxiv.org/abs/2210.15513v3","updated":"2023-06-20T08:55:23Z","published":"2022-10-27T14:48:49Z","title":"Lifelong Bandit Optimization: No Prior and No Regret","summary":"  Machine learning algorithms are often repeatedly applied to problems with\nsimilar structure over and over again. We focus on solving a sequence of bandit\noptimization tasks and develop LIBO, an algorithm which adapts to the\nenvironment by learning from past experience and becomes more sample-efficient\nin the process. We assume a kernelized structure where the kernel is unknown\nbut shared across all tasks. LIBO sequentially meta-learns a kernel that\napproximates the true kernel and solves the incoming tasks with the latest\nkernel estimate. Our algorithm can be paired with any kernelized or linear\nbandit algorithm and guarantees oracle optimal performance, meaning that as\nmore tasks are solved, the regret of LIBO on each task converges to the regret\nof the bandit algorithm with oracle knowledge of the true kernel. Naturally, if\npaired with a sublinear bandit algorithm, LIBO yields a sublinear lifelong\nregret. We also show that direct access to the data from each task is not\nnecessary for attaining sublinear regret. We propose F-LIBO, which solves the\nlifelong problem in a federated manner.\n","authors":["Felix Schur","Parnian Kassraie","Jonas Rothfuss","Andreas Krause"],"pdf_url":"https://arxiv.org/pdf/2210.15513v3.pdf","comment":"35 pages, 6 figures, In Proceedings of UAI 2023"},{"id":"http://arxiv.org/abs/2302.10364v3","updated":"2023-06-20T08:53:12Z","published":"2023-02-20T23:51:33Z","title":"Gaussian processes at the Helm(holtz): A more fluid model for ocean\n  currents","summary":"  Given sparse observations of buoy velocities, oceanographers are interested\nin reconstructing ocean currents away from the buoys and identifying\ndivergences in a current vector field. As a first and modular step, we focus on\nthe time-stationary case - for instance, by restricting to short time periods.\nSince we expect current velocity to be a continuous but highly non-linear\nfunction of spatial location, Gaussian processes (GPs) offer an attractive\nmodel. But we show that applying a GP with a standard stationary kernel\ndirectly to buoy data can struggle at both current reconstruction and\ndivergence identification, due to some physically unrealistic prior\nassumptions. To better reflect known physical properties of currents, we\npropose to instead put a standard stationary kernel on the divergence and\ncurl-free components of a vector field obtained through a Helmholtz\ndecomposition. We show that, because this decomposition relates to the original\nvector field just via mixed partial derivatives, we can still perform inference\ngiven the original data with only a small constant multiple of additional\ncomputational expense. We illustrate the benefits of our method with theory and\nexperiments on synthetic and real ocean data.\n","authors":["Renato Berlinghieri","Brian L. Trippe","David R. Burt","Ryan Giordano","Kaushik Srinivasan","Tamay Özgökmen","Junfei Xia","Tamara Broderick"],"pdf_url":"https://arxiv.org/pdf/2302.10364v3.pdf","comment":"51 pages, 16 figures"},{"id":"http://arxiv.org/abs/2306.11380v1","updated":"2023-06-20T08:38:31Z","published":"2023-06-20T08:38:31Z","title":"A Bayesian Take on Gaussian Process Networks","summary":"  Gaussian Process Networks (GPNs) are a class of directed graphical models\nwhich employ Gaussian processes as priors for the conditional expectation of\neach variable given its parents in the network. The model allows describing\ncontinuous joint distributions in a compact but flexible manner with minimal\nparametric assumptions on the dependencies between variables. Bayesian\nstructure learning of GPNs requires computing the posterior over graphs of the\nnetwork and is computationally infeasible even in low dimensions. This work\nimplements Monte Carlo and Markov Chain Monte Carlo methods to sample from the\nposterior distribution of network structures. As such, the approach follows the\nBayesian paradigm, comparing models via their marginal likelihood and computing\nthe posterior probability of the GPN features. Simulation studies show that our\nmethod outperforms state-of-the-art algorithms in recovering the graphical\nstructure of the network and provides an accurate approximation of its\nposterior distribution.\n","authors":["Enrico Giudice","Jack Kuipers","Giusi Moffa"],"pdf_url":"https://arxiv.org/pdf/2306.11380v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05698v3","updated":"2023-06-20T08:37:42Z","published":"2023-02-11T14:02:08Z","title":"Compositional Exemplars for In-context Learning","summary":"  Large pretrained language models (LMs) have shown impressive In-Context\nLearning (ICL) ability, where the model learns to do an unseen task via a\nprompt consisting of input-output examples as the demonstration, without any\nparameter updates. The performance of ICL is highly dominated by the quality of\nthe selected in-context examples. However, previous selection methods are\nmostly based on simple heuristics, leading to sub-optimal performance. In this\nwork, we formulate in-context example selection as a subset selection problem.\nWe propose CEIL (Compositional Exemplars for In-context Learning), which is\ninstantiated by Determinantal Point Processes (DPPs) to model the interaction\nbetween the given input and in-context examples, and optimized through a\ncarefully-designed contrastive learning objective to obtain preference from\nLMs. We validate CEIL on 12 classification and generation datasets from 7\ndistinct NLP tasks, including sentiment analysis, paraphrase detection, natural\nlanguage inference, commonsense reasoning, open-domain question answering, code\ngeneration, and semantic parsing. Extensive experiments demonstrate not only\nthe state-of-the-art performance but also the transferability and\ncompositionality of CEIL, shedding new light on effective and efficient\nin-context learning. Our code is released at\nhttps://github.com/HKUNLP/icl-ceil.\n","authors":["Jiacheng Ye","Zhiyong Wu","Jiangtao Feng","Tao Yu","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2302.05698v3.pdf","comment":"Accepted in ICML 2023"},{"id":"http://arxiv.org/abs/2306.11375v1","updated":"2023-06-20T08:31:24Z","published":"2023-06-20T08:31:24Z","title":"Top-down machine learning of coarse-grained protein force-fields","summary":"  Developing accurate and efficient coarse-grained representations of proteins\nis crucial for understanding their folding, function, and interactions over\nextended timescales. Our methodology involves simulating proteins with\nmolecular dynamics and utilizing the resulting trajectories to train a neural\nnetwork potential through differentiable trajectory reweighting. Remarkably,\nthis method requires only the native conformation of proteins, eliminating the\nneed for labeled data derived from extensive simulations or memory-intensive\nend-to-end differentiable simulations. Once trained, the model can be employed\nto run parallel molecular dynamics simulations and sample folding events for\nproteins both within and beyond the training distribution, showcasing its\nextrapolation capabilities. By applying Markov State Models, native-like\nconformations of the simulated proteins can be predicted from the\ncoarse-grained simulations. Owing to its theoretical transferability and\nability to use solely experimental static structures as training data, we\nanticipate that this approach will prove advantageous for developing new\nprotein force fields and further advancing the study of protein dynamics,\nfolding, and interactions.\n","authors":["Cales Navarro","Maciej Majewski","Gianni de Fabritiis"],"pdf_url":"https://arxiv.org/pdf/2306.11375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.00356v3","updated":"2023-06-20T08:28:38Z","published":"2022-06-01T09:43:10Z","title":"A Survey on Deep Learning for Skin Lesion Segmentation","summary":"  Skin cancer is a major public health problem that could benefit from\ncomputer-aided diagnosis to reduce the burden of this common disease. Skin\nlesion segmentation from images is an important step toward achieving this\ngoal. However, the presence of natural and artificial artifacts (e.g., hair and\nair bubbles), intrinsic factors (e.g., lesion shape and contrast), and\nvariations in image acquisition conditions make skin lesion segmentation a\nchallenging task. Recently, various researchers have explored the applicability\nof deep learning models to skin lesion segmentation. In this survey, we\ncross-examine 177 research papers that deal with deep learning-based\nsegmentation of skin lesions. We analyze these works along several dimensions,\nincluding input data (datasets, preprocessing, and synthetic data generation),\nmodel design (architecture, modules, and losses), and evaluation aspects (data\nannotation requirements and segmentation performance). We discuss these\ndimensions both from the viewpoint of select seminal works, and from a\nsystematic viewpoint, examining how those choices have influenced current\ntrends, and how their limitations should be addressed. To facilitate\ncomparisons, we summarize all examined works in a comprehensive table as well\nas an interactive table available online at\nhttps://github.com/sfu-mial/skin-lesion-segmentation-survey.\n","authors":["Zahra Mirikharaji","Kumar Abhishek","Alceu Bissoto","Catarina Barata","Sandra Avila","Eduardo Valle","M. Emre Celebi","Ghassan Hamarneh"],"pdf_url":"https://arxiv.org/pdf/2206.00356v3.pdf","comment":"Published in Medical Image Analysis (2023); 55 pages, 10 figures;\n  Mirikharaji and Abhishek: Joint first authors; Celebi and Hamarneh: Joint\n  senior authors"},{"id":"http://arxiv.org/abs/2306.11363v1","updated":"2023-06-20T08:02:59Z","published":"2023-06-20T08:02:59Z","title":"Masked Diffusion Models are Fast Learners","summary":"  Diffusion models have emerged as the de-facto technique for image generation,\nyet they entail significant computational overhead, hindering the technique's\nbroader application in the research community. We propose a prior-based\ndenoising training framework, the first to incorporate the pre-train and\nfine-tune paradigm into the diffusion model training process, which\nsubstantially improves training efficiency and shows potential in facilitating\nvarious downstream tasks. Our approach centers on masking a high proportion\n(e.g., up to 90%) of the input image and employing masked score matching to\ndenoise the visible areas, thereby guiding the diffusion model to learn more\nsalient features from training data as prior knowledge. By utilizing this\nmasked learning process in a pre-training stage, we efficiently train the\nViT-based diffusion model on CelebA-HQ 256x256 in the pixel space, achieving a\n4x acceleration and enhancing the quality of generated images compared to DDPM.\nMoreover, our masked pre-training technique is universally applicable to\nvarious diffusion models that directly generate images in the pixel space and\nfacilitates learning pre-trained models with excellent generalizability: a\ndiffusion model pre-trained on VGGFace2 attains a 46% quality improvement\nthrough fine-tuning with merely 10% local data. Our code is available at\nhttps://github.com/jiachenlei/maskdm.\n","authors":["Jiachen Lei","Peng Cheng","Zhongjie Ba","Kui Ren"],"pdf_url":"https://arxiv.org/pdf/2306.11363v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11344v1","updated":"2023-06-20T07:25:14Z","published":"2023-06-20T07:25:14Z","title":"Contrastive Disentangled Learning on Graph for Node Classification","summary":"  Contrastive learning methods have attracted considerable attention due to\ntheir remarkable success in analyzing graph-structured data. Inspired by the\nsuccess of contrastive learning, we propose a novel framework for contrastive\ndisentangled learning on graphs, employing a disentangled graph encoder and two\ncarefully crafted self-supervision signals. Specifically, we introduce a\ndisentangled graph encoder to enforce the framework to distinguish various\nlatent factors corresponding to underlying semantic information and learn the\ndisentangled node embeddings. Moreover, to overcome the heavy reliance on\nlabels, we design two self-supervision signals, namely node specificity and\nchannel independence, which capture informative knowledge without the need for\nlabeled data, thereby guiding the automatic disentanglement of nodes. Finally,\nwe perform node classification tasks on three citation networks by using the\ndisentangled node embeddings, and the relevant analysis is provided.\nExperimental results validate the effectiveness of the proposed framework\ncompared with various baselines.\n","authors":["Xiaojuan Zhang","Jun Fu","Shuang Li"],"pdf_url":"https://arxiv.org/pdf/2306.11344v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11343v1","updated":"2023-06-20T07:22:01Z","published":"2023-06-20T07:22:01Z","title":"A Universal Unbiased Method for Classification from Aggregate\n  Observations","summary":"  In conventional supervised classification, true labels are required for\nindividual instances. However, it could be prohibitive to collect the true\nlabels for individual instances, due to privacy concerns or unaffordable\nannotation costs. This motivates the study on classification from aggregate\nobservations (CFAO), where the supervision is provided to groups of instances,\ninstead of individual instances. CFAO is a generalized learning framework that\ncontains various learning problems, such as multiple-instance learning and\nlearning from label proportions. The goal of this paper is to present a novel\nuniversal method of CFAO, which holds an unbiased estimator of the\nclassification risk for arbitrary losses -- previous research failed to achieve\nthis goal. Practically, our method works by weighing the importance of each\nlabel for each instance in the group, which provides purified supervision for\nthe classifier to learn. Theoretically, our proposed method not only guarantees\nthe risk consistency due to the unbiased risk estimator but also can be\ncompatible with arbitrary losses. Extensive experiments on various problems of\nCFAO demonstrate the superiority of our proposed method.\n","authors":["Zixi Wei","Lei Feng","Bo Han","Tongliang Liu","Gang Niu","Xiaofeng Zhu","Heng Tao Shen"],"pdf_url":"https://arxiv.org/pdf/2306.11343v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11342v1","updated":"2023-06-20T07:21:31Z","published":"2023-06-20T07:21:31Z","title":"Exploring Antitrust and Platform Power in Generative AI","summary":"  The concentration of power in a few digital technology companies has become a\nsubject of increasing interest in both academic and non-academic discussions.\nOne of the most noteworthy contributions to the debate is Lina Khan's Amazon's\nAntitrust Paradox. In this work, Khan contends that Amazon has systematically\nexerted its dominance in online retail to eliminate competitors and\nsubsequently charge above-market prices. This work contributed to Khan's\nappointment as the chair of the US Federal Trade Commission (FTC), one of the\nmost influential antitrust organizations. Today, several ongoing antitrust\nlawsuits in the US and Europe involve major technology companies like Apple,\nGoogle/Alphabet, and Facebook/Meta. In the realm of generative AI, we are once\nagain witnessing the same companies taking the lead in technological\nadvancements, leaving little room for others to compete. This article examines\nthe market dominance of these corporations in the technology stack behind\ngenerative AI from an antitrust law perspective.\n","authors":["Konrad Kollnig","Qian Li"],"pdf_url":"https://arxiv.org/pdf/2306.11342v1.pdf","comment":"Accepted by the Workshop on Generative AI and Law (GenLaw '23) of\n  ICML '23"},{"id":"http://arxiv.org/abs/2306.11341v1","updated":"2023-06-20T07:19:36Z","published":"2023-06-20T07:19:36Z","title":"MSVD-Indonesian: A Benchmark for Multimodal Video-Text Tasks in\n  Indonesian","summary":"  Multimodal learning on video and text data has been receiving growing\nattention from many researchers in various research tasks, including\ntext-to-video retrieval, video-to-text retrieval, and video captioning.\nAlthough many algorithms have been proposed for those challenging tasks, most\nof them are developed on English language datasets. Despite Indonesian being\none of the most spoken languages in the world, the research progress on the\nmultimodal video-text with Indonesian sentences is still under-explored, likely\ndue to the absence of the public benchmark dataset. To address this issue, we\nconstruct the first public Indonesian video-text dataset by translating English\nsentences from the MSVD dataset to Indonesian sentences. Using our dataset, we\nthen train neural network models which were developed for the English\nvideo-text dataset on three tasks, i.e., text-to-video retrieval, video-to-text\nretrieval, and video captioning. The recent neural network-based approaches to\nvideo-text tasks often utilized a feature extractor that is primarily\npretrained on an English vision-language dataset. Since the availability of the\npretraining resources with Indonesian sentences is relatively limited, the\napplicability of those approaches to our dataset is still questionable. To\novercome the lack of pretraining resources, we apply cross-lingual transfer\nlearning by utilizing the feature extractors pretrained on the English dataset,\nand we then fine-tune the models on our Indonesian dataset. Our experimental\nresults show that this approach can help to improve the performance for the\nthree tasks on all metrics. Finally, we discuss potential future works using\nour dataset, inspiring further research in the Indonesian multimodal video-text\ntasks. We believe that our dataset and our experimental results could provide\nvaluable contributions to the community. Our dataset is available on GitHub.\n","authors":["Willy Fitra Hendria"],"pdf_url":"https://arxiv.org/pdf/2306.11341v1.pdf","comment":"13 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2306.11339v1","updated":"2023-06-20T07:17:38Z","published":"2023-06-20T07:17:38Z","title":"Augmenting Sub-model to Improve Main Model","summary":"  Image classification has improved with the development of training\ntechniques. However, these techniques often require careful parameter tuning to\nbalance the strength of regularization, limiting their potential benefits. In\nthis paper, we propose a novel way to use regularization called Augmenting\nSub-model (AugSub). AugSub consists of two models: the main model and the\nsub-model. While the main model employs conventional training recipes, the\nsub-model leverages the benefit of additional regularization. AugSub achieves\nthis by mitigating adverse effects through a relaxed loss function similar to\nself-distillation loss. We demonstrate the effectiveness of AugSub with three\ndrop techniques: dropout, drop-path, and random masking. Our analysis shows\nthat all AugSub improves performance, with the training loss converging even\nfaster than regular training. Among the three, AugMask is identified as the\nmost practical method due to its performance and cost efficiency. We further\nvalidate AugMask across diverse training recipes, including DeiT-III, ResNet,\nMAE fine-tuning, and Swin Transformer. The results show that AugMask\nconsistently provides significant performance gain. AugSub provides a practical\nand effective solution for introducing additional regularization under various\ntraining recipes. Code is available at\n\\url{https://github.com/naver-ai/augsub}.\n","authors":["Byeongho Heo","Taekyung Kim","Sangdoo Yun","Dongyoon Han"],"pdf_url":"https://arxiv.org/pdf/2306.11339v1.pdf","comment":"15 pages, 3 figures"},{"id":"http://arxiv.org/abs/2306.11338v1","updated":"2023-06-20T07:14:37Z","published":"2023-06-20T07:14:37Z","title":"FDInet: Protecting against DNN Model Extraction via Feature Distortion\n  Index","summary":"  Machine Learning as a Service (MLaaS) platforms have gained popularity due to\ntheir accessibility, cost-efficiency, scalability, and rapid development\ncapabilities. However, recent research has highlighted the vulnerability of\ncloud-based models in MLaaS to model extraction attacks. In this paper, we\nintroduce FDINET, a novel defense mechanism that leverages the feature\ndistribution of deep neural network (DNN) models. Concretely, by analyzing the\nfeature distribution from the adversary's queries, we reveal that the feature\ndistribution of these queries deviates from that of the model's training set.\nBased on this key observation, we propose Feature Distortion Index (FDI), a\nmetric designed to quantitatively measure the feature distribution deviation of\nreceived queries. The proposed FDINET utilizes FDI to train a binary detector\nand exploits FDI similarity to identify colluding adversaries from distributed\nextraction attacks. We conduct extensive experiments to evaluate FDINET against\nsix state-of-the-art extraction attacks on four benchmark datasets and four\npopular model architectures. Empirical results demonstrate the following\nfindings FDINET proves to be highly effective in detecting model extraction,\nachieving a 100% detection accuracy on DFME and DaST. FDINET is highly\nefficient, using just 50 queries to raise an extraction alarm with an average\nconfidence of 96.08% for GTSRB. FDINET exhibits the capability to identify\ncolluding adversaries with an accuracy exceeding 91%. Additionally, it\ndemonstrates the ability to detect two types of adaptive attacks.\n","authors":["Hongwei Yao","Zheng Li","Haiqin Weng","Feng Xue","Kui Ren","Zhan Qin"],"pdf_url":"https://arxiv.org/pdf/2306.11338v1.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.11336v1","updated":"2023-06-20T07:06:17Z","published":"2023-06-20T07:06:17Z","title":"Cooperative Multi-Agent Learning for Navigation via Structured State\n  Abstraction","summary":"  Cooperative multi-agent reinforcement learning (MARL) for navigation enables\nagents to cooperate to achieve their navigation goals. Using emergent\ncommunication, agents learn a communication protocol to coordinate and share\ninformation that is needed to achieve their navigation tasks. In emergent\ncommunication, symbols with no pre-specified usage rules are exchanged, in\nwhich the meaning and syntax emerge through training. Learning a navigation\npolicy along with a communication protocol in a MARL environment is highly\ncomplex due to the huge state space to be explored. To cope with this\ncomplexity, this work proposes a novel neural network architecture, for jointly\nlearning an adaptive state space abstraction and a communication protocol among\nagents participating in navigation tasks. The goal is to come up with an\nadaptive abstractor that significantly reduces the size of the state space to\nbe explored, without degradation in the policy performance. Simulation results\nshow that the proposed method reaches a better policy, in terms of achievable\nrewards, resulting in fewer training iterations compared to the case where raw\nstates or fixed state abstraction are used. Moreover, it is shown that a\ncommunication protocol emerges during training which enables the agents to\nlearn better policies within fewer training iterations.\n","authors":["Mohamed K. Abdelaziz","Mohammed S. Elbamby","Sumudu Samarakoon","Mehdi Bennis"],"pdf_url":"https://arxiv.org/pdf/2306.11336v1.pdf","comment":"24 Pages, 13 Figures, Submitted to a journal for possible publication"},{"id":"http://arxiv.org/abs/2306.11335v1","updated":"2023-06-20T07:06:04Z","published":"2023-06-20T07:06:04Z","title":"RM-PRT: Realistic Robotic Manipulation Simulator and Benchmark with\n  Progressive Reasoning Tasks","summary":"  Recently, the advent of pre-trained large-scale language models (LLMs) like\nChatGPT and GPT-4 have significantly advanced the machine's natural language\nunderstanding capabilities. This breakthrough has allowed us to seamlessly\nintegrate these open-source LLMs into a unified robot simulator environment to\nhelp robots accurately understand and execute human natural language\ninstructions. To this end, in this work, we introduce a realistic robotic\nmanipulation simulator and build a Robotic Manipulation with Progressive\nReasoning Tasks (RM-PRT) benchmark on this basis. Specifically, the RM-PRT\nbenchmark builds a new high-fidelity digital twin scene based on Unreal Engine\n5, which includes 782 categories, 2023 objects, and 15K natural language\ninstructions generated by ChatGPT for a detailed evaluation of robot\nmanipulation. We propose a general pipeline for the RM-PRT benchmark that takes\nas input multimodal prompts containing natural language instructions and\nautomatically outputs actions containing the movement and position transitions.\nWe set four natural language understanding tasks with progressive reasoning\nlevels and evaluate the robot's ability to understand natural language\ninstructions in two modes of adsorption and grasping. In addition, we also\nconduct a comprehensive analysis and comparison of the differences and\nadvantages of 10 different LLMs in instruction understanding and generation\nquality. We hope the new simulator and benchmark will facilitate future\nresearch on language-guided robotic manipulation. Project website:\nhttps://necolizer.github.io/RM-PRT/ .\n","authors":["Pengzhen Ren","Kaidong Zhang","Hetao Zheng","Zixuan Li","Yuhang Wen","Fengda Zhu","Mas Ma","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2306.11335v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05479v2","updated":"2023-06-20T06:41:18Z","published":"2023-03-09T18:31:13Z","title":"Cal-QL: Calibrated Offline RL Pre-Training for Efficient Online\n  Fine-Tuning","summary":"  A compelling use case of offline reinforcement learning (RL) is to obtain a\npolicy initialization from existing datasets followed by fast online\nfine-tuning with limited interaction. However, existing offline RL methods tend\nto behave poorly during fine-tuning. In this paper, we study the fine-tuning\nproblem in the context of conservative offline RL methods and we devise an\napproach for learning an effective initialization from offline data that also\nenables fast online fine-tuning capabilities. Our approach, calibrated\nQ-learning (Cal-QL), accomplishes this by learning a conservative value\nfunction initialization that underestimates the value of the learned policy\nfrom offline data, while also ensuring that the learned Q-values are at a\nreasonable scale. We refer to this property as calibration, and define it\nformally as providing a lower bound on the true value function of the learned\npolicy and an upper bound on the value of some other (suboptimal) reference\npolicy, which may simply be the behavior policy. We show that a conservative\noffline RL algorithm that also learns a calibrated value function leads to\neffective online fine-tuning, enabling us to take the benefits of offline\ninitializations in online fine-tuning. In practice, Cal-QL can be implemented\non top of the conservative Q learning (CQL) for offline RL within a one-line\ncode change. Empirically, Cal-QL outperforms state-of-the-art methods on 9/11\nfine-tuning benchmark tasks that we study in this paper. Code and video are\navailable at https://nakamotoo.github.io/projects/Cal-QL\n","authors":["Mitsuhiko Nakamoto","Yuexiang Zhai","Anikait Singh","Max Sobol Mark","Yi Ma","Chelsea Finn","Aviral Kumar","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2303.05479v2.pdf","comment":"project page: https://nakamotoo.github.io/projects/Cal-QL"},{"id":"http://arxiv.org/abs/2304.01545v4","updated":"2023-06-20T06:38:28Z","published":"2023-04-04T05:44:12Z","title":"Effects of spatiotemporal correlations in wind data on neural\n  network-based wind predictions","summary":"  This paper investigates the influence of incorporating spatiotemporal wind\ndata on the performance of wind forecasting neural networks. While previous\nstudies have shown that including spatial data enhances the accuracy of such\nmodels, limited research has explored the impact of different spatial and\ntemporal scales of input wind data on the learnability of neural network\nmodels. In this study, convolutional neural networks (CNNs) are employed and\ntrained using various scales of spatiotemporal wind data. The research\ndemonstrates that using spatiotemporally correlated data from the surrounding\narea and past time steps for training a CNN favorably affects the predictive\nperformance of the model. The study proposes correlation analyses, including\nautocorrelation and Pearson correlation analyses, to unveil the influence of\nspatiotemporal wind characteristics on the predictive performance of different\nCNN models. The spatiotemporal correlations and performances of CNN models are\ninvestigated in three regions: Korea, the USA, and the UK. The findings reveal\nthat regions with smaller deviations of autocorrelation coefficients (ACC) are\nmore favorable for CNNs to learn the regional and seasonal wind\ncharacteristics. Specifically, the regions of Korea, the USA, and the UK\nexhibit maximum standard deviations of ACCs of 0.100, 0.043, and 0.023,\nrespectively. The CNNs wind prediction performances follow the reverse order of\nthe regions: UK, USA, and Korea. This highlights the significant impact of\nregional and seasonal wind conditions on the performance of the prediction\nmodels.\n","authors":["Heesoo Shin","Mario Rüttgers","Sangseung Lee"],"pdf_url":"https://arxiv.org/pdf/2304.01545v4.pdf","comment":"27 pages, 18 figures"},{"id":"http://arxiv.org/abs/2306.11315v1","updated":"2023-06-20T06:25:05Z","published":"2023-06-20T06:25:05Z","title":"Variational Disentangled Graph Auto-Encoders for Link Prediction","summary":"  With the explosion of graph-structured data, link prediction has emerged as\nan increasingly important task. Embedding methods for link prediction utilize\nneural networks to generate node embeddings, which are subsequently employed to\npredict links between nodes. However, the existing embedding methods typically\ntake a holistic strategy to learn node embeddings and ignore the entanglement\nof latent factors. As a result, entangled embeddings fail to effectively\ncapture the underlying information and are vulnerable to irrelevant\ninformation, leading to unconvincing and uninterpretable link prediction\nresults. To address these challenges, this paper proposes a novel framework\nwith two variants, the disentangled graph auto-encoder (DGAE) and the\nvariational disentangled graph auto-encoder (VDGAE). Our work provides a\npioneering effort to apply the disentanglement strategy to link prediction. The\nproposed framework infers the latent factors that cause edges in the graph and\ndisentangles the representation into multiple channels corresponding to unique\nlatent factors, which contributes to improving the performance of link\nprediction. To further encourage the embeddings to capture mutually exclusive\nlatent factors, we introduce mutual information regularization to enhance the\nindependence among different channels. Extensive experiments on various\nreal-world benchmarks demonstrate that our proposed methods achieve\nstate-of-the-art results compared to a variety of strong baselines on link\nprediction tasks. Qualitative analysis on the synthetic dataset also\nillustrates that the proposed methods can capture distinct latent factors that\ncause links, providing empirical evidence that our models are able to explain\nthe results of link prediction to some extent. All code will be made publicly\navailable upon publication of the paper.\n","authors":["Jun Fu","Xiaojuan Zhang","Shuang Li","Dali Chen"],"pdf_url":"https://arxiv.org/pdf/2306.11315v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11313v1","updated":"2023-06-20T06:15:19Z","published":"2023-06-20T06:15:19Z","title":"Deep graph kernel point processes","summary":"  Point process models are widely used to analyze asynchronous events occurring\nwithin a graph that reflect how different types of events influence one\nanother. Predicting future events' times and types is a crucial task, and the\nsize and topology of the graph add to the challenge of the problem. Recent\nneural point process models unveil the possibility of capturing intricate\ninter-event-category dependencies. However, such methods utilize an unfiltered\nhistory of events, including all event categories in the intensity computation\nfor each target event type. In this work, we propose a graph point process\nmethod where event interactions occur based on a latent graph topology. The\ncorresponding undirected graph has nodes representing event categories and\nedges indicating potential contribution relationships. We then develop a novel\ndeep graph kernel to characterize the triggering and inhibiting effects between\nevents. The intrinsic influence structures are incorporated via the graph\nneural network (GNN) model used to represent the learnable kernel. The\ncomputational efficiency of the GNN approach allows our model to scale to large\ngraphs. Comprehensive experiments on synthetic and real-world data show the\nsuperior performance of our approach against the state-of-the-art methods in\npredicting future events and uncovering the relational structure among data.\n","authors":["Zheng Dong","Matthew Repasky","Xiuyuan Cheng","Yao Xie"],"pdf_url":"https://arxiv.org/pdf/2306.11313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11312v1","updated":"2023-06-20T06:13:56Z","published":"2023-06-20T06:13:56Z","title":"Data Structures for Density Estimation","summary":"  We study statistical/computational tradeoffs for the following density\nestimation problem: given $k$ distributions $v_1, \\ldots, v_k$ over a discrete\ndomain of size $n$, and sampling access to a distribution $p$, identify $v_i$\nthat is \"close\" to $p$. Our main result is the first data structure that, given\na sublinear (in $n$) number of samples from $p$, identifies $v_i$ in time\nsublinear in $k$. We also give an improved version of the algorithm of Acharya\net al. (2018) that reports $v_i$ in time linear in $k$. The experimental\nevaluation of the latter algorithm shows that it achieves a significant\nreduction in the number of operations needed to achieve a given accuracy\ncompared to prior work.\n","authors":["Anders Aamand","Alexandr Andoni","Justin Y. Chen","Piotr Indyk","Shyam Narayanan","Sandeep Silwal"],"pdf_url":"https://arxiv.org/pdf/2306.11312v1.pdf","comment":"To appear at ICML'23"},{"id":"http://arxiv.org/abs/2306.11307v1","updated":"2023-06-20T06:04:03Z","published":"2023-06-20T06:04:03Z","title":"Transforming Graphs for Enhanced Attribute-Based Clustering: An\n  Innovative Graph Transformer Method","summary":"  Graph Representation Learning (GRL) is an influential methodology, enabling a\nmore profound understanding of graph-structured data and aiding graph\nclustering, a critical task across various domains. The recent incursion of\nattention mechanisms, originally an artifact of Natural Language Processing\n(NLP), into the realm of graph learning has spearheaded a notable shift in\nresearch trends. Consequently, Graph Attention Networks (GATs) and Graph\nAttention Auto-Encoders have emerged as preferred tools for graph clustering\ntasks. Yet, these methods primarily employ a local attention mechanism, thereby\ncurbing their capacity to apprehend the intricate global dependencies between\nnodes within graphs. Addressing these impediments, this study introduces an\ninnovative method known as the Graph Transformer Auto-Encoder for Graph\nClustering (GTAGC). By melding the Graph Auto-Encoder with the Graph\nTransformer, GTAGC is adept at capturing global dependencies between nodes.\nThis integration amplifies the graph representation and surmounts the\nconstraints posed by the local attention mechanism. The architecture of GTAGC\nencompasses graph embedding, integration of the Graph Transformer within the\nautoencoder structure, and a clustering component. It strategically alternates\nbetween graph embedding and clustering, thereby tailoring the Graph Transformer\nfor clustering tasks, whilst preserving the graph's global structural\ninformation. Through extensive experimentation on diverse benchmark datasets,\nGTAGC has exhibited superior performance against existing state-of-the-art\ngraph clustering methodologies. This pioneering approach represents a novel\ncontribution to the field of graph clustering, paving the way for promising\navenues in future research.\n","authors":["Shuo Han","Jiachegn Liu","Jiayun Wu","Yinan Chen","Li Tao"],"pdf_url":"https://arxiv.org/pdf/2306.11307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11305v1","updated":"2023-06-20T06:02:19Z","published":"2023-06-20T06:02:19Z","title":"Progressive Neural Representation for Sequential Video Compilation","summary":"  Neural Implicit Representations (NIR) have gained significant attention\nrecently due to their ability to represent complex and high-dimensional data.\nUnlike explicit representations, which require storing and manipulating\nindividual data points, implicit representations capture information through a\nlearned mapping function without explicitly representing the data points\nthemselves. They often prune or quantize neural networks after training to\naccelerate encoding/decoding speed, yet we find that conventional methods fail\nto transfer learned representations to new videos. This work studies the\ncontinuous expansion of implicit video representations as videos arrive\nsequentially over time, where the model can only access the videos from the\ncurrent session. We propose a novel neural video representation, Progressive\nNeural Representation (PNR), that finds an adaptive substructure from the\nsupernet for a given video based on Lottery Ticket Hypothesis. At each training\nsession, our PNR transfers the learned knowledge of the previously obtained\nsubnetworks to learn the representation of the current video while keeping the\npast subnetwork weights intact. Therefore it can almost perfectly preserve the\ndecoding ability (i.e., catastrophic forgetting) of the NIR on previous videos.\nWe demonstrate the effectiveness of our proposed PNR on the neural sequential\nvideo representation compilation on the novel UVG8/17 video sequence\nbenchmarks.\n","authors":["Haeyong Kang","DaHyun Kim","Jaehong Yoon","Sung Ju Hwang","Chang D Yoo"],"pdf_url":"https://arxiv.org/pdf/2306.11305v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11304v1","updated":"2023-06-20T05:52:26Z","published":"2023-06-20T05:52:26Z","title":"Traversing Between Modes in Function Space for Fast Ensembling","summary":"  Deep ensemble is a simple yet powerful way to improve the performance of deep\nneural networks. Under this motivation, recent works on mode connectivity have\nshown that parameters of ensembles are connected by low-loss subspaces, and one\ncan efficiently collect ensemble parameters in those subspaces. While this\nprovides a way to efficiently train ensembles, for inference, multiple forward\npasses should still be executed using all the ensemble parameters, which often\nbecomes a serious bottleneck for real-world deployment. In this work, we\npropose a novel framework to reduce such costs. Given a low-loss subspace\nconnecting two modes of a neural network, we build an additional neural network\nthat predicts the output of the original neural network evaluated at a certain\npoint in the low-loss subspace. The additional neural network, which we call a\n\"bridge\", is a lightweight network that takes minimal features from the\noriginal network and predicts outputs for the low-loss subspace without forward\npasses through the original network. We empirically demonstrate that we can\nindeed train such bridge networks and significantly reduce inference costs with\nthe help of bridge networks.\n","authors":["EungGu Yun","Hyungi Lee","Giung Nam","Juho Lee"],"pdf_url":"https://arxiv.org/pdf/2306.11304v1.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2303.14338v2","updated":"2023-06-20T05:46:17Z","published":"2023-03-25T03:04:14Z","title":"From Gödel's Incompleteness Theorem to the completeness of bot beliefs\n  (Extended abstract)","summary":"  Hilbert and Ackermann asked for a method to consistently extend incomplete\ntheories to complete theories. G\\\"odel essentially proved that any theory\ncapable of encoding its own statements and their proofs contains statements\nthat are true but not provable. Hilbert did not accept that G\\\"odel's\nconstruction answered his question, and in his late writings and lectures,\nG\\\"odel agreed that it did not, since theories can be completed incrementally,\nby adding axioms to prove ever more true statements, as science normally does,\nwith completeness as the vanishing point. This pragmatic view of validity is\nfamiliar not only to scientists who conjecture test hypotheses but also to real\nestate agents and other dealers, who conjure claims, albeit invalid, as\nnecessary to close a deal, confident that they will be able to conjure other\nclaims, albeit invalid, sufficient to make the first claims valid. We study the\nunderlying logical process and describe the trajectories leading to testable\nbut unfalsifiable theories to which bots and other automated learners are\nlikely to converge.\n","authors":["Dusko Pavlovic","Temra Pavlovic"],"pdf_url":"https://arxiv.org/pdf/2303.14338v2.pdf","comment":"19 pages, 13 figures; version updates: changed one word in the title,\n  expanded Introduction, improved presentation, tidied up some diagrams"},{"id":"http://arxiv.org/abs/2209.04142v6","updated":"2023-06-20T05:31:37Z","published":"2022-09-09T06:50:37Z","title":"Causal Modeling of Policy Interventions From Sequences of Treatments and\n  Outcomes","summary":"  A treatment policy defines when and what treatments are applied to affect\nsome outcome of interest. Data-driven decision-making requires the ability to\npredict what happens if a policy is changed. Existing methods that predict how\nthe outcome evolves under different scenarios assume that the tentative\nsequences of future treatments are fixed in advance, while in practice the\ntreatments are determined stochastically by a policy and may depend, for\nexample, on the efficiency of previous treatments. Therefore, the current\nmethods are not applicable if the treatment policy is unknown or a\ncounterfactual analysis is needed. To handle these limitations, we model the\ntreatments and outcomes jointly in continuous time, by combining Gaussian\nprocesses and point processes. Our model enables the estimation of a treatment\npolicy from observational sequences of treatments and outcomes, and it can\npredict the interventional and counterfactual progression of the outcome after\nan intervention on the treatment policy (in contrast with the causal effect of\na single treatment). We show with real-world and semi-synthetic data on blood\nglucose progression that our method can answer causal queries more accurately\nthan existing alternatives.\n","authors":["Çağlar Hızlı","ST John","Anne Juuti","Tuure Saarinen","Kirsi Pietiläinen","Pekka Marttinen"],"pdf_url":"https://arxiv.org/pdf/2209.04142v6.pdf","comment":"Accepted at ICML 2023"},{"id":"http://arxiv.org/abs/2306.11301v1","updated":"2023-06-20T05:31:13Z","published":"2023-06-20T05:31:13Z","title":"Adversarial Search and Track with Multiagent Reinforcement Learning in\n  Sparsely Observable Environment","summary":"  We study a search and tracking (S&T) problem for a team of dynamic search\nagents to capture an adversarial evasive agent with only sparse temporal and\nspatial knowledge of its location in this paper. The domain is challenging for\ntraditional Reinforcement Learning (RL) approaches as the large space leads to\nsparse observations of the adversary and in turn sparse rewards for the search\nagents. Additionally, the opponent's behavior is reactionary to the search\nagents, which causes a data distribution shift for RL during training as search\nagents improve their policies. We propose a differentiable Multi-Agent RL\n(MARL) architecture that utilizes a novel filtering module to supplement\nestimated adversary location information and enables the effective learning of\na team policy. Our algorithm learns how to balance information from prior\nknowledge and a motion model to remain resilient to the data distribution shift\nand outperforms all baseline methods with a 46% increase of detection rate.\n","authors":["Zixuan Wu","Sean Ye","Manisha Natarajan","Letian Chen","Rohan Paleja","Matthew C. Gombolay"],"pdf_url":"https://arxiv.org/pdf/2306.11301v1.pdf","comment":"Submitted to IEEE/RSJ International Conference on Intelligent Robots\n  (IROS) 2023"},{"id":"http://arxiv.org/abs/2306.11297v1","updated":"2023-06-20T05:23:30Z","published":"2023-06-20T05:23:30Z","title":"Decentralized Quantum Federated Learning for Metaverse: Analysis, Design\n  and Implementation","summary":"  With the emerging developments of the Metaverse, a virtual world where people\ncan interact, socialize, play, and conduct their business, it has become\ncritical to ensure that the underlying systems are transparent, secure, and\ntrustworthy. To this end, we develop a decentralized and trustworthy quantum\nfederated learning (QFL) framework. The proposed QFL leverages the power of\nblockchain to create a secure and transparent system that is robust against\ncyberattacks and fraud. In addition, the decentralized QFL system addresses the\nrisks associated with a centralized server-based approach. With extensive\nexperiments and analysis, we evaluate classical federated learning (CFL) and\nQFL in a distributed setting and demonstrate the practicality and benefits of\nthe proposed design. Our theoretical analysis and discussions develop a\ngenuinely decentralized financial system essential for the Metaverse.\nFurthermore, we present the application of blockchain-based QFL in a hybrid\nmetaverse powered by a metaverse observer and world model. Our implementation\ndetails and code are publicly available 1.\n","authors":["Dev Gurung","Shiva Raj Pokhrel","Gang Li"],"pdf_url":"https://arxiv.org/pdf/2306.11297v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.05978v3","updated":"2023-06-20T05:16:51Z","published":"2022-01-16T06:01:58Z","title":"Discrete Simulation Optimization for Tuning Machine Learning Method\n  Hyperparameters","summary":"  Machine learning (ML) methods are used in most technical areas such as image\nrecognition, product recommendation, financial analysis, medical diagnosis, and\npredictive maintenance. An important aspect of implementing ML methods involves\ncontrolling the learning process for the ML method so as to maximize the\nperformance of the method under consideration. Hyperparameter tuning is the\nprocess of selecting a suitable set of ML method parameters that control its\nlearning process. In this work, we demonstrate the use of discrete simulation\noptimization methods such as ranking and selection (R&S) and random search for\nidentifying a hyperparameter set that maximizes the performance of a ML method.\nSpecifically, we use the KN R&S method and the stochastic ruler random search\nmethod and one of its variations for this purpose. We also construct the\ntheoretical basis for applying the KN method, which determines the optimal\nsolution with a statistical guarantee via solution space enumeration. In\ncomparison, the stochastic ruler method asymptotically converges to global\noptima and incurs smaller computational overheads. We demonstrate the\napplication of these methods to a wide variety of machine learning models,\nincluding deep neural network models used for time series prediction and image\nclassification. We benchmark our application of these methods with\nstate-of-the-art hyperparameter optimization libraries such as $hyperopt$ and\n$mango$. The KN method consistently outperforms $hyperopt$'s random search (RS)\nand Tree of Parzen Estimators (TPE) methods. The stochastic ruler method\noutperforms the $hyperopt$ RS method and offers statistically comparable\nperformance with respect to $hyperopt$'s TPE method and the $mango$ algorithm.\n","authors":["Varun Ramamohan","Shobhit Singhal","Aditya Raj Gupta","Nomesh Bhojkumar Bolia"],"pdf_url":"https://arxiv.org/pdf/2201.05978v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.19600v2","updated":"2023-06-20T05:12:30Z","published":"2023-05-31T07:00:42Z","title":"Federated Learning on Heterogeneous Data via Adaptive Self-Distillation","summary":"  Federated Learning (FL) is a machine learning paradigm that enables clients\nto jointly train a global model by aggregating the locally trained models\nwithout sharing any local training data. In practice, there can often be\nsubstantial heterogeneity (e.g., class imbalance) across the local data\ndistributions observed by each of these clients. Under such non-iid data\ndistributions across clients, FL suffers from the 'client-drift' problem where\nevery client converges to its own local optimum. This results in slower\nconvergence and poor performance of the aggregated model. To address this\nlimitation, we propose a novel regularization technique based on adaptive\nself-distillation (ASD) for training models on the client side. Our\nregularization scheme adaptively adjusts to the client's training data based\non: (1) the closeness of the local model's predictions with that of the global\nmodel and (2) the client's label distribution. The proposed regularization can\nbe easily integrated atop existing, state-of-the-art FL algorithms leading to a\nfurther boost in the performance of these off-the-shelf methods. We demonstrate\nthe efficacy of our proposed FL approach through extensive experiments on\nmultiple real-world benchmarks (including datasets with common corruptions and\nperturbations) and show substantial gains in performance over the\nstate-of-the-art methods.\n","authors":["M. Yashwanth","Gaurav Kumar Nayak","Arya Singh","Yogesh Simmhan","Anirban Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2305.19600v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.06211v3","updated":"2023-06-20T05:10:37Z","published":"2021-11-11T14:05:46Z","title":"Model-Based Reinforcement Learning via Stochastic Hybrid Models","summary":"  Optimal control of general nonlinear systems is a central challenge in\nautomation. Enabled by powerful function approximators, data-driven approaches\nto control have recently successfully tackled challenging applications.\nHowever, such methods often obscure the structure of dynamics and control\nbehind black-box over-parameterized representations, thus limiting our ability\nto understand closed-loop behavior. This paper adopts a hybrid-system view of\nnonlinear modeling and control that lends an explicit hierarchical structure to\nthe problem and breaks down complex dynamics into simpler localized units. We\nconsider a sequence modeling paradigm that captures the temporal structure of\nthe data and derive an expectation-maximization (EM) algorithm that\nautomatically decomposes nonlinear dynamics into stochastic piecewise affine\nmodels with nonlinear transition boundaries. Furthermore, we show that these\ntime-series models naturally admit a closed-loop extension that we use to\nextract local polynomial feedback controllers from nonlinear experts via\nbehavioral cloning. Finally, we introduce a novel hybrid relative entropy\npolicy search (Hb-REPS) technique that incorporates the hierarchical nature of\nhybrid models and optimizes a set of time-invariant piecewise feedback\ncontrollers derived from a piecewise polynomial approximation of a global\nstate-value function.\n","authors":["Hany Abdulsamad","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2111.06211v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.19587v2","updated":"2023-06-20T05:07:58Z","published":"2023-05-31T06:14:34Z","title":"Towards Omni-generalizable Neural Methods for Vehicle Routing Problems","summary":"  Learning heuristics for vehicle routing problems (VRPs) has gained much\nattention due to the less reliance on hand-crafted rules. However, existing\nmethods are typically trained and tested on the same task with a fixed size and\ndistribution (of nodes), and hence suffer from limited generalization\nperformance. This paper studies a challenging yet realistic setting, which\nconsiders generalization across both size and distribution in VRPs. We propose\na generic meta-learning framework, which enables effective training of an\ninitialized model with the capability of fast adaptation to new tasks during\ninference. We further develop a simple yet efficient approximation method to\nreduce the training overhead. Extensive experiments on both synthetic and\nbenchmark instances of the traveling salesman problem (TSP) and capacitated\nvehicle routing problem (CVRP) demonstrate the effectiveness of our method. The\ncode is available at: https://github.com/RoyalSkye/Omni-VRP.\n","authors":["Jianan Zhou","Yaoxin Wu","Wen Song","Zhiguang Cao","Jie Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.19587v2.pdf","comment":"Accepted at ICML 2023"},{"id":"http://arxiv.org/abs/2212.02846v4","updated":"2023-06-20T04:41:22Z","published":"2022-12-06T09:32:45Z","title":"Statistical mechanics of continual learning: variational principle and\n  mean-field potential","summary":"  An obstacle to artificial general intelligence is set by continual learning\nof multiple tasks of different nature. Recently, various heuristic tricks, both\nfrom machine learning and from neuroscience angles, were proposed, but they\nlack a unified theory ground. Here, we focus on continual learning in\nsingle-layered and multi-layered neural networks of binary weights. A\nvariational Bayesian learning setting is thus proposed, where the neural\nnetworks are trained in a field-space, rather than gradient-ill-defined\ndiscrete-weight space, and furthermore, weight uncertainty is naturally\nincorporated, and modulates synaptic resources among tasks. From a physics\nperspective, we translate the variational continual learning into Franz-Parisi\nthermodynamic potential framework, where previous task knowledge acts as a\nprior and a reference as well. We thus interpret the continual learning of the\nbinary perceptron in a teacher-student setting as a Franz-Parisi potential\ncomputation. The learning performance can then be analytically studied with\nmean-field order parameters, whose predictions coincide with numerical\nexperiments using stochastic gradient descent methods. Based on the variational\nprinciple and Gaussian field approximation of internal preactivations in hidden\nlayers, we also derive the learning algorithm considering weight uncertainty,\nwhich solves the continual learning with binary weights using multi-layered\nneural networks, and performs better than the currently available\nmetaplasticity algorithm. Our proposed principled frameworks also connect to\nelastic weight consolidation, weight-uncertainty modulated learning, and\nneuroscience inspired metaplasticity, providing a theory-grounded method for\nthe real-world multi-task learning with deep networks.\n","authors":["Chan Li","Zhenye Huang","Wenxuan Zou","Haiping Huang"],"pdf_url":"https://arxiv.org/pdf/2212.02846v4.pdf","comment":"48 pages, 8 figures, final version to Phys Rev E"},{"id":"http://arxiv.org/abs/2210.10275v2","updated":"2023-06-20T04:30:42Z","published":"2022-10-19T03:38:57Z","title":"Towards Explaining Distribution Shifts","summary":"  A distribution shift can have fundamental consequences such as signaling a\nchange in the operating environment or significantly reducing the accuracy of\ndownstream models. Thus, understanding distribution shifts is critical for\nexamining and hopefully mitigating the effect of such a shift. Most prior work\nfocuses on merely detecting if a shift has occurred and assumes any detected\nshift can be understood and handled appropriately by a human operator. We hope\nto aid in these manual mitigation tasks by explaining the distribution shift\nusing interpretable transportation maps from the original distribution to the\nshifted one. We derive our interpretable mappings from a relaxation of optimal\ntransport, where the candidate mappings are restricted to a set of\ninterpretable mappings. We then inspect multiple quintessential use-cases of\ndistribution shift in real-world tabular, text, and image datasets to showcase\nhow our explanatory mappings provide a better balance between detail and\ninterpretability than baseline explanations by both visual inspection and our\nPercentExplained metric.\n","authors":["Sean Kulinski","David I. Inouye"],"pdf_url":"https://arxiv.org/pdf/2210.10275v2.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2306.11281v1","updated":"2023-06-20T04:19:06Z","published":"2023-06-20T04:19:06Z","title":"Towards Characterizing Domain Counterfactuals For Invertible Latent\n  Causal Models","summary":"  Learning latent causal models from data has many important applications such\nas robustness, model extrapolation, and counterfactuals. Most prior theoretic\nwork has focused on full causal discovery (i.e., recovering the true latent\nvariables) but requires strong assumptions such as linearity or fails to have\nany analysis of the equivalence class of solutions (e.g., IRM). Instead of full\ncausal discovery, we focus on a specific type of causal query called the domain\ncounterfactual, which hypothesizes what a sample would have looked like if it\nhad been generated in a different domain (or environment). Concretely, we\nassume domain-specific invertible latent structural causal models and a shared\ninvertible observation function, both of which are less restrictive assumptions\nthan prior theoretic works. Under these assumptions, we define domain\ncounterfactually equivalent models and prove that any model can be transformed\ninto an equivalent model via two invertible functions. This constructive\nproperty provides a tight characterization of the domain counterfactual\nequivalence classes. Building upon this result, we prove that every equivalence\nclass contains a model where all intervened variables are at the end when\ntopologically sorted by the causal DAG, i.e., all non-intervened variables have\nnon-intervened ancestors. This surprising result suggests that an algorithm\nthat only allows intervention in the last $k$ latent variables may improve\nmodel estimation for counterfactuals. In experiments, we enforce the sparse\nintervention hypothesis via this theoretic result by constraining that the\nlatent SCMs can only differ in the last few causal mechanisms and demonstrate\nthe feasibility of this algorithm in simulated and image-based experiments.\n","authors":["Sean Kulinski","Zeyu Zhou","Ruqi Bai","Murat Kocaoglu","David I. Inouye"],"pdf_url":"https://arxiv.org/pdf/2306.11281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11279v1","updated":"2023-06-20T04:16:53Z","published":"2023-06-20T04:16:53Z","title":"Less Can Be More: Exploring Population Rating Dispositions with\n  Partitioned Models in Recommender Systems","summary":"  In this study, we partition users by rating disposition - looking first at\ntheir percentage of negative ratings, and then at the general use of the rating\nscale. We hypothesize that users with different rating dispositions may use the\nrecommender system differently and therefore the agreement with their past\nratings may be less predictive of the future agreement.\n  We use data from a large movie rating website to explore whether users should\nbe grouped by disposition, focusing on identifying their various rating\ndistributions that may hurt recommender effectiveness. We find that such\npartitioning not only improves computational efficiency but also improves top-k\nperformance and predictive accuracy. Though such effects are largest for the\nuser-based KNN CF, smaller for item-based KNN CF, and smallest for latent\nfactor algorithms such as SVD.\n","authors":["Ruixuan Sun","Ruoyan Kong","Qiao Jin","Joseph A. Konstan"],"pdf_url":"https://arxiv.org/pdf/2306.11279v1.pdf","comment":"Ruixuan Sun, Ruoyan Kong, Qiao Jin, and Joseph A. Konstan. 2023. Less\n  Can Be More: Exploring Population Rating Dispositions with Partitioned Models\n  in Recommender Systems. In UMAP 23 Adjunct: Adjunct Proceedings of the 31st\n  ACM Conference on User Modeling, Adaptation and Personalization (UMAP 23\n  Adjunct), June 26-29, 2023, Limassol, Cyprus. ACM, New York, NY, USA, 5 pages"},{"id":"http://arxiv.org/abs/2306.11271v1","updated":"2023-06-20T03:58:35Z","published":"2023-06-20T03:58:35Z","title":"Warm-Start Actor-Critic: From Approximation Error to Sub-optimality Gap","summary":"  Warm-Start reinforcement learning (RL), aided by a prior policy obtained from\noffline training, is emerging as a promising RL approach for practical\napplications. Recent empirical studies have demonstrated that the performance\nof Warm-Start RL can be improved \\textit{quickly} in some cases but become\n\\textit{stagnant} in other cases, especially when the function approximation is\nused. To this end, the primary objective of this work is to build a fundamental\nunderstanding on ``\\textit{whether and when online learning can be\nsignificantly accelerated by a warm-start policy from offline RL?}''.\nSpecifically, we consider the widely used Actor-Critic (A-C) method with a\nprior policy. We first quantify the approximation errors in the Actor update\nand the Critic update, respectively. Next, we cast the Warm-Start A-C algorithm\nas Newton's method with perturbation, and study the impact of the approximation\nerrors on the finite-time learning performance with inaccurate Actor/Critic\nupdates. Under some general technical conditions, we derive the upper bounds,\nwhich shed light on achieving the desired finite-learning performance in the\nWarm-Start A-C algorithm. In particular, our findings reveal that it is\nessential to reduce the algorithm bias in online learning.\n  We also obtain lower bounds on the sub-optimality gap of the Warm-Start A-C\nalgorithm to quantify the impact of the bias and error propagation.\n","authors":["Hang Wang","Sen Lin","Junshan Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.11271v1.pdf","comment":"ICML 2023 Oral"},{"id":"http://arxiv.org/abs/2306.11270v1","updated":"2023-06-20T03:48:51Z","published":"2023-06-20T03:48:51Z","title":"Evaluating the Zero-shot Robustness of Instruction-tuned Language Models","summary":"  Instruction fine-tuning has recently emerged as a promising approach for\nimproving the zero-shot capabilities of Large Language Models (LLMs) on new\ntasks. This technique has shown particular strength in improving the\nperformance of modestly sized LLMs, sometimes inducing performance competitive\nwith much larger model variants. In this paper we ask two questions: (1) How\nsensitive are instruction-tuned models to the particular phrasings of\ninstructions, and, (2) How can we make them more robust to such natural\nlanguage variation? To answer the former, we collect a set of 319 instructions\nmanually written by NLP practitioners for over 80 unique tasks included in\nwidely used benchmarks, and we evaluate the variance and average performance of\nthese instructions as compared to instruction phrasings observed during\ninstruction fine-tuning. We find that using novel (unobserved) but appropriate\ninstruction phrasings consistently degrades model performance, sometimes\nsubstantially so. Further, such natural instructions yield a wide variance in\ndownstream performance, despite their semantic equivalence. Put another way,\ninstruction-tuned models are not especially robust to instruction re-phrasings.\nWe propose a simple method to mitigate this issue by introducing ``soft\nprompt'' embedding parameters and optimizing these to maximize the similarity\nbetween representations of semantically equivalent instructions. We show that\nthis method consistently improves the robustness of instruction-tuned models.\n","authors":["Jiuding Sun","Chantal Shaib","Byron C. Wallace"],"pdf_url":"https://arxiv.org/pdf/2306.11270v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11264v1","updated":"2023-06-20T03:33:22Z","published":"2023-06-20T03:33:22Z","title":"GraphGLOW: Universal and Generalizable Structure Learning for Graph\n  Neural Networks","summary":"  Graph structure learning is a well-established problem that aims at\noptimizing graph structures adaptive to specific graph datasets to help message\npassing neural networks (i.e., GNNs) to yield effective and robust node\nembeddings. However, the common limitation of existing models lies in the\nunderlying \\textit{closed-world assumption}: the testing graph is the same as\nthe training graph. This premise requires independently training the structure\nlearning model from scratch for each graph dataset, which leads to prohibitive\ncomputation costs and potential risks for serious over-fitting. To mitigate\nthese issues, this paper explores a new direction that moves forward to learn a\nuniversal structure learning model that can generalize across graph datasets in\nan open world. We first introduce the mathematical definition of this novel\nproblem setting, and describe the model formulation from a probabilistic\ndata-generative aspect. Then we devise a general framework that coordinates a\nsingle graph-shared structure learner and multiple graph-specific GNNs to\ncapture the generalizable patterns of optimal message-passing topology across\ndatasets. The well-trained structure learner can directly produce adaptive\nstructures for unseen target graphs without any fine-tuning. Across diverse\ndatasets and various challenging cross-graph generalization protocols, our\nexperiments show that even without training on target graphs, the proposed\nmodel i) significantly outperforms expressive GNNs trained on input\n(non-optimized) topology, and ii) surprisingly performs on par with\nstate-of-the-art models that independently optimize adaptive structures for\nspecific target graphs, with notably orders-of-magnitude acceleration for\ntraining on the target graph.\n","authors":["Wentao Zhao","Qitian Wu","Chenxiao Yang","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2306.11264v1.pdf","comment":"Published as a conference paper at KDD 2023"},{"id":"http://arxiv.org/abs/2306.09872v2","updated":"2023-06-20T03:31:43Z","published":"2023-06-14T03:37:55Z","title":"GenORM: Generalizable One-shot Rope Manipulation with Parameter-Aware\n  Policy","summary":"  Due to the inherent uncertainty in their deformability during motion,\nprevious methods in rope manipulation often require hundreds of real-world\ndemonstrations to train a manipulation policy for each rope, even for simple\ntasks such as rope goal reaching, which hinder their applications in our\never-changing world. To address this issue, we introduce GenORM, a framework\nthat allows the manipulation policy to handle different deformable ropes with a\nsingle real-world demonstration. To achieve this, we augment the policy by\nconditioning it on deformable rope parameters and training it with a diverse\nrange of simulated deformable ropes so that the policy can adjust actions based\non different rope parameters. At the time of inference, given a new rope,\nGenORM estimates the deformable rope parameters by minimizing the disparity\nbetween the grid density of point clouds of real-world demonstrations and\nsimulations. With the help of a differentiable physics simulator, we require\nonly a single real-world demonstration. Empirical validations on both simulated\nand real-world rope manipulation setups clearly show that our method can\nmanipulate different ropes with a single demonstration and significantly\noutperforms the baseline in both environments (62% improvement in in-domain\nropes, and 15% improvement in out-of-distribution ropes in simulation, 26%\nimprovement in real-world), demonstrating the effectiveness of our approach in\none-shot rope manipulation.\n","authors":["So Kuroki","Jiaxian Guo","Tatsuya Matsushima","Takuya Okubo","Masato Kobayashi","Yuya Ikeda","Ryosuke Takanami","Paul Yoo","Yutaka Matsuo","Yusuke Iwasawa"],"pdf_url":"https://arxiv.org/pdf/2306.09872v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.12085v3","updated":"2023-06-20T03:27:32Z","published":"2023-05-20T03:49:29Z","title":"Stability and Generalization of lp-Regularized Stochastic Learning for\n  GCN","summary":"  Graph convolutional networks (GCN) are viewed as one of the most popular\nrepresentations among the variants of graph neural networks over graph data and\nhave shown powerful performance in empirical experiments. That $\\ell_2$-based\ngraph smoothing enforces the global smoothness of GCN, while (soft)\n$\\ell_1$-based sparse graph learning tends to promote signal sparsity to trade\nfor discontinuity. This paper aims to quantify the trade-off of GCN between\nsmoothness and sparsity, with the help of a general $\\ell_p$-regularized\n$(1<p\\leq 2)$ stochastic learning proposed within. While stability-based\ngeneralization analyses have been given in prior work for a second derivative\nobjectiveness function, our $\\ell_p$-regularized learning scheme does not\nsatisfy such a smooth condition. To tackle this issue, we propose a novel SGD\nproximal algorithm for GCNs with an inexact operator. For a single-layer GCN,\nwe establish an explicit theoretical understanding of GCN with the\n$\\ell_p$-regularized stochastic learning by analyzing the stability of our SGD\nproximal algorithm. We conduct multiple empirical experiments to validate our\ntheoretical findings.\n","authors":["Shiyu Liu","Linsen Wei","Shaogao Lv","Ming Li"],"pdf_url":"https://arxiv.org/pdf/2305.12085v3.pdf","comment":"Accepted to IJCAI 2023"},{"id":"http://arxiv.org/abs/2306.11258v1","updated":"2023-06-20T03:23:32Z","published":"2023-06-20T03:23:32Z","title":"Deep Learning of Dynamical System Parameters from Return Maps as Images","summary":"  We present a novel approach to system identification (SI) using deep learning\ntechniques. Focusing on parametric system identification (PSI), we use a\nsupervised learning approach for estimating the parameters of discrete and\ncontinuous-time dynamical systems, irrespective of chaos. To accomplish this,\nwe transform collections of state-space trajectory observations into image-like\ndata to retain the state-space topology of trajectories from dynamical systems\nand train convolutional neural networks to estimate the parameters of dynamical\nsystems from these images. We demonstrate that our approach can learn parameter\nestimation functions for various dynamical systems, and by using training-time\ndata augmentation, we are able to learn estimation functions whose parameter\nestimates are robust to changes in the sample fidelity of their inputs. Once\ntrained, these estimation models return parameter estimations for new systems\nwith negligible time and computation costs.\n","authors":["Connor James Stephens","Emmanuel Blazquez"],"pdf_url":"https://arxiv.org/pdf/2306.11258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11252v1","updated":"2023-06-20T03:09:32Z","published":"2023-06-20T03:09:32Z","title":"HK-LegiCoST: Leveraging Non-Verbatim Transcripts for Speech Translation","summary":"  We introduce HK-LegiCoST, a new three-way parallel corpus of\nCantonese-English translations, containing 600+ hours of Cantonese audio, its\nstandard traditional Chinese transcript, and English translation, segmented and\naligned at the sentence level. We describe the notable challenges in corpus\npreparation: segmentation, alignment of long audio recordings, and\nsentence-level alignment with non-verbatim transcripts. Such transcripts make\nthe corpus suitable for speech translation research when there are significant\ndifferences between the spoken and written forms of the source language. Due to\nits large size, we are able to demonstrate competitive speech translation\nbaselines on HK-LegiCoST and extend them to promising cross-corpus results on\nthe FLEURS Cantonese subset. These results deliver insights into speech\nrecognition and translation research in languages for which non-verbatim or\n``noisy'' transcription is common due to various factors, including vernacular\nand dialectal speech.\n","authors":["Cihan Xiao","Henry Li Xinyuan","Jinyi Yang","Dongji Gao","Matthew Wiesner","Kevin Duh","Sanjeev Khudanpur"],"pdf_url":"https://arxiv.org/pdf/2306.11252v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02605v3","updated":"2023-06-20T03:07:15Z","published":"2023-02-06T07:57:50Z","title":"Toward Large Kernel Models","summary":"  Recent studies indicate that kernel machines can often perform similarly or\nbetter than deep neural networks (DNNs) on small datasets. The interest in\nkernel machines has been additionally bolstered by the discovery of their\nequivalence to wide neural networks in certain regimes. However, a key feature\nof DNNs is their ability to scale the model size and training data size\nindependently, whereas in traditional kernel machines model size is tied to\ndata size. Because of this coupling, scaling kernel machines to large data has\nbeen computationally challenging. In this paper, we provide a way forward for\nconstructing large-scale general kernel models, which are a generalization of\nkernel machines that decouples the model and data, allowing training on large\ndatasets. Specifically, we introduce EigenPro 3.0, an algorithm based on\nprojected dual preconditioned SGD and show scaling to model and data sizes\nwhich have not been possible with existing kernel methods.\n","authors":["Amirhesam Abedsoltan","Mikhail Belkin","Parthe Pandit"],"pdf_url":"https://arxiv.org/pdf/2302.02605v3.pdf","comment":"Code is available at github.com/EigenPro/EigenPro3"},{"id":"http://arxiv.org/abs/2306.11250v1","updated":"2023-06-20T03:03:04Z","published":"2023-06-20T03:03:04Z","title":"InRank: Incremental Low-Rank Learning","summary":"  The theory of greedy low-rank learning (GLRL) aims to explain the impressive\ngeneralization capabilities of deep learning. It proves that stochastic\ngradient-based training implicitly regularizes neural networks towards low-rank\nsolutions through a gradual increase of the rank during training. However,\nthere is a gap between theory and practice since GLRL requires an infinitesimal\ninitialization of the weights, which is not practical due to the fact that it\nis a saddle point. In this work, we remove the assumption of infinitesimal\ninitialization by focusing on cumulative weight updates. We prove the\ncumulative weight updates follow an incremental low-rank trajectory for\narbitrary orthogonal initialization of weights in a three-layer linear network.\nEmpirically, we demonstrate that our theory holds on a broad range of neural\nnetworks (e.g., transformers) and standard training algorithms (e.g., SGD,\nAdam). However, existing training algorithms do not exploit the low-rank\nproperty to improve computational efficiency as the networks are not\nparameterized in low-rank. To remedy this, we design a new training algorithm\nIncremental Low-Rank Learning (InRank), which explicitly expresses cumulative\nweight updates as low-rank matrices while incrementally augmenting their ranks\nduring training. We evaluate InRank on GPT-2, and our results indicate that\nInRank achieves comparable prediction performance as the full-rank counterpart\nwhile requiring at most 33% of the total ranks throughout training. We also\npropose an efficient version of InRank that achieves a reduction of 20% in\ntotal training time and 37% in memory usage when training GPT-medium on\nWikiText-103 from scratch.\n","authors":["Jiawei Zhao","Yifei Zhang","Beidi Chen","Florian Schäfer","Anima Anandkumar"],"pdf_url":"https://arxiv.org/pdf/2306.11250v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12197v2","updated":"2023-06-20T02:59:32Z","published":"2023-01-28T13:38:48Z","title":"Mutual Wasserstein Discrepancy Minimization for Sequential\n  Recommendation","summary":"  Self-supervised sequential recommendation significantly improves\nrecommendation performance by maximizing mutual information with well-designed\ndata augmentations. However, the mutual information estimation is based on the\ncalculation of Kullback Leibler divergence with several limitations, including\nasymmetrical estimation, the exponential need of the sample size, and training\ninstability. Also, existing data augmentations are mostly stochastic and can\npotentially break sequential correlations with random modifications. These two\nissues motivate us to investigate an alternative robust mutual information\nmeasurement capable of modeling uncertainty and alleviating KL divergence\nlimitations. To this end, we propose a novel self-supervised learning framework\nbased on Mutual WasserStein discrepancy minimization MStein for the sequential\nrecommendation. We propose the Wasserstein Discrepancy Measurement to measure\nthe mutual information between augmented sequences. Wasserstein Discrepancy\nMeasurement builds upon the 2-Wasserstein distance, which is more robust, more\nefficient in small batch sizes, and able to model the uncertainty of stochastic\naugmentation processes. We also propose a novel contrastive learning loss based\non Wasserstein Discrepancy Measurement. Extensive experiments on four benchmark\ndatasets demonstrate the effectiveness of MStein over baselines. More\nquantitative analyses show the robustness against perturbations and training\nefficiency in batch size. Finally, improvements analysis indicates better\nrepresentations of popular users or items with significant uncertainty. The\nsource code is at https://github.com/zfan20/MStein.\n","authors":["Ziwei Fan","Zhiwei Liu","Hao Peng","Philip S Yu"],"pdf_url":"https://arxiv.org/pdf/2301.12197v2.pdf","comment":"Updated with the correction of the asymmetric mistake on the mutual\n  information connection"},{"id":"http://arxiv.org/abs/2306.11246v1","updated":"2023-06-20T02:58:25Z","published":"2023-06-20T02:58:25Z","title":"Neural Inventory Control in Networks via Hindsight Differentiable Policy\n  Optimization","summary":"  Inventory management offers unique opportunities for reliably evaluating and\napplying deep reinforcement learning (DRL). Rather than evaluate DRL algorithms\nby comparing against one another or against human experts, we can compare to\nthe optimum itself in several problem classes with hidden structure. Our DRL\nmethods consistently recover near-optimal policies in such settings, despite\nbeing applied with up to 600-dimensional raw state vectors. In others, they can\nvastly outperform problem-specific heuristics. To reliably apply DRL, we\nleverage two insights. First, one can directly optimize the hindsight\nperformance of any policy using stochastic gradient descent. This uses (i) an\nability to backtest any policy's performance on a subsample of historical\ndemand observations, and (ii) the differentiability of the total cost incurred\non any subsample with respect to policy parameters. Second, we propose a\nnatural neural network architecture to address problems with weak (or\naggregate) coupling constraints between locations in an inventory network. This\narchitecture employs weight duplication for ``sibling'' locations in the\nnetwork, and state summarization. We justify this architecture through an\nasymptotic guarantee, and empirically affirm its value in handling large-scale\nproblems.\n","authors":["Matias Alvo","Daniel Russo","Yash Kanoria"],"pdf_url":"https://arxiv.org/pdf/2306.11246v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.10794v2","updated":"2023-06-20T02:25:58Z","published":"2022-11-19T20:43:39Z","title":"NVDiff: Graph Generation through the Diffusion of Node Vectors","summary":"  Learning to generate graphs is challenging as a graph is a set of pairwise\nconnected, unordered nodes encoding complex combinatorial structures. Recently,\nseveral works have proposed graph generative models based on normalizing flows\nor score-based diffusion models. However, these models need to generate nodes\nand edges in parallel from the same process, whose dimensionality is\nunnecessarily high. We propose NVDiff, which takes the VGAE structure and uses\na score-based generative model (SGM) as a flexible prior to sample node\nvectors. By modeling only node vectors in the latent space, NVDiff\nsignificantly reduces the dimension of the diffusion process and thus improves\nsampling speed. Built on the NVDiff framework, we introduce an attention-based\nscore network capable of capturing both local and global contexts of graphs.\nExperiments indicate that NVDiff significantly reduces computations and can\nmodel much larger graphs than competing methods. At the same time, it achieves\nsuperior or competitive performances over various datasets compared to previous\nmethods.\n","authors":["Xiaohui Chen","Yukun Li","Aonan Zhang","Li-Ping Liu"],"pdf_url":"https://arxiv.org/pdf/2211.10794v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11222v1","updated":"2023-06-20T01:16:11Z","published":"2023-06-20T01:16:11Z","title":"LoSparse: Structured Compression of Large Language Models based on\n  Low-Rank and Sparse Approximation","summary":"  Transformer models have achieved remarkable results in various natural\nlanguage tasks, but they are often prohibitively large, requiring massive\nmemories and computational resources. To reduce the size and complexity of\nthese models, we propose LoSparse (Low-Rank and Sparse approximation), a novel\nmodel compression technique that approximates a weight matrix by the sum of a\nlow-rank matrix and a sparse matrix. Our method combines the advantages of both\nlow-rank approximations and pruning, while avoiding their limitations. Low-rank\napproximation compresses the coherent and expressive parts in neurons, while\npruning removes the incoherent and non-expressive parts in neurons. Pruning\nenhances the diversity of low-rank approximations, and low-rank approximation\nprevents pruning from losing too many expressive neurons. We evaluate our\nmethod on natural language understanding, question answering, and natural\nlanguage generation tasks. We show that it significantly outperforms existing\ncompression methods.\n","authors":["Yixiao Li","Yifan Yu","Qingru Zhang","Chen Liang","Pengcheng He","Weizhu Chen","Tuo Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.11222v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08989v3","updated":"2023-06-20T01:01:34Z","published":"2022-12-18T02:03:00Z","title":"Deep learning applied to computational mechanics: A comprehensive\n  review, state of the art, and the classics","summary":"  Three recent breakthroughs due to AI in arts and science serve as motivation:\nAn award winning digital image, protein folding, fast matrix multiplication.\nMany recent developments in artificial neural networks, particularly deep\nlearning (DL), applied and relevant to computational mechanics (solid, fluids,\nfinite-element technology) are reviewed in detail. Both hybrid and pure machine\nlearning (ML) methods are discussed. Hybrid methods combine traditional PDE\ndiscretizations with ML methods either (1) to help model complex nonlinear\nconstitutive relations, (2) to nonlinearly reduce the model order for efficient\nsimulation (turbulence), or (3) to accelerate the simulation by predicting\ncertain components in the traditional integration methods. Here, methods (1)\nand (2) relied on Long-Short-Term Memory (LSTM) architecture, with method (3)\nrelying on convolutional neural networks. Pure ML methods to solve (nonlinear)\nPDEs are represented by Physics-Informed Neural network (PINN) methods, which\ncould be combined with attention mechanism to address discontinuous solutions.\nBoth LSTM and attention architectures, together with modern and generalized\nclassic optimizers to include stochasticity for DL networks, are extensively\nreviewed. Kernel machines, including Gaussian processes, are provided to\nsufficient depth for more advanced works such as shallow networks with infinite\nwidth. Not only addressing experts, readers are assumed familiar with\ncomputational mechanics, but not with DL, whose concepts and applications are\nbuilt up from the basics, aiming at bringing first-time learners quickly to the\nforefront of research. History and limitations of AI are recounted and\ndiscussed, with particular attention at pointing out misstatements or\nmisconceptions of the classics, even in well-known references. Positioning and\npointing control of a large-deformable beam is given as an example.\n","authors":["Loc Vu-Quoc","Alexander Humer"],"pdf_url":"https://arxiv.org/pdf/2212.08989v3.pdf","comment":"275 pages, 158 figures. Appeared online on 2023.03.01 at\n  CMES-Computer Modeling in Engineering & Sciences"},{"id":"http://arxiv.org/abs/2302.04451v2","updated":"2023-06-20T00:55:20Z","published":"2023-02-09T05:54:17Z","title":"Generalization in Graph Neural Networks: Improved PAC-Bayesian Bounds on\n  Graph Diffusion","summary":"  Graph neural networks are widely used tools for graph prediction tasks.\nMotivated by their empirical performance, prior works have developed\ngeneralization bounds for graph neural networks, which scale with graph\nstructures in terms of the maximum degree. In this paper, we present\ngeneralization bounds that instead scale with the largest singular value of the\ngraph neural network's feature diffusion matrix. These bounds are numerically\nmuch smaller than prior bounds for real-world graphs. We also construct a lower\nbound of the generalization gap that matches our upper bound asymptotically. To\nachieve these results, we analyze a unified model that includes prior works'\nsettings (i.e., convolutional and message-passing networks) and new settings\n(i.e., graph isomorphism networks). Our key idea is to measure the stability of\ngraph neural networks against noise perturbations using Hessians. Empirically,\nwe find that Hessian-based measurements correlate with the observed\ngeneralization gaps of graph neural networks accurately. Optimizing noise\nstability properties for fine-tuning pretrained graph neural networks also\nimproves test performance on several graph-level classification tasks.\n","authors":["Haotian Ju","Dongyue Li","Aneesh Sharma","Hongyang R. Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.04451v2.pdf","comment":"36 pages, 2 tables, 3 figures. Appeared in AISTATS 2023"},{"id":"http://arxiv.org/abs/2306.11217v1","updated":"2023-06-20T00:54:20Z","published":"2023-06-20T00:54:20Z","title":"Autonomous Driving with Deep Reinforcement Learning in CARLA Simulation","summary":"  Nowadays, autonomous vehicles are gaining traction due to their numerous\npotential applications in resolving a variety of other real-world challenges.\nHowever, developing autonomous vehicles need huge amount of training and\ntesting before deploying it to real world. While the field of reinforcement\nlearning (RL) has evolved into a powerful learning framework to the development\nof deep representation learning, and it is now capable of learning complicated\npolicies in high-dimensional environments like in autonomous vehicles. In this\nregard, we make an effort, using Deep Q-Learning, to discover a method by which\nan autonomous car may maintain its lane at top speed while avoiding other\nvehicles. After that, we used CARLA simulation environment to test and verify\nour newly acquired policy based on the problem formulation.\n","authors":["Jumman Hossain"],"pdf_url":"https://arxiv.org/pdf/2306.11217v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11216v1","updated":"2023-06-20T00:50:09Z","published":"2023-06-20T00:50:09Z","title":"CF-GODE: Continuous-Time Causal Inference for Multi-Agent Dynamical\n  Systems","summary":"  Multi-agent dynamical systems refer to scenarios where multiple units\ninteract with each other and evolve collectively over time. To make informed\ndecisions in multi-agent dynamical systems, such as determining the optimal\nvaccine distribution plan, it is essential for decision-makers to estimate the\ncontinuous-time counterfactual outcomes. However, existing studies of causal\ninference over time rely on the assumption that units are mutually independent,\nwhich is not valid for multi-agent dynamical systems. In this paper, we aim to\nbridge this gap and study how to estimate counterfactual outcomes in\nmulti-agent dynamical systems. Causal inference in a multi-agent dynamical\nsystem has unique challenges: 1) Confounders are time-varying and are present\nin both individual unit covariates and those of other units; 2) Units are\naffected by not only their own but also others' treatments; 3) The treatments\nare naturally dynamic, such as receiving vaccines and boosters in a seasonal\nmanner. We model a multi-agent dynamical system as a graph and propose\nCounterFactual GraphODE (CF-GODE), a causal model that estimates\ncontinuous-time counterfactual outcomes in the presence of inter-dependencies\nbetween units. To facilitate continuous-time estimation, we propose\nTreatment-Induced GraphODE, a novel ordinary differential equation based on\nGNN, which incorporates dynamical treatments as additional inputs to predict\npotential outcomes over time. To remove confounding bias, we propose two domain\nadversarial learning based objectives that learn balanced continuous\nrepresentation trajectories, which are not predictive of treatments and\ninterference. We further provide theoretical justification to prove their\neffectiveness. Experiments on two semi-synthetic datasets confirm that CF-GODE\noutperforms baselines on counterfactual estimation. We also provide extensive\nanalyses to understand how our model works.\n","authors":["Song Jiang","Zijie Huang","Xiao Luo","Yizhou Sun"],"pdf_url":"https://arxiv.org/pdf/2306.11216v1.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2304.07288v2","updated":"2023-06-20T00:48:23Z","published":"2023-04-14T17:58:23Z","title":"Cross-Entropy Loss Functions: Theoretical Analysis and Applications","summary":"  Cross-entropy is a widely used loss function in applications. It coincides\nwith the logistic loss applied to the outputs of a neural network, when the\nsoftmax is used. But, what guarantees can we rely on when using cross-entropy\nas a surrogate loss? We present a theoretical analysis of a broad family of\nloss functions, comp-sum losses, that includes cross-entropy (or logistic\nloss), generalized cross-entropy, the mean absolute error and other\ncross-entropy-like loss functions. We give the first $H$-consistency bounds for\nthese loss functions. These are non-asymptotic guarantees that upper bound the\nzero-one loss estimation error in terms of the estimation error of a surrogate\nloss, for the specific hypothesis set $H$ used. We further show that our bounds\nare tight. These bounds depend on quantities called minimizability gaps. To\nmake them more explicit, we give a specific analysis of these gaps for comp-sum\nlosses. We also introduce a new family of loss functions, smooth adversarial\ncomp-sum losses, that are derived from their comp-sum counterparts by adding in\na related smooth term. We show that these loss functions are beneficial in the\nadversarial setting by proving that they admit $H$-consistency bounds. This\nleads to new adversarial robustness algorithms that consist of minimizing a\nregularized smooth adversarial comp-sum loss. While our main purpose is a\ntheoretical analysis, we also present an extensive empirical analysis comparing\ncomp-sum losses. We further report the results of a series of experiments\ndemonstrating that our adversarial robustness algorithms outperform the current\nstate-of-the-art, while also achieving a superior non-adversarial accuracy.\n","authors":["Anqi Mao","Mehryar Mohri","Yutao Zhong"],"pdf_url":"https://arxiv.org/pdf/2304.07288v2.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2306.11208v1","updated":"2023-06-20T00:16:22Z","published":"2023-06-20T00:16:22Z","title":"The Unintended Consequences of Discount Regularization: Improving\n  Regularization in Certainty Equivalence Reinforcement Learning","summary":"  Discount regularization, using a shorter planning horizon when calculating\nthe optimal policy, is a popular choice to restrict planning to a less complex\nset of policies when estimating an MDP from sparse or noisy data (Jiang et al.,\n2015). It is commonly understood that discount regularization functions by\nde-emphasizing or ignoring delayed effects. In this paper, we reveal an\nalternate view of discount regularization that exposes unintended consequences.\nWe demonstrate that planning under a lower discount factor produces an\nidentical optimal policy to planning using any prior on the transition matrix\nthat has the same distribution for all states and actions. In fact, it\nfunctions like a prior with stronger regularization on state-action pairs with\nmore transition data. This leads to poor performance when the transition matrix\nis estimated from data sets with uneven amounts of data across state-action\npairs. Our equivalence theorem leads to an explicit formula to set\nregularization parameters locally for individual state-action pairs rather than\nglobally. We demonstrate the failures of discount regularization and how we\nremedy them using our state-action-specific method across simple empirical\nexamples as well as a medical cancer simulator.\n","authors":["Sarah Rathnam","Sonali Parbhoo","Weiwei Pan","Susan A. Murphy","Finale Doshi-Velez"],"pdf_url":"https://arxiv.org/pdf/2306.11208v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11207v1","updated":"2023-06-20T00:14:47Z","published":"2023-06-20T00:14:47Z","title":"Quilt-1M: One Million Image-Text Pairs for Histopathology","summary":"  Recent accelerations in multi-modal applications have been made possible with\nthe plethora of image and text data available online. However, the scarcity of\nanalogous data in the medical field, specifically in histopathology, has halted\ncomparable progress. To enable similar representation learning for\nhistopathology, we turn to YouTube, an untapped resource of videos, offering\n$1,087$ hours of valuable educational histopathology videos from expert\nclinicians. From YouTube, we curate Quilt: a large-scale vision-language\ndataset consisting of $768,826$ image and text pairs. Quilt was automatically\ncurated using a mixture of models, including large language models, handcrafted\nalgorithms, human knowledge databases, and automatic speech recognition. In\ncomparison, the most comprehensive datasets curated for histopathology amass\nonly around $200$K samples. We combine Quilt with datasets from other sources,\nincluding Twitter, research papers, and the internet in general, to create an\neven larger dataset: Quilt-1M, with $1$M paired image-text samples, marking it\nas the largest vision-language histopathology dataset to date. We demonstrate\nthe value of Quilt-1M by fine-tuning a pre-trained CLIP model. Our model\noutperforms state-of-the-art models on both zero-shot and linear probing tasks\nfor classifying new histopathology images across $13$ diverse patch-level\ndatasets of $8$ different sub-pathologies and cross-modal retrieval tasks.\n","authors":["Wisdom Oluchi Ikezogwo","Mehmet Saygin Seyfioglu","Fatemeh Ghezloo","Dylan Stefan Chan Geva","Fatwir Sheikh Mohammed","Pavan Kumar Anand","Ranjay Krishna","Linda Shapiro"],"pdf_url":"https://arxiv.org/pdf/2306.11207v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.08938v2","updated":"2023-06-20T00:08:20Z","published":"2023-06-15T08:21:41Z","title":"Scalable Resource Management for Dynamic MEC: An Unsupervised\n  Link-Output Graph Neural Network Approach","summary":"  Deep learning has been successfully adopted in mobile edge computing (MEC) to\noptimize task offloading and resource allocation. However, the dynamics of edge\nnetworks raise two challenges in neural network (NN)-based optimization\nmethods: low scalability and high training costs. Although conventional\nnode-output graph neural networks (GNN) can extract features of edge nodes when\nthe network scales, they fail to handle a new scalability issue whereas the\ndimension of the decision space may change as the network scales. To address\nthe issue, in this paper, a novel link-output GNN (LOGNN)-based resource\nmanagement approach is proposed to flexibly optimize the resource allocation in\nMEC for an arbitrary number of edge nodes with extremely low algorithm\ninference delay. Moreover, a label-free unsupervised method is applied to train\nthe LOGNN efficiently, where the gradient of edge tasks processing delay with\nrespect to the LOGNN parameters is derived explicitly. In addition, a\ntheoretical analysis of the scalability of the node-output GNN and link-output\nGNN is performed. Simulation results show that the proposed LOGNN can\nefficiently optimize the MEC resource allocation problem in a scalable way,\nwith an arbitrary number of servers and users. In addition, the proposed\nunsupervised training method has better convergence performance and speed than\nsupervised learning and reinforcement learning-based training methods. The code\nis available at \\url{https://github.com/UNIC-Lab/LOGNN}.\n","authors":["Xiucheng Wang","Nan Cheng","Lianhao Fu","Wei Quan","Ruijin Sun","Yilong Hui","Tom Luan","Xuemin Shen"],"pdf_url":"https://arxiv.org/pdf/2306.08938v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11946v1","updated":"2023-06-20T23:52:39Z","published":"2023-06-20T23:52:39Z","title":"Winter Wheat Crop Yield Prediction on Multiple Heterogeneous Datasets\n  using Machine Learning","summary":"  Winter wheat is one of the most important crops in the United Kingdom, and\ncrop yield prediction is essential for the nation's food security. Several\nstudies have employed machine learning (ML) techniques to predict crop yield on\na county or farm-based level. The main objective of this study is to predict\nwinter wheat crop yield using ML models on multiple heterogeneous datasets,\ni.e., soil and weather on a zone-based level. Experimental results demonstrated\ntheir impact when used alone and in combination. In addition, we employ\nnumerous ML algorithms to emphasize the significance of data quality in any\nmachine-learning strategy.\n","authors":["Yogesh Bansal","Dr. David Lillis","Prof. Mohand Tahar Kechadi"],"pdf_url":"https://arxiv.org/pdf/2306.11946v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11943v1","updated":"2023-06-20T23:42:14Z","published":"2023-06-20T23:42:14Z","title":"Towards Understanding What Code Language Models Learned","summary":"  Pre-trained language models are effective in a variety of natural language\ntasks, but it has been argued their capabilities fall short of fully learning\nmeaning or understanding language. To understand the extent to which language\nmodels can learn some form of meaning, we investigate their ability to capture\nsemantics of code beyond superficial frequency and co-occurrence. In contrast\nto previous research on probing models for linguistic features, we study\npre-trained models in a setting that allows for objective and straightforward\nevaluation of a model's ability to learn semantics. In this paper, we examine\nwhether such models capture the semantics of code, which is precisely and\nformally defined. Through experiments involving the manipulation of code\nfragments, we show that code pre-trained models of code learn a robust\nrepresentation of the computational semantics of code that goes beyond\nsuperficial features of form alone\n","authors":["Toufique Ahmed","Dian Yu","Chengxuan Huang","Cathy Wang","Prem Devanbu","Kenji Sagae"],"pdf_url":"https://arxiv.org/pdf/2306.11943v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11942v1","updated":"2023-06-20T23:39:06Z","published":"2023-06-20T23:39:06Z","title":"A Deep Learning Model for Heterogeneous Dataset Analysis -- Application\n  to Winter Wheat Crop Yield Prediction","summary":"  Western countries rely heavily on wheat, and yield prediction is crucial.\nTime-series deep learning models, such as Long Short Term Memory (LSTM), have\nalready been explored and applied to yield prediction. Existing literature\nreported that they perform better than traditional Machine Learning (ML)\nmodels. However, the existing LSTM cannot handle heterogeneous datasets (a\ncombination of data which varies and remains static with time). In this paper,\nwe propose an efficient deep learning model that can deal with heterogeneous\ndatasets. We developed the system architecture and applied it to the real-world\ndataset in the digital agriculture area. We showed that it outperforms the\nexisting ML models.\n","authors":["Yogesh Bansal","David Lillis","Mohand Tahar Kechadi"],"pdf_url":"https://arxiv.org/pdf/2306.11942v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11941v1","updated":"2023-06-20T23:38:24Z","published":"2023-06-20T23:38:24Z","title":"Efficient Dynamics Modeling in Interactive Environments with Koopman\n  Theory","summary":"  The accurate modeling of dynamics in interactive environments is critical for\nsuccessful long-range prediction. Such a capability could advance Reinforcement\nLearning (RL) and Planning algorithms, but achieving it is challenging.\nInaccuracies in model estimates can compound, resulting in increased errors\nover long horizons. We approach this problem from the lens of Koopman theory,\nwhere the nonlinear dynamics of the environment can be linearized in a\nhigh-dimensional latent space. This allows us to efficiently parallelize the\nsequential problem of long-range prediction using convolution, while accounting\nfor the agent's action at every time step. Our approach also enables stability\nanalysis and better control over gradients through time. Taken together, these\nadvantages result in significant improvement over the existing approaches, both\nin the efficiency and the accuracy of modeling dynamics over extended horizons.\nWe also report promising experimental results in dynamics modeling for the\nscenarios of both model-based planning and model-free RL.\n","authors":["Arnab Kumar Mondal","Siba Smarak Panigrahi","Sai Rajeswar","Kaleem Siddiqi","Siamak Ravanbakhsh"],"pdf_url":"https://arxiv.org/pdf/2306.11941v1.pdf","comment":"18 pages, 3 figures"},{"id":"http://arxiv.org/abs/2306.11928v1","updated":"2023-06-20T22:31:13Z","published":"2023-06-20T22:31:13Z","title":"Open Problem: Learning with Variational Objectives on Measures","summary":"  The theory of statistical learning has focused on variational objectives\nexpressed on functions. In this note, we discuss motivations to write similar\nobjectives on measures, in particular to discuss out-of-distribution\ngeneralization and weakly-supervised learning. It raises a natural question:\ncan one cast usual statistical learning results to objectives expressed on\nmeasures? Does the resulting construction lead to new algorithms of practical\ninterest?\n","authors":["Vivien Cabannes","Carles Domingo-Enrich"],"pdf_url":"https://arxiv.org/pdf/2306.11928v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11922v1","updated":"2023-06-20T22:10:40Z","published":"2023-06-20T22:10:40Z","title":"No Wrong Turns: The Simple Geometry Of Neural Networks Optimization\n  Paths","summary":"  Understanding the optimization dynamics of neural networks is necessary for\nclosing the gap between theory and practice. Stochastic first-order\noptimization algorithms are known to efficiently locate favorable minima in\ndeep neural networks. This efficiency, however, contrasts with the non-convex\nand seemingly complex structure of neural loss landscapes. In this study, we\ndelve into the fundamental geometric properties of sampled gradients along\noptimization paths. We focus on two key quantities, which appear in the\nrestricted secant inequality and error bound. Both hold high significance for\nfirst-order optimization. Our analysis reveals that these quantities exhibit\npredictable, consistent behavior throughout training, despite the stochasticity\ninduced by sampling minibatches. Our findings suggest that not only do\noptimization trajectories never encounter significant obstacles, but they also\nmaintain stable dynamics during the majority of training. These observed\nproperties are sufficiently expressive to theoretically guarantee linear\nconvergence and prescribe learning rate schedules mirroring empirical\npractices. We conduct our experiments on image classification, semantic\nsegmentation and language modeling across different batch sizes, network\narchitectures, datasets, optimizers, and initialization seeds. We discuss the\nimpact of each factor. Our work provides novel insights into the properties of\nneural network loss functions, and opens the door to theoretical frameworks\nmore relevant to prevalent practice.\n","authors":["Charles Guille-Escuret","Hiroki Naganuma","Kilian Fatras","Ioannis Mitliagkas"],"pdf_url":"https://arxiv.org/pdf/2306.11922v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11918v1","updated":"2023-06-20T22:06:14Z","published":"2023-06-20T22:06:14Z","title":"Adaptive Ensemble Q-learning: Minimizing Estimation Bias via Error\n  Feedback","summary":"  The ensemble method is a promising way to mitigate the overestimation issue\nin Q-learning, where multiple function approximators are used to estimate the\naction values. It is known that the estimation bias hinges heavily on the\nensemble size (i.e., the number of Q-function approximators used in the\ntarget), and that determining the `right' ensemble size is highly nontrivial,\nbecause of the time-varying nature of the function approximation errors during\nthe learning process. To tackle this challenge, we first derive an upper bound\nand a lower bound on the estimation bias, based on which the ensemble size is\nadapted to drive the bias to be nearly zero, thereby coping with the impact of\nthe time-varying approximation errors accordingly. Motivated by the theoretic\nfindings, we advocate that the ensemble method can be combined with Model\nIdentification Adaptive Control (MIAC) for effective ensemble size adaptation.\nSpecifically, we devise Adaptive Ensemble Q-learning (AdaEQ), a generalized\nensemble method with two key steps: (a) approximation error characterization\nwhich serves as the feedback for flexibly controlling the ensemble size, and\n(b) ensemble size adaptation tailored towards minimizing the estimation bias.\nExtensive experiments are carried out to show that AdaEQ can improve the\nlearning performance than the existing methods for the MuJoCo benchmark.\n","authors":["Hang Wang","Sen Lin","Junshan Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.11918v1.pdf","comment":"NeurIPS 2021"},{"id":"http://arxiv.org/abs/2306.11915v1","updated":"2023-06-20T22:01:37Z","published":"2023-06-20T22:01:37Z","title":"Structure-Aware Robustness Certificates for Graph Classification","summary":"  Certifying the robustness of a graph-based machine learning model poses a\ncritical challenge for safety. Current robustness certificates for graph\nclassifiers guarantee output invariance with respect to the total number of\nnode pair flips (edge addition or edge deletion), which amounts to an $l_{0}$\nball centred on the adjacency matrix. Although theoretically attractive, this\ntype of isotropic structural noise can be too restrictive in practical\nscenarios where some node pairs are more critical than others in determining\nthe classifier's output. The certificate, in this case, gives a pessimistic\ndepiction of the robustness of the graph model. To tackle this issue, we\ndevelop a randomised smoothing method based on adding an anisotropic noise\ndistribution to the input graph structure. We show that our process generates\nstructural-aware certificates for our classifiers, whereby the magnitude of\nrobustness certificates can vary across different pre-defined structures of the\ngraph. We demonstrate the benefits of these certificates in both synthetic and\nreal-world experiments.\n","authors":["Pierre Osselin","Henry Kenlay","Xiaowen Dong"],"pdf_url":"https://arxiv.org/pdf/2306.11915v1.pdf","comment":"9 pages, 6 figures (15 pages, 10 figures including references and\n  appendices)"},{"id":"http://arxiv.org/abs/2203.13887v5","updated":"2023-06-20T22:00:45Z","published":"2022-03-25T19:54:17Z","title":"Automatic Debiased Machine Learning for Dynamic Treatment Effects and\n  General Nested Functionals","summary":"  We extend the idea of automated debiased machine learning to the dynamic\ntreatment regime and more generally to nested functionals. We show that the\nmultiply robust formula for the dynamic treatment regime with discrete\ntreatments can be re-stated in terms of a recursive Riesz representer\ncharacterization of nested mean regressions. We then apply a recursive Riesz\nrepresenter estimation learning algorithm that estimates de-biasing corrections\nwithout the need to characterize how the correction terms look like, such as\nfor instance, products of inverse probability weighting terms, as is done in\nprior work on doubly robust estimation in the dynamic regime. Our approach\ndefines a sequence of loss minimization problems, whose minimizers are the\nmulitpliers of the de-biasing correction, hence circumventing the need for\nsolving auxiliary propensity models and directly optimizing for the mean\nsquared error of the target de-biasing correction. We provide further\napplications of our approach to estimation of dynamic discrete choice models\nand estimation of long-term effects with surrogates.\n","authors":["Victor Chernozhukov","Whitney Newey","Rahul Singh","Vasilis Syrgkanis"],"pdf_url":"https://arxiv.org/pdf/2203.13887v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11913v1","updated":"2023-06-20T21:54:13Z","published":"2023-06-20T21:54:13Z","title":"Randomized Quantization is All You Need for Differential Privacy in\n  Federated Learning","summary":"  Federated learning (FL) is a common and practical framework for learning a\nmachine model in a decentralized fashion. A primary motivation behind this\ndecentralized approach is data privacy, ensuring that the learner never sees\nthe data of each local source itself. Federated learning then comes with two\nmajors challenges: one is handling potentially complex model updates between a\nserver and a large number of data sources; the other is that de-centralization\nmay, in fact, be insufficient for privacy, as the local updates themselves can\nreveal information about the sources' data. To address these issues, we\nconsider an approach to federated learning that combines quantization and\ndifferential privacy. Absent privacy, Federated Learning often relies on\nquantization to reduce communication complexity. We build upon this approach\nand develop a new algorithm called the \\textbf{R}andomized\n\\textbf{Q}uantization \\textbf{M}echanism (RQM), which obtains privacy through a\ntwo-levels of randomization. More precisely, we randomly sub-sample feasible\nquantization levels, then employ a randomized rounding procedure using these\nsub-sampled discrete levels. We are able to establish that our results preserve\n``Renyi differential privacy'' (Renyi DP). We empirically study the performance\nof our algorithm and demonstrate that compared to previous work it yields\nimproved privacy-accuracy trade-offs for DP federated learning. To the best of\nour knowledge, this is the first study that solely relies on randomized\nquantization without incorporating explicit discrete noise to achieve Renyi DP\nguarantees in Federated Learning systems.\n","authors":["Yeojoon Youn","Zihao Hu","Juba Ziani","Jacob Abernethy"],"pdf_url":"https://arxiv.org/pdf/2306.11913v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11912v1","updated":"2023-06-20T21:51:13Z","published":"2023-06-20T21:51:13Z","title":"Copula-Based Deep Survival Models for Dependent Censoring","summary":"  A survival dataset describes a set of instances (e.g. patients) and provides,\nfor each, either the time until an event (e.g. death), or the censoring time\n(e.g. when lost to follow-up - which is a lower bound on the time until the\nevent). We consider the challenge of survival prediction: learning, from such\ndata, a predictive model that can produce an individual survival distribution\nfor a novel instance. Many contemporary methods of survival prediction\nimplicitly assume that the event and censoring distributions are independent\nconditional on the instance's covariates - a strong assumption that is\ndifficult to verify (as we observe only one outcome for each instance) and\nwhich can induce significant bias when it does not hold. This paper presents a\nparametric model of survival that extends modern non-linear survival analysis\nby relaxing the assumption of conditional independence. On synthetic and\nsemi-synthetic data, our approach significantly improves estimates of survival\ndistributions compared to the standard that assumes conditional independence in\nthe data.\n","authors":["Ali Hossein Gharari Foomani","Michael Cooper","Russell Greiner","Rahul G. Krishnan"],"pdf_url":"https://arxiv.org/pdf/2306.11912v1.pdf","comment":"23 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.11908v1","updated":"2023-06-20T21:45:35Z","published":"2023-06-20T21:45:35Z","title":"Accelerating Generalized Random Forests with Fixed-Point Trees","summary":"  Generalized random forests arXiv:1610.01271 build upon the well-established\nsuccess of conventional forests (Breiman, 2001) to offer a flexible and\npowerful non-parametric method for estimating local solutions of heterogeneous\nestimating equations. Estimators are constructed by leveraging random forests\nas an adaptive kernel weighting algorithm and implemented through a\ngradient-based tree-growing procedure. By expressing this gradient-based\napproximation as being induced from a single Newton-Raphson root-finding\niteration, and drawing upon the connection between estimating equations and\nfixed-point problems arXiv:2110.11074, we propose a new tree-growing rule for\ngeneralized random forests induced from a fixed-point iteration type of\napproximation, enabling gradient-free optimization, and yielding substantial\ntime savings for tasks involving even modest dimensionality of the target\nquantity (e.g. multiple/multi-level treatment effects). We develop an\nasymptotic theory for estimators obtained from forests whose trees are grown\nthrough the fixed-point splitting rule, and provide numerical simulations\ndemonstrating that the estimators obtained from such forests are comparable to\nthose obtained from the more costly gradient-based rule.\n","authors":["David Fleischer","David A. Stephens","Archer Yang"],"pdf_url":"https://arxiv.org/pdf/2306.11908v1.pdf","comment":"22 pages, 5 figures"},{"id":"http://arxiv.org/abs/2306.11903v1","updated":"2023-06-20T21:30:54Z","published":"2023-06-20T21:30:54Z","title":"Deep Fusion: Efficient Network Training via Pre-trained Initializations","summary":"  In recent years, deep learning has made remarkable progress in a wide range\nof domains, with a particularly notable impact on natural language processing\ntasks. One of the challenges associated with training deep neural networks is\nthe need for large amounts of computational resources and time. In this paper,\nwe present Deep Fusion, an efficient approach to network training that\nleverages pre-trained initializations of smaller networks. % We show that Deep\nFusion accelerates the training process, reduces computational requirements,\nand leads to improved generalization performance on a variety of NLP tasks and\nT5 model sizes. % Our experiments demonstrate that Deep Fusion is a practical\nand effective approach to reduce the training time and resource consumption\nwhile maintaining, or even surpassing, the performance of traditional training\nmethods.\n","authors":["Hanna Mazzawi","Xavi Gonzalvo","Michael Wunder"],"pdf_url":"https://arxiv.org/pdf/2306.11903v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14231v2","updated":"2023-06-20T21:27:36Z","published":"2023-02-28T01:30:06Z","title":"CHGNet: Pretrained universal neural network potential for\n  charge-informed atomistic modeling","summary":"  The simulation of large-scale systems with complex electron interactions\nremains one of the greatest challenges for the atomistic modeling of materials.\nAlthough classical force fields often fail to describe the coupling between\nelectronic states and ionic rearrangements, the more accurate\n\\textit{ab-initio} molecular dynamics suffers from computational complexity\nthat prevents long-time and large-scale simulations, which are essential to\nstudy many technologically relevant phenomena, such as reactions, ion\nmigrations, phase transformations, and degradation.\n  In this work, we present the Crystal Hamiltonian Graph neural Network\n(CHGNet) as a novel machine-learning interatomic potential (MLIP), using a\ngraph-neural-network-based force field to model a universal potential energy\nsurface. CHGNet is pretrained on the energies, forces, stresses, and magnetic\nmoments from the Materials Project Trajectory Dataset, which consists of over\n10 years of density functional theory static and relaxation trajectories of\n$\\sim 1.5$ million inorganic structures. The explicit inclusion of magnetic\nmoments enables CHGNet to learn and accurately represent the orbital occupancy\nof electrons, enhancing its capability to describe both atomic and electronic\ndegrees of freedom. We demonstrate several applications of CHGNet in\nsolid-state materials, including charge-informed molecular dynamics in\nLi$_x$MnO$_2$, the finite temperature phase diagram for Li$_x$FePO$_4$ and Li\ndiffusion in garnet conductors. We critically analyze the significance of\nincluding charge information for capturing appropriate chemistry, and we\nprovide new insights into ionic systems with additional electronic degrees of\nfreedom that can not be observed by previous MLIPs.\n","authors":["Bowen Deng","Peichen Zhong","KyuJung Jun","Janosh Riebesell","Kevin Han","Christopher J. Bartel","Gerbrand Ceder"],"pdf_url":"https://arxiv.org/pdf/2302.14231v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.05622v3","updated":"2023-06-20T21:23:10Z","published":"2023-04-12T05:39:38Z","title":"SAMM (Segment Any Medical Model): A 3D Slicer Integration to SAM","summary":"  The Segment Anything Model (SAM) is a new image segmentation tool trained\nwith the largest available segmentation dataset. The model has demonstrated\nthat, with efficient prompting, it can create high-quality, generalized masks\nfor image segmentation. However, the performance of the model on medical images\nrequires further validation. To assist with the development, assessment, and\napplication of SAM on medical images, we introduce Segment Any Medical Model\n(SAMM), an extension of SAM on 3D Slicer - an open-source image processing and\nvisualization software extensively used by the medical imaging community. This\nopen-source extension to 3D Slicer and its demonstrations are posted on GitHub\n(https://github.com/bingogome/samm). SAMM achieves 0.6-second latency of a\ncomplete cycle and can infer image masks in nearly real-time.\n","authors":["Yihao Liu","Jiaming Zhang","Zhangcong She","Amir Kheradmand","Mehran Armand"],"pdf_url":"https://arxiv.org/pdf/2304.05622v3.pdf","comment":"6 pages, 4 figures"},{"id":"http://arxiv.org/abs/2305.13681v2","updated":"2023-06-20T21:23:06Z","published":"2023-05-23T04:40:29Z","title":"GUARD: A Safe Reinforcement Learning Benchmark","summary":"  Due to the trial-and-error nature, it is typically challenging to apply RL\nalgorithms to safety-critical real-world applications, such as autonomous\ndriving, human-robot interaction, robot manipulation, etc, where such errors\nare not tolerable. Recently, safe RL (i.e. constrained RL) has emerged rapidly\nin the literature, in which the agents explore the environment while satisfying\nconstraints. Due to the diversity of algorithms and tasks, it remains difficult\nto compare existing safe RL algorithms. To fill that gap, we introduce GUARD, a\nGeneralized Unified SAfe Reinforcement Learning Development Benchmark. GUARD\nhas several advantages compared to existing benchmarks. First, GUARD is a\ngeneralized benchmark with a wide variety of RL agents, tasks, and safety\nconstraint specifications. Second, GUARD comprehensively covers\nstate-of-the-art safe RL algorithms with self-contained implementations. Third,\nGUARD is highly customizable in tasks and algorithms. We present a comparison\nof state-of-the-art safe RL algorithms in various task settings using GUARD and\nestablish baselines that future work can build on.\n","authors":["Weiye Zhao","Rui Chen","Yifan Sun","Ruixuan Liu","Tianhao Wei","Changliu Liu"],"pdf_url":"https://arxiv.org/pdf/2305.13681v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11899v1","updated":"2023-06-20T21:21:19Z","published":"2023-06-20T21:21:19Z","title":"Closing the loop: Autonomous experiments enabled by\n  machine-learning-based online data analysis in synchrotron beamline\n  environments","summary":"  Recently, there has been significant interest in applying machine learning\n(ML) techniques to X-ray scattering experiments, which proves to be a valuable\ntool for enhancing research that involves large or rapidly generated datasets.\nML allows for the automated interpretation of experimental results,\nparticularly those obtained from synchrotron or neutron facilities. The speed\nat which ML models can process data presents an important opportunity to\nestablish a closed-loop feedback system, enabling real-time decision-making\nbased on online data analysis. In this study, we describe the incorporation of\nML into a closed-loop workflow for X-ray reflectometry (XRR), using the growth\nof organic thin films as an example. Our focus lies on the beamline integration\nof ML-based online data analysis and closed-loop feedback. We present solutions\nthat provide an elementary data analysis in real time during the experiment\nwithout introducing the additional software dependencies in the beamline\ncontrol software environment. Our data demonstrates the accuracy and robustness\nof ML methods for analyzing XRR curves and Bragg reflections and its autonomous\ncontrol over a vacuum deposition setup.\n","authors":["Linus Pithan","Vladimir Starostin","David Mareček","Lukas Petersdorf","Constantin Völter","Valentin Munteanu","Maciej Jankowski","Oleg Konovalov","Alexander Gerlach","Alexander Hinderhofer","Bridget Murphy","Stefan Kowarik","Frank Schreiber"],"pdf_url":"https://arxiv.org/pdf/2306.11899v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11898v1","updated":"2023-06-20T21:19:57Z","published":"2023-06-20T21:19:57Z","title":"Unexplainable Explanations: Towards Interpreting tSNE and UMAP\n  Embeddings","summary":"  It has become standard to explain neural network latent spaces with\nattraction/repulsion dimensionality reduction (ARDR) methods like tSNE and\nUMAP. This relies on the premise that structure in the 2D representation is\nconsistent with the structure in the model's latent space. However, this is an\nunproven assumption -- we are unaware of any convergence guarantees for ARDR\nalgorithms. We work on closing this question by relating ARDR methods to\nclassical dimensionality reduction techniques. Specifically, we show that one\ncan fully recover a PCA embedding by applying attractions and repulsions onto a\nrandomly initialized dataset. We also show that, with a small change, Locally\nLinear Embeddings (LLE) can reproduce ARDR embeddings. Finally, we formalize a\nseries of conjectures that, if true, would allow one to attribute structure in\nthe 2D embedding back to the input distribution.\n","authors":["Andrew Draganov","Simon Dohn"],"pdf_url":"https://arxiv.org/pdf/2306.11898v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2306.11724v1","updated":"2023-06-20T17:55:48Z","published":"2023-06-20T17:55:48Z","title":"Low-complexity Multidimensional DCT Approximations","summary":"  In this paper, we introduce low-complexity multidimensional discrete cosine\ntransform (DCT) approximations. Three dimensional DCT (3D DCT) approximations\nare formalized in terms of high-order tensor theory. The formulation is\nextended to higher dimensions with arbitrary lengths. Several multiplierless\n$8\\times 8\\times 8$ approximate methods are proposed and the computational\ncomplexity is discussed for the general multidimensional case. The proposed\nmethods complexity cost was assessed, presenting considerably lower arithmetic\noperations when compared with the exact 3D DCT. The proposed approximations\nwere embedded into 3D DCT-based video coding scheme and a modified quantization\nstep was introduced. The simulation results showed that the approximate 3D DCT\ncoding methods offer almost identical output visual quality when compared with\nexact 3D DCT scheme. The proposed 3D approximations were also employed as a\ntool for visual tracking. The approximate 3D DCT-based proposed system performs\nsimilarly to the original exact 3D DCT-based method. In general, the suggested\nmethods showed competitive performance at a considerably lower computational\ncost.\n","authors":["V. A. Coutinho","R. J. Cintra","F. M. Bayer"],"pdf_url":"https://arxiv.org/pdf/2306.11724v1.pdf","comment":"28 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2112.09402v2","updated":"2023-06-20T09:47:10Z","published":"2021-12-17T09:29:06Z","title":"Extending 3-DoF Metrics to Model User Behaviour Similarity in 6-DoF\n  Immersive Applications","summary":"  Immersive reality technologies, such as Virtual and Augmented Reality, have\nushered a new era of user-centric systems, in which every aspect of the\ncoding--delivery--rendering chain is tailored to the interaction of the users.\nUnderstanding the actual interactivity and behaviour of the users is still an\nopen challenge and a key step to enabling such a user-centric system. Our main\ngoal is to extend the applicability of existing behavioural methodologies for\nstudying user navigation in the case of 6 Degree-of-Freedom (DoF).\nSpecifically, we first compare the navigation in 6-DoF with its 3-DoF\ncounterpart highlighting the main differences and novelties. Then, we define\nnew metrics aimed at better modelling behavioural similarities between users in\na 6-DoF system. We validate and test our solutions on real navigation paths of\nusers interacting with dynamic volumetric media in 6-DoF Virtual Reality\nconditions. Our results show that metrics that consider both user position and\nviewing direction better perform in detecting user similarity while navigating\nin a 6-DoF system. Having easy-to-use but robust metrics that underpin multiple\ntools and answer the question ``how do we detect if two users look at the same\ncontent?\" open the gate to new solutions for a user-centric system.\n","authors":["Silvia Rossi","Irene Viola","Laura Toni","Pablo Cesar"],"pdf_url":"https://arxiv.org/pdf/2112.09402v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.08309v2","updated":"2023-06-20T08:03:35Z","published":"2023-06-14T07:27:06Z","title":"Taming Reversible Halftoning via Predictive Luminance","summary":"  Traditional halftoning usually drops colors when dithering images with binary\ndots, which makes it difficult to recover the original color information. We\nproposed a novel halftoning technique that converts a color image into a binary\nhalftone with full restorability to its original version. Our novel base\nhalftoning technique consists of two convolutional neural networks (CNNs) to\nproduce the reversible halftone patterns, and a noise incentive block (NIB) to\nmitigate the flatness degradation issue of CNNs. Furthermore, to tackle the\nconflicts between the blue-noise quality and restoration accuracy in our novel\nbase method, we proposed a predictor-embedded approach to offload predictable\ninformation from the network, which in our case is the luminance information\nresembling from the halftone pattern. Such an approach allows the network to\ngain more flexibility to produce halftones with better blue-noise quality\nwithout compromising the restoration quality. Detailed studies on the\nmultiple-stage training method and loss weightings have been conducted. We have\ncompared our predictor-embedded method and our novel method regarding spectrum\nanalysis on halftone, halftone accuracy, restoration accuracy, and the data\nembedding studies. Our entropy evaluation evidences our halftone contains less\nencoding information than our novel base method. The experiments show our\npredictor-embedded method gains more flexibility to improve the blue-noise\nquality of halftones and maintains a comparable restoration quality with a\nhigher tolerance for disturbances.\n","authors":["Cheuk-Kit Lau","Menghan Xia","Tien-Tsin Wong"],"pdf_url":"https://arxiv.org/pdf/2306.08309v2.pdf","comment":"to be published in IEEE Transactions on Visualization and Computer\n  Graphics"},{"id":"http://arxiv.org/abs/2306.11341v1","updated":"2023-06-20T07:19:36Z","published":"2023-06-20T07:19:36Z","title":"MSVD-Indonesian: A Benchmark for Multimodal Video-Text Tasks in\n  Indonesian","summary":"  Multimodal learning on video and text data has been receiving growing\nattention from many researchers in various research tasks, including\ntext-to-video retrieval, video-to-text retrieval, and video captioning.\nAlthough many algorithms have been proposed for those challenging tasks, most\nof them are developed on English language datasets. Despite Indonesian being\none of the most spoken languages in the world, the research progress on the\nmultimodal video-text with Indonesian sentences is still under-explored, likely\ndue to the absence of the public benchmark dataset. To address this issue, we\nconstruct the first public Indonesian video-text dataset by translating English\nsentences from the MSVD dataset to Indonesian sentences. Using our dataset, we\nthen train neural network models which were developed for the English\nvideo-text dataset on three tasks, i.e., text-to-video retrieval, video-to-text\nretrieval, and video captioning. The recent neural network-based approaches to\nvideo-text tasks often utilized a feature extractor that is primarily\npretrained on an English vision-language dataset. Since the availability of the\npretraining resources with Indonesian sentences is relatively limited, the\napplicability of those approaches to our dataset is still questionable. To\novercome the lack of pretraining resources, we apply cross-lingual transfer\nlearning by utilizing the feature extractors pretrained on the English dataset,\nand we then fine-tune the models on our Indonesian dataset. Our experimental\nresults show that this approach can help to improve the performance for the\nthree tasks on all metrics. Finally, we discuss potential future works using\nour dataset, inspiring further research in the Indonesian multimodal video-text\ntasks. We believe that our dataset and our experimental results could provide\nvaluable contributions to the community. Our dataset is available on GitHub.\n","authors":["Willy Fitra Hendria"],"pdf_url":"https://arxiv.org/pdf/2306.11341v1.pdf","comment":"13 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2306.11300v1","updated":"2023-06-20T05:30:59Z","published":"2023-06-20T05:30:59Z","title":"RS5M: A Large Scale Vision-Language Dataset for Remote Sensing\n  Vision-Language Foundation Model","summary":"  Pre-trained Vision-Language Foundation Models utilizing extensive image-text\npaired data have demonstrated unprecedented image-text association\ncapabilities, achieving remarkable results across various downstream tasks. A\ncritical challenge is how to make use of existing large-scale pre-trained VLMs,\nwhich are trained on common objects, to perform the domain-specific transfer\nfor accomplishing domain-related downstream tasks. In this paper, we propose a\nnew framework that includes the Domain Foundation Model (DFM), bridging the gap\nbetween the General Foundation Model (GFM) and domain-specific downstream\ntasks. Moreover, we present an image-text paired dataset in the field of remote\nsensing (RS), RS5M, which has 5 million RS images with English descriptions.\nThe dataset is obtained from filtering publicly available image-text paired\ndatasets and captioning label-only RS datasets with pre-trained VLM. These\nconstitute the first large-scale RS image-text paired dataset. Additionally, we\ntried several Parameter-Efficient Fine-Tuning methods on RS5M to implement the\nDFM. Experimental results show that our proposed dataset are highly effective\nfor various tasks, improving upon the baseline by $8 \\% \\sim 16 \\%$ in\nzero-shot classification tasks, and obtaining good results in both\nVision-Language Retrieval and Semantic Localization tasks. Finally, we show\nsuccessful results of training the RS Stable Diffusion model using the RS5M,\nuncovering more use cases of the dataset.\n","authors":["Zilun Zhang","Tiancheng Zhao","Yulong Guo","Jianwei Yin"],"pdf_url":"https://arxiv.org/pdf/2306.11300v1.pdf","comment":null}]},"2023-06-21T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2306.12424v1","updated":"2023-06-21T17:59:51Z","published":"2023-06-21T17:59:51Z","title":"VisoGender: A dataset for benchmarking gender bias in image-text pronoun\n  resolution","summary":"  We introduce VisoGender, a novel dataset for benchmarking gender bias in\nvision-language models. We focus on occupation-related gender biases, inspired\nby Winograd and Winogender schemas, where each image is associated with a\ncaption containing a pronoun relationship of subjects and objects in the scene.\nVisoGender is balanced by gender representation in professional roles,\nsupporting bias evaluation in two ways: i) resolution bias, where we evaluate\nthe difference between gender resolution accuracies for men and women and ii)\nretrieval bias, where we compare ratios of male and female professionals\nretrieved for a gender-neutral search query. We benchmark several\nstate-of-the-art vision-language models and find that they lack the reasoning\nabilities to correctly resolve gender in complex scenes. While the direction\nand magnitude of gender bias depends on the task and the model being evaluated,\ncaptioning models generally are more accurate and less biased than CLIP-like\nmodels. Dataset and code are available at https://github.com/oxai/visogender\n","authors":["Siobhan Mackenzie Hall","Fernanda Gonçalves Abrantes","Hanwen Zhu","Grace Sodunke","Aleksandar Shtedritski","Hannah Rose Kirk"],"pdf_url":"https://arxiv.org/pdf/2306.12424v1.pdf","comment":"Data and code available at https://github.com/oxai/visogender"},{"id":"http://arxiv.org/abs/2306.12420v1","updated":"2023-06-21T17:58:25Z","published":"2023-06-21T17:58:25Z","title":"LMFlow: An Extensible Toolkit for Finetuning and Inference of Large\n  Foundation Models","summary":"  Large foundation models have demonstrated a great ability to achieve general\nhuman-level intelligence far beyond traditional approaches. As the technique\nkeeps attracting attention from the AI community, more and more large\nfoundation models have become publically available. However, most of those\nmodels exhibit a major deficiency in specialized-task applications, where the\nstep of finetuning is still required for obtaining satisfactory performance. As\nthe number of available models and specialized tasks keeps growing, the job of\ngeneral finetuning becomes highly nontrivial. In this paper, we take the first\nstep to address this issue. We introduce an extensible and lightweight toolkit,\nLMFlow, which aims to simplify the finetuning and inference of general large\nfoundation models. LMFlow offers a complete finetuning workflow for a large\nfoundation model to support personalized training with limited computing\nresources. Furthermore, it supports continuous pretraining, instruction tuning,\nparameter-efficient finetuning, alignment tuning, and large model inference,\nalong with carefully designed and extensible APIs. This toolkit has been\nthoroughly tested and is available at https://github.com/OptimalScale/LMFlow.\n","authors":["Shizhe Diao","Rui Pan","Hanze Dong","Ka Shun Shum","Jipeng Zhang","Wei Xiong","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.12420v1.pdf","comment":"13 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.05040v2","updated":"2023-06-21T17:44:58Z","published":"2023-02-10T04:05:24Z","title":"PATCorrect: Non-autoregressive Phoneme-augmented Transformer for ASR\n  Error Correction","summary":"  Speech-to-text errors made by automatic speech recognition (ASR) systems\nnegatively impact downstream models. Error correction models as a\npost-processing text editing method have been recently developed for refining\nthe ASR outputs. However, efficient models that meet the low latency\nrequirements of industrial grade production systems have not been well studied.\nWe propose PATCorrect-a novel non-autoregressive (NAR) approach based on\nmulti-modal fusion leveraging representations from both text and phoneme\nmodalities, to reduce word error rate (WER) and perform robustly with varying\ninput transcription quality. We demonstrate that PATCorrect consistently\noutperforms state-of-the-art NAR method on English corpus across different\nupstream ASR systems, with an overall 11.62% WER reduction (WERR) compared to\n9.46% WERR achieved by other methods using text only modality. Besides, its\ninference latency is at tens of milliseconds, making it ideal for systems with\nlow latency requirements.\n","authors":["Ziji Zhang","Zhehui Wang","Rajesh Kamma","Sharanya Eswaran","Narayanan Sadagopan"],"pdf_url":"https://arxiv.org/pdf/2302.05040v2.pdf","comment":"Accepted camera-ready version for INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2306.12387v1","updated":"2023-06-21T17:17:09Z","published":"2023-06-21T17:17:09Z","title":"Solving Dialogue Grounding Embodied Task in a Simulated Environment\n  using Further Masked Language Modeling","summary":"  Enhancing AI systems with efficient communication skills that align with\nhuman understanding is crucial for their effective assistance to human users.\nProactive initiatives from the system side are needed to discern specific\ncircumstances and interact aptly with users to solve these scenarios. In this\nresearch, we opt for a collective building assignment taken from the Minecraft\ndataset. Our proposed method employs language modeling to enhance task\nunderstanding through state-of-the-art (SOTA) methods using language models.\nThese models focus on grounding multi-modal understandinging and task-oriented\ndialogue comprehension tasks. This focus aids in gaining insights into how well\nthese models interpret and respond to a variety of inputs and tasks. Our\nexperimental results provide compelling evidence of the superiority of our\nproposed method. This showcases a substantial improvement and points towards a\npromising direction for future research in this domain.\n","authors":["Weijie Jack Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.12387v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2306.03361v2","updated":"2023-06-21T16:37:22Z","published":"2023-06-06T02:28:38Z","title":"WHAT, WHEN, and HOW to Ground: Designing User Persona-Aware\n  Conversational Agents for Engaging Dialogue","summary":"  This paper presents a method for building a personalized open-domain dialogue\nsystem to address the $\\textit{WWH}$ ($\\textit{WHAT}$, $\\textit{WHEN}$, and\n$\\textit{HOW}$) problem for natural response generation in a commercial\nsetting, where personalized dialogue responses are heavily interleaved with\ncasual response turns. The proposed approach involves weighted dataset\nblending, negative persona information augmentation methods, and the design of\npersonalized conversation datasets to address the challenges of $\\textit{WWH}$\nin personalized, open-domain dialogue systems. Our work effectively balances\ndialogue fluency and tendency to ground, while also introducing a response-type\nlabel to improve the controllability and explainability of the grounded\nresponses. The combination of these methods leads to more fluent conversations,\nas evidenced by subjective human evaluations as well as objective evaluations.\n","authors":["Deuksin Kwon","Sunwoo Lee","Ki Hyun Kim","Seojin Lee","Taeyoon Kim","Eric Davis"],"pdf_url":"https://arxiv.org/pdf/2306.03361v2.pdf","comment":"Accepted in ACL 2023 Industry Track"},{"id":"http://arxiv.org/abs/2304.02138v3","updated":"2023-06-21T15:55:24Z","published":"2023-04-04T21:47:41Z","title":"Geotechnical Parrot Tales (GPT): Harnessing Large Language Models in\n  geotechnical engineering","summary":"  The widespread adoption of large language models (LLMs), such as OpenAI's\nChatGPT, could revolutionize various industries, including geotechnical\nengineering. However, GPT models can sometimes generate plausible-sounding but\nfalse outputs, leading to hallucinations. In this article, we discuss the\nimportance of prompt engineering in mitigating these risks and harnessing the\nfull potential of GPT for geotechnical applications. We explore the challenges\nand pitfalls associated with LLMs and highlight the role of context in ensuring\naccurate and valuable responses. Furthermore, we examine the development of\ncontext-specific search engines and the potential of LLMs to become a natural\ninterface for complex tasks, such as data analysis and design. We also develop\na unified interface using natural language to handle complex geotechnical\nengineering tasks and data analysis. By integrating GPT into geotechnical\nengineering workflows, professionals can streamline their work and develop\nsustainable and resilient infrastructure systems for the future.\n","authors":["Krishna Kumar"],"pdf_url":"https://arxiv.org/pdf/2304.02138v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12317v1","updated":"2023-06-21T14:58:31Z","published":"2023-06-21T14:58:31Z","title":"Iterated Piecewise Affine (IPA) Approximation for Language Modeling","summary":"  In this work, we demonstrate the application of a simple first-order Taylor\nexpansion to approximate a generic function $F: R^{n \\times m} \\to R^{n \\times\nm}$ and utilize it in language modeling. To enhance the basic Taylor expansion,\nwe introduce iteration and piecewise modeling, leading us to name the algorithm\nthe Iterative Piecewise Affine (IPA) approximation. The final algorithm\nexhibits interesting resemblances to the Transformers decoder architecture. By\ncomparing parameter arrangements in IPA and Transformers, we observe a\nstrikingly similar performance, with IPA outperforming Transformers by 1.5\\% in\nthe next token prediction task with cross-entropy loss for smaller sequence\nlengths.\n","authors":["Davood Shamsi","Wen-yu Hua","Brian Williams"],"pdf_url":"https://arxiv.org/pdf/2306.12317v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12310v1","updated":"2023-06-21T14:43:25Z","published":"2023-06-21T14:43:25Z","title":"Medical ministrations through web scraping","summary":"  Web scraping is a technique that allows us to extract data from websites\nautomatically. in the field of medicine, web scraping can be used to collect\ninformation about medical procedures, treatments, and healthcare providers.\nthis information can be used to improve patient care, monitor the quality of\nhealthcare services, and identify areas for improvement. one area where web\nscraping can be particularly useful is in medical ministrations. medical\nministrations are the actions taken to provide medical care to patients, and\nweb scraping can help healthcare providers identify the most effective\nministrations for their patients. for example, healthcare providers can use web\nscraping to collect data about the symptoms and medical histories of their\npatients, and then use this information to determine the most appropriate\nministrations. they can also use web scraping to gather information about the\nlatest medical research and clinical trials, which can help them stay\nup-to-date with the latest treatments and procedures.\n","authors":["Niketha Sabesan"," Nivethitha","J. N Shreyah","Pranauv A J","Shyam R"],"pdf_url":"https://arxiv.org/pdf/2306.12310v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12280v1","updated":"2023-06-21T14:08:08Z","published":"2023-06-21T14:08:08Z","title":"SIFTER: A Task-specific Alignment Strategy for Enhancing Sentence\n  Embeddings","summary":"  The paradigm of pre-training followed by fine-tuning on downstream tasks has\nbecome the mainstream method in natural language processing tasks. Although\npre-trained models have the advantage of generalization, their performance may\nstill vary significantly across different domain tasks. This is because the\ndata distribution in different domains varies. For example, the different parts\nof the sentence 'He married Smt. Dipali Ghosh in 1947 and led a very happy\nmarried life' may have different impact for downstream tasks. For similarity\ncalculations, words such as 'led' and 'life' are more important. On the other\nhand, for sentiment analysis, the word 'happy' is crucial. This indicates that\ndifferent downstream tasks have different levels of sensitivity to sentence\ncomponents. Our starting point is to scale information of the model and data\naccording to the specifics of downstream tasks, enhancing domain information of\nrelevant parts for these tasks and reducing irrelevant elements for different\ndomain tasks, called SIFTER. In the experimental part, we use the SIFTER to\nimprove SimCSE by constructing positive sample pairs based on enhancing the\nsentence stem and reducing the unimportant components in the sentence, and\nmaximize the similarity between three sentences. Similarly, SIFTER can improve\nthe gate mechanism of the LSTM model by short-circuiting the input gate of\nimportant words so that the LSTM model remembers the important parts of the\nsentence. Our experiments demonstrate that SIFTER outperforms the SimCSE and\nLSTM baselines.\n","authors":["Chao Yu","Wenhao Zhu","Chaoming Liu","Xiaoyu Zhang","Qiuhong zhai"],"pdf_url":"https://arxiv.org/pdf/2306.12280v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12255v1","updated":"2023-06-21T13:23:48Z","published":"2023-06-21T13:23:48Z","title":"Solving and Generating NPR Sunday Puzzles with Large Language Models","summary":"  We explore the ability of large language models to solve and generate puzzles\nfrom the NPR Sunday Puzzle game show using PUZZLEQA, a dataset comprising 15\nyears of on-air puzzles. We evaluate four large language models using PUZZLEQA,\nin both multiple choice and free response formats, and explore two prompt\nengineering techniques to improve free response performance: chain-of-thought\nreasoning and prompt summarization. We find that state-of-the-art large\nlanguage models can solve many PUZZLEQA puzzles: the best model, GPT-3.5,\nachieves 50.2% loose accuracy. However, in our few-shot puzzle generation\nexperiment, we find no evidence that models can generate puzzles: GPT-3.5\ngenerates puzzles with answers that do not conform to the generated rules.\nPuzzle generation remains a challenging task for future work.\n","authors":["Jingmiao Zhao","Carolyn Jane Anderson"],"pdf_url":"https://arxiv.org/pdf/2306.12255v1.pdf","comment":"To appear in the Proceedings of the 14th International Conference on\n  Computational Creativity (ICCC)"},{"id":"http://arxiv.org/abs/2306.12245v1","updated":"2023-06-21T13:04:30Z","published":"2023-06-21T13:04:30Z","title":"Bidirectional End-to-End Learning of Retriever-Reader Paradigm for\n  Entity Linking","summary":"  Entity Linking (EL) is a fundamental task for Information Extraction and\nKnowledge Graphs. The general form of EL (i.e., end-to-end EL) aims to first\nfind mentions in the given input document and then link the mentions to\ncorresponding entities in a specific knowledge base. Recently, the paradigm of\nretriever-reader promotes the progress of end-to-end EL, benefiting from the\nadvantages of dense entity retrieval and machine reading comprehension.\nHowever, the existing study only trains the retriever and the reader separately\nin a pipeline manner, which ignores the benefit that the interaction between\nthe retriever and the reader can bring to the task. To advance the\nretriever-reader paradigm to perform more perfectly on end-to-end EL, we\npropose BEER$^2$, a Bidirectional End-to-End training framework for Retriever\nand Reader. Through our designed bidirectional end-to-end training, BEER$^2$\nguides the retriever and the reader to learn from each other, make progress\ntogether, and ultimately improve EL performance. Extensive experiments on\nbenchmarks of multiple domains demonstrate the effectiveness of our proposed\nBEER$^2$.\n","authors":["Yinghui Li","Yong Jiang","Shen Huang","Xingyu Lu","Yangning Li","Pengjun Xie","Fei Huang","Hai-Tao Zheng"],"pdf_url":"https://arxiv.org/pdf/2306.12245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.13224v2","updated":"2023-06-21T12:35:16Z","published":"2022-11-23T18:59:05Z","title":"Peekaboo: Text to Image Diffusion Models are Zero-Shot Segmentors","summary":"  Recently, text-to-image diffusion models have shown remarkable capabilities\nin creating realistic images from natural language prompts. However, few works\nhave explored using these models for semantic localization or grounding. In\nthis work, we explore how an off-the-shelf text-to-image diffusion model,\ntrained without exposure to localization information, can ground various\nsemantic phrases without segmentation-specific re-training. We introduce an\ninference time optimization process capable of generating segmentation masks\nconditioned on natural language prompts. Our proposal, Peekaboo, is a\nfirst-of-its-kind zero-shot, open-vocabulary, unsupervised semantic grounding\ntechnique leveraging diffusion models without any training. We evaluate\nPeekaboo on the Pascal VOC dataset for unsupervised semantic segmentation and\nthe RefCOCO dataset for referring segmentation, showing results competitive\nwith promising results. We also demonstrate how Peekaboo can be used to\ngenerate images with transparency, even though the underlying diffusion model\nwas only trained on RGB images - which to our knowledge we are the first to\nattempt. Please see our project page, including our code:\nhttps://ryanndagreat.github.io/peekaboo\n","authors":["Ryan Burgert","Kanchana Ranasinghe","Xiang Li","Michael S. Ryoo"],"pdf_url":"https://arxiv.org/pdf/2211.13224v2.pdf","comment":"19 pages; contains appendix"},{"id":"http://arxiv.org/abs/2306.12213v1","updated":"2023-06-21T12:11:31Z","published":"2023-06-21T12:11:31Z","title":"Limits for Learning with Language Models","summary":"  With the advent of large language models (LLMs), the trend in NLP has been to\ntrain LLMs on vast amounts of data to solve diverse language understanding and\ngeneration tasks. The list of LLM successes is long and varied. Nevertheless,\nseveral recent papers provide empirical evidence that LLMs fail to capture\nimportant aspects of linguistic meaning. Focusing on universal quantification,\nwe provide a theoretical foundation for these empirical findings by proving\nthat LLMs cannot learn certain fundamental semantic properties including\nsemantic entailment and consistency as they are defined in formal semantics.\nMore generally, we show that LLMs are unable to learn concepts beyond the first\nlevel of the Borel Hierarchy, which imposes severe limits on the ability of\nLMs, both large and small, to capture many aspects of linguistic meaning. This\nmeans that LLMs will continue to operate without formal guarantees on tasks\nthat require entailments and deep linguistic understanding.\n","authors":["Nicholas Asher","Swarnadeep Bhar","Akshay Chaturvedi","Julie Hunter","Soumya Paul"],"pdf_url":"https://arxiv.org/pdf/2306.12213v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12205v1","updated":"2023-06-21T11:55:17Z","published":"2023-06-21T11:55:17Z","title":"Investigating Pre-trained Language Models on Cross-Domain Datasets, a\n  Step Closer to General AI","summary":"  Pre-trained language models have recently emerged as a powerful tool for\nfine-tuning a variety of language tasks. Ideally, when models are pre-trained\non large amount of data, they are expected to gain implicit knowledge. In this\npaper, we investigate the ability of pre-trained language models to generalize\nto different non-language tasks. In particular, we test them on tasks from\ndifferent domains such as computer vision, reasoning on hierarchical data, and\nprotein fold prediction. The four pre-trained models that we used, T5, BART,\nBERT, and GPT-2 achieve outstanding results. They all have similar performance\nand they outperform transformers that are trained from scratch by a large\nmargin. For instance, pre-trained language models perform better on the Listops\ndataset, with an average accuracy of 58.7\\%, compared to transformers trained\nfrom scratch, which have an average accuracy of 29.0\\%. The significant\nimprovement demonstrated across three types of datasets suggests that\npre-training on language helps the models to acquire general knowledge,\nbringing us a step closer to general AI. We also showed that reducing the\nnumber of parameters in pre-trained language models does not have a great\nimpact as the performance drops slightly when using T5-Small instead of\nT5-Base. In fact, when using only 2\\% of the parameters, we achieved a great\nimprovement compared to training from scratch. Finally, in contrast to prior\nwork, we find out that using pre-trained embeddings for the input layer is\nnecessary to achieve the desired results.\n","authors":["Mohamad Ballout","Ulf Krumnack","Gunther Heidemann","Kai-Uwe Kühnberger"],"pdf_url":"https://arxiv.org/pdf/2306.12205v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12198v1","updated":"2023-06-21T11:48:07Z","published":"2023-06-21T11:48:07Z","title":"Opening the Black Box: Analyzing Attention Weights and Hidden States in\n  Pre-trained Language Models for Non-language Tasks","summary":"  Investigating deep learning language models has always been a significant\nresearch area due to the ``black box\" nature of most advanced models. With the\nrecent advancements in pre-trained language models based on transformers and\ntheir increasing integration into daily life, addressing this issue has become\nmore pressing. In order to achieve an explainable AI model, it is essential to\ncomprehend the procedural steps involved and compare them with human thought\nprocesses. Thus, in this paper, we use simple, well-understood non-language\ntasks to explore these models' inner workings. Specifically, we apply a\npre-trained language model to constrained arithmetic problems with hierarchical\nstructure, to analyze their attention weight scores and hidden states. The\ninvestigation reveals promising results, with the model addressing hierarchical\nproblems in a moderately structured manner, similar to human problem-solving\nstrategies. Additionally, by inspecting the attention weights layer by layer,\nwe uncover an unconventional finding that layer 10, rather than the model's\nfinal layer, is the optimal layer to unfreeze for the least parameter-intensive\napproach to fine-tune the model. We support these findings with entropy\nanalysis and token embeddings similarity analysis. The attention analysis\nallows us to hypothesize that the model can generalize to longer sequences in\nListOps dataset, a conclusion later confirmed through testing on sequences\nlonger than those in the training set. Lastly, by utilizing a straightforward\ntask in which the model predicts the winner of a Tic Tac Toe game, we identify\nlimitations in attention analysis, particularly its inability to capture 2D\npatterns.\n","authors":["Mohamad Ballout","Ulf Krumnack","Gunther Heidemann","Kai-Uwe Kühnberger"],"pdf_url":"https://arxiv.org/pdf/2306.12198v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.07611v2","updated":"2023-06-21T11:35:00Z","published":"2023-05-12T16:56:13Z","title":"Multimodal Sentiment Analysis: A Survey","summary":"  Multimodal sentiment analysis has become an important research area in the\nfield of artificial intelligence. With the latest advances in deep learning,\nthis technology has reached new heights. It has great potential for both\napplication and research, making it a popular research topic. This review\nprovides an overview of the definition, background, and development of\nmultimodal sentiment analysis. It also covers recent datasets and advanced\nmodels, emphasizing the challenges and future prospects of this technology.\nFinally, it looks ahead to future research directions. It should be noted that\nthis review provides constructive suggestions for promising research directions\nand building better performing multimodal sentiment analysis models, which can\nhelp researchers in this field.\n","authors":["Songning Lai","Haoxuan Xu","Xifeng Hu","Zhaoxia Ren","Zhi Liu"],"pdf_url":"https://arxiv.org/pdf/2305.07611v2.pdf","comment":"It needs to be returned for major modifications"},{"id":"http://arxiv.org/abs/2306.10968v2","updated":"2023-06-21T11:31:50Z","published":"2023-06-19T14:30:52Z","title":"BayLing: Bridging Cross-lingual Alignment and Instruction Following\n  through Interactive Translation for Large Language Models","summary":"  Large language models (LLMs) have demonstrated remarkable prowess in language\nunderstanding and generation. Advancing from foundation LLMs to\ninstructionfollowing LLMs, instruction tuning plays a vital role in aligning\nLLMs to human preferences. However, the existing LLMs are usually focused on\nEnglish, leading to inferior performance in non-English languages. In order to\nimprove the performance for non-English languages, it is necessary to collect\nlanguage-specific training data for foundation LLMs and construct\nlanguage-specific instructions for instruction tuning, both of which are heavy\nloads. To minimize human workload, we propose to transfer the capabilities of\nlanguage generation and instruction following from English to other languages\nthrough an interactive translation task. We have developed BayLing, an\ninstruction-following LLM by utilizing LLaMA as the foundation LLM and\nautomatically constructing interactive translation instructions for instructing\ntuning. Extensive assessments demonstrate that BayLing achieves comparable\nperformance to GPT-3.5-turbo, despite utilizing a considerably smaller\nparameter size of only 13 billion. Experimental results on translation tasks\nshow that BayLing achieves 95% of single-turn translation capability compared\nto GPT-4 with automatic evaluation and 96% of interactive translation\ncapability compared to GPT-3.5-turbo with human evaluation. To estimate the\nperformance on general tasks, we created a multi-turn instruction test set\ncalled BayLing-80. The experimental results on BayLing-80 indicate that BayLing\nachieves 89% of performance compared to GPT-3.5-turbo. BayLing also\ndemonstrates outstanding performance on knowledge assessment of Chinese GaoKao\nand English SAT, second only to GPT-3.5-turbo among a multitude of\ninstruction-following LLMs. Demo, homepage, code and models of BayLing are\navailable.\n","authors":["Shaolei Zhang","Qingkai Fang","Zhuocheng Zhang","Zhengrui Ma","Yan Zhou","Langlin Huang","Mengyu Bu","Shangtong Gui","Yunji Chen","Xilin Chen","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2306.10968v2.pdf","comment":"Try BayLing's online demo at http://nlp.ict.ac.cn/bayling/demo"},{"id":"http://arxiv.org/abs/2306.12181v1","updated":"2023-06-21T11:24:41Z","published":"2023-06-21T11:24:41Z","title":"Feature Interactions Reveal Linguistic Structure in Language Models","summary":"  We study feature interactions in the context of feature attribution methods\nfor post-hoc interpretability. In interpretability research, getting to grips\nwith feature interactions is increasingly recognised as an important challenge,\nbecause interacting features are key to the success of neural networks. Feature\ninteractions allow a model to build up hierarchical representations for its\ninput, and might provide an ideal starting point for the investigation into\nlinguistic structure in language models. However, uncovering the exact role\nthat these interactions play is also difficult, and a diverse range of\ninteraction attribution methods has been proposed. In this paper, we focus on\nthe question which of these methods most faithfully reflects the inner workings\nof the target models. We work out a grey box methodology, in which we train\nmodels to perfection on a formal language classification task, using PCFGs. We\nshow that under specific configurations, some methods are indeed able to\nuncover the grammatical rules acquired by a model. Based on these findings we\nextend our evaluation to a case study on language models, providing novel\ninsights into the linguistic structure that these models have acquired.\n","authors":["Jaap Jumelet","Willem Zuidema"],"pdf_url":"https://arxiv.org/pdf/2306.12181v1.pdf","comment":"ACL Findings 2023"},{"id":"http://arxiv.org/abs/2306.12173v1","updated":"2023-06-21T11:01:31Z","published":"2023-06-21T11:01:31Z","title":"Mixture Encoder for Joint Speech Separation and Recognition","summary":"  Multi-speaker automatic speech recognition (ASR) is crucial for many\nreal-world applications, but it requires dedicated modeling techniques.\nExisting approaches can be divided into modular and end-to-end methods. Modular\napproaches separate speakers and recognize each of them with a single-speaker\nASR system. End-to-end models process overlapped speech directly in a single,\npowerful neural network. This work proposes a middle-ground approach that\nleverages explicit speech separation similarly to the modular approach but also\nincorporates mixture speech information directly into the ASR module in order\nto mitigate the propagation of errors made by the speech separator. We also\nexplore a way to exchange cross-speaker context information through a layer\nthat combines information of the individual speakers. Our system is optimized\nthrough separate and joint training stages and achieves a relative improvement\nof 7% in word error rate over a purely modular setup on the SMS-WSJ task.\n","authors":["Simon Berger","Peter Vieting","Christoph Boeddeker","Ralf Schlüter","Reinhold Haeb-Umbach"],"pdf_url":"https://arxiv.org/pdf/2306.12173v1.pdf","comment":"Accepted at Interspeech 2023"},{"id":"http://arxiv.org/abs/2306.09170v2","updated":"2023-06-21T09:59:38Z","published":"2023-06-15T14:47:03Z","title":"Can ChatGPT pass the Vietnamese National High School Graduation\n  Examination?","summary":"  This research article highlights the potential of AI-powered chatbots in\neducation and presents the results of using ChatGPT, a large language model, to\ncomplete the Vietnamese National High School Graduation Examination (VNHSGE).\nThe study dataset included 30 essays in the literature test case and 1,700\nmultiple-choice questions designed for other subjects. The results showed that\nChatGPT was able to pass the examination with an average score of 6-7,\ndemonstrating the technology's potential to revolutionize the educational\nlandscape. The analysis of ChatGPT performance revealed its proficiency in a\nrange of subjects, including mathematics, English, physics, chemistry, biology,\nhistory, geography, civic education, and literature, which suggests its\npotential to provide effective support for learners. However, further research\nis needed to assess ChatGPT performance on more complex exam questions and its\npotential to support learners in different contexts. As technology continues to\nevolve and improve, we can expect to see the use of AI tools like ChatGPT\nbecome increasingly common in educational settings, ultimately enhancing the\neducational experience for both students and educators.\n","authors":["Xuan-Quy Dao","Ngoc-Bich Le","Xuan-Dung Phan","Bac-Bien Ngo"],"pdf_url":"https://arxiv.org/pdf/2306.09170v2.pdf","comment":"11 pages, 12 figures, 4 tables"},{"id":"http://arxiv.org/abs/2306.12146v1","updated":"2023-06-21T09:50:48Z","published":"2023-06-21T09:50:48Z","title":"Which Spurious Correlations Impact Reasoning in NLI Models? A Visual\n  Interactive Diagnosis through Data-Constrained Counterfactuals","summary":"  We present a human-in-the-loop dashboard tailored to diagnosing potential\nspurious features that NLI models rely on for predictions. The dashboard\nenables users to generate diverse and challenging examples by drawing\ninspiration from GPT-3 suggestions. Additionally, users can receive feedback\nfrom a trained NLI model on how challenging the newly created example is and\nmake refinements based on the feedback. Through our investigation, we discover\nseveral categories of spurious correlations that impact the reasoning of NLI\nmodels, which we group into three categories: Semantic Relevance, Logical\nFallacies, and Bias. Based on our findings, we identify and describe various\nresearch opportunities, including diversifying training data and assessing NLI\nmodels' robustness by creating adversarial test suites.\n","authors":["Robin Chan","Afra Amini","Mennatallah El-Assady"],"pdf_url":"https://arxiv.org/pdf/2306.12146v1.pdf","comment":"7 pages, Accepted at ACL 2023: System Demonstrations"},{"id":"http://arxiv.org/abs/2306.12105v1","updated":"2023-06-21T08:43:29Z","published":"2023-06-21T08:43:29Z","title":"Mass-Producing Failures of Multimodal Systems with Language Models","summary":"  Deployed multimodal systems can fail in ways that evaluators did not\nanticipate. In order to find these failures before deployment, we introduce\nMultiMon, a system that automatically identifies systematic failures --\ngeneralizable, natural-language descriptions of patterns of model failures. To\nuncover systematic failures, MultiMon scrapes a corpus for examples of\nerroneous agreement: inputs that produce the same output, but should not. It\nthen prompts a language model (e.g., GPT-4) to find systematic patterns of\nfailure and describe them in natural language. We use MultiMon to find 14\nsystematic failures (e.g., \"ignores quantifiers\") of the CLIP text-encoder,\neach comprising hundreds of distinct inputs (e.g., \"a shelf with a few/many\nbooks\"). Because CLIP is the backbone for most state-of-the-art multimodal\nsystems, these inputs produce failures in Midjourney 5.1, DALL-E, VideoFusion,\nand others. MultiMon can also steer towards failures relevant to specific use\ncases, such as self-driving cars. We see MultiMon as a step towards evaluation\nthat autonomously explores the long tail of potential system failures. Code for\nMULTIMON is available at https://github.com/tsb0601/MultiMon.\n","authors":["Shengbang Tong","Erik Jones","Jacob Steinhardt"],"pdf_url":"https://arxiv.org/pdf/2306.12105v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2306.10974v2","updated":"2023-06-21T08:31:48Z","published":"2023-06-19T14:34:49Z","title":"Fine-Tuning Language Models for Scientific Writing Support","summary":"  We support scientific writers in determining whether a written sentence is\nscientific, to which section it belongs, and suggest paraphrasings to improve\nthe sentence. Firstly, we propose a regression model trained on a corpus of\nscientific sentences extracted from peer-reviewed scientific papers and\nnon-scientific text to assign a score that indicates the scientificness of a\nsentence. We investigate the effect of equations and citations on this score to\ntest the model for potential biases. Secondly, we create a mapping of section\ntitles to a standard paper layout in AI and machine learning to classify a\nsentence to its most likely section. We study the impact of context, i.e.,\nsurrounding sentences, on the section classification performance. Finally, we\npropose a paraphraser, which suggests an alternative for a given sentence that\nincludes word substitutions, additions to the sentence, and structural changes\nto improve the writing style. We train various large language models on\nsentences extracted from arXiv papers that were peer reviewed and published at\nA*, A, B, and C ranked conferences. On the scientificness task, all models\nachieve an MSE smaller than $2\\%$. For the section classification, BERT\noutperforms WideMLP and SciBERT in most cases. We demonstrate that using\ncontext enhances the classification of a sentence, achieving up to a $90\\%$\nF1-score. Although the paraphrasing models make comparatively few alterations,\nthey produce output sentences close to the gold standard. Large fine-tuned\nmodels such as T5 Large perform best in experiments considering various\nmeasures of difference between input sentence and gold standard. Code is\nprovided under https://github.com/JustinMuecke/SciSen.\n","authors":["Justin Mücke","Daria Waldow","Luise Metzger","Philipp Schauz","Marcel Hoffman","Nicolas Lell","Ansgar Scherp"],"pdf_url":"https://arxiv.org/pdf/2306.10974v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12089v1","updated":"2023-06-21T08:08:15Z","published":"2023-06-21T08:08:15Z","title":"Towards Accurate Translation via Semantically Appropriate Application of\n  Lexical Constraints","summary":"  Lexically-constrained NMT (LNMT) aims to incorporate user-provided\nterminology into translations. Despite its practical advantages, existing work\nhas not evaluated LNMT models under challenging real-world conditions. In this\npaper, we focus on two important but under-studied issues that lie in the\ncurrent evaluation process of LNMT studies. The model needs to cope with\nchallenging lexical constraints that are \"homographs\" or \"unseen\" during\ntraining. To this end, we first design a homograph disambiguation module to\ndifferentiate the meanings of homographs. Moreover, we propose PLUMCOT, which\nintegrates contextually rich information about unseen lexical constraints from\npre-trained language models and strengthens a copy mechanism of the pointer\nnetwork via direct supervision of a copying score. We also release HOLLY, an\nevaluation benchmark for assessing the ability of a model to cope with\n\"homographic\" and \"unseen\" lexical constraints. Experiments on HOLLY and the\nprevious test setup show the effectiveness of our method. The effects of\nPLUMCOT are shown to be remarkable in \"unseen\" constraints. Our dataset is\navailable at https://github.com/papago-lab/HOLLY-benchmark\n","authors":["Yujin Baek","Koanho Lee","Dayeon Ki","Hyoung-Gyu Lee","Cheonbok Park","Jaegul Choo"],"pdf_url":"https://arxiv.org/pdf/2306.12089v1.pdf","comment":"Findings of ACL2023. 15 pages"},{"id":"http://arxiv.org/abs/2301.00626v2","updated":"2023-06-21T08:01:38Z","published":"2023-01-02T12:40:05Z","title":"Design and analysis of tweet-based election models for the 2021 Mexican\n  legislative election","summary":"  Modelling and forecasting real-life human behaviour using online social media\nis an active endeavour of interest in politics, government, academia, and\nindustry. Since its creation in 2006, Twitter has been proposed as a potential\nlaboratory that could be used to gauge and predict social behaviour. During the\nlast decade, the user base of Twitter has been growing and becoming more\nrepresentative of the general population. Here we analyse this user base in the\ncontext of the 2021 Mexican Legislative Election. To do so, we use a dataset of\n15 million election-related tweets in the six months preceding election day. We\nexplore different election models that assign political preference to either\nthe ruling parties or the opposition. We find that models using data with\ngeographical attributes determine the results of the election with better\nprecision and accuracy than conventional polling methods. These results\ndemonstrate that analysis of public online data can outperform conventional\npolling methods, and that political analysis and general forecasting would\nlikely benefit from incorporating such data in the immediate future. Moreover,\nthe same Twitter dataset with geographical attributes is positively correlated\nwith results from official census data on population and internet usage in\nMexico. These findings suggest that we have reached a period in time when\nonline activity, appropriately curated, can provide an accurate representation\nof offline behaviour.\n","authors":["Alejandro Vigna-Gómez","Javier Murillo","Manelik Ramirez","Alberto Borbolla","Ian Márquez","Prasun K. Ray"],"pdf_url":"https://arxiv.org/pdf/2301.00626v2.pdf","comment":"Accepted for publication in EPJ Data Science. 20 pages, 7 figures, 1\n  table"},{"id":"http://arxiv.org/abs/2306.12069v1","updated":"2023-06-21T07:34:27Z","published":"2023-06-21T07:34:27Z","title":"Modeling Hierarchical Reasoning Chains by Linking Discourse Units and\n  Key Phrases for Reading Comprehension","summary":"  Machine reading comprehension (MRC) poses new challenges over logical\nreasoning, which aims to understand the implicit logical relations entailed in\nthe given contexts and perform inference over them. Due to the complexity of\nlogic, logical relations exist at different granularity levels. However, most\nexisting methods of logical reasoning individually focus on either entity-aware\nor discourse-based information but ignore the hierarchical relations that may\neven have mutual effects. In this paper, we propose a holistic graph network\n(HGN) which deals with context at both discourse level and word level, as the\nbasis for logical reasoning, to provide a more fine-grained relation\nextraction. Specifically, node-level and type-level relations, which can be\ninterpreted as bridges in the reasoning process, are modeled by a hierarchical\ninteraction mechanism to improve the interpretation of MRC systems.\nExperimental results on logical reasoning QA datasets (ReClor and LogiQA) and\nnatural language inference datasets (SNLI and ANLI) show the effectiveness and\ngeneralization of our method, and in-depth analysis verifies its capability to\nunderstand complex logical relations.\n","authors":["Jialin Chen","Zhuosheng Zhang","Hai Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.12069v1.pdf","comment":"Accepted at COLING 2022, 9 pages"},{"id":"http://arxiv.org/abs/2306.11371v2","updated":"2023-06-21T07:22:08Z","published":"2023-06-20T08:27:42Z","title":"Visually grounded few-shot word learning in low-resource settings","summary":"  We propose a visually grounded speech model that learns new words and their\nvisual depictions from just a few word-image example pairs. Given a set of test\nimages and a spoken query, we ask the model which image depicts the query word.\nPrevious work has simplified this few-shot learning problem by either using an\nartificial setting with digit word-image pairs or by using a large number of\nexamples per class. Moreover, all previous studies were performed using English\nspeech-image data. We propose an approach that can work on natural word-image\npairs but with less examples, i.e. fewer shots, and then illustrate how this\napproach can be applied for multimodal few-shot learning in a real low-resource\nlanguage, Yoruba. Our approach involves using the given word-image example\npairs to mine new unsupervised word-image training pairs from large collections\nof unlabelledspeech and images. Additionally, we use a word-to-image attention\nmechanism to determine word-image similarity. With this new model, we achieve\nbetter performance with fewer shots than previous approaches on an existing\nEnglish benchmark. Many of the model's mistakes are due to confusion between\nvisual concepts co-occurring in similar contexts. The experiments on Yoruba\nshow the benefit of transferring knowledge from a multimodal model trained on a\nlarger set of English speech-image data.\n","authors":["Leanne Nortje","Dan Oneata","Herman Kamper"],"pdf_url":"https://arxiv.org/pdf/2306.11371v2.pdf","comment":"Submitted to TASLP. arXiv admin note: substantial text overlap with\n  arXiv:2305.15937"},{"id":"http://arxiv.org/abs/2305.16863v2","updated":"2023-06-21T07:06:15Z","published":"2023-05-26T12:15:54Z","title":"Controlling Learned Effects to Reduce Spurious Correlations in Text\n  Classifiers","summary":"  To address the problem of NLP classifiers learning spurious correlations\nbetween training features and target labels, a common approach is to make the\nmodel's predictions invariant to these features. However, this can be\ncounter-productive when the features have a non-zero causal effect on the\ntarget label and thus are important for prediction. Therefore, using methods\nfrom the causal inference literature, we propose an algorithm to regularize the\nlearnt effect of the features on the model's prediction to the estimated effect\nof feature on label. This results in an automated augmentation method that\nleverages the estimated effect of a feature to appropriately change the labels\nfor new augmented inputs. On toxicity and IMDB review datasets, the proposed\nalgorithm minimises spurious correlations and improves the minority group\n(i.e., samples breaking spurious correlations) accuracy, while also improving\nthe total accuracy compared to standard training.\n","authors":["Parikshit Bansal","Amit Sharma"],"pdf_url":"https://arxiv.org/pdf/2305.16863v2.pdf","comment":"Accepted to ACL 2023"},{"id":"http://arxiv.org/abs/2306.12043v1","updated":"2023-06-21T06:20:51Z","published":"2023-06-21T06:20:51Z","title":"Sample Attackability in Natural Language Adversarial Attacks","summary":"  Adversarial attack research in natural language processing (NLP) has made\nsignificant progress in designing powerful attack methods and defence\napproaches. However, few efforts have sought to identify which source samples\nare the most attackable or robust, i.e. can we determine for an unseen target\nmodel, which samples are the most vulnerable to an adversarial attack. This\nwork formally extends the definition of sample attackability/robustness for NLP\nattacks. Experiments on two popular NLP datasets, four state of the art models\nand four different NLP adversarial attack methods, demonstrate that sample\nuncertainty is insufficient for describing characteristics of attackable/robust\nsamples and hence a deep learning based detector can perform much better at\nidentifying the most attackable and robust samples for an unseen target model.\nNevertheless, further analysis finds that there is little agreement in which\nsamples are considered the most attackable/robust across different NLP attack\nmethods, explaining a lack of portability of attackability detection methods\nacross attack methods.\n","authors":["Vyas Raina","Mark Gales"],"pdf_url":"https://arxiv.org/pdf/2306.12043v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12040v1","updated":"2023-06-21T06:12:14Z","published":"2023-06-21T06:12:14Z","title":"Strategies in Transfer Learning for Low-Resource Speech Synthesis: Phone\n  Mapping, Features Input, and Source Language Selection","summary":"  We compare using a PHOIBLE-based phone mapping method and using phonological\nfeatures input in transfer learning for TTS in low-resource languages. We use\ndiverse source languages (English, Finnish, Hindi, Japanese, and Russian) and\ntarget languages (Bulgarian, Georgian, Kazakh, Swahili, Urdu, and Uzbek) to\ntest the language-independence of the methods and enhance the findings'\napplicability. We use Character Error Rates from automatic speech recognition\nand predicted Mean Opinion Scores for evaluation. Results show that both phone\nmapping and features input improve the output quality and the latter performs\nbetter, but these effects also depend on the specific language combination. We\nalso compare the recently-proposed Angular Similarity of Phone Frequencies\n(ASPF) with a family tree-based distance measure as a criterion to select\nsource languages in transfer learning. ASPF proves effective if label-based\nphone input is used, while the language distance does not have expected\neffects.\n","authors":["Phat Do","Matt Coler","Jelske Dijkstra","Esther Klabbers"],"pdf_url":"https://arxiv.org/pdf/2306.12040v1.pdf","comment":"Accepted at the Speech Synthesis Workshop 2023"},{"id":"http://arxiv.org/abs/2306.12020v1","updated":"2023-06-21T05:11:39Z","published":"2023-06-21T05:11:39Z","title":"Visual-Aware Text-to-Speech","summary":"  Dynamically synthesizing talking speech that actively responds to a listening\nhead is critical during the face-to-face interaction. For example, the speaker\ncould take advantage of the listener's facial expression to adjust the tones,\nstressed syllables, or pauses. In this work, we present a new visual-aware\ntext-to-speech (VA-TTS) task to synthesize speech conditioned on both textual\ninputs and sequential visual feedback (e.g., nod, smile) of the listener in\nface-to-face communication. Different from traditional text-to-speech, VA-TTS\nhighlights the impact of visual modality. On this newly-minted task, we devise\na baseline model to fuse phoneme linguistic information and listener visual\nsignals for speech synthesis. Extensive experiments on multimodal conversation\ndataset ViCo-X verify our proposal for generating more natural audio with\nscenario-appropriate rhythm and prosody.\n","authors":["Mohan Zhou","Yalong Bai","Wei Zhang","Ting Yao","Tiejun Zhao","Tao Mei"],"pdf_url":"https://arxiv.org/pdf/2306.12020v1.pdf","comment":"accepted as oral and top 3% paper by ICASSP 2023"},{"id":"http://arxiv.org/abs/2306.12018v1","updated":"2023-06-21T05:07:40Z","published":"2023-06-21T05:07:40Z","title":"A Semi-Autoregressive Graph Generative Model for Dependency Graph\n  Parsing","summary":"  Recent years have witnessed the impressive progress in Neural Dependency\nParsing. According to the different factorization approaches to the graph joint\nprobabilities, existing parsers can be roughly divided into autoregressive and\nnon-autoregressive patterns. The former means that the graph should be\nfactorized into multiple sequentially dependent components, then it can be\nbuilt up component by component. And the latter assumes these components to be\nindependent so that they can be outputted in a one-shot manner. However, when\ntreating the directed edge as an explicit dependency relationship, we discover\nthat there is a mixture of independent and interdependent components in the\ndependency graph, signifying that both aforementioned models fail to precisely\ncapture the explicit dependencies among nodes and edges. Based on this\nproperty, we design a Semi-Autoregressive Dependency Parser to generate\ndependency graphs via adding node groups and edge groups autoregressively while\npouring out all group elements in parallel. The model gains a trade-off between\nnon-autoregression and autoregression, which respectively suffer from the lack\nof target inter-dependencies and the uncertainty of graph generation orders.\nThe experiments show the proposed parser outperforms strong baselines on\nEnhanced Universal Dependencies of multiple languages, especially achieving\n$4\\%$ average promotion at graph-level accuracy. Also, the performances of\nmodel variations show the importance of specific parts.\n","authors":["Ye Ma","Mingming Sun","Ping Li"],"pdf_url":"https://arxiv.org/pdf/2306.12018v1.pdf","comment":"Accepted by ACL 2023 Findings"},{"id":"http://arxiv.org/abs/2306.12014v1","updated":"2023-06-21T04:34:27Z","published":"2023-06-21T04:34:27Z","title":"3HAN: A Deep Neural Network for Fake News Detection","summary":"  The rapid spread of fake news is a serious problem calling for AI solutions.\nWe employ a deep learning based automated detector through a three level\nhierarchical attention network (3HAN) for fast, accurate detection of fake\nnews. 3HAN has three levels, one each for words, sentences, and the headline,\nand constructs a news vector: an effective representation of an input news\narticle, by processing an article in an hierarchical bottom-up manner. The\nheadline is known to be a distinguishing feature of fake news, and furthermore,\nrelatively few words and sentences in an article are more important than the\nrest. 3HAN gives a differential importance to parts of an article, on account\nof its three layers of attention. By experiments on a large real-world data\nset, we observe the effectiveness of 3HAN with an accuracy of 96.77%. Unlike\nsome other deep learning models, 3HAN provides an understandable output through\nthe attention weights given to different parts of an article, which can be\nvisualized through a heatmap to enable further manual fact checking.\n","authors":["Sneha Singhania","Nigel Fernandez","Shrisha Rao"],"pdf_url":"https://arxiv.org/pdf/2306.12014v1.pdf","comment":"Published as a conference paper at ICONIP 2017"},{"id":"http://arxiv.org/abs/2306.11066v2","updated":"2023-06-21T03:56:39Z","published":"2023-06-19T17:01:13Z","title":"Adversarial Robustness of Prompt-based Few-Shot Learning for Natural\n  Language Understanding","summary":"  State-of-the-art few-shot learning (FSL) methods leverage prompt-based\nfine-tuning to obtain remarkable results for natural language understanding\n(NLU) tasks. While much of the prior FSL methods focus on improving downstream\ntask performance, there is a limited understanding of the adversarial\nrobustness of such methods. In this work, we conduct an extensive study of\nseveral state-of-the-art FSL methods to assess their robustness to adversarial\nperturbations. To better understand the impact of various factors towards\nrobustness (or the lack of it), we evaluate prompt-based FSL methods against\nfully fine-tuned models for aspects such as the use of unlabeled data, multiple\nprompts, number of few-shot examples, model size and type. Our results on six\nGLUE tasks indicate that compared to fully fine-tuned models, vanilla FSL\nmethods lead to a notable relative drop in task performance (i.e., are less\nrobust) in the face of adversarial perturbations. However, using (i) unlabeled\ndata for prompt-based FSL and (ii) multiple prompts flip the trend. We further\ndemonstrate that increasing the number of few-shot examples and model size lead\nto increased adversarial robustness of vanilla FSL methods. Broadly, our work\nsheds light on the adversarial robustness evaluation of prompt-based FSL\nmethods for NLU tasks.\n","authors":["Venkata Prabhakara Sarath Nookala","Gaurav Verma","Subhabrata Mukherjee","Srijan Kumar"],"pdf_url":"https://arxiv.org/pdf/2306.11066v2.pdf","comment":"Accepted full paper at Findings of ACL 2023; Code available at\n  https://github.com/claws-lab/few-shot-adversarial-robustness"},{"id":"http://arxiv.org/abs/2306.11976v1","updated":"2023-06-21T02:05:48Z","published":"2023-06-21T02:05:48Z","title":"Interactive Molecular Discovery with Natural Language","summary":"  Natural language is expected to be a key medium for various human-machine\ninteractions in the era of large language models. When it comes to the\nbiochemistry field, a series of tasks around molecules (e.g., property\nprediction, molecule mining, etc.) are of great significance while having a\nhigh technical threshold. Bridging the molecule expressions in natural language\nand chemical language can not only hugely improve the interpretability and\nreduce the operation difficulty of these tasks, but also fuse the chemical\nknowledge scattered in complementary materials for a deeper comprehension of\nmolecules. Based on these benefits, we propose the conversational molecular\ndesign, a novel task adopting natural language for describing and editing\ntarget molecules. To better accomplish this task, we design ChatMol, a\nknowledgeable and versatile generative pre-trained model, enhanced by injecting\nexperimental property information, molecular spatial knowledge, and the\nassociations between natural and chemical languages into it. Several typical\nsolutions including large language models (e.g., ChatGPT) are evaluated,\nproving the challenge of conversational molecular design and the effectiveness\nof our knowledge enhancement method. Case observations and analysis are\nconducted to provide directions for further exploration of natural-language\ninteraction in molecular discovery.\n","authors":["Zheni Zeng","Bangchen Yin","Shipeng Wang","Jiarui Liu","Cheng Yang","Haishen Yao","Xingzhi Sun","Maosong Sun","Guotong Xie","Zhiyuan Liu"],"pdf_url":"https://arxiv.org/pdf/2306.11976v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.03868v3","updated":"2023-06-21T22:48:39Z","published":"2021-12-07T18:01:35Z","title":"EmTract: Extracting Emotions from Social Media","summary":"  We develop an open-source tool (EmTract) that extracts emotions from social\nmedia text tailed for financial context. To do so, we annotate ten thousand\nshort messages from a financial social media platform (StockTwits) and combine\nit with open-source emotion data. We then use a pre-tuned NLP model,\nDistilBERT, augment its embedding space by including 4,861 tokens (emojis and\nemoticons), and then fit it first on the open-source emotion data, then\ntransfer it to our annotated financial social media data. Our model outperforms\ncompeting open-source state-of-the-art emotion classifiers, such as Emotion\nEnglish DistilRoBERTa-base on both human and chatGPT annotated data. Compared\nto dictionary based methods, our methodology has three main advantages for\nresearch in finance. First, our model is tailored to financial social media\ntext; second, it incorporates key aspects of social media data, such as\nnon-standard phrases, emojis, and emoticons; and third, it operates by\nsequentially learning a latent representation that includes features such as\nword order, word usage, and local context. Using EmTract, we explore the\nrelationship between investor emotions expressed on social media and asset\nprices. We show that firm-specific investor emotions are predictive of daily\nprice movements. Our findings show that emotions and market dynamics are\nclosely related, and we provide a tool to help study the role emotions play in\nfinancial markets.\n","authors":["Domonkos F. Vamossy","Rolf Skog"],"pdf_url":"https://arxiv.org/pdf/2112.03868v3.pdf","comment":"Substantial changes to the project"},{"id":"http://arxiv.org/abs/2306.12596v1","updated":"2023-06-21T22:37:51Z","published":"2023-06-21T22:37:51Z","title":"A Hierarchical Approach to exploiting Multiple Datasets from TalkBank","summary":"  TalkBank is an online database that facilitates the sharing of linguistics\nresearch data. However, the existing TalkBank's API has limited data filtering\nand batch processing capabilities. To overcome these limitations, this paper\nintroduces a pipeline framework that employs a hierarchical search approach,\nenabling efficient complex data selection. This approach involves a quick\npreliminary screening of relevant corpora that a researcher may need, and then\nperform an in-depth search for target data based on specific criteria. The\nidentified files are then indexed, providing easier access for future analysis.\nFurthermore, the paper demonstrates how data from different studies curated\nwith the framework can be integrated by standardizing and cleaning metadata,\nallowing researchers to extract insights from a large, integrated dataset.\nWhile being designed for TalkBank, the framework can also be adapted to process\ndata from other open-science platforms.\n","authors":["Man Ho Wong"],"pdf_url":"https://arxiv.org/pdf/2306.12596v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12587v1","updated":"2023-06-21T22:00:03Z","published":"2023-06-21T22:00:03Z","title":"ARIES: A Corpus of Scientific Paper Edits Made in Response to Peer\n  Reviews","summary":"  Revising scientific papers based on peer feedback is a challenging task that\nrequires not only deep scientific knowledge and reasoning, but also the ability\nto recognize the implicit requests in high-level feedback and to choose the\nbest of many possible ways to update the manuscript in response. We introduce\nthis task for large language models and release ARIES, a dataset of review\ncomments and their corresponding paper edits, to enable training and evaluating\nmodels. We study two versions of the task: comment-edit alignment and edit\ngeneration, and evaluate several baselines, including GPT-4. We find that\nmodels struggle even to identify the edits that correspond to a comment,\nespecially in cases where the comment is phrased in an indirect way or where\nthe edit addresses the spirit of a comment but not the precise request. When\ntasked with generating edits, GPT-4 often succeeds in addressing comments on a\nsurface level, but it rigidly follows the wording of the feedback rather than\nthe underlying intent, and includes fewer technical details than human-written\nedits. We hope that our formalization, dataset, and analysis will form a\nfoundation for future work in this area.\n","authors":["Mike D'Arcy","Alexis Ross","Erin Bransom","Bailey Kuehl","Jonathan Bragg","Tom Hope","Doug Downey"],"pdf_url":"https://arxiv.org/pdf/2306.12587v1.pdf","comment":"11 pages, 2 figures"},{"id":"http://arxiv.org/abs/2306.12581v1","updated":"2023-06-21T21:34:39Z","published":"2023-06-21T21:34:39Z","title":"Morphological Inflection with Phonological Features","summary":"  Recent years have brought great advances into solving morphological tasks,\nmostly due to powerful neural models applied to various tasks as (re)inflection\nand analysis. Yet, such morphological tasks cannot be considered solved,\nespecially when little training data is available or when generalizing to\npreviously unseen lemmas. This work explores effects on performance obtained\nthrough various ways in which morphological models get access to subcharacter\nphonological features that are the targets of morphological processes. We\ndesign two methods to achieve this goal: one that leaves models as is but\nmanipulates the data to include features instead of characters, and another\nthat manipulates models to take phonological features into account when\nbuilding representations for phonemes. We elicit phonemic data from standard\ngraphemic data using language-specific grammars for languages with shallow\ngrapheme-to-phoneme mapping, and we experiment with two reinflection models\nover eight languages. Our results show that our methods yield comparable\nresults to the grapheme-based baseline overall, with minor improvements in some\nof the languages. All in all, we conclude that patterns in character\ndistributions are likely to allow models to infer the underlying phonological\ncharacteristics, even when phonemes are not explicitly represented.\n","authors":["David Guriel","Omer Goldman","Reut Tsarfaty"],"pdf_url":"https://arxiv.org/pdf/2306.12581v1.pdf","comment":"ACL 2023 main conference; 8 pages, 1 figure"},{"id":"http://arxiv.org/abs/2306.12577v1","updated":"2023-06-21T21:26:19Z","published":"2023-06-21T21:26:19Z","title":"NoRefER: a Referenceless Quality Metric for Automatic Speech Recognition\n  via Semi-Supervised Language Model Fine-Tuning with Contrastive Learning","summary":"  This paper introduces NoRefER, a novel referenceless quality metric for\nautomatic speech recognition (ASR) systems. Traditional reference-based metrics\nfor evaluating ASR systems require costly ground-truth transcripts. NoRefER\novercomes this limitation by fine-tuning a multilingual language model for\npair-wise ranking ASR hypotheses using contrastive learning with Siamese\nnetwork architecture. The self-supervised NoRefER exploits the known quality\nrelationships between hypotheses from multiple compression levels of an ASR for\nlearning to rank intra-sample hypotheses by quality, which is essential for\nmodel comparisons. The semi-supervised version also uses a referenced dataset\nto improve its inter-sample quality ranking, which is crucial for selecting\npotentially erroneous samples. The results indicate that NoRefER correlates\nhighly with reference-based metrics and their intra-sample ranks, indicating a\nhigh potential for referenceless ASR evaluation or a/b testing.\n","authors":["Kamer Ali Yuksel","Thiago Ferreira","Golara Javadi","Mohamed El-Badrashiny","Ahmet Gunduz"],"pdf_url":"https://arxiv.org/pdf/2306.12577v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12567v1","updated":"2023-06-21T21:04:11Z","published":"2023-06-21T21:04:11Z","title":"Evaluating Large Language Models with NeuBAROCO: Syllogistic Reasoning\n  Ability and Human-like Biases","summary":"  This paper investigates whether current large language models exhibit biases\nin logical reasoning, similar to humans. Specifically, we focus on syllogistic\nreasoning, a well-studied form of inference in the cognitive science of human\ndeduction. To facilitate our analysis, we introduce a dataset called NeuBAROCO,\noriginally designed for psychological experiments that assess human logical\nabilities in syllogistic reasoning. The dataset consists of syllogistic\ninferences in both English and Japanese. We examine three types of biases\nobserved in human syllogistic reasoning: belief biases, conversion errors, and\natmosphere effects. Our findings demonstrate that current large language models\nstruggle more with problems involving these three types of biases.\n","authors":["Risako Ando","Takanobu Morishita","Hirohiko Abe","Koji Mineshima","Mitsuhiro Okada"],"pdf_url":"https://arxiv.org/pdf/2306.12567v1.pdf","comment":"To appear in Proceedings of the 4th Natural Logic Meets Machine\n  Learning Workshop (NALOMA IV)"},{"id":"http://arxiv.org/abs/2306.09442v2","updated":"2023-06-21T20:48:40Z","published":"2023-06-15T18:49:50Z","title":"Explore, Establish, Exploit: Red Teaming Language Models from Scratch","summary":"  Deploying Large language models (LLMs) can pose hazards from harmful outputs\nsuch as toxic or dishonest speech. Prior work has introduced tools that elicit\nharmful outputs in order to identify and mitigate these risks. While this is a\nvaluable step toward securing language models, these approaches typically rely\non a pre-existing classifier for undesired outputs. This limits their\napplication to situations where the type of harmful behavior is known with\nprecision beforehand. However, this skips a central challenge of red teaming:\ndeveloping a contextual understanding of the behaviors that a model can\nexhibit. Furthermore, when such a classifier already exists, red teaming has\nlimited marginal value because the classifier could simply be used to filter\ntraining data or model outputs. In this work, we consider red teaming under the\nassumption that the adversary is working from a high-level, abstract\nspecification of undesired behavior. The red team is expected to refine/extend\nthis specification and identify methods to elicit this behavior from the model.\nOur red teaming framework consists of three steps: 1) Exploring the model's\nbehavior in the desired context; 2) Establishing a measurement of undesired\nbehavior (e.g., a classifier trained to reflect human evaluations); and 3)\nExploiting the model's flaws using this measure and an established red teaming\nmethodology. We apply this approach to red team GPT-2 and GPT-3 models to\nsystematically discover classes of prompts that elicit toxic and dishonest\nstatements. In doing so, we also construct and release the CommonClaim dataset\nof 20,000 statements that have been labeled by human subjects as\ncommon-knowledge-true, common-knowledge-false, or neither. Code is available at\nhttps://github.com/thestephencasper/explore_establish_exploit_llms. CommonClaim\nis available at https://github.com/Algorithmic-Alignment-Lab/CommonClaim.\n","authors":["Stephen Casper","Jason Lin","Joe Kwon","Gatlen Culp","Dylan Hadfield-Menell"],"pdf_url":"https://arxiv.org/pdf/2306.09442v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12552v1","updated":"2023-06-21T20:36:55Z","published":"2023-06-21T20:36:55Z","title":"SituatedGen: Incorporating Geographical and Temporal Contexts into\n  Generative Commonsense Reasoning","summary":"  Recently, commonsense reasoning in text generation has attracted much\nattention. Generative commonsense reasoning is the task that requires machines,\ngiven a group of keywords, to compose a single coherent sentence with\ncommonsense plausibility. While existing datasets targeting generative\ncommonsense reasoning focus on everyday scenarios, it is unclear how well\nmachines reason under specific geographical and temporal contexts. We formalize\nthis challenging task as SituatedGen, where machines with commonsense should\ngenerate a pair of contrastive sentences given a group of keywords including\ngeographical or temporal entities. We introduce a corresponding English dataset\nconsisting of 8,268 contrastive sentence pairs, which are built upon several\nexisting commonsense reasoning benchmarks with minimal manual labor.\nExperiments show that state-of-the-art generative language models struggle to\ngenerate sentences with commonsense plausibility and still lag far behind human\nperformance. Our dataset is publicly available at\nhttps://github.com/yunx-z/situated_gen.\n","authors":["Yunxiang Zhang","Xiaojun Wan"],"pdf_url":"https://arxiv.org/pdf/2306.12552v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12550v1","updated":"2023-06-21T20:32:22Z","published":"2023-06-21T20:32:22Z","title":"On Evaluation of Document Classification using RVL-CDIP","summary":"  The RVL-CDIP benchmark is widely used for measuring performance on the task\nof document classification. Despite its widespread use, we reveal several\nundesirable characteristics of the RVL-CDIP benchmark. These include (1)\nsubstantial amounts of label noise, which we estimate to be 8.1% (ranging\nbetween 1.6% to 16.9% per document category); (2) presence of many ambiguous or\nmulti-label documents; (3) a large overlap between test and train splits, which\ncan inflate model performance metrics; and (4) presence of sensitive\npersonally-identifiable information like US Social Security numbers (SSNs). We\nargue that there is a risk in using RVL-CDIP for benchmarking document\nclassifiers, as its limited scope, presence of errors (state-of-the-art models\nnow achieve accuracy error rates that are within our estimated label error\nrate), and lack of diversity make it less than ideal for benchmarking. We\nfurther advocate for the creation of a new document classification benchmark,\nand provide recommendations for what characteristics such a resource should\ninclude.\n","authors":["Stefan Larson","Gordon Lim","Kevin Leach"],"pdf_url":"https://arxiv.org/pdf/2306.12550v1.pdf","comment":"EACL 2023"},{"id":"http://arxiv.org/abs/2306.12509v1","updated":"2023-06-21T18:45:56Z","published":"2023-06-21T18:45:56Z","title":"Deep Language Networks: Joint Prompt Training of Stacked LLMs using\n  Variational Inference","summary":"  We view large language models (LLMs) as stochastic \\emph{language layers} in\na network, where the learnable parameters are the natural language\n\\emph{prompts} at each layer. We stack two such layers, feeding the output of\none layer to the next. We call the stacked architecture a \\emph{Deep Language\nNetwork} (DLN). We first show how to effectively perform prompt optimization\nfor a 1-Layer language network (DLN-1). We then show how to train 2-layer DLNs\n(DLN-2), where two prompts must be learnt. We consider the output of the first\nlayer as a latent variable to marginalize, and devise a variational inference\nalgorithm for joint prompt training. A DLN-2 reaches higher performance than a\nsingle layer, sometimes comparable to few-shot GPT-4 even when each LLM in the\nnetwork is smaller and less powerful. The DLN code is open source:\nhttps://github.com/microsoft/deep-language-networks .\n","authors":["Alessandro Sordoni","Xingdi Yuan","Marc-Alexandre Côté","Matheus Pereira","Adam Trischler","Ziang Xiao","Arian Hosseini","Friederike Niedtner","Nicolas Le Roux"],"pdf_url":"https://arxiv.org/pdf/2306.12509v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12466v1","updated":"2023-06-21T17:30:02Z","published":"2023-06-21T17:30:02Z","title":"Misinformation as Information Pollution","summary":"  Social media feed algorithms are designed to optimize online social\nengagements for the purpose of maximizing advertising profits, and therefore\nhave an incentive to promote controversial posts including misinformation. By\nthinking about misinformation as information pollution, we can draw parallels\nwith environmental policy for countering pollution such as carbon taxes.\nSimilar to pollution, a Pigouvian tax on misinformation provides economic\nincentives for social media companies to control the spread of misinformation\nmore effectively to avoid or reduce their misinformation tax, while preserving\nsome degree of freedom in platforms' response. In this paper, we highlight a\nbird's eye view of a Pigouvian misinformation tax and discuss the key questions\nand next steps for implementing such a taxing scheme.\n","authors":["Ashkan Kazemi","Rada Mihalcea"],"pdf_url":"https://arxiv.org/pdf/2306.12466v1.pdf","comment":"9 pages"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2306.12423v1","updated":"2023-06-21T17:59:51Z","published":"2023-06-21T17:59:51Z","title":"Benchmarking and Analyzing 3D-aware Image Synthesis with a Modularized\n  Codebase","summary":"  Despite the rapid advance of 3D-aware image synthesis, existing studies\nusually adopt a mixture of techniques and tricks, leaving it unclear how each\npart contributes to the final performance in terms of generality. Following the\nmost popular and effective paradigm in this field, which incorporates a neural\nradiance field (NeRF) into the generator of a generative adversarial network\n(GAN), we build a well-structured codebase, dubbed Carver, through modularizing\nthe generation process. Such a design allows researchers to develop and replace\neach module independently, and hence offers an opportunity to fairly compare\nvarious approaches and recognize their contributions from the module\nperspective. The reproduction of a range of cutting-edge algorithms\ndemonstrates the availability of our modularized codebase. We also perform a\nvariety of in-depth analyses, such as the comparison across different types of\npoint feature, the necessity of the tailing upsampler in the generator, the\nreliance on the camera pose prior, etc., which deepen our understanding of\nexisting methods and point out some further directions of the research work. We\nrelease code and models at https://github.com/qiuyu96/Carver to facilitate the\ndevelopment and evaluation of this field.\n","authors":["Qiuyu Wang","Zifan Shi","Kecheng Zheng","Yinghao Xu","Sida Peng","Yujun Shen"],"pdf_url":"https://arxiv.org/pdf/2306.12423v1.pdf","comment":"Code: https://github.com/qiuyu96/Carver"},{"id":"http://arxiv.org/abs/2306.12424v1","updated":"2023-06-21T17:59:51Z","published":"2023-06-21T17:59:51Z","title":"VisoGender: A dataset for benchmarking gender bias in image-text pronoun\n  resolution","summary":"  We introduce VisoGender, a novel dataset for benchmarking gender bias in\nvision-language models. We focus on occupation-related gender biases, inspired\nby Winograd and Winogender schemas, where each image is associated with a\ncaption containing a pronoun relationship of subjects and objects in the scene.\nVisoGender is balanced by gender representation in professional roles,\nsupporting bias evaluation in two ways: i) resolution bias, where we evaluate\nthe difference between gender resolution accuracies for men and women and ii)\nretrieval bias, where we compare ratios of male and female professionals\nretrieved for a gender-neutral search query. We benchmark several\nstate-of-the-art vision-language models and find that they lack the reasoning\nabilities to correctly resolve gender in complex scenes. While the direction\nand magnitude of gender bias depends on the task and the model being evaluated,\ncaptioning models generally are more accurate and less biased than CLIP-like\nmodels. Dataset and code are available at https://github.com/oxai/visogender\n","authors":["Siobhan Mackenzie Hall","Fernanda Gonçalves Abrantes","Hanwen Zhu","Grace Sodunke","Aleksandar Shtedritski","Hannah Rose Kirk"],"pdf_url":"https://arxiv.org/pdf/2306.12424v1.pdf","comment":"Data and code available at https://github.com/oxai/visogender"},{"id":"http://arxiv.org/abs/2306.12422v1","updated":"2023-06-21T17:59:45Z","published":"2023-06-21T17:59:45Z","title":"DreamTime: An Improved Optimization Strategy for Text-to-3D Content\n  Creation","summary":"  Text-to-image diffusion models pre-trained on billions of image-text pairs\nhave recently enabled text-to-3D content creation by optimizing a randomly\ninitialized Neural Radiance Fields (NeRF) with score distillation. However, the\nresultant 3D models exhibit two limitations: (a) quality concerns such as\nsaturated color and the Janus problem; (b) extremely low diversity comparing to\ntext-guided image synthesis. In this paper, we show that the conflict between\nNeRF optimization process and uniform timestep sampling in score distillation\nis the main reason for these limitations. To resolve this conflict, we propose\nto prioritize timestep sampling with monotonically non-increasing functions,\nwhich aligns NeRF optimization with the sampling process of diffusion model.\nExtensive experiments show that our simple redesign significantly improves\ntext-to-3D content creation with higher quality and diversity.\n","authors":["Yukun Huang","Jianan Wang","Yukai Shi","Xianbiao Qi","Zheng-Jun Zha","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.12422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12398v1","updated":"2023-06-21T17:34:31Z","published":"2023-06-21T17:34:31Z","title":"Multi-Task Consistency for Active Learning","summary":"  Learning-based solutions for vision tasks require a large amount of labeled\ntraining data to ensure their performance and reliability. In single-task\nvision-based settings, inconsistency-based active learning has proven to be\neffective in selecting informative samples for annotation. However, there is a\nlack of research exploiting the inconsistency between multiple tasks in\nmulti-task networks. To address this gap, we propose a novel multi-task active\nlearning strategy for two coupled vision tasks: object detection and semantic\nsegmentation. Our approach leverages the inconsistency between them to identify\ninformative samples across both tasks. We propose three constraints that\nspecify how the tasks are coupled and introduce a method for determining the\npixels belonging to the object detected by a bounding box, to later quantify\nthe constraints as inconsistency scores. To evaluate the effectiveness of our\napproach, we establish multiple baselines for multi-task active learning and\nintroduce a new metric, mean Detection Segmentation Quality (mDSQ), tailored\nfor the multi-task active learning comparison that addresses the performance of\nboth tasks. We conduct extensive experiments on the nuImages and A9 datasets,\ndemonstrating that our approach outperforms existing state-of-the-art methods\nby up to 3.4% mDSQ on nuImages. Our approach achieves 95% of the fully-trained\nperformance using only 67% of the available data, corresponding to 20% fewer\nlabels compared to random selection and 5% fewer labels compared to\nstate-of-the-art selection strategy. Our code will be made publicly available\nafter the review process.\n","authors":["Aral Hekimoglu","Philipp Friedrich","Walter Zimmer","Michael Schmidt","Alvaro Marcos-Ramiro","Alois C. Knoll"],"pdf_url":"https://arxiv.org/pdf/2306.12398v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.03442v2","updated":"2023-06-21T16:57:19Z","published":"2022-07-07T17:14:10Z","title":"Back to the Source: Diffusion-Driven Test-Time Adaptation","summary":"  Test-time adaptation harnesses test inputs to improve the accuracy of a model\ntrained on source data when tested on shifted target data. Existing methods\nupdate the source model by (re-)training on each target domain. While\neffective, re-training is sensitive to the amount and order of the data and the\nhyperparameters for optimization. We instead update the target data, by\nprojecting all test inputs toward the source domain with a generative diffusion\nmodel. Our diffusion-driven adaptation method, DDA, shares its models for\nclassification and generation across all domains. Both models are trained on\nthe source domain, then fixed during testing. We augment diffusion with image\nguidance and self-ensembling to automatically decide how much to adapt. Input\nadaptation by DDA is more robust than prior model adaptation approaches across\na variety of corruptions, architectures, and data regimes on the ImageNet-C\nbenchmark. With its input-wise updates, DDA succeeds where model adaptation\ndegrades on too little data in small batches, dependent data in non-uniform\norder, or mixed data with multiple corruptions.\n","authors":["Jin Gao","Jialing Zhang","Xihui Liu","Trevor Darrell","Evan Shelhamer","Dequan Wang"],"pdf_url":"https://arxiv.org/pdf/2207.03442v2.pdf","comment":"published at CVPR 2023"},{"id":"http://arxiv.org/abs/2306.12376v1","updated":"2023-06-21T16:40:37Z","published":"2023-06-21T16:40:37Z","title":"M-VAAL: Multimodal Variational Adversarial Active Learning for\n  Downstream Medical Image Analysis Tasks","summary":"  Acquiring properly annotated data is expensive in the medical field as it\nrequires experts, time-consuming protocols, and rigorous validation. Active\nlearning attempts to minimize the need for large annotated samples by actively\nsampling the most informative examples for annotation. These examples\ncontribute significantly to improving the performance of supervised machine\nlearning models, and thus, active learning can play an essential role in\nselecting the most appropriate information in deep learning-based diagnosis,\nclinical assessments, and treatment planning. Although some existing works have\nproposed methods for sampling the best examples for annotation in medical image\nanalysis, they are not task-agnostic and do not use multimodal auxiliary\ninformation in the sampler, which has the potential to increase robustness.\nTherefore, in this work, we propose a Multimodal Variational Adversarial Active\nLearning (M-VAAL) method that uses auxiliary information from additional\nmodalities to enhance the active sampling. We applied our method to two\ndatasets: i) brain tumor segmentation and multi-label classification using the\nBraTS2018 dataset, and ii) chest X-ray image classification using the\nCOVID-QU-Ex dataset. Our results show a promising direction toward\ndata-efficient learning under limited annotations.\n","authors":["Bidur Khanal","Binod Bhattarai","Bishesh Khanal","Danail Stoyanov","Cristian A. Linte"],"pdf_url":"https://arxiv.org/pdf/2306.12376v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12365v1","updated":"2023-06-21T16:19:07Z","published":"2023-06-21T16:19:07Z","title":"Attention Hybrid Variational Net for Accelerated MRI Reconstruction","summary":"  The application of compressed sensing (CS)-enabled data reconstruction for\naccelerating magnetic resonance imaging (MRI) remains a challenging problem.\nThis is due to the fact that the information lost in k-space from the\nacceleration mask makes it difficult to reconstruct an image similar to the\nquality of a fully sampled image. Multiple deep learning-based structures have\nbeen proposed for MRI reconstruction using CS, both in the k-space and image\ndomains as well as using unrolled optimization methods. However, the drawback\nof these structures is that they are not fully utilizing the information from\nboth domains (k-space and image). Herein, we propose a deep learning-based\nattention hybrid variational network that performs learning in both the k-space\nand image domain. We evaluate our method on a well-known open-source MRI\ndataset and a clinical MRI dataset of patients diagnosed with strokes from our\ninstitution to demonstrate the performance of our network. In addition to\nquantitative evaluation, we undertook a blinded comparison of image quality\nacross networks performed by a subspecialty trained radiologist. Overall, we\ndemonstrate that our network achieves a superior performance among others under\nmultiple reconstruction tasks.\n","authors":["Guoyao Shen","Boran Hao","Mengyu Li","Chad W. Farris","Ioannis Ch. Paschalidis","Stephan W. Anderson","Xin Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.12365v1.pdf","comment":"22 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2306.04719v2","updated":"2023-06-21T15:52:05Z","published":"2023-06-07T18:31:39Z","title":"Don't trust your eyes: on the (un)reliability of feature visualizations","summary":"  How do neural networks extract patterns from pixels? Feature visualizations\nattempt to answer this important question by visualizing highly activating\npatterns through optimization. Today, visualization methods form the foundation\nof our knowledge about the internal workings of neural networks, as a type of\nmechanistic interpretability. Here we ask: How reliable are feature\nvisualizations? We start our investigation by developing network circuits that\ntrick feature visualizations into showing arbitrary patterns that are\ncompletely disconnected from normal network behavior on natural input. We then\nprovide evidence for a similar phenomenon occurring in standard, unmanipulated\nnetworks: feature visualizations are processed very differently from standard\ninput, casting doubt on their ability to \"explain\" how neural networks process\nnatural images. We underpin this empirical finding by theory proving that the\nset of functions that can be reliably understood by feature visualization is\nextremely small and does not include general black-box neural networks.\nTherefore, a promising way forward could be the development of networks that\nenforce certain structures in order to ensure more reliable feature\nvisualizations.\n","authors":["Robert Geirhos","Roland S. Zimmermann","Blair Bilodeau","Wieland Brendel","Been Kim"],"pdf_url":"https://arxiv.org/pdf/2306.04719v2.pdf","comment":"Added github link to\n  https://github.com/google-research/fooling-feature-visualizations/"},{"id":"http://arxiv.org/abs/2305.18944v2","updated":"2023-06-21T15:50:08Z","published":"2023-05-30T11:20:14Z","title":"Fast Dynamic 1D Simulation of Divertor Plasmas with Neural PDE\n  Surrogates","summary":"  Managing divertor plasmas is crucial for operating reactor scale tokamak\ndevices due to heat and particle flux constraints on the divertor target.\nSimulation is an important tool to understand and control these plasmas,\nhowever, for real-time applications or exhaustive parameter scans only simple\napproximations are currently fast enough. We address this lack of fast\nsimulators using neural PDE surrogates, data-driven neural network-based\nsurrogate models trained using solutions generated with a classical numerical\nmethod. The surrogate approximates a time-stepping operator that evolves the\nfull spatial solution of a reference physics-based model over time. We use\nDIV1D, a 1D dynamic model of the divertor plasma, as reference model to\ngenerate data. DIV1D's domain covers a 1D heat flux tube from the X-point\n(upstream) to the target. We simulate a realistic TCV divertor plasma with\ndynamics induced by upstream density ramps and provide an exploratory outlook\ntowards fast transients. State-of-the-art neural PDE surrogates are evaluated\nin a common framework and extended for properties of the DIV1D data. We\nevaluate (1) the speed-accuracy trade-off; (2) recreating non-linear behavior;\n(3) data efficiency; and (4) parameter inter- and extrapolation. Once trained,\nneural PDE surrogates can faithfully approximate DIV1D's divertor plasma\ndynamics at sub real-time computation speeds: In the proposed configuration,\n2ms of plasma dynamics can be computed in $\\approx$0.63ms of wall-clock time,\nseveral orders of magnitude faster than DIV1D.\n","authors":["Yoeri Poels","Gijs Derks","Egbert Westerhof","Koen Minartz","Sven Wiesen","Vlado Menkovski"],"pdf_url":"https://arxiv.org/pdf/2305.18944v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.01457v2","updated":"2023-06-21T15:44:19Z","published":"2023-04-04T01:56:16Z","title":"Exploring Vision-Language Models for Imbalanced Learning","summary":"  Vision-Language models (VLMs) that use contrastive language-image\npre-training have shown promising zero-shot classification performance.\nHowever, their performance on imbalanced dataset is relatively poor, where the\ndistribution of classes in the training dataset is skewed, leading to poor\nperformance in predicting minority classes. For instance, CLIP achieved only 5%\naccuracy on the iNaturalist18 dataset. We propose to add a lightweight decoder\nto VLMs to avoid OOM (out of memory) problem caused by large number of classes\nand capture nuanced features for tail classes. Then, we explore improvements of\nVLMs using prompt tuning, fine-tuning, and incorporating imbalanced algorithms\nsuch as Focal Loss, Balanced SoftMax and Distribution Alignment. Experiments\ndemonstrate that the performance of VLMs can be further boosted when used with\ndecoder and imbalanced methods. Specifically, our improved VLMs significantly\noutperforms zero-shot classification by an average accuracy of 6.58%, 69.82%,\nand 6.17%, on ImageNet-LT, iNaturalist18, and Places-LT, respectively. We\nfurther analyze the influence of pre-training data size, backbones, and\ntraining cost. Our study highlights the significance of imbalanced learning\nalgorithms in face of VLMs pre-trained by huge data. We release our code at\nhttps://github.com/Imbalance-VLM/Imbalance-VLM.\n","authors":["Yidong Wang","Zhuohao Yu","Jindong Wang","Qiang Heng","Hao Chen","Wei Ye","Rui Xie","Xing Xie","Shikun Zhang"],"pdf_url":"https://arxiv.org/pdf/2304.01457v2.pdf","comment":"IJCV minor revision; 16 pages; code:\n  https://github.com/Imbalance-VLM/Imbalance-VLM"},{"id":"http://arxiv.org/abs/2306.12341v1","updated":"2023-06-21T15:39:17Z","published":"2023-06-21T15:39:17Z","title":"Geometric Pooling: maintaining more useful information","summary":"  Graph Pooling technology plays an important role in graph node classification\ntasks. Sorting pooling technologies maintain large-value units for pooling\ngraphs of varying sizes. However, by analyzing the statistical characteristic\nof activated units after pooling, we found that a large number of units dropped\nby sorting pooling are negative-value units that contain useful information and\ncan contribute considerably to the final decision. To maintain more useful\ninformation, a novel pooling technology, called Geometric Pooling (GP), was\nproposed to contain the unique node features with negative values by measuring\nthe similarity of all node features. We reveal the effectiveness of GP from the\nentropy reduction view. The experiments were conducted on TUdatasets to show\nthe effectiveness of GP. The results showed that the proposed GP outperforms\nthe SOTA graph pooling technologies by 1%\\sim5% with fewer parameters.\n","authors":["Hao Xu","Jia Liu","Yang Shen","Kenan Lou","Yanxia Bao","Ruihua Zhang","Shuyue Zhou","Hongsen Zhao","Shuai Wang"],"pdf_url":"https://arxiv.org/pdf/2306.12341v1.pdf","comment":"6 pages, 4 figures"},{"id":"http://arxiv.org/abs/2306.12321v1","updated":"2023-06-21T15:04:34Z","published":"2023-06-21T15:04:34Z","title":"Dynamic Implicit Image Function for Efficient Arbitrary-Scale Image\n  Representation","summary":"  Recent years have witnessed the remarkable success of implicit neural\nrepresentation methods. The recent work Local Implicit Image Function (LIIF)\nhas achieved satisfactory performance for continuous image representation,\nwhere pixel values are inferred from a neural network in a continuous spatial\ndomain. However, the computational cost of such implicit arbitrary-scale\nsuper-resolution (SR) methods increases rapidly as the scale factor increases,\nwhich makes arbitrary-scale SR time-consuming. In this paper, we propose\nDynamic Implicit Image Function (DIIF), which is a fast and efficient method to\nrepresent images with arbitrary resolution. Instead of taking an image\ncoordinate and the nearest 2D deep features as inputs to predict its pixel\nvalue, we propose a coordinate grouping and slicing strategy, which enables the\nneural network to perform decoding from coordinate slices to pixel value\nslices. We further propose a Coarse-to-Fine Multilayer Perceptron (C2F-MLP) to\nperform decoding with dynamic coordinate slicing, where the number of\ncoordinates in each slice varies as the scale factor varies. With dynamic\ncoordinate slicing, DIIF significantly reduces the computational cost when\nencountering arbitrary-scale SR. Experimental results demonstrate that DIIF can\nbe integrated with implicit arbitrary-scale SR methods and achieves SOTA SR\nperformance with significantly superior computational efficiency, thereby\nopening a path for real-time arbitrary-scale image representation. Our code can\nbe found at https://github.com/HeZongyao/DIIF.\n","authors":["Zongyao He","Zhi Jin"],"pdf_url":"https://arxiv.org/pdf/2306.12321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.13241v3","updated":"2023-06-21T14:36:42Z","published":"2023-03-23T13:18:05Z","title":"6D Object Pose Estimation from Approximate 3D Models for Orbital\n  Robotics","summary":"  We present a novel technique to estimate the 6D pose of objects from single\nimages where the 3D geometry of the object is only given approximately and not\nas a precise 3D model. To achieve this, we employ a dense 2D-to-3D\ncorrespondence predictor that regresses 3D model coordinates for every pixel.\nIn addition to the 3D coordinates, our model also estimates the pixel-wise\ncoordinate error to discard correspondences that are likely wrong. This allows\nus to generate multiple 6D pose hypotheses of the object, which we then refine\niteratively using a highly efficient region-based approach. We also introduce a\nnovel pixel-wise posterior formulation by which we can estimate the probability\nfor each hypothesis and select the most likely one. As we show in experiments,\nour approach is capable of dealing with extreme visual conditions including\noverexposure, high contrast, or low signal-to-noise ratio. This makes it a\npowerful technique for the particularly challenging task of estimating the pose\nof tumbling satellites for in-orbit robotic applications. Our method achieves\nstate-of-the-art performance on the SPEED+ dataset and has won the SPEC2021\npost-mortem competition.\n","authors":["Maximilian Ulmer","Maximilian Durner","Martin Sundermeyer","Manuel Stoiber","Rudolph Triebel"],"pdf_url":"https://arxiv.org/pdf/2303.13241v3.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2306.12298v1","updated":"2023-06-21T14:27:31Z","published":"2023-06-21T14:27:31Z","title":"StarVQA+: Co-training Space-Time Attention for Video Quality Assessment","summary":"  Self-attention based Transformer has achieved great success in many computer\nvision tasks. However, its application to video quality assessment (VQA) has\nnot been satisfactory so far. Evaluating the quality of in-the-wild videos is\nchallenging due to the unknown of pristine reference and shooting distortion.\nThis paper presents a co-trained Space-Time Attention network for the VQA\nproblem, termed StarVQA+. Specifically, we first build StarVQA+ by alternately\nconcatenating the divided space-time attention. Then, to facilitate the\ntraining of StarVQA+, we design a vectorized regression loss by encoding the\nmean opinion score (MOS) to the probability vector and embedding a special\ntoken as the learnable variable of MOS, leading to better fitting of human's\nrating process. Finally, to solve the data hungry problem with Transformer, we\npropose to co-train the spatial and temporal attention weights using both\nimages and videos. Various experiments are conducted on the de-facto\nin-the-wild video datasets, including LIVE-Qualcomm, LIVE-VQC, KoNViD-1k,\nYouTube-UGC, LSVQ, LSVQ-1080p, and DVL2021. Experimental results demonstrate\nthe superiority of the proposed StarVQA+ over the state-of-the-art.\n","authors":["Fengchuang Xing","Yuan-Gen Wang","Weixuan Tang","Guopu Zhu","Sam Kwong"],"pdf_url":"https://arxiv.org/pdf/2306.12298v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.11332v2","updated":"2023-06-21T14:04:45Z","published":"2023-04-22T07:11:53Z","title":"Input Augmentation with SAM: Boosting Medical Image Segmentation with\n  Segmentation Foundation Model","summary":"  The Segment Anything Model (SAM) is a recently developed large model for\ngeneral-purpose segmentation for computer vision tasks. SAM was trained using\n11 million images with over 1 billion masks and can produce segmentation\nresults for a wide range of objects in natural scene images. SAM can be viewed\nas a general perception model for segmentation (partitioning images into\nsemantically meaningful regions). Thus, how to utilize such a large foundation\nmodel for medical image segmentation is an emerging research target. This paper\nshows that although SAM does not immediately give high-quality segmentation for\nmedical image data, its generated masks, features, and stability scores are\nuseful for building and training better medical image segmentation models. In\nparticular, we demonstrate how to use SAM to augment image input for\ncommonly-used medical image segmentation models (e.g., U-Net). Experiments on\nthree segmentation tasks show the effectiveness of our proposed SAMAug method.\nThe code is available at \\url{https://github.com/yizhezhang2000/SAMAug}.\n","authors":["Yizhe Zhang","Tao Zhou","Shuo Wang","Peixian Liang","Danny Z. Chen"],"pdf_url":"https://arxiv.org/pdf/2304.11332v2.pdf","comment":"GitHub: https://github.com/yizhezhang2000/SAMAug. Comments and\n  questions are welcome"},{"id":"http://arxiv.org/abs/2306.12276v1","updated":"2023-06-21T13:57:04Z","published":"2023-06-21T13:57:04Z","title":"Wildfire Detection Via Transfer Learning: A Survey","summary":"  This paper surveys different publicly available neural network models used\nfor detecting wildfires using regular visible-range cameras which are placed on\nhilltops or forest lookout towers. The neural network models are pre-trained on\nImageNet-1K and fine-tuned on a custom wildfire dataset. The performance of\nthese models is evaluated on a diverse set of wildfire images, and the survey\nprovides useful information for those interested in using transfer learning for\nwildfire detection. Swin Transformer-tiny has the highest AUC value but\nConvNext-tiny detects all the wildfire events and has the lowest false alarm\nrate in our dataset.\n","authors":["Ziliang Hong","Emadeldeen Hamdan","Yifei Zhao","Tianxiao Ye","Hongyi Pan","A. Enis Cetin"],"pdf_url":"https://arxiv.org/pdf/2306.12276v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.00800v2","updated":"2023-06-21T13:55:08Z","published":"2023-06-01T15:28:41Z","title":"FigGen: Text to Scientific Figure Generation","summary":"  The generative modeling landscape has experienced tremendous growth in recent\nyears, particularly in generating natural images and art. Recent techniques\nhave shown impressive potential in creating complex visual compositions while\ndelivering impressive realism and quality. However, state-of-the-art methods\nhave been focusing on the narrow domain of natural images, while other\ndistributions remain unexplored. In this paper, we introduce the problem of\ntext-to-figure generation, that is creating scientific figures of papers from\ntext descriptions. We present FigGen, a diffusion-based approach for\ntext-to-figure as well as the main challenges of the proposed task. Code and\nmodels are available at https://github.com/joanrod/figure-diffusion\n","authors":["Juan A. Rodriguez","David Vazquez","Issam Laradji","Marco Pedersoli","Pau Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2306.00800v2.pdf","comment":"Published at ICLR 2023 as a Tiny Paper"},{"id":"http://arxiv.org/abs/2306.00595v4","updated":"2023-06-21T13:49:41Z","published":"2023-06-01T12:12:22Z","title":"Revisit Weakly-Supervised Audio-Visual Video Parsing from the Language\n  Perspective","summary":"  We focus on the weakly-supervised audio-visual video parsing task (AVVP),\nwhich aims to identify and locate all the events in audio/visual modalities.\nPrevious works only concentrate on video-level overall label denoising across\nmodalities, but overlook the segment-level label noise, where adjacent video\nsegments (i.e., 1-second video clips) may contain different events. However,\nrecognizing events in the segment is challenging because its label could be any\ncombination of events that occur in the video. To address this issue, we\nconsider tackling AVVP from the language perspective, since language could\nfreely describe how various events appear in each segment beyond fixed labels.\nSpecifically, we design language prompts to describe all cases of event\nappearance for each video. Then, the similarity between language prompts and\nsegments is calculated, where the event of the most similar prompt is regarded\nas the segment-level label. In addition, to deal with the mislabeled segments,\nwe propose to perform dynamic re-weighting on the unreliable segments to adjust\ntheir labels. Experiments show that our simple yet effective approach\noutperforms state-of-the-art methods by a large margin.\n","authors":["Yingying Fan","Yu Wu","Yutian Lin","Bo Du"],"pdf_url":"https://arxiv.org/pdf/2306.00595v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12244v1","updated":"2023-06-21T13:04:16Z","published":"2023-06-21T13:04:16Z","title":"Discovering Intrinsic Spatial-Temporal Logic Rules to Explain Human\n  Actions","summary":"  We propose a logic-informed knowledge-driven modeling framework for human\nmovements by analyzing their trajectories. Our approach is inspired by the fact\nthat human actions are usually driven by their intentions or desires, and are\ninfluenced by environmental factors such as the spatial relationships with\nsurrounding objects. In this paper, we introduce a set of spatial-temporal\nlogic rules as knowledge to explain human actions. These rules will be\nautomatically discovered from observational data. To learn the model parameters\nand the rule content, we design an expectation-maximization (EM) algorithm,\nwhich treats the rule content as latent variables. The EM algorithm alternates\nbetween the E-step and M-step: in the E-step, the posterior distribution over\nthe latent rule content is evaluated; in the M-step, the rule generator and\nmodel parameters are jointly optimized by maximizing the current expected\nlog-likelihood. Our model may have a wide range of applications in areas such\nas sports analytics, robotics, and autonomous cars, where understanding human\nmovements are essential. We demonstrate the model's superior interpretability\nand prediction performance on pedestrian and NBA basketball player datasets,\nboth achieving promising results.\n","authors":["Chengzhi Cao","Chao Yang","Shuang Li"],"pdf_url":"https://arxiv.org/pdf/2306.12244v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12243v1","updated":"2023-06-21T13:03:47Z","published":"2023-06-21T13:03:47Z","title":"Inter-Instance Similarity Modeling for Contrastive Learning","summary":"  The existing contrastive learning methods widely adopt one-hot instance\ndiscrimination as pretext task for self-supervised learning, which inevitably\nneglects rich inter-instance similarities among natural images, then leading to\npotential representation degeneration. In this paper, we propose a novel image\nmix method, PatchMix, for contrastive learning in Vision Transformer (ViT), to\nmodel inter-instance similarities among images. Following the nature of ViT, we\nrandomly mix multiple images from mini-batch in patch level to construct mixed\nimage patch sequences for ViT. Compared to the existing sample mix methods, our\nPatchMix can flexibly and efficiently mix more than two images and simulate\nmore complicated similarity relations among natural images. In this manner, our\ncontrastive framework can significantly reduce the gap between contrastive\nobjective and ground truth in reality. Experimental results demonstrate that\nour proposed method significantly outperforms the previous state-of-the-art on\nboth ImageNet-1K and CIFAR datasets, e.g., 3.0% linear accuracy improvement on\nImageNet-1K and 8.7% kNN accuracy improvement on CIFAR100. Moreover, our method\nachieves the leading transfer performance on downstream tasks, object detection\nand instance segmentation on COCO dataset. The code is available at\nhttps://github.com/visresearch/patchmix.\n","authors":["Chengchao Shen","Dawei Liu","Hao Tang","Zhe Qu","Jianxin Wang"],"pdf_url":"https://arxiv.org/pdf/2306.12243v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12242v1","updated":"2023-06-21T13:00:49Z","published":"2023-06-21T13:00:49Z","title":"Concurrent ischemic lesion age estimation and segmentation of CT brain\n  using a Transformer-based network","summary":"  The cornerstone of stroke care is expedient management that varies depending\non the time since stroke onset. Consequently, clinical decision making is\ncentered on accurate knowledge of timing and often requires a radiologist to\ninterpret Computed Tomography (CT) of the brain to confirm the occurrence and\nage of an event. These tasks are particularly challenging due to the subtle\nexpression of acute ischemic lesions and the dynamic nature of their\nappearance. Automation efforts have not yet applied deep learning to estimate\nlesion age and treated these two tasks independently, so, have overlooked their\ninherent complementary relationship. To leverage this, we propose a novel\nend-to-end multi-task transformer-based network optimized for concurrent\nsegmentation and age estimation of cerebral ischemic lesions. By utilizing\ngated positional self-attention and CT-specific data augmentation, the proposed\nmethod can capture long-range spatial dependencies while maintaining its\nability to be trained from scratch under low-data regimes commonly found in\nmedical imaging. Furthermore, to better combine multiple predictions, we\nincorporate uncertainty by utilizing quantile loss to facilitate estimating a\nprobability density function of lesion age. The effectiveness of our model is\nthen extensively evaluated on a clinical dataset consisting of 776 CT images\nfrom two medical centers. Experimental results demonstrate that our method\nobtains promising performance, with an area under the curve (AUC) of 0.933 for\nclassifying lesion ages <=4.5 hours compared to 0.858 using a conventional\napproach, and outperforms task-specific state-of-the-art algorithms.\n","authors":["Adam Marcus","Paul Bentley","Daniel Rueckert"],"pdf_url":"https://arxiv.org/pdf/2306.12242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12230v1","updated":"2023-06-21T12:43:55Z","published":"2023-06-21T12:43:55Z","title":"Fantastic Weights and How to Find Them: Where to Prune in Dynamic Sparse\n  Training","summary":"  Dynamic Sparse Training (DST) is a rapidly evolving area of research that\nseeks to optimize the sparse initialization of a neural network by adapting its\ntopology during training. It has been shown that under specific conditions, DST\nis able to outperform dense models. The key components of this framework are\nthe pruning and growing criteria, which are repeatedly applied during the\ntraining process to adjust the network's sparse connectivity. While the growing\ncriterion's impact on DST performance is relatively well studied, the influence\nof the pruning criterion remains overlooked. To address this issue, we design\nand perform an extensive empirical analysis of various pruning criteria to\nbetter understand their effect on the dynamics of DST solutions. Surprisingly,\nwe find that most of the studied methods yield similar results. The differences\nbecome more significant in the low-density regime, where the best performance\nis predominantly given by the simplest technique: magnitude-based pruning. The\ncode is provided at https://github.com/alooow/fantastic_weights_paper\n","authors":["Aleksandra I. Nowak","Bram Grooten","Decebal Constantin Mocanu","Jacek Tabor"],"pdf_url":"https://arxiv.org/pdf/2306.12230v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.13224v2","updated":"2023-06-21T12:35:16Z","published":"2022-11-23T18:59:05Z","title":"Peekaboo: Text to Image Diffusion Models are Zero-Shot Segmentors","summary":"  Recently, text-to-image diffusion models have shown remarkable capabilities\nin creating realistic images from natural language prompts. However, few works\nhave explored using these models for semantic localization or grounding. In\nthis work, we explore how an off-the-shelf text-to-image diffusion model,\ntrained without exposure to localization information, can ground various\nsemantic phrases without segmentation-specific re-training. We introduce an\ninference time optimization process capable of generating segmentation masks\nconditioned on natural language prompts. Our proposal, Peekaboo, is a\nfirst-of-its-kind zero-shot, open-vocabulary, unsupervised semantic grounding\ntechnique leveraging diffusion models without any training. We evaluate\nPeekaboo on the Pascal VOC dataset for unsupervised semantic segmentation and\nthe RefCOCO dataset for referring segmentation, showing results competitive\nwith promising results. We also demonstrate how Peekaboo can be used to\ngenerate images with transparency, even though the underlying diffusion model\nwas only trained on RGB images - which to our knowledge we are the first to\nattempt. Please see our project page, including our code:\nhttps://ryanndagreat.github.io/peekaboo\n","authors":["Ryan Burgert","Kanchana Ranasinghe","Xiang Li","Michael S. Ryoo"],"pdf_url":"https://arxiv.org/pdf/2211.13224v2.pdf","comment":"19 pages; contains appendix"},{"id":"http://arxiv.org/abs/2008.01478v3","updated":"2023-06-21T12:25:28Z","published":"2020-08-04T12:10:35Z","title":"Learning Interpretable Microscopic Features of Tumor by Multi-task\n  Adversarial CNNs To Improve Generalization","summary":"  Adopting Convolutional Neural Networks (CNNs) in the daily routine of primary\ndiagnosis requires not only near-perfect precision, but also a sufficient\ndegree of generalization to data acquisition shifts and transparency. Existing\nCNN models act as black boxes, not ensuring to the physicians that important\ndiagnostic features are used by the model. Building on top of successfully\nexisting techniques such as multi-task learning, domain adversarial training\nand concept-based interpretability, this paper addresses the challenge of\nintroducing diagnostic factors in the training objectives. Here we show that\nour architecture, by learning end-to-end an uncertainty-based weighting\ncombination of multi-task and adversarial losses, is encouraged to focus on\npathology features such as density and pleomorphism of nuclei, e.g. variations\nin size and appearance, while discarding misleading features such as staining\ndifferences. Our results on breast lymph node tissue show significantly\nimproved generalization in the detection of tumorous tissue, with best average\nAUC 0.89 (0.01) against the baseline AUC 0.86 (0.005). By applying the\ninterpretability technique of linearly probing intermediate representations, we\nalso demonstrate that interpretable pathology features such as nuclei density\nare learned by the proposed CNN architecture, confirming the increased\ntransparency of this model. This result is a starting point towards building\ninterpretable multi-task architectures that are robust to data heterogeneity.\nOur code is available at https://github.com/maragraziani/multitask_adversarial\n","authors":["Mara Graziani","Sebastian Otalora","Stephane Marchand-Maillet","Henning Muller","Vincent Andrearczyk"],"pdf_url":"https://arxiv.org/pdf/2008.01478v3.pdf","comment":"Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org/2023:011"},{"id":"http://arxiv.org/abs/2306.12217v1","updated":"2023-06-21T12:19:17Z","published":"2023-06-21T12:19:17Z","title":"Lumbar spine segmentation in MR images: a dataset and a public benchmark","summary":"  This paper presents a large publicly available multi-center lumbar spine\nmagnetic resonance imaging (MRI) dataset with reference segmentations of\nvertebrae, intervertebral discs (IVDs), and spinal canal. The dataset includes\n447 sagittal T1 and T2 MRI series from 218 patients with a history of low back\npain. It was collected from four different hospitals and was divided into a\ntraining (179 patients) and validation (39 patients) set. An iterative data\nannotation approach was used by training a segmentation algorithm on a small\npart of the dataset, enabling semi-automatic segmentation of the remaining\nimages. The algorithm provided an initial segmentation, which was subsequently\nreviewed, manually corrected, and added to the training data. We provide\nreference performance values for this baseline algorithm and nnU-Net, which\nperformed comparably. We set up a continuous segmentation challenge to allow\nfor a fair comparison of different segmentation algorithms. This study may\nencourage wider collaboration in the field of spine segmentation, and improve\nthe diagnostic value of lumbar spine MRI.\n","authors":["Jasper W. van der Graaf","Miranda L. van Hooff","Constantinus F. M. Buckens","Matthieu Rutten","Job L. C. van Susante","Robert Jan Kroeze","Marinus de Kleuver","Bram van Ginneken","Nikolas Lessmann"],"pdf_url":"https://arxiv.org/pdf/2306.12217v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13104v2","updated":"2023-06-21T12:03:57Z","published":"2023-01-30T17:43:47Z","title":"Equivariant Differentially Private Deep Learning: Why DP-SGD Needs\n  Sparser Models","summary":"  Differentially Private Stochastic Gradient Descent (DP-SGD) limits the amount\nof private information deep learning models can memorize during training. This\nis achieved by clipping and adding noise to the model's gradients, and thus\nnetworks with more parameters require proportionally stronger perturbation. As\na result, large models have difficulties learning useful information, rendering\ntraining with DP-SGD exceedingly difficult on more challenging training tasks.\nRecent research has focused on combating this challenge through training\nadaptations such as heavy data augmentation and large batch sizes. However,\nthese techniques further increase the computational overhead of DP-SGD and\nreduce its practical applicability. In this work, we propose using the\nprinciple of sparse model design to solve precisely such complex tasks with\nfewer parameters, higher accuracy, and in less time, thus serving as a\npromising direction for DP-SGD. We achieve such sparsity by design by\nintroducing equivariant convolutional networks for model training with\nDifferential Privacy. Using equivariant networks, we show that small and\nefficient architecture design can outperform current state-of-the-art models\nwith substantially lower computational requirements. On CIFAR-10, we achieve an\nincrease of up to $9\\%$ in accuracy while reducing the computation time by more\nthan $85\\%$. Our results are a step towards efficient model architectures that\nmake optimal use of their parameters and bridge the privacy-utility gap between\nprivate and non-private deep learning for computer vision.\n","authors":["Florian A. Hölzl","Daniel Rueckert","Georgios Kaissis"],"pdf_url":"https://arxiv.org/pdf/2301.13104v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12203v1","updated":"2023-06-21T11:55:15Z","published":"2023-06-21T11:55:15Z","title":"Polygon Detection for Room Layout Estimation using Heterogeneous Graphs\n  and Wireframes","summary":"  This paper presents a neural network based semantic plane detection method\nutilizing polygon representations. The method can for example be used to solve\nroom layout estimations tasks. The method is built on, combines and further\ndevelops several different modules from previous research. The network takes an\nRGB image and estimates a wireframe as well as a feature space using an\nhourglass backbone. From these, line and junction features are sampled. The\nlines and junctions are then represented as an undirected graph, from which\npolygon representations of the sought planes are obtained. Two different\nmethods for this last step are investigated, where the most promising method is\nbuilt on a heterogeneous graph transformer. The final output is in all cases a\nprojection of the semantic planes in 2D. The methods are evaluated on the\nStructured 3D dataset and we investigate the performance both using sampled and\nestimated wireframes. The experiments show the potential of the graph-based\nmethod by outperforming state of the art methods in Room Layout estimation in\nthe 2D metrics using synthetic wireframe detections.\n","authors":["David Gillsjö","Gabrielle Flood","Kalle Åström"],"pdf_url":"https://arxiv.org/pdf/2306.12203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12189v1","updated":"2023-06-21T11:35:37Z","published":"2023-06-21T11:35:37Z","title":"Annotating Ambiguous Images: General Annotation Strategy for Image\n  Classification with Real-World Biomedical Validation on Vertebral Fracture\n  Diagnosis","summary":"  While numerous methods exist to solve classification problems within curated\ndatasets, these solutions often fall short in biomedical applications due to\nthe biased or ambiguous nature of the data. These difficulties are particularly\nevident when inferring height reduction from vertebral data, a key component of\nthe clinically-recognized Genant score. Although strategies such as\nsemi-supervised learning, proposal usage, and class blending may provide some\nresolution, a clear and superior solution remains elusive. This paper\nintroduces a flowchart of general strategy to address these issues. We\ndemonstrate the application of this strategy by constructing a vertebral\nfracture dataset with over 300,000 annotations. This work facilitates the\ntransition of the classification problem into clinically meaningful scores and\nenriches our understanding of vertebral height reduction.\n","authors":["Lars Schmarje","Vasco Grossmann","Claudius Zelenka","Reinhard Koch"],"pdf_url":"https://arxiv.org/pdf/2306.12189v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12188v1","updated":"2023-06-21T11:35:22Z","published":"2023-06-21T11:35:22Z","title":"Facial Expression Re-targeting from a Single Character","summary":"  Video retargeting for digital face animation is used in virtual reality,\nsocial media, gaming, movies, and video conference, aiming to animate avatars'\nfacial expressions based on videos of human faces. The standard method to\nrepresent facial expressions for 3D characters is by blendshapes, a vector of\nweights representing the avatar's neutral shape and its variations under facial\nexpressions, e.g., smile, puff, blinking. Datasets of paired frames with\nblendshape vectors are rare, and labeling can be laborious, time-consuming, and\nsubjective. In this work, we developed an approach that handles the lack of\nappropriate datasets. Instead, we used a synthetic dataset of only one\ncharacter. To generalize various characters, we re-represented each frame to\nface landmarks. We developed a unique deep-learning architecture that groups\nlandmarks for each facial organ and connects them to relevant blendshape\nweights. Additionally, we incorporated complementary methods for facial\nexpressions that landmarks did not represent well and gave special attention to\neye expressions. We have demonstrated the superiority of our approach to\nprevious research in qualitative and quantitative metrics. Our approach\nachieved a higher MOS of 68% and a lower MSE of 44.2% when tested on videos\nwith various users and expressions.\n","authors":["Ariel Larey","Omri Asraf","Adam Kelder","Itzik Wilf","Ofer Kruzel","Nati Daniel"],"pdf_url":"https://arxiv.org/pdf/2306.12188v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.07611v2","updated":"2023-06-21T11:35:00Z","published":"2023-05-12T16:56:13Z","title":"Multimodal Sentiment Analysis: A Survey","summary":"  Multimodal sentiment analysis has become an important research area in the\nfield of artificial intelligence. With the latest advances in deep learning,\nthis technology has reached new heights. It has great potential for both\napplication and research, making it a popular research topic. This review\nprovides an overview of the definition, background, and development of\nmultimodal sentiment analysis. It also covers recent datasets and advanced\nmodels, emphasizing the challenges and future prospects of this technology.\nFinally, it looks ahead to future research directions. It should be noted that\nthis review provides constructive suggestions for promising research directions\nand building better performing multimodal sentiment analysis models, which can\nhelp researchers in this field.\n","authors":["Songning Lai","Haoxuan Xu","Xifeng Hu","Zhaoxia Ren","Zhi Liu"],"pdf_url":"https://arxiv.org/pdf/2305.07611v2.pdf","comment":"It needs to be returned for major modifications"},{"id":"http://arxiv.org/abs/2305.20055v3","updated":"2023-06-21T11:34:33Z","published":"2023-05-31T17:28:13Z","title":"Cross-Domain Car Detection Model with Integrated Convolutional Block\n  Attention Mechanism","summary":"  Car detection, particularly through camera vision, has become a major focus\nin the field of computer vision and has gained widespread adoption. While\ncurrent car detection systems are capable of good detection, reliable detection\ncan still be challenging due to factors such as proximity between the car,\nlight intensity, and environmental visibility. To address these issues, we\npropose cross-domain Car Detection Model with integrated convolutional block\nAttention mechanism(CDMA) that we apply to car recognition for autonomous\ndriving and other areas. CDMA includes several novelties: 1)Building a complete\ncross-domain target detection framework. 2)Developing an unpaired target domain\npicture generation module with an integrated convolutional attention mechanism\nwhich specifically emphasizes the car headlights feature. 3)Adopting\nGeneralized Intersection over Union (GIOU) as the loss function of the target\ndetection framework. 4)Designing an object detection model integrated with\ntwo-headed Convolutional Block Attention Module(CBAM). 5)Utilizing an effective\ndata enhancement method. To evaluate the model's effectiveness, we performed a\nreduced will resolution process on the data in the SSLAD dataset and used it as\nthe benchmark dataset for our task. Experimental results show that the\nperformance of the cross-domain car target detection model improves by 40% over\nthe model without our framework, and our improvements have a significant impact\non cross-domain car recognition.\n","authors":["Haoxuan Xu","Songning Lai","Xianyang Li","Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2305.20055v3.pdf","comment":"It needs to be returned for major modifications"},{"id":"http://arxiv.org/abs/2207.09934v5","updated":"2023-06-21T11:31:28Z","published":"2022-07-20T14:20:35Z","title":"DeepIPC: Deeply Integrated Perception and Control for an Autonomous\n  Vehicle in Real Environments","summary":"  We propose DeepIPC, an end-to-end autonomous driving model that handles both\nperception and control tasks in driving a vehicle. The model consists of two\nmain parts, perception and controller modules. The perception module takes an\nRGBD image to perform semantic segmentation and bird's eye view (BEV) semantic\nmapping along with providing their encoded features. Meanwhile, the controller\nmodule processes these features with the measurement of GNSS locations and\nangular speed to estimate waypoints that come with latent features. Then, two\ndifferent agents are used to translate waypoints and latent features into a set\nof navigational controls to drive the vehicle. The model is evaluated by\npredicting driving records and performing automated driving under various\nconditions in real environments. The experimental results show that DeepIPC\nachieves the best drivability and multi-task performance even with fewer\nparameters compared to the other models. Codes will be published at\nhttps://github.com/oskarnatan/DeepIPC.\n","authors":["Oskar Natan","Jun Miura"],"pdf_url":"https://arxiv.org/pdf/2207.09934v5.pdf","comment":"Submitted to Robotics and Autonomous Systems"},{"id":"http://arxiv.org/abs/2306.12174v1","updated":"2023-06-21T11:09:48Z","published":"2023-06-21T11:09:48Z","title":"OphGLM: Training an Ophthalmology Large Language-and-Vision Assistant\n  based on Instructions and Dialogue","summary":"  Large multimodal language models (LMMs) have achieved significant success in\ngeneral domains. However, due to the significant differences between medical\nimages and text and general web content, the performance of LMMs in medical\nscenarios is limited. In ophthalmology, clinical diagnosis relies on multiple\nmodalities of medical images, but unfortunately, multimodal ophthalmic large\nlanguage models have not been explored to date. In this paper, we study and\nconstruct an ophthalmic large multimodal model. Firstly, we use fundus images\nas an entry point to build a disease assessment and diagnosis pipeline to\nachieve common ophthalmic disease diagnosis and lesion segmentation. Then, we\nestablish a new ophthalmic multimodal instruction-following and dialogue\nfine-tuning dataset based on disease-related knowledge data and publicly\navailable real-world medical dialogue. We introduce visual ability into the\nlarge language model to complete the ophthalmic large language and vision\nassistant (OphGLM). Our experimental results demonstrate that the OphGLM model\nperforms exceptionally well, and it has the potential to revolutionize clinical\napplications in ophthalmology. The dataset, code, and models will be made\npublicly available at https://github.com/ML-AILab/OphGLM.\n","authors":["Weihao Gao","Zhuo Deng","Zhiyuan Niu","Fuju Rong","Chucheng Chen","Zheng Gong","Wenze Zhang","Daimin Xiao","Fang Li","Zhenjie Cao","Lan Ma"],"pdf_url":"https://arxiv.org/pdf/2306.12174v1.pdf","comment":"OphGLM:The first ophthalmology Large Language-and-Vision Assistant\n  based on Instructions and Dialogue"},{"id":"http://arxiv.org/abs/2112.05478v3","updated":"2023-06-21T11:06:04Z","published":"2021-12-10T12:12:00Z","title":"Critical configurations for three projective views","summary":"  The problem of structure from motion is concerned with recovering the\n3-dimensional structure of an object from a set of 2-dimensional images taken\nby unknown cameras. Generally, all information can be uniquely recovered if\nenough images and point correspondences are provided, yet there are certain\ncases where unique recovery is impossible; these are called critical\nconfigurations. We use an algebraic approach to study the critical\nconfigurations for three projective cameras. We show that all critical\nconfigurations lie on the intersection of quadric surfaces, and classify\nexactly which intersections constitute a critical configuration.\n","authors":["Martin Bråtelund"],"pdf_url":"https://arxiv.org/pdf/2112.05478v3.pdf","comment":"40 pages, 9 figures. This is a companion paper to arXiv:2112.05074.\n  Accepted manuscript, to appear in Mathematica Scandinavica"},{"id":"http://arxiv.org/abs/2305.03678v2","updated":"2023-06-21T10:50:09Z","published":"2023-05-05T16:48:45Z","title":"How Segment Anything Model (SAM) Boost Medical Image Segmentation: A\n  Survey","summary":"  Due to the flexibility of prompting, foundation models have become the\ndominant force in the domains of natural language processing and image\ngeneration. With the recent introduction of the Segment Anything Model (SAM),\nthe prompt-driven paradigm has entered the realm of image segmentation,\nbringing with a range of previously unexplored capabilities. However, it\nremains unclear whether it can be applicable to medical image segmentation due\nto the significant differences between natural images and medical images. In\nthis work, we summarize recent efforts to extend the success of SAM to medical\nimage segmentation tasks, including both empirical benchmarking and\nmethodological adaptations, and discuss potential future directions for SAM in\nmedical image segmentation. Although directly applying SAM to medical image\nsegmentation cannot obtain satisfying performance on multi-modal and\nmulti-target medical datasets, many insights are drawn to guide future research\nto develop foundation models for medical image analysis. We also set up a\ncontinuously updated paper list and open-source project summary to boost the\nresearch on this topic at https://github.com/YichiZhang98/SAM4MIS.\n","authors":["Yichi Zhang","Rushi Jiao"],"pdf_url":"https://arxiv.org/pdf/2305.03678v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.08648v2","updated":"2023-06-21T10:48:12Z","published":"2023-06-14T17:28:45Z","title":"SimpleMapping: Real-Time Visual-Inertial Dense Mapping with Deep\n  Multi-View Stereo","summary":"  We present a real-time visual-inertial dense mapping method capable of\nperforming incremental 3D mesh reconstruction with high quality using only\nsequential monocular images and inertial measurement unit (IMU) readings. 6-DoF\ncamera poses are estimated by a robust feature-based visual-inertial odometry\n(VIO), which also generates noisy sparse 3D map points as a by-product. We\npropose a sparse point aided multi-view stereo neural network (SPA-MVSNet) that\ncan effectively leverage the informative but noisy sparse points from the VIO\nsystem. The sparse depth from VIO is firstly completed by a single-view depth\ncompletion network. This dense depth map, although naturally limited in\naccuracy, is then used as a prior to guide our MVS network in the cost volume\ngeneration and regularization for accurate dense depth prediction. Predicted\ndepth maps of keyframe images by the MVS network are incrementally fused into a\nglobal map using TSDF-Fusion. We extensively evaluate both the proposed\nSPA-MVSNet and the entire visual-inertial dense mapping system on several\npublic datasets as well as our own dataset, demonstrating the system's\nimpressive generalization capabilities and its ability to deliver high-quality\n3D mesh reconstruction online. Our proposed dense mapping system achieves a\n39.7% improvement in F-score over existing systems when evaluated on the\nchallenging scenarios of the EuRoC dataset.\n","authors":["Yingye Xin","Xingxing Zuo","Dongyue Lu","Stefan Leutenegger"],"pdf_url":"https://arxiv.org/pdf/2306.08648v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12156v1","updated":"2023-06-21T10:08:29Z","published":"2023-06-21T10:08:29Z","title":"Fast Segment Anything","summary":"  The recently proposed segment anything model (SAM) has made a significant\ninfluence in many computer vision tasks. It is becoming a foundation step for\nmany high-level tasks, like image segmentation, image caption, and image\nediting. However, its huge computation costs prevent it from wider applications\nin industry scenarios. The computation mainly comes from the Transformer\narchitecture at high-resolution inputs. In this paper, we propose a speed-up\nalternative method for this fundamental task with comparable performance. By\nreformulating the task as segments-generation and prompting, we find that a\nregular CNN detector with an instance segmentation branch can also accomplish\nthis task well. Specifically, we convert this task to the well-studied instance\nsegmentation task and directly train the existing instance segmentation method\nusing only 1/50 of the SA-1B dataset published by SAM authors. With our method,\nwe achieve a comparable performance with the SAM method at 50 times higher\nrun-time speed. We give sufficient experimental results to demonstrate its\neffectiveness. The codes and demos will be released at\nhttps://github.com/CASIA-IVA-Lab/FastSAM.\n","authors":["Xu Zhao","Wenchao Ding","Yongqi An","Yinglong Du","Tao Yu","Min Li","Ming Tang","Jinqiao Wang"],"pdf_url":"https://arxiv.org/pdf/2306.12156v1.pdf","comment":"Technical Report. The code is released at\n  https://github.com/CASIA-IVA-Lab/FastSAM"},{"id":"http://arxiv.org/abs/2306.12155v1","updated":"2023-06-21T10:07:17Z","published":"2023-06-21T10:07:17Z","title":"Joint Dense-Point Representation for Contour-Aware Graph Segmentation","summary":"  We present a novel methodology that combines graph and dense segmentation\ntechniques by jointly learning both point and pixel contour representations,\nthereby leveraging the benefits of each approach. This addresses deficiencies\nin typical graph segmentation methods where misaligned objectives restrict the\nnetwork from learning discriminative vertex and contour features. Our joint\nlearning strategy allows for rich and diverse semantic features to be encoded,\nwhile alleviating common contour stability issues in dense-based approaches,\nwhere pixel-level objectives can lead to anatomically implausible topologies.\nIn addition, we identify scenarios where correct predictions that fall on the\ncontour boundary are penalised and address this with a novel hybrid contour\ndistance loss. Our approach is validated on several Chest X-ray datasets,\ndemonstrating clear improvements in segmentation stability and accuracy against\na variety of dense- and point-based methods. Our source code is freely\navailable at: www.github.com/kitbransby/Joint_Graph_Segmentation\n","authors":["Kit Mills Bransby","Greg Slabaugh","Christos Bourantas","Qianni Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.12155v1.pdf","comment":"MICCAI 2023 pre-print"},{"id":"http://arxiv.org/abs/2306.12153v1","updated":"2023-06-21T10:03:56Z","published":"2023-06-21T10:03:56Z","title":"DIAS: A Comprehensive Benchmark for DSA-sequence Intracranial Artery\n  Segmentation","summary":"  Automatic segmentation of the intracranial artery (IA) in digital subtraction\nangiography (DSA) sequence is an essential step in diagnosing IA-related\ndiseases and guiding neuro-interventional surgery. However, the lack of\npublicly available datasets has impeded research in this area. In this paper,\nwe release DIAS, an IA segmentation dataset, consisting of 120 DSA sequences\nfrom intracranial interventional therapy. In addition to pixel-wise\nannotations, this dataset provides two types of scribble annotations for weakly\nsupervised IA segmentation research. We present a comprehensive benchmark for\nevaluating the performance of this challenging dataset by utilizing fully-,\nweakly-, and semi-supervised learning approaches. Specifically, we propose a\nmethod that incorporates a dimensionality reduction module into a 2D/3D model\nto achieve vessel segmentation in DSA sequences. For weakly-supervised\nlearning, we propose a scribble learning-based image segmentation framework,\nSSCR, which comprises scribble supervision and consistency regularization.\nFurthermore, we introduce a random patch-based self-training framework that\nutilizes unlabeled DSA sequences to improve segmentation performance. Our\nextensive experiments on the DIAS dataset demonstrate the effectiveness of\nthese methods as potential baselines for future research and clinical\napplications.\n","authors":["Wentao Liu","Tong Tian","Lemeng Wang","Weijin Xu","Haoyuan Li","Wenyi Zhao","Xipeng Pan","Huihua Yang","Feng Gao","Yiming Deng","Ruisheng Su"],"pdf_url":"https://arxiv.org/pdf/2306.12153v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.14520v2","updated":"2023-06-21T09:56:57Z","published":"2023-04-27T20:21:18Z","title":"Multimodal Dataset from Harsh Sub-Terranean Environment with Aerosol\n  Particles for Frontier Exploration","summary":"  Algorithms for autonomous navigation in environments without Global\nNavigation Satellite System (GNSS) coverage mainly rely on onboard perception\nsystems. These systems commonly incorporate sensors like cameras and Light\nDetection and Rangings (LiDARs), the performance of which may degrade in the\npresence of aerosol particles. Thus, there is a need of fusing acquired data\nfrom these sensors with data from Radio Detection and Rangings (RADARs) which\ncan penetrate through such particles. Overall, this will improve the\nperformance of localization and collision avoidance algorithms under such\nenvironmental conditions. This paper introduces a multimodal dataset from the\nharsh and unstructured underground environment with aerosol particles. A\ndetailed description of the onboard sensors and the environment, where the\ndataset is collected are presented to enable full evaluation of acquired data.\nFurthermore, the dataset contains synchronized raw data measurements from all\nonboard sensors in Robot Operating System (ROS) format to facilitate the\nevaluation of navigation, and localization algorithms in such environments. In\ncontrast to the existing datasets, the focus of this paper is not only to\ncapture both temporal and spatial data diversities but also to present the\nimpact of harsh conditions on captured data. Therefore, to validate the\ndataset, a preliminary comparison of odometry from onboard LiDARs is presented.\n","authors":["Alexander Kyuroson","Niklas Dahlquist","Nikolaos Stathoulopoulos","Vignesh Kottayam Viswanathan","Anton Koval","George Nikolakopoulos"],"pdf_url":"https://arxiv.org/pdf/2304.14520v2.pdf","comment":"Accepted in the 31st Mediterranean Conference on Control and\n  Automation [MED2023]"},{"id":"http://arxiv.org/abs/2306.12152v1","updated":"2023-06-21T09:56:55Z","published":"2023-06-21T09:56:55Z","title":"Exploiting Multimodal Synthetic Data for Egocentric Human-Object\n  Interaction Detection in an Industrial Scenario","summary":"  In this paper, we tackle the problem of Egocentric Human-Object Interaction\n(EHOI) detection in an industrial setting. To overcome the lack of public\ndatasets in this context, we propose a pipeline and a tool for generating\nsynthetic images of EHOIs paired with several annotations and data signals\n(e.g., depth maps or instance segmentation masks). Using the proposed pipeline,\nwe present EgoISM-HOI a new multimodal dataset composed of synthetic EHOI\nimages in an industrial environment with rich annotations of hands and objects.\nTo demonstrate the utility and effectiveness of synthetic EHOI data produced by\nthe proposed tool, we designed a new method that predicts and combines\ndifferent multimodal signals to detect EHOIs in RGB images. Our study shows\nthat exploiting synthetic data to pre-train the proposed method significantly\nimproves performance when tested on real-world data. Moreover, the proposed\napproach outperforms state-of-the-art class-agnostic methods. To support\nresearch in this field, we publicly release the datasets, source code, and\npre-trained models at https://iplab.dmi.unict.it/egoism-hoi.\n","authors":["Rosario Leonardi","Francesco Ragusa","Antonino Furnari","Giovanni Maria Farinella"],"pdf_url":"https://arxiv.org/pdf/2306.12152v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12150v1","updated":"2023-06-21T09:53:37Z","published":"2023-06-21T09:53:37Z","title":"Benchmark data to study the influence of pre-training on explanation\n  performance in MR image classification","summary":"  Convolutional Neural Networks (CNNs) are frequently and successfully used in\nmedical prediction tasks. They are often used in combination with transfer\nlearning, leading to improved performance when training data for the task are\nscarce. The resulting models are highly complex and typically do not provide\nany insight into their predictive mechanisms, motivating the field of\n'explainable' artificial intelligence (XAI). However, previous studies have\nrarely quantitatively evaluated the 'explanation performance' of XAI methods\nagainst ground-truth data, and transfer learning and its influence on objective\nmeasures of explanation performance has not been investigated. Here, we propose\na benchmark dataset that allows for quantifying explanation performance in a\nrealistic magnetic resonance imaging (MRI) classification task. We employ this\nbenchmark to understand the influence of transfer learning on the quality of\nexplanations. Experimental results show that popular XAI methods applied to the\nsame underlying model differ vastly in performance, even when considering only\ncorrectly classified examples. We further observe that explanation performance\nstrongly depends on the task used for pre-training and the number of CNN layers\npre-trained. These results hold after correcting for a substantial correlation\nbetween explanation and classification performance.\n","authors":["Marta Oliveira","Rick Wilming","Benedict Clark","Céline Budding","Fabian Eitel","Kerstin Ritter","Stefan Haufe"],"pdf_url":"https://arxiv.org/pdf/2306.12150v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2306.12113v1","updated":"2023-06-21T08:55:45Z","published":"2023-06-21T08:55:45Z","title":"Lightweight wood panel defect detection method incorporating attention\n  mechanism and feature fusion network","summary":"  In recent years, deep learning has made significant progress in wood panel\ndefect detection. However, there are still challenges such as low detection ,\nslow detection speed, and difficulties in deploying embedded devices on wood\npanel surfaces. To overcome these issues, we propose a lightweight wood panel\ndefect detection method called YOLOv5-LW, which incorporates attention\nmechanisms and a feature fusion network.Firstly, to enhance the detection\ncapability of acceptable defects, we introduce the Multi-scale Bi-directional\nFeature Pyramid Network (MBiFPN) as a feature fusion network. The MBiFPN\nreduces feature loss, enriches local and detailed features, and improves the\nmodel's detection capability for acceptable defects.Secondly, to achieve a\nlightweight design, we reconstruct the ShuffleNetv2 network model as the\nbackbone network. This reconstruction reduces the number of parameters and\ncomputational requirements while maintaining performance. We also introduce the\nStem Block and Spatial Pyramid Pooling Fast (SPPF) models to compensate for any\naccuracy loss resulting from the lightweight design, ensuring the model's\ndetection capabilities remain intact while being computationally\nefficient.Thirdly, we enhance the backbone network by incorporating Efficient\nChannel Attention (ECA), which improves the network's focus on key information\nrelevant to defect detection. By attending to essential features, the model\nbecomes more proficient in accurately identifying and localizing defects.We\nvalidate the proposed method using a self-developed wood panel defect\ndataset.The experimental results demonstrate the effectiveness of the improved\nYOLOv5-LW method. Compared to the original model, our approach achieves a\n92.8\\% accuracy rate, reduces the number of parameters by 27.78\\%, compresses\ncomputational volume by 41.25\\%, improves detection inference speed by 10.16\\%\n","authors":["Yongxin Cao","Fanghua Liu","Lai Jiang","Cheng Bao","You Miao","Yang Chen"],"pdf_url":"https://arxiv.org/pdf/2306.12113v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12111v1","updated":"2023-06-21T08:52:35Z","published":"2023-06-21T08:52:35Z","title":"A Comprehensive Study on the Robustness of Image Classification and\n  Object Detection in Remote Sensing: Surveying and Benchmarking","summary":"  Deep neural networks (DNNs) have found widespread applications in\ninterpreting remote sensing (RS) imagery. However, it has been demonstrated in\nprevious works that DNNs are vulnerable to different types of noises,\nparticularly adversarial noises. Surprisingly, there has been a lack of\ncomprehensive studies on the robustness of RS tasks, prompting us to undertake\na thorough survey and benchmark on the robustness of image classification and\nobject detection in RS. To our best knowledge, this study represents the first\ncomprehensive examination of both natural robustness and adversarial robustness\nin RS tasks. Specifically, we have curated and made publicly available datasets\nthat contain natural and adversarial noises. These datasets serve as valuable\nresources for evaluating the robustness of DNNs-based models. To provide a\ncomprehensive assessment of model robustness, we conducted meticulous\nexperiments with numerous different classifiers and detectors, encompassing a\nwide range of mainstream methods. Through rigorous evaluation, we have\nuncovered insightful and intriguing findings, which shed light on the\nrelationship between adversarial noise crafting and model training, yielding a\ndeeper understanding of the susceptibility and limitations of various models,\nand providing guidance for the development of more resilient and robust models\n","authors":["Shaohui Mei","Jiawei Lian","Xiaofei Wang","Yuru Su","Mingyang Ma","Lap-Pui Chau"],"pdf_url":"https://arxiv.org/pdf/2306.12111v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12109v1","updated":"2023-06-21T08:49:28Z","published":"2023-06-21T08:49:28Z","title":"DiffuseIR:Diffusion Models For Isotropic Reconstruction of 3D\n  Microscopic Images","summary":"  Three-dimensional microscopy is often limited by anisotropic spatial\nresolution, resulting in lower axial resolution than lateral resolution.\nCurrent State-of-The-Art (SoTA) isotropic reconstruction methods utilizing deep\nneural networks can achieve impressive super-resolution performance in fixed\nimaging settings. However, their generality in practical use is limited by\ndegraded performance caused by artifacts and blurring when facing unseen\nanisotropic factors. To address these issues, we propose DiffuseIR, an\nunsupervised method for isotropic reconstruction based on diffusion models.\nFirst, we pre-train a diffusion model to learn the structural distribution of\nbiological tissue from lateral microscopic images, resulting in generating\nnaturally high-resolution images. Then we use low-axial-resolution microscopy\nimages to condition the generation process of the diffusion model and generate\nhigh-axial-resolution reconstruction results. Since the diffusion model learns\nthe universal structural distribution of biological tissues, which is\nindependent of the axial resolution, DiffuseIR can reconstruct authentic images\nwith unseen low-axial resolutions into a high-axial resolution without\nrequiring re-training. The proposed DiffuseIR achieves SoTA performance in\nexperiments on EM data and can even compete with supervised methods.\n","authors":["Mingjie Pan","Yulu Gan","Fangxu Zhou","Jiaming Liu","Aimin Wang","Shanghang Zhang","Dawei Li"],"pdf_url":"https://arxiv.org/pdf/2306.12109v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12106v1","updated":"2023-06-21T08:47:20Z","published":"2023-06-21T08:47:20Z","title":"ViTEraser: Harnessing the Power of Vision Transformers for Scene Text\n  Removal with SegMIM Pretraining","summary":"  Scene text removal (STR) aims at replacing text strokes in natural scenes\nwith visually coherent backgrounds. Recent STR approaches rely on iterative\nrefinements or explicit text masks, resulting in higher complexity and\nsensitivity to the accuracy of text localization. Moreover, most existing STR\nmethods utilize convolutional neural networks (CNNs) for feature representation\nwhile the potential of vision Transformers (ViTs) remains largely unexplored.\nIn this paper, we propose a simple-yet-effective ViT-based text eraser, dubbed\nViTEraser. Following a concise encoder-decoder framework, different types of\nViTs can be easily integrated into ViTEraser to enhance the long-range\ndependencies and global reasoning. Specifically, the encoder hierarchically\nmaps the input image into the hidden space through ViT blocks and patch\nembedding layers, while the decoder gradually upsamples the hidden features to\nthe text-erased image with ViT blocks and patch splitting layers. As ViTEraser\nimplicitly integrates text localization and inpainting, we propose a novel\nend-to-end pretraining method, termed SegMIM, which focuses the encoder and\ndecoder on the text box segmentation and masked image modeling tasks,\nrespectively. To verify the effectiveness of the proposed methods, we\ncomprehensively explore the architecture, pretraining, and scalability of the\nViT-based encoder-decoder for STR, which provides deep insights into the\napplication of ViT to STR. Experimental results demonstrate that ViTEraser with\nSegMIM achieves state-of-the-art performance on STR by a substantial margin.\nFurthermore, the extended experiment on tampered scene text detection\ndemonstrates the generality of ViTEraser to other tasks. We believe this paper\ncan inspire more research on ViT-based STR approaches. Code will be available\nat https://github.com/shannanyinxiang/ViTEraser.\n","authors":["Dezhi Peng","Chongyu Liu","Yuliang Liu","Lianwen Jin"],"pdf_url":"https://arxiv.org/pdf/2306.12106v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12100v1","updated":"2023-06-21T08:28:51Z","published":"2023-06-21T08:28:51Z","title":"Efficient ResNets: Residual Network Design","summary":"  ResNets (or Residual Networks) are one of the most commonly used models for\nimage classification tasks. In this project, we design and train a modified\nResNet model for CIFAR-10 image classification. In particular, we aimed at\nmaximizing the test accuracy on the CIFAR-10 benchmark while keeping the size\nof our ResNet model under the specified fixed budget of 5 million trainable\nparameters. Model size, typically measured as the number of trainable\nparameters, is important when models need to be stored on devices with limited\nstorage capacity (e.g. IoT/edge devices). In this article, we present our\nresidual network design which has less than 5 million parameters. We show that\nour ResNet achieves a test accuracy of 96.04% on CIFAR-10 which is much higher\nthan ResNet18 (which has greater than 11 million trainable parameters) when\nequipped with a number of training strategies and suitable ResNet\nhyperparameters. Models and code are available at\nhttps://github.com/Nikunj-Gupta/Efficient_ResNets.\n","authors":["Aditya Thakur","Harish Chauhan","Nikunj Gupta"],"pdf_url":"https://arxiv.org/pdf/2306.12100v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12093v1","updated":"2023-06-21T08:13:41Z","published":"2023-06-21T08:13:41Z","title":"Edge Devices Inference Performance Comparison","summary":"  In this work, we investigate the inference time of the MobileNet family,\nEfficientNet V1 and V2 family, VGG models, Resnet family, and InceptionV3 on\nfour edge platforms. Specifically NVIDIA Jetson Nano, Intel Neural Stick,\nGoogle Coral USB Dongle, and Google Coral PCIe. Our main contribution is a\nthorough analysis of the aforementioned models in multiple settings, especially\nas a function of input size, the presence of the classification head, its size,\nand the scale of the model. Since throughout the industry, those architectures\nare mainly utilized as feature extractors we put our main focus on analyzing\nthem as such. We show that Google platforms offer the fastest average inference\ntime, especially for newer models like MobileNet or EfficientNet family, while\nIntel Neural Stick is the most universal accelerator allowing to run most\narchitectures. These results should provide guidance for engineers in the early\nstages of AI edge systems development. All of them are accessible at\nhttps://bulletprove.com/research/edge_inference_results.csv\n","authors":["R. Tobiasz","G. Wilczyński","P. Graszka","N. Czechowski","S. Łuczak"],"pdf_url":"https://arxiv.org/pdf/2306.12093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12085v1","updated":"2023-06-21T08:04:30Z","published":"2023-06-21T08:04:30Z","title":"HSR-Diff:Hyperspectral Image Super-Resolution via Conditional Diffusion\n  Models","summary":"  Despite the proven significance of hyperspectral images (HSIs) in performing\nvarious computer vision tasks, its potential is adversely affected by the\nlow-resolution (LR) property in the spatial domain, resulting from multiple\nphysical factors. Inspired by recent advancements in deep generative models, we\npropose an HSI Super-resolution (SR) approach with Conditional Diffusion Models\n(HSR-Diff) that merges a high-resolution (HR) multispectral image (MSI) with\nthe corresponding LR-HSI. HSR-Diff generates an HR-HSI via repeated refinement,\nin which the HR-HSI is initialized with pure Gaussian noise and iteratively\nrefined. At each iteration, the noise is removed with a Conditional Denoising\nTransformer (CDF ormer) that is trained on denoising at different noise levels,\nconditioned on the hierarchical feature maps of HR-MSI and LR-HSI. In addition,\na progressive learning strategy is employed to exploit the global information\nof full-resolution images. Systematic experiments have been conducted on four\npublic datasets, demonstrating that HSR-Diff outperforms state-of-the-art\nmethods.\n","authors":["Chanyue Wu","Dong Wang","Hanyu Mao","Ying Li"],"pdf_url":"https://arxiv.org/pdf/2306.12085v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12078v1","updated":"2023-06-21T07:53:00Z","published":"2023-06-21T07:53:00Z","title":"Accelerating Multiframe Blind Deconvolution via Deep Learning","summary":"  Ground-based solar image restoration is a computationally expensive procedure\nthat involves nonlinear optimization techniques. The presence of atmospheric\nturbulence produces perturbations in individual images that make it necessary\nto apply blind deconvolution techniques. These techniques rely on the\nobservation of many short exposure frames that are used to simultaneously infer\nthe instantaneous state of the atmosphere and the unperturbed object. We have\nrecently explored the use of machine learning to accelerate this process, with\npromising results. We build upon this previous work to propose several\ninteresting improvements that lead to better models. As well, we propose a new\nmethod to accelerate the restoration based on algorithm unrolling. In this\nmethod, the image restoration problem is solved with a gradient descent method\nthat is unrolled and accelerated aided by a few small neural networks. The role\nof the neural networks is to correct the estimation of the solution at each\niterative step. The model is trained to perform the optimization in a small\nfixed number of steps with a curated dataset. Our findings demonstrate that\nboth methods significantly reduce the restoration time compared to the standard\noptimization procedure. Furthermore, we showcase that these models can be\ntrained in an unsupervised manner using observed images from three different\ninstruments. Remarkably, they also exhibit robust generalization capabilities\nwhen applied to new datasets. To foster further research and collaboration, we\nopenly provide the trained models, along with the corresponding training and\nevaluation code, as well as the training dataset, to the scientific community.\n","authors":["A. Asensio Ramos","S. Esteban Pozuelo","C. Kuckein"],"pdf_url":"https://arxiv.org/pdf/2306.12078v1.pdf","comment":"26 pages, 9 figures, accepted for publication in Solar Physics"},{"id":"http://arxiv.org/abs/2306.06908v2","updated":"2023-06-21T07:52:47Z","published":"2023-06-12T07:26:21Z","title":"Active Learning Guided Fine-Tuning for enhancing Self-Supervised Based\n  Multi-Label Classification of Remote Sensing Images","summary":"  In recent years, deep neural networks (DNNs) have been found very successful\nfor multi-label classification (MLC) of remote sensing (RS) images.\nSelf-supervised pre-training combined with fine-tuning on a randomly selected\nsmall training set has become a popular approach to minimize annotation efforts\nof data-demanding DNNs. However, fine-tuning on a small and biased training set\nmay limit model performance. To address this issue, we investigate the\neffectiveness of the joint use of self-supervised pre-training with active\nlearning (AL). The considered AL strategy aims at guiding the MLC fine-tuning\nof a self-supervised model by selecting informative training samples to\nannotate in an iterative manner. Experimental results show the effectiveness of\napplying AL-guided fine-tuning (particularly for the case where strong\nclass-imbalance is present in MLC problems) compared to the application of\nfine-tuning using a randomly constructed small training set.\n","authors":["Lars Möllenbrok","Begüm Demir"],"pdf_url":"https://arxiv.org/pdf/2306.06908v2.pdf","comment":"Accepted at IEEE International Geoscience and Remote Sensing\n  Symposium 2023"},{"id":"http://arxiv.org/abs/2306.08013v2","updated":"2023-06-21T07:51:07Z","published":"2023-06-13T11:46:00Z","title":"TopP&R: Robust Support Estimation Approach for Evaluating Fidelity and\n  Diversity in Generative Models","summary":"  We propose a robust and reliable evaluation metric for generative models by\nintroducing topological and statistical treatments for rigorous support\nestimation. Existing metrics, such as Inception Score (IS), Frechet Inception\nDistance (FID), and the variants of Precision and Recall (P&R), heavily rely on\nsupports that are estimated from sample features. However, the reliability of\ntheir estimation has not been seriously discussed (and overlooked) even though\nthe quality of the evaluation entirely depends on it. In this paper, we propose\nTopological Precision and Recall (TopP&R, pronounced 'topper'), which provides\na systematic approach to estimating supports, retaining only topologically and\nstatistically important features with a certain level of confidence. This not\nonly makes TopP&R strong for noisy features, but also provides statistical\nconsistency. Our theoretical and experimental results show that TopP&R is\nrobust to outliers and non-independent and identically distributed (Non-IID)\nperturbations, while accurately capturing the true trend of change in samples.\nTo the best of our knowledge, this is the first evaluation metric focused on\nthe robust estimation of the support and provides its statistical consistency\nunder noise.\n","authors":["Pum Jun Kim","Yoojin Jang","Jisu Kim","Jaejun Yoo"],"pdf_url":"https://arxiv.org/pdf/2306.08013v2.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2306.12073v1","updated":"2023-06-21T07:46:27Z","published":"2023-06-21T07:46:27Z","title":"NeuroCLIP: Neuromorphic Data Understanding by CLIP and SNN","summary":"  Recently, the neuromorphic vision sensor has received more and more interest.\nHowever, the neuromorphic data consists of asynchronous event spikes, which is\nnot natural and difficult to construct a benchmark, thus limiting the\nneuromorphic data understanding for \"unseen\" objects by deep learning.\nZero-shot and few-shot learning via Contrastive Vision-Language Pre-training\n(CLIP) have shown inspirational performance in 2D frame image recognition. To\nhandle \"unseen\" recognition for the neuromorphic data, in this paper, we\npropose NeuroCLIP, which transfers the CLIP's 2D pre-trained knowledge to event\nspikes. To improve the few-shot performance, we also provide an inter-timestep\nadapter based on a spiking neural network. Our code is open-sourced at\nhttps://github.com/yfguo91/NeuroCLIP.git.\n","authors":["Yufei Guo","Yuanpei Chen"],"pdf_url":"https://arxiv.org/pdf/2306.12073v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12070v1","updated":"2023-06-21T07:43:23Z","published":"2023-06-21T07:43:23Z","title":"Task-Robust Pre-Training for Worst-Case Downstream Adaptation","summary":"  Pre-training has achieved remarkable success when transferred to downstream\ntasks. In machine learning, we care about not only the good performance of a\nmodel but also its behavior under reasonable shifts of condition. The same\nphilosophy holds when pre-training a foundation model. However, the foundation\nmodel may not uniformly behave well for a series of related downstream tasks.\nThis happens, for example, when conducting mask recovery regression where the\nrecovery ability or the training instances diverge like pattern features are\nextracted dominantly on pre-training, but semantic features are also required\non a downstream task. This paper considers pre-training a model that guarantees\na uniformly good performance over the downstream tasks. We call this goal as\n$\\textit{downstream-task robustness}$. Our method first separates the upstream\ntask into several representative ones and applies a simple minimax loss for\npre-training. We then design an efficient algorithm to solve the minimax loss\nand prove its convergence in the convex setting. In the experiments, we show\nboth on large-scale natural language processing and computer vision datasets\nour method increases the metrics on worse-case downstream tasks. Additionally,\nsome theoretical explanations for why our loss is beneficial are provided.\nSpecifically, we show fewer samples are inherently required for the most\nchallenging downstream task in some cases.\n","authors":["Jianghui Wang","Cheng Yang","Xingyu Xie","Cong Fang","Zhouchen Lin"],"pdf_url":"https://arxiv.org/pdf/2306.12070v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05334v2","updated":"2023-06-21T07:15:19Z","published":"2023-03-09T15:24:26Z","title":"Natural scene reconstruction from fMRI signals using generative latent\n  diffusion","summary":"  In neural decoding research, one of the most intriguing topics is the\nreconstruction of perceived natural images based on fMRI signals. Previous\nstudies have succeeded in re-creating different aspects of the visuals, such as\nlow-level properties (shape, texture, layout) or high-level features (category\nof objects, descriptive semantics of scenes) but have typically failed to\nreconstruct these properties together for complex scene images. Generative AI\nhas recently made a leap forward with latent diffusion models capable of\ngenerating high-complexity images. Here, we investigate how to take advantage\nof this innovative technology for brain decoding. We present a two-stage scene\nreconstruction framework called ``Brain-Diffuser''. In the first stage,\nstarting from fMRI signals, we reconstruct images that capture low-level\nproperties and overall layout using a VDVAE (Very Deep Variational Autoencoder)\nmodel. In the second stage, we use the image-to-image framework of a latent\ndiffusion model (Versatile Diffusion) conditioned on predicted multimodal (text\nand visual) features, to generate final reconstructed images. On the publicly\navailable Natural Scenes Dataset benchmark, our method outperforms previous\nmodels both qualitatively and quantitatively. When applied to synthetic fMRI\npatterns generated from individual ROI (region-of-interest) masks, our trained\nmodel creates compelling ``ROI-optimal'' scenes consistent with neuroscientific\nknowledge. Thus, the proposed methodology can have an impact on both applied\n(e.g. brain-computer interface) and fundamental neuroscience.\n","authors":["Furkan Ozcelik","Rufin VanRullen"],"pdf_url":"https://arxiv.org/pdf/2303.05334v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12058v1","updated":"2023-06-21T06:59:07Z","published":"2023-06-21T06:59:07Z","title":"Beyond Learned Metadata-based Raw Image Reconstruction","summary":"  While raw images have distinct advantages over sRGB images, e.g., linearity\nand fine-grained quantization levels, they are not widely adopted by general\nusers due to their substantial storage requirements. Very recent studies\npropose to compress raw images by designing sampling masks within the pixel\nspace of the raw image. However, these approaches often leave space for\npursuing more effective image representations and compact metadata. In this\nwork, we propose a novel framework that learns a compact representation in the\nlatent space, serving as metadata, in an end-to-end manner. Compared with lossy\nimage compression, we analyze the intrinsic difference of the raw image\nreconstruction task caused by rich information from the sRGB image. Based on\nthe analysis, a novel backbone design with asymmetric and hybrid spatial\nfeature resolutions is proposed, which significantly improves the\nrate-distortion performance. Besides, we propose a novel design of the context\nmodel, which can better predict the order masks of encoding/decoding based on\nboth the sRGB image and the masks of already processed features. Benefited from\nthe better modeling of the correlation between order masks, the already\nprocessed information can be better utilized. Moreover, a novel sRGB-guided\nadaptive quantization precision strategy, which dynamically assigns varying\nlevels of quantization precision to different regions, further enhances the\nrepresentation ability of the model. Finally, based on the iterative properties\nof the proposed context model, we propose a novel strategy to achieve variable\nbit rates using a single model. This strategy allows for the continuous\nconvergence of a wide range of bit rates. Extensive experimental results\ndemonstrate that the proposed method can achieve better reconstruction quality\nwith a smaller metadata size.\n","authors":["Yufei Wang","Yi Yu","Wenhan Yang","Lanqing Guo","Lap-Pui Chau","Alex C. Kot","Bihan Wen"],"pdf_url":"https://arxiv.org/pdf/2306.12058v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12057v1","updated":"2023-06-21T06:58:46Z","published":"2023-06-21T06:58:46Z","title":"Chili Pepper Disease Diagnosis via Image Reconstruction Using GrabCut\n  and Generative Adversarial Serial Autoencoder","summary":"  With the recent development of smart farms, researchers are very interested\nin such fields. In particular, the field of disease diagnosis is the most\nimportant factor. Disease diagnosis belongs to the field of anomaly detection\nand aims to distinguish whether plants or fruits are normal or abnormal. The\nproblem can be solved by binary or multi-classification based on CNN, but it\ncan also be solved by image reconstruction. However, due to the limitation of\nthe performance of image generation, SOTA's methods propose a score calculation\nmethod using a latent vector error. In this paper, we propose a network that\nfocuses on chili peppers and proceeds with background removal through Grabcut.\nIt shows high performance through image-based score calculation method. Due to\nthe difficulty of reconstructing the input image, the difference between the\ninput and output images is large. However, the serial autoencoder proposed in\nthis paper uses the difference between the two fake images except for the\nactual input as a score. We propose a method of generating meaningful images\nusing the GAN structure and classifying three results simultaneously by one\ndiscriminator. The proposed method showed higher performance than previous\nresearches, and image-based scores showed the best performanc\n","authors":["Jongwook Si","Sungyoung Kim"],"pdf_url":"https://arxiv.org/pdf/2306.12057v1.pdf","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.11335v2","updated":"2023-06-21T06:56:47Z","published":"2023-06-20T07:06:04Z","title":"RM-PRT: Realistic Robotic Manipulation Simulator and Benchmark with\n  Progressive Reasoning Tasks","summary":"  Recently, the advent of pre-trained large-scale language models (LLMs) like\nChatGPT and GPT-4 have significantly advanced the machine's natural language\nunderstanding capabilities. This breakthrough has allowed us to seamlessly\nintegrate these open-source LLMs into a unified robot simulator environment to\nhelp robots accurately understand and execute human natural language\ninstructions. To this end, in this work, we introduce a realistic robotic\nmanipulation simulator and build a Robotic Manipulation with Progressive\nReasoning Tasks (RM-PRT) benchmark on this basis. Specifically, the RM-PRT\nbenchmark builds a new high-fidelity digital twin scene based on Unreal Engine\n5, which includes 782 categories, 2023 objects, and 15K natural language\ninstructions generated by ChatGPT for a detailed evaluation of robot\nmanipulation. We propose a general pipeline for the RM-PRT benchmark that takes\nas input multimodal prompts containing natural language instructions and\nautomatically outputs actions containing the movement and position transitions.\nWe set four natural language understanding tasks with progressive reasoning\nlevels and evaluate the robot's ability to understand natural language\ninstructions in two modes of adsorption and grasping. In addition, we also\nconduct a comprehensive analysis and comparison of the differences and\nadvantages of 10 different LLMs in instruction understanding and generation\nquality. We hope the new simulator and benchmark will facilitate future\nresearch on language-guided robotic manipulation. Project website:\nhttps://necolizer.github.io/RM-PRT/ .\n","authors":["Pengzhen Ren","Kaidong Zhang","Hetao Zheng","Zixuan Li","Yuhang Wen","Fengda Zhu","Mas Ma","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2306.11335v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12082v2","updated":"2023-06-21T06:55:16Z","published":"2023-01-28T03:58:32Z","title":"Pushing the Limits of Fewshot Anomaly Detection in Industry Vision:\n  Graphcore","summary":"  In the area of fewshot anomaly detection (FSAD), efficient visual feature\nplays an essential role in memory bank M-based methods. However, these methods\ndo not account for the relationship between the visual feature and its rotated\nvisual feature, drastically limiting the anomaly detection performance. To push\nthe limits, we reveal that rotation-invariant feature property has a\nsignificant impact in industrial-based FSAD. Specifically, we utilize graph\nrepresentation in FSAD and provide a novel visual isometric invariant feature\n(VIIF) as anomaly measurement feature. As a result, VIIF can robustly improve\nthe anomaly discriminating ability and can further reduce the size of redundant\nfeatures stored in M by a large amount. Besides, we provide a novel model\nGraphCore via VIIFs that can fast implement unsupervised FSAD training and can\nimprove the performance of anomaly detection. A comprehensive evaluation is\nprovided for comparing GraphCore and other SOTA anomaly detection models under\nour proposed fewshot anomaly detection setting, which shows GraphCore can\nincrease average AUC by 5.8%, 4.1%, 3.4%, and 1.6% on MVTec AD and by 25.5%,\n22.0%, 16.9%, and 14.1% on MPDD for 1, 2, 4, and 8-shot cases, respectively.\n","authors":["Guoyang Xie","Jingbao Wang","Jiaqi Liu","Feng Zheng","Yaochu Jin"],"pdf_url":"https://arxiv.org/pdf/2301.12082v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12054v1","updated":"2023-06-21T06:53:51Z","published":"2023-06-21T06:53:51Z","title":"A Reliable and Interpretable Framework of Multi-view Learning for Liver\n  Fibrosis Staging","summary":"  Staging of liver fibrosis is important in the diagnosis and treatment\nplanning of patients suffering from liver diseases. Current deep learning-based\nmethods using abdominal magnetic resonance imaging (MRI) usually take a\nsub-region of the liver as an input, which nevertheless could miss critical\ninformation. To explore richer representations, we formulate this task as a\nmulti-view learning problem and employ multiple sub-regions of the liver.\nPreviously, features or predictions are usually combined in an implicit manner,\nand uncertainty-aware methods have been proposed. However, these methods could\nbe challenged to capture cross-view representations, which can be important in\nthe accurate prediction of staging. Therefore, we propose a reliable multi-view\nlearning method with interpretable combination rules, which can model global\nrepresentations to improve the accuracy of predictions. Specifically, the\nproposed method estimates uncertainties based on subjective logic to improve\nreliability, and an explicit combination rule is applied based on\nDempster-Shafer's evidence theory with good power of interpretability.\nMoreover, a data-efficient transformer is introduced to capture representations\nin the global view. Results evaluated on enhanced MRI data show that our method\ndelivers superior performance over existing multi-view learning methods.\n","authors":["Zheyao Gao","Yuanye Liu","Fuping Wu","NanNan Shi","Yuxin Shi","Xiahai Zhuang"],"pdf_url":"https://arxiv.org/pdf/2306.12054v1.pdf","comment":"Early accepted by MICCAI 2023"},{"id":"http://arxiv.org/abs/2306.12050v1","updated":"2023-06-21T06:43:22Z","published":"2023-06-21T06:43:22Z","title":"Analyzing Font Style Usage and Contextual Factors in Real Images","summary":"  There are various font styles in the world. Different styles give different\nimpressions and readability. This paper analyzes the relationship between font\nstyles and contextual factors that might affect font style selection with\nlarge-scale datasets. For example, we will analyze the relationship between\nfont style and its surrounding object (such as ``bus'') by using about 800,000\nwords in the Open Images dataset. We also use a book cover dataset to analyze\nthe relationship between font styles with book genres. Moreover, the meaning of\nthe word is assumed as another contextual factor. For these numeric analyses,\nwe utilize our own font-style feature extraction model and word2vec. As a\nresult of co-occurrence-based relationship analysis, we found several instances\nof specific font styles being used for specific contextual factors.\n","authors":["Naoya Yasukochi","Hideaki Hayashi","Daichi Haraguchi","Seiichi Uchida"],"pdf_url":"https://arxiv.org/pdf/2306.12050v1.pdf","comment":"Accepted at ICDAR 2023"},{"id":"http://arxiv.org/abs/2306.12049v1","updated":"2023-06-21T06:42:57Z","published":"2023-06-21T06:42:57Z","title":"Ambigram Generation by A Diffusion Model","summary":"  Ambigrams are graphical letter designs that can be read not only from the\noriginal direction but also from a rotated direction (especially with 180\ndegrees). Designing ambigrams is difficult even for human experts because\nkeeping their dual readability from both directions is often difficult. This\npaper proposes an ambigram generation model. As its generation module, we use a\ndiffusion model, which has recently been used to generate high-quality\nphotographic images. By specifying a pair of letter classes, such as 'A' and\n'B', the proposed model generates various ambigram images which can be read as\n'A' from the original direction and 'B' from a direction rotated 180 degrees.\nQuantitative and qualitative analyses of experimental results show that the\nproposed model can generate high-quality and diverse ambigrams. In addition, we\ndefine ambigramability, an objective measure of how easy it is to generate\nambigrams for each letter pair. For example, the pair of 'A' and 'V' shows a\nhigh ambigramability (that is, it is easy to generate their ambigrams), and the\npair of 'D' and 'K' shows a lower ambigramability. The ambigramability gives\nvarious hints of the ambigram generation not only for computers but also for\nhuman experts. The code can be found at\n(https://github.com/univ-esuty/ambifusion).\n","authors":["Takahiro Shirakawa","Seiichi Uchida"],"pdf_url":"https://arxiv.org/pdf/2306.12049v1.pdf","comment":"Accepted at ICDAR 2023"},{"id":"http://arxiv.org/abs/2306.12048v1","updated":"2023-06-21T06:40:31Z","published":"2023-06-21T06:40:31Z","title":"Online Unsupervised Video Object Segmentation via Contrastive Motion\n  Clustering","summary":"  Online unsupervised video object segmentation (UVOS) uses the previous frames\nas its input to automatically separate the primary object(s) from a streaming\nvideo without using any further manual annotation. A major challenge is that\nthe model has no access to the future and must rely solely on the history,\ni.e., the segmentation mask is predicted from the current frame as soon as it\nis captured. In this work, a novel contrastive motion clustering algorithm with\nan optical flow as its input is proposed for the online UVOS by exploiting the\ncommon fate principle that visual elements tend to be perceived as a group if\nthey possess the same motion pattern. We build a simple and effective\nauto-encoder to iteratively summarize non-learnable prototypical bases for the\nmotion pattern, while the bases in turn help learn the representation of the\nembedding network. Further, a contrastive learning strategy based on a boundary\nprior is developed to improve foreground and background feature discrimination\nin the representation learning stage. The proposed algorithm can be optimized\non arbitrarily-scale data i.e., frame, clip, dataset) and performed in an\nonline fashion. Experiments on $\\textit{DAVIS}_{\\textit{16}}$, $\\textit{FBMS}$,\nand $\\textit{SegTrackV2}$ datasets show that the accuracy of our method\nsurpasses the previous state-of-the-art (SoTA) online UVOS method by a margin\nof 0.8%, 2.9%, and 1.1%, respectively. Furthermore, by using an online deep\nsubspace clustering to tackle the motion grouping, our method is able to\nachieve higher accuracy at $3\\times$ faster inference time compared to SoTA\nonline UVOS method, and making a good trade-off between effectiveness and\nefficiency.\n","authors":["Lin Xi","Weihai Chen","Xingming Wu","Zhong Liu","Zhengguo Li"],"pdf_url":"https://arxiv.org/pdf/2306.12048v1.pdf","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.12045v1","updated":"2023-06-21T06:30:18Z","published":"2023-06-21T06:30:18Z","title":"Temporal Conditioning Spiking Latent Variable Models of the Neural\n  Response to Natural Visual Scenes","summary":"  Developing computational models of neural response is crucial for\nunderstanding sensory processing and neural computations. Current\nstate-of-the-art neural network methods use temporal filters to handle temporal\ndependencies, resulting in an unrealistic and inflexible processing flow.\nMeanwhile, these methods target trial-averaged firing rates and fail to capture\nimportant features in spike trains. This work presents the temporal\nconditioning spiking latent variable models (TeCoS-LVM) to simulate the neural\nresponse to natural visual stimuli. We use spiking neurons to produce spike\noutputs that directly match the recorded trains. This approach helps to avoid\nlosing information embedded in the original spike trains. We exclude the\ntemporal dimension from the model parameter space and introduce a temporal\nconditioning operation to allow the model to adaptively explore and exploit\ntemporal dependencies in stimuli sequences in a natural paradigm. We show that\nTeCoS-LVM models can produce more realistic spike activities and accurately fit\nspike statistics than powerful alternatives. Additionally, learned TeCoS-LVM\nmodels can generalize well to longer time scales. Overall, while remaining\ncomputationally tractable, our model effectively captures key features of\nneural coding systems. It thus provides a useful tool for building accurate\npredictive computational accounts for various sensory perception circuits.\n","authors":["Gehua Ma","Runhao Jiang","Rui Yan","Huajin Tang"],"pdf_url":"https://arxiv.org/pdf/2306.12045v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12041v1","updated":"2023-06-21T06:18:05Z","published":"2023-06-21T06:18:05Z","title":"Self-Distilled Masked Auto-Encoders are Efficient Video Anomaly\n  Detectors","summary":"  We propose an efficient abnormal event detection model based on a lightweight\nmasked auto-encoder (AE) applied at the video frame level. The novelty of the\nproposed model is threefold. First, we introduce an approach to weight tokens\nbased on motion gradients, thus avoiding learning to reconstruct the static\nbackground scene. Second, we integrate a teacher decoder and a student decoder\ninto our architecture, leveraging the discrepancy between the outputs given by\nthe two decoders to improve anomaly detection. Third, we generate synthetic\nabnormal events to augment the training videos, and task the masked AE model to\njointly reconstruct the original frames (without anomalies) and the\ncorresponding pixel-level anomaly maps. Our design leads to an efficient and\neffective model, as demonstrated by the extensive experiments carried out on\nthree benchmarks: Avenue, ShanghaiTech and UCSD Ped2. The empirical results\nshow that our model achieves an excellent trade-off between speed and accuracy,\nobtaining competitive AUC scores, while processing 1670 FPS. Hence, our model\nis between 8 and 70 times faster than competing methods. We also conduct an\nablation study to justify our design.\n","authors":["Nicolae-Catalin Ristea","Florinel-Alin Croitoru","Radu Tudor Ionescu","Marius Popescu","Fahad Shahbaz Khan","Mubarak Shah"],"pdf_url":"https://arxiv.org/pdf/2306.12041v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12033v1","updated":"2023-06-21T05:48:51Z","published":"2023-06-21T05:48:51Z","title":"End-to-End Augmentation Hyperparameter Tuning for Self-Supervised\n  Anomaly Detection","summary":"  Self-supervised learning (SSL) has emerged as a promising paradigm that\npresents self-generated supervisory signals to real-world problems, bypassing\nthe extensive manual labeling burden. SSL is especially attractive for\nunsupervised tasks such as anomaly detection, where labeled anomalies are often\nnonexistent and costly to obtain. While self-supervised anomaly detection\n(SSAD) has seen a recent surge of interest, the literature has failed to treat\ndata augmentation as a hyperparameter. Meanwhile, recent works have reported\nthat the choice of augmentation has significant impact on detection\nperformance. In this paper, we introduce ST-SSAD (Self-Tuning Self-Supervised\nAnomaly Detection), the first systematic approach to SSAD in regards to\nrigorously tuning augmentation. To this end, our work presents two key\ncontributions. The first is a new unsupervised validation loss that quantifies\nthe alignment between the augmented training data and the (unlabeled) test\ndata. In principle we adopt transduction, quantifying the extent to which\naugmentation mimics the true anomaly-generating mechanism, in contrast to\naugmenting data with arbitrary pseudo anomalies without regard to test data.\nSecond, we present new differentiable augmentation functions, allowing data\naugmentation hyperparameter(s) to be tuned end-to-end via our proposed\nvalidation loss. Experiments on two testbeds with semantic class anomalies and\nsubtle industrial defects show that systematically tuning augmentation offers\nsignificant performance gains over current practices.\n","authors":["Jaemin Yoo","Lingxiao Zhao","Leman Akoglu"],"pdf_url":"https://arxiv.org/pdf/2306.12033v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12026v1","updated":"2023-06-21T05:26:28Z","published":"2023-06-21T05:26:28Z","title":"Continual Learners are Incremental Model Generalizers","summary":"  Motivated by the efficiency and rapid convergence of pre-trained models for\nsolving downstream tasks, this paper extensively studies the impact of\nContinual Learning (CL) models as pre-trainers. In both supervised and\nunsupervised CL, we find that the transfer quality of the representation often\nincreases gradually without noticeable degradation in fine-tuning performance.\nThis is because CL models can learn improved task-general features when easily\nforgetting task-specific knowledge. Based on this observation, we suggest a new\nunsupervised CL framework with masked modeling, which aims to capture fluent\ntask-generic representation during training. Furthermore, we propose a new\nfine-tuning scheme, GLobal Attention Discretization (GLAD), that preserves rich\ntask-generic representation during solving downstream tasks. The model\nfine-tuned with GLAD achieves competitive performance and can also be used as a\ngood pre-trained model itself. We believe this paper breaks the barriers\nbetween pre-training and fine-tuning steps and leads to a sustainable learning\nframework in which the continual learner incrementally improves model\ngeneralization, yielding better transfer to unseen tasks.\n","authors":["Jaehong Yoon","Sung Ju Hwang","Yue Cao"],"pdf_url":"https://arxiv.org/pdf/2306.12026v1.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2306.12010v1","updated":"2023-06-21T04:21:40Z","published":"2023-06-21T04:21:40Z","title":"Spiking Neural Network for Ultra-low-latency and High-accurate Object\n  Detection","summary":"  Spiking Neural Networks (SNNs) have garnered widespread interest for their\nenergy efficiency and brain-inspired event-driven properties. While recent\nmethods like Spiking-YOLO have expanded the SNNs to more challenging object\ndetection tasks, they often suffer from high latency and low detection\naccuracy, making them difficult to deploy on latency sensitive mobile\nplatforms. Furthermore, the conversion method from Artificial Neural Networks\n(ANNs) to SNNs is hard to maintain the complete structure of the ANNs,\nresulting in poor feature representation and high conversion errors. To address\nthese challenges, we propose two methods: timesteps compression and\nspike-time-dependent integrated (STDI) coding. The former reduces the timesteps\nrequired in ANN-SNN conversion by compressing information, while the latter\nsets a time-varying threshold to expand the information holding capacity. We\nalso present a SNN-based ultra-low latency and high accurate object detection\nmodel (SUHD) that achieves state-of-the-art performance on nontrivial datasets\nlike PASCAL VOC and MS COCO, with about remarkable 750x fewer timesteps and 30%\nmean average precision (mAP) improvement, compared to the Spiking-YOLO on MS\nCOCO datasets. To the best of our knowledge, SUHD is the deepest spike-based\nobject detection model to date that achieves ultra low timesteps to complete\nthe lossless conversion.\n","authors":["Jinye Qu","Zeyu Gao","Tielin Zhang","Yanfeng Lu","Huajin Tang","Hong Qiao"],"pdf_url":"https://arxiv.org/pdf/2306.12010v1.pdf","comment":"14 pages, 10 figures"},{"id":"http://arxiv.org/abs/2304.10950v3","updated":"2023-06-21T03:37:26Z","published":"2023-04-21T13:40:30Z","title":"Factored Neural Representation for Scene Understanding","summary":"  A long-standing goal in scene understanding is to obtain interpretable and\neditable representations that can be directly constructed from a raw monocular\nRGB-D video, without requiring specialized hardware setup or priors. The\nproblem is significantly more challenging in the presence of multiple moving\nand/or deforming objects. Traditional methods have approached the setup with a\nmix of simplifications, scene priors, pretrained templates, or known\ndeformation models. The advent of neural representations, especially neural\nimplicit representations and radiance fields, opens the possibility of\nend-to-end optimization to collectively capture geometry, appearance, and\nobject motion. However, current approaches produce global scene encoding,\nassume multiview capture with limited or no motion in the scenes, and do not\nfacilitate easy manipulation beyond novel view synthesis. In this work, we\nintroduce a factored neural scene representation that can directly be learned\nfrom a monocular RGB-D video to produce object-level neural presentations with\nan explicit encoding of object movement (e.g., rigid trajectory) and/or\ndeformations (e.g., nonrigid movement). We evaluate ours against a set of\nneural approaches on both synthetic and real data to demonstrate that the\nrepresentation is efficient, interpretable, and editable (e.g., change object\ntrajectory). Code and data are available at\nhttp://geometry.cs.ucl.ac.uk/projects/2023/factorednerf .\n","authors":["Yu-Shiang Wong","Niloy J. Mitra"],"pdf_url":"https://arxiv.org/pdf/2304.10950v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11290v2","updated":"2023-06-21T03:19:20Z","published":"2023-06-20T05:07:23Z","title":"Habitat Synthetic Scenes Dataset (HSSD-200): An Analysis of 3D Scene\n  Scale and Realism Tradeoffs for ObjectGoal Navigation","summary":"  We contribute the Habitat Synthetic Scene Dataset, a dataset of 211\nhigh-quality 3D scenes, and use it to test navigation agent generalization to\nrealistic 3D environments. Our dataset represents real interiors and contains a\ndiverse set of 18,656 models of real-world objects. We investigate the impact\nof synthetic 3D scene dataset scale and realism on the task of training\nembodied agents to find and navigate to objects (ObjectGoal navigation). By\ncomparing to synthetic 3D scene datasets from prior work, we find that scale\nhelps in generalization, but the benefits quickly saturate, making visual\nfidelity and correlation to real-world scenes more important. Our experiments\nshow that agents trained on our smaller-scale dataset can match or outperform\nagents trained on much larger datasets. Surprisingly, we observe that agents\ntrained on just 122 scenes from our dataset outperform agents trained on 10,000\nscenes from the ProcTHOR-10K dataset in terms of zero-shot generalization in\nreal-world scanned environments.\n","authors":["Mukul Khanna","Yongsen Mao","Hanxiao Jiang","Sanjay Haresh","Brennan Shacklett","Dhruv Batra","Alexander Clegg","Eric Undersander","Angel X. Chang","Manolis Savva"],"pdf_url":"https://arxiv.org/pdf/2306.11290v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.10286v2","updated":"2023-06-21T03:09:34Z","published":"2023-06-17T07:58:44Z","title":"Enlighten-anything:When Segment Anything Model Meets Low-light Image\n  Enhancement","summary":"  Image restoration is a low-level visual task, and most CNN methods are\ndesigned as black boxes, lacking transparency and intrinsic aesthetics. Many\nunsupervised approaches ignore the degradation of visible information in\nlow-light scenes, which will seriously affect the aggregation of complementary\ninformation and also make the fusion algorithm unable to produce satisfactory\nfusion results under extreme conditions. In this paper, we propose\nEnlighten-anything, which is able to enhance and fuse the semantic intent of\nSAM segmentation with low-light images to obtain fused images with good visual\nperception. The generalization ability of unsupervised learning is greatly\nimproved, and experiments on LOL dataset are conducted to show that our method\nimproves 3db in PSNR over baseline and 8 in SSIM. zero-shot learning of SAM\nintroduces a powerful aid for unsupervised low-light enhancement. The source\ncode of Enlighten-anything can be obtained from\nhttps://github.com/zhangbaijin/enlighten-anything\n","authors":["Qihan Zhao","Xiaofeng Zhang","Hao Tang","Chaochen Gu","Shanying Zhu"],"pdf_url":"https://arxiv.org/pdf/2306.10286v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11991v1","updated":"2023-06-21T03:05:25Z","published":"2023-06-21T03:05:25Z","title":"Generalizable Metric Network for Cross-domain Person Re-identification","summary":"  Person Re-identification (Re-ID) is a crucial technique for public security\nand has made significant progress in supervised settings. However, the\ncross-domain (i.e., domain generalization) scene presents a challenge in Re-ID\ntasks due to unseen test domains and domain-shift between the training and test\nsets. To tackle this challenge, most existing methods aim to learn\ndomain-invariant or robust features for all domains. In this paper, we observe\nthat the data-distribution gap between the training and test sets is smaller in\nthe sample-pair space than in the sample-instance space. Based on this\nobservation, we propose a Generalizable Metric Network (GMN) to further explore\nsample similarity in the sample-pair space. Specifically, we add a Metric\nNetwork (M-Net) after the main network and train it on positive and negative\nsample-pair features, which is then employed during the test stage.\nAdditionally, we introduce the Dropout-based Perturbation (DP) module to\nenhance the generalization capability of the metric network by enriching the\nsample-pair diversity. Moreover, we develop a Pair-Identity Center (PIC) loss\nto enhance the model's discrimination by ensuring that sample-pair features\nwith the same pair-identity are consistent. We validate the effectiveness of\nour proposed method through a lot of experiments on multiple benchmark datasets\nand confirm the value of each module in our GMN.\n","authors":["Lei Qi","Ziang Liu","Yinghuan Shi","Xin Geng"],"pdf_url":"https://arxiv.org/pdf/2306.11991v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11990v1","updated":"2023-06-21T03:01:45Z","published":"2023-06-21T03:01:45Z","title":"Evaluating Adversarial Robustness of Convolution-based Human Motion\n  Prediction","summary":"  Human motion prediction has achieved a brilliant performance with the help of\nCNNs, which facilitates human-machine cooperation. However, currently, there is\nno work evaluating the potential risk in human motion prediction when facing\nadversarial attacks, which may cause danger in real applications. The\nadversarial attack will face two problems against human motion prediction: 1.\nFor naturalness, pose data is highly related to the physical dynamics of human\nskeletons where Lp norm constraints cannot constrain the adversarial example\nwell; 2. Unlike the pixel value in images, pose data is diverse at scale\nbecause of the different acquisition equipment and the data processing, which\nmakes it hard to set fixed parameters to perform attacks. To solve the problems\nabove, we propose a new adversarial attack method that perturbs the input human\nmotion sequence by maximizing the prediction error with physical constraints.\nSpecifically, we introduce a novel adaptable scheme that facilitates the attack\nto suit the scale of the target pose and two physical constraints to enhance\nthe imperceptibility of the adversarial example. The evaluating experiments on\nthree datasets show that the prediction errors of all target models are\nenlarged significantly, which means current convolution-based human motion\nprediction models can be easily disturbed under the proposed attack. The\nquantitative analysis shows that prior knowledge and semantic information\nmodeling can be the key to the adversarial robustness of human motion\npredictors. The qualitative results indicate that the adversarial sample is\nhard to be noticed when compared frame by frame but is relatively easy to be\ndetected when the sample is animated.\n","authors":["Chengxu Duan","Zhicheng Zhang","Xiaoli Liu","Yonghao Dang","Jianqin Yin"],"pdf_url":"https://arxiv.org/pdf/2306.11990v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11984v1","updated":"2023-06-21T02:27:07Z","published":"2023-06-21T02:27:07Z","title":"TauPETGen: Text-Conditional Tau PET Image Synthesis Based on Latent\n  Diffusion Models","summary":"  In this work, we developed a novel text-guided image synthesis technique\nwhich could generate realistic tau PET images from textual descriptions and the\nsubject's MR image. The generated tau PET images have the potential to be used\nin examining relations between different measures and also increasing the\npublic availability of tau PET datasets. The method was based on latent\ndiffusion models. Both textual descriptions and the subject's MR prior image\nwere utilized as conditions during image generation. The subject's MR image can\nprovide anatomical details, while the text descriptions, such as gender, scan\ntime, cognitive test scores, and amyloid status, can provide further guidance\nregarding where the tau neurofibrillary tangles might be deposited. Preliminary\nexperimental results based on clinical [18F]MK-6240 datasets demonstrate the\nfeasibility of the proposed method in generating realistic tau PET images at\ndifferent clinical stages.\n","authors":["Se-In Jang","Cristina Lois","Emma Thibault","J. Alex Becker","Yafei Dong","Marc D. Normandin","Julie C. Price","Keith A. Johnson","Georges El Fakhri","Kuang Gong"],"pdf_url":"https://arxiv.org/pdf/2306.11984v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11982v1","updated":"2023-06-21T02:18:27Z","published":"2023-06-21T02:18:27Z","title":"Balanced Mixture of SuperNets for Learning the CNN Pooling Architecture","summary":"  Downsampling layers, including pooling and strided convolutions, are crucial\ncomponents of the convolutional neural network architecture that determine both\nthe granularity/scale of image feature analysis as well as the receptive field\nsize of a given layer. To fully understand this problem, we analyse the\nperformance of models independently trained with each pooling configurations on\nCIFAR10, using a ResNet20 network, and show that the position of the\ndownsampling layers can highly influence the performance of a network and\npredefined downsampling configurations are not optimal. Network Architecture\nSearch (NAS) might be used to optimize downsampling configurations as an\nhyperparameter. However, we find that common one-shot NAS based on a single\nSuperNet does not work for this problem. We argue that this is because a\nSuperNet trained for finding the optimal pooling configuration fully shares its\nparameters among all pooling configurations. This makes its training hard,\nbecause learning some configurations can harm the performance of others.\nTherefore, we propose a balanced mixture of SuperNets that automatically\nassociates pooling configurations to different weight models and helps to\nreduce the weight-sharing and inter-influence of pooling configurations on the\nSuperNet parameters. We evaluate our proposed approach on CIFAR10, CIFAR100, as\nwell as Food101 and show that in all cases, our model outperforms other\napproaches and improves over the default pooling configurations.\n","authors":["Mehraveh Javan","Matthew Toews","Marco Pedersoli"],"pdf_url":"https://arxiv.org/pdf/2306.11982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.06384v3","updated":"2023-06-21T02:13:41Z","published":"2022-12-13T05:42:44Z","title":"PV3D: A 3D Generative Model for Portrait Video Generation","summary":"  Recent advances in generative adversarial networks (GANs) have demonstrated\nthe capabilities of generating stunning photo-realistic portrait images. While\nsome prior works have applied such image GANs to unconditional 2D portrait\nvideo generation and static 3D portrait synthesis, there are few works\nsuccessfully extending GANs for generating 3D-aware portrait videos. In this\nwork, we propose PV3D, the first generative framework that can synthesize\nmulti-view consistent portrait videos. Specifically, our method extends the\nrecent static 3D-aware image GAN to the video domain by generalizing the 3D\nimplicit neural representation to model the spatio-temporal space. To introduce\nmotion dynamics to the generation process, we develop a motion generator by\nstacking multiple motion layers to generate motion features via modulated\nconvolution. To alleviate motion ambiguities caused by camera/human motions, we\npropose a simple yet effective camera condition strategy for PV3D, enabling\nboth temporal and multi-view consistent video generation. Moreover, PV3D\nintroduces two discriminators for regularizing the spatial and temporal domains\nto ensure the plausibility of the generated portrait videos. These elaborated\ndesigns enable PV3D to generate 3D-aware motion-plausible portrait videos with\nhigh-quality appearance and geometry, significantly outperforming prior works.\nAs a result, PV3D is able to support many downstream applications such as\nanimating static portraits and view-consistent video motion editing. Code and\nmodels are released at https://showlab.github.io/pv3d.\n","authors":["Zhongcong Xu","Jianfeng Zhang","Jun Hao Liew","Wenqing Zhang","Song Bai","Jiashi Feng","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2212.06384v3.pdf","comment":"Accepted to ICLR2023, Project Page https://showlab.github.io/pv3d"},{"id":"http://arxiv.org/abs/2306.11977v1","updated":"2023-06-21T02:08:27Z","published":"2023-06-21T02:08:27Z","title":"Encoding Enhanced Complex CNN for Accurate and Highly Accelerated MRI","summary":"  Magnetic resonance imaging (MRI) using hyperpolarized noble gases provides a\nway to visualize the structure and function of human lung, but the long imaging\ntime limits its broad research and clinical applications. Deep learning has\ndemonstrated great potential for accelerating MRI by reconstructing images from\nundersampled data. However, most existing deep conventional neural networks\n(CNN) directly apply square convolution to k-space data without considering the\ninherent properties of k-space sampling, limiting k-space learning efficiency\nand image reconstruction quality. In this work, we propose an encoding enhanced\n(EN2) complex CNN for highly undersampled pulmonary MRI reconstruction. EN2\nemploys convolution along either the frequency or phase-encoding direction,\nresembling the mechanisms of k-space sampling, to maximize the utilization of\nthe encoding correlation and integrity within a row or column of k-space. We\nalso employ complex convolution to learn rich representations from the complex\nk-space data. In addition, we develop a feature-strengthened modularized unit\nto further boost the reconstruction performance. Experiments demonstrate that\nour approach can accurately reconstruct hyperpolarized 129Xe and 1H lung MRI\nfrom 6-fold undersampled k-space data and provide lung function measurements\nwith minimal biases compared with fully-sampled image. These results\ndemonstrate the effectiveness of the proposed algorithmic components and\nindicate that the proposed approach could be used for accelerated pulmonary MRI\nin research and clinical lung disease patient care.\n","authors":["Zimeng Li","Sa Xiao","Cheng Wang","Haidong Li","Xiuchao Zhao","Caohui Duan","Qian Zhou","Qiuchen Rao","Yuan Fang","Junshuai Xie","Lei Shi","Fumin Guo","Chaohui Ye","Xin Zhou"],"pdf_url":"https://arxiv.org/pdf/2306.11977v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11528v2","updated":"2023-06-21T01:51:59Z","published":"2023-06-20T13:31:33Z","title":"TransRef: Multi-Scale Reference Embedding Transformer for\n  Reference-Guided Image Inpainting","summary":"  Image inpainting for completing complicated semantic environments and diverse\nhole patterns of corrupted images is challenging even for state-of-the-art\nlearning-based inpainting methods trained on large-scale data. A reference\nimage capturing the same scene of a corrupted image offers informative guidance\nfor completing the corrupted image as it shares similar texture and structure\npriors to that of the holes of the corrupted image. In this work, we propose a\ntransformer-based encoder-decoder network, named TransRef, for reference-guided\nimage inpainting. Specifically, the guidance is conducted progressively through\na reference embedding procedure, in which the referencing features are\nsubsequently aligned and fused with the features of the corrupted image. For\nprecise utilization of the reference features for guidance, a reference-patch\nalignment (Ref-PA) module is proposed to align the patch features of the\nreference and corrupted images and harmonize their style differences, while a\nreference-patch transformer (Ref-PT) module is proposed to refine the embedded\nreference feature. Moreover, to facilitate the research of reference-guided\nimage restoration tasks, we construct a publicly accessible benchmark dataset\ncontaining 50K pairs of input and reference images. Both quantitative and\nqualitative evaluations demonstrate the efficacy of the reference information\nand the proposed method over the state-of-the-art methods in completing complex\nholes. Code and dataset can be accessed at https://github.com/Cameltr/TransRef.\n","authors":["Liang Liao","Taorong Liu","Delin Chen","Jing Xiao","Zheng Wang","Chia-Wen Lin","Shin'ichi Satoh"],"pdf_url":"https://arxiv.org/pdf/2306.11528v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2303.07345v3","updated":"2023-06-21T01:51:17Z","published":"2023-03-13T17:59:55Z","title":"Erasing Concepts from Diffusion Models","summary":"  Motivated by recent advancements in text-to-image diffusion, we study erasure\nof specific concepts from the model's weights. While Stable Diffusion has shown\npromise in producing explicit or realistic artwork, it has raised concerns\nregarding its potential for misuse. We propose a fine-tuning method that can\nerase a visual concept from a pre-trained diffusion model, given only the name\nof the style and using negative guidance as a teacher. We benchmark our method\nagainst previous approaches that remove sexually explicit content and\ndemonstrate its effectiveness, performing on par with Safe Latent Diffusion and\ncensored training. To evaluate artistic style removal, we conduct experiments\nerasing five modern artists from the network and conduct a user study to assess\nthe human perception of the removed styles. Unlike previous methods, our\napproach can remove concepts from a diffusion model permanently rather than\nmodifying the output at the inference time, so it cannot be circumvented even\nif a user has access to model weights. Our code, data, and results are\navailable at https://erasing.baulab.info/\n","authors":["Rohit Gandikota","Joanna Materzynska","Jaden Fiotto-Kaufman","David Bau"],"pdf_url":"https://arxiv.org/pdf/2303.07345v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11970v1","updated":"2023-06-21T01:50:04Z","published":"2023-06-21T01:50:04Z","title":"RSMT: Real-time Stylized Motion Transition for Characters","summary":"  Styled online in-between motion generation has important application\nscenarios in computer animation and games. Its core challenge lies in the need\nto satisfy four critical requirements simultaneously: generation speed, motion\nquality, style diversity, and synthesis controllability. While the first two\nchallenges demand a delicate balance between simple fast models and learning\ncapacity for generation quality, the latter two are rarely investigated\ntogether in existing methods, which largely focus on either control without\nstyle or uncontrolled stylized motions. To this end, we propose a Real-time\nStylized Motion Transition method (RSMT) to achieve all aforementioned goals.\nOur method consists of two critical, independent components: a general motion\nmanifold model and a style motion sampler. The former acts as a high-quality\nmotion source and the latter synthesizes styled motions on the fly under\ncontrol signals. Since both components can be trained separately on different\ndatasets, our method provides great flexibility, requires less data, and\ngeneralizes well when no/few samples are available for unseen styles. Through\nexhaustive evaluation, our method proves to be fast, high-quality, versatile,\nand controllable. The code and data are available at\n{https://github.com/yuyujunjun/RSMT-Realtime-Stylized-Motion-Transition.}\n","authors":["Xiangjun Tang","Linjun Wu","He Wang","Bo Hu","Xu Gong","Yuchen Liao","Songnan Li","Qilong Kou","Xiaogang Jin"],"pdf_url":"https://arxiv.org/pdf/2306.11970v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11967v1","updated":"2023-06-21T01:43:25Z","published":"2023-06-21T01:43:25Z","title":"Complementary Learning Subnetworks for Parameter-Efficient\n  Class-Incremental Learning","summary":"  In the scenario of class-incremental learning (CIL), deep neural networks\nhave to adapt their model parameters to non-stationary data distributions,\ne.g., the emergence of new classes over time. However, CIL models are\nchallenged by the well-known catastrophic forgetting phenomenon. Typical\nmethods such as rehearsal-based ones rely on storing exemplars of old classes\nto mitigate catastrophic forgetting, which limits real-world applications\nconsidering memory resources and privacy issues. In this paper, we propose a\nnovel rehearsal-free CIL approach that learns continually via the synergy\nbetween two Complementary Learning Subnetworks. Our approach involves jointly\noptimizing a plastic CNN feature extractor and an analytical feed-forward\nclassifier. The inaccessibility of historical data is tackled by holistically\ncontrolling the parameters of a well-trained model, ensuring that the decision\nboundary learned fits new classes while retaining recognition of previously\nlearned classes. Specifically, the trainable CNN feature extractor provides\ntask-dependent knowledge separately without interference; and the final\nclassifier integrates task-specific knowledge incrementally for decision-making\nwithout forgetting. In each CIL session, it accommodates new tasks by attaching\na tiny set of declarative parameters to its backbone, in which only one matrix\nper task or one vector per class is kept for knowledge retention. Extensive\nexperiments on a variety of task sequences show that our method achieves\ncompetitive results against state-of-the-art methods, especially in accuracy\ngain, memory cost, training efficiency, and task-order robustness. Furthermore,\nto make the non-growing backbone (i.e., a model with limited network capacity)\nsuffice to train on more incoming tasks, a graceful forgetting implementation\non previously learned trivial tasks is empirically investigated.\n","authors":["Depeng Li","Zhigang Zeng"],"pdf_url":"https://arxiv.org/pdf/2306.11967v1.pdf","comment":"13 pages, 4 figures. Under review"},{"id":"http://arxiv.org/abs/2306.08487v2","updated":"2023-06-21T01:42:17Z","published":"2023-06-14T13:07:48Z","title":"Recognizing Unseen Objects via Multimodal Intensive Knowledge Graph\n  Propagation","summary":"  Zero-Shot Learning (ZSL), which aims at automatically recognizing unseen\nobjects, is a promising learning paradigm to understand new real-world\nknowledge for machines continuously. Recently, the Knowledge Graph (KG) has\nbeen proven as an effective scheme for handling the zero-shot task with\nlarge-scale and non-attribute data. Prior studies always embed relationships of\nseen and unseen objects into visual information from existing knowledge graphs\nto promote the cognitive ability of the unseen data. Actually, real-world\nknowledge is naturally formed by multimodal facts. Compared with ordinary\nstructural knowledge from a graph perspective, multimodal KG can provide\ncognitive systems with fine-grained knowledge. For example, the text\ndescription and visual content can depict more critical details of a fact than\nonly depending on knowledge triplets. Unfortunately, this multimodal\nfine-grained knowledge is largely unexploited due to the bottleneck of feature\nalignment between different modalities. To that end, we propose a multimodal\nintensive ZSL framework that matches regions of images with corresponding\nsemantic embeddings via a designed dense attention module and self-calibration\nloss. It makes the semantic transfer process of our ZSL framework learns more\ndifferentiated knowledge between entities. Our model also gets rid of the\nperformance limitation of only using rough global features. We conduct\nextensive experiments and evaluate our model on large-scale real-world data.\nThe experimental results clearly demonstrate the effectiveness of the proposed\nmodel in standard zero-shot classification tasks.\n","authors":["Likang Wu","Zhi Li","Hongke Zhao","Zhefeng Wang","Qi Liu","Baoxing Huai","Nicholas Jing Yuan","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2306.08487v2.pdf","comment":"arXiv admin note: text overlap with arXiv:1805.11724 by other authors"},{"id":"http://arxiv.org/abs/2303.16187v2","updated":"2023-06-21T01:27:37Z","published":"2023-03-28T17:53:06Z","title":"Visual Chain-of-Thought Diffusion Models","summary":"  Recent progress with conditional image diffusion models has been stunning,\nand this holds true whether we are speaking about models conditioned on a text\ndescription, a scene layout, or a sketch. Unconditional image diffusion models\nare also improving but lag behind, as do diffusion models which are conditioned\non lower-dimensional features like class labels. We propose to close the gap\nbetween conditional and unconditional models using a two-stage sampling\nprocedure. In the first stage we sample an embedding describing the semantic\ncontent of the image. In the second stage we sample the image conditioned on\nthis embedding and then discard the embedding. Doing so lets us leverage the\npower of conditional diffusion models on the unconditional generation task,\nwhich we show improves FID by 25-50% compared to standard unconditional\ngeneration.\n","authors":["William Harvey","Frank Wood"],"pdf_url":"https://arxiv.org/pdf/2303.16187v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06211v2","updated":"2023-06-21T01:12:29Z","published":"2023-05-12T07:21:59Z","title":"A Survey on Segment Anything Model (SAM): Vision Foundation Model Meets\n  Prompt Engineering","summary":"  Segment anything model (SAM) developed by Meta AI Research has recently\nattracted significant attention. Trained on a large segmentation dataset of\nover 1 billion masks, SAM is capable of segmenting any object on a certain\nimage. In the original SAM work, the authors turned to zero-short transfer\ntasks (like edge detection) for evaluating the performance of SAM. Recently,\nnumerous works have attempted to investigate the performance of SAM in various\nscenarios to recognize and segment objects. Moreover, numerous projects have\nemerged to show the versatility of SAM as a foundation model by combining it\nwith other models, like Grounding DINO, Stable Diffusion, ChatGPT, etc. With\nthe relevant papers and projects increasing exponentially, it is challenging\nfor the readers to catch up with the development of SAM. To this end, this work\nconducts the first yet comprehensive survey on SAM. This is an ongoing project\nand we intend to update the manuscript on a regular basis. Therefore, readers\nare welcome to contact us if they complete new works related to SAM so that we\ncan include them in our next version.\n","authors":["Chaoning Zhang","Sheng Zheng","Chenghao Li","Yu Qiao","Taegoo Kang","Xinru Shan","Chenshuang Zhang","Caiyan Qin","Francois Rameau","Sung-Ho Bae","Choong Seon Hong"],"pdf_url":"https://arxiv.org/pdf/2306.06211v2.pdf","comment":"First survey on Segment Anything Model (SAM), work under progress"},{"id":"http://arxiv.org/abs/2011.12267v3","updated":"2023-06-21T01:04:15Z","published":"2020-11-24T18:23:39Z","title":"A Framework for Fluid Motion Estimation using a Constraint-Based\n  Refinement Approach","summary":"  Physics-based optical flow models have been successful in capturing the\ndeformities in fluid motion arising from digital imagery. However, a common\ntheoretical framework analyzing several physics-based models is missing. In\nthis regard, we formulate a general framework for fluid motion estimation using\na constraint-based refinement approach. We demonstrate that for a particular\nchoice of constraint, our results closely approximate the classical continuity\nequation-based method for fluid flow. This closeness is theoretically justified\nby augmented Lagrangian method in a novel way. The convergence of Uzawa\niterates is shown using a modified bounded constraint algorithm. The\nmathematical well-posedness is studied in a Hilbert space setting. Further, we\nobserve a surprising connection to the Cauchy-Riemann operator that\ndiagonalizes the system leading to a diffusive phenomenon involving the\ndivergence and the curl of the flow. Several numerical experiments are\nperformed and the results are shown on different datasets. Additionally, we\ndemonstrate that a flow-driven refinement process involving the curl of the\nflow outperforms the classical physics-based optical flow method without any\nadditional assumptions on the image data.\n","authors":["Hirak Doshi","N. Uday Kiran"],"pdf_url":"https://arxiv.org/pdf/2011.12267v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11955v1","updated":"2023-06-21T00:55:02Z","published":"2023-06-21T00:55:02Z","title":"TADIL: Task-Agnostic Domain-Incremental Learning through Task-ID\n  Inference using Transformer Nearest-Centroid Embeddings","summary":"  Machine Learning (ML) models struggle with data that changes over time or\nacross domains due to factors such as noise, occlusion, illumination, or\nfrequency, unlike humans who can learn from such non independent and\nidentically distributed data. Consequently, a Continual Learning (CL) approach\nis indispensable, particularly, Domain-Incremental Learning. In this paper, we\npropose a novel pipeline for identifying tasks in domain-incremental learning\nscenarios without supervision. The pipeline comprises four steps. First, we\nobtain base embeddings from the raw data using an existing transformer-based\nmodel. Second, we group the embedding densities based on their similarity to\nobtain the nearest points to each cluster centroid. Third, we train an\nincremental task classifier using only these few points. Finally, we leverage\nthe lightweight computational requirements of the pipeline to devise an\nalgorithm that decides in an online fashion when to learn a new task using the\ntask classifier and a drift detector. We conduct experiments using the SODA10M\nreal-world driving dataset and several CL strategies. We demonstrate that the\nperformance of these CL strategies with our pipeline can match the ground-truth\napproach, both in classical experiments assuming task boundaries, and also in\nmore realistic task-agnostic scenarios that require detecting new tasks\non-the-fly\n","authors":["Gusseppe Bravo-Rocca","Peini Liu","Jordi Guitart","Ajay Dholakia","David Ellison"],"pdf_url":"https://arxiv.org/pdf/2306.11955v1.pdf","comment":"An early version of this work was presented at CVPR 2023, LXAI\n  Workshop"},{"id":"http://arxiv.org/abs/2212.14427v2","updated":"2023-06-21T22:44:37Z","published":"2022-12-29T18:57:27Z","title":"Efficient Movie Scene Detection using State-Space Transformers","summary":"  The ability to distinguish between different movie scenes is critical for\nunderstanding the storyline of a movie. However, accurately detecting movie\nscenes is often challenging as it requires the ability to reason over very long\nmovie segments. This is in contrast to most existing video recognition models,\nwhich are typically designed for short-range video analysis. This work proposes\na State-Space Transformer model that can efficiently capture dependencies in\nlong movie videos for accurate movie scene detection. Our model, dubbed\nTranS4mer, is built using a novel S4A building block, which combines the\nstrengths of structured state-space sequence (S4) and self-attention (A)\nlayers. Given a sequence of frames divided into movie shots (uninterrupted\nperiods where the camera position does not change), the S4A block first applies\nself-attention to capture short-range intra-shot dependencies. Afterward, the\nstate-space operation in the S4A block is used to aggregate long-range\ninter-shot cues. The final TranS4mer model, which can be trained end-to-end, is\nobtained by stacking the S4A blocks one after the other multiple times. Our\nproposed TranS4mer outperforms all prior methods in three movie scene detection\ndatasets, including MovieNet, BBC, and OVSD, while also being $2\\times$ faster\nand requiring $3\\times$ less GPU memory than standard Transformer models. We\nwill release our code and models.\n","authors":["Md Mohaiminul Islam","Mahmudul Hasan","Kishan Shamsundar Athrey","Tony Braskich","Gedas Bertasius"],"pdf_url":"https://arxiv.org/pdf/2212.14427v2.pdf","comment":"Accepted by CVPR 2023. Code:\n  https://github.com/md-mohaiminul/TranS4mer"},{"id":"http://arxiv.org/abs/2306.12589v1","updated":"2023-06-21T22:01:12Z","published":"2023-06-21T22:01:12Z","title":"Rapid building damage assessment workflow: An implementation for the\n  2023 Rolling Fork, Mississippi tornado event","summary":"  Rapid and accurate building damage assessments from high-resolution satellite\nimagery following a natural disaster is essential to inform and optimize first\nresponder efforts. However, performing such building damage assessments in an\nautomated manner is non-trivial due to the challenges posed by variations in\ndisaster-specific damage, diversity in satellite imagery, and the dearth of\nextensive, labeled datasets. To circumvent these issues, this paper introduces\na human-in-the-loop workflow for rapidly training building damage assessment\nmodels after a natural disaster. This article details a case study using this\nworkflow, executed in partnership with the American Red Cross during a tornado\nevent in Rolling Fork, Mississippi in March, 2023. The output from our\nhuman-in-the-loop modeling process achieved a precision of 0.86 and recall of\n0.80 for damaged buildings when compared to ground truth data collected\npost-disaster. This workflow was implemented end-to-end in under 2 hours per\nsatellite imagery scene, highlighting its potential for real-time deployment.\n","authors":["Caleb Robinson","Simone Fobi Nsutezo","Anthony Ortiz","Tina Sederholm","Rahul Dodhia","Cameron Birge","Kasie Richards","Kris Pitcher","Paulo Duarte","Juan M. Lavista Ferres"],"pdf_url":"https://arxiv.org/pdf/2306.12589v1.pdf","comment":"In submission to the 2023 ICCV Humanitarian Assistance and Disaster\n  Response Workshop"},{"id":"http://arxiv.org/abs/2306.12572v1","updated":"2023-06-21T21:17:03Z","published":"2023-06-21T21:17:03Z","title":"Uniqueness of Iris Pattern Based on AR Model","summary":"  The assessment of iris uniqueness plays a crucial role in analyzing the\ncapabilities and limitations of iris recognition systems. Among the various\nmethodologies proposed, Daugman's approach to iris uniqueness stands out as one\nof the most widely accepted. According to Daugman, uniqueness refers to the\niris recognition system's ability to enroll an increasing number of classes\nwhile maintaining a near-zero probability of collision between new and enrolled\nclasses. Daugman's approach involves creating distinct IrisCode templates for\neach iris class within the system and evaluating the sustainable population\nunder a fixed Hamming distance between codewords. In our previous work [23], we\nutilized Rate-Distortion Theory (as it pertains to the limits of\nerror-correction codes) to establish boundaries for the maximum possible\npopulation of iris classes supported by Daugman's IrisCode, given the\nconstraint of a fixed Hamming distance between codewords. Building upon that\nresearch, we propose a novel methodology to evaluate the scalability of an iris\nrecognition system, while also measuring iris quality. We achieve this by\nemploying a sphere-packing bound for Gaussian codewords and adopting a approach\nsimilar to Daugman's, which utilizes relative entropy as a distance measure\nbetween iris classes. To demonstrate the efficacy of our methodology, we\nillustrate its application on two small datasets of iris images. We determine\nthe sustainable maximum population for each dataset based on the quality of the\nimages. By providing these illustrations, we aim to assist researchers in\ncomprehending the limitations inherent in their recognition systems, depending\non the quality of their iris databases.\n","authors":["Katelyn M. Hampel","Jinyu Zuo","Priyanka Das","Natalia A. Schmid","Stephanie Schuckers","Joseph Skufca","Matthew C. Valenti"],"pdf_url":"https://arxiv.org/pdf/2306.12572v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12570v1","updated":"2023-06-21T21:09:45Z","published":"2023-06-21T21:09:45Z","title":"Local 3D Editing via 3D Distillation of CLIP Knowledge","summary":"  3D content manipulation is an important computer vision task with many\nreal-world applications (e.g., product design, cartoon generation, and 3D\nAvatar editing). Recently proposed 3D GANs can generate diverse photorealistic\n3D-aware contents using Neural Radiance fields (NeRF). However, manipulation of\nNeRF still remains a challenging problem since the visual quality tends to\ndegrade after manipulation and suboptimal control handles such as 2D semantic\nmaps are used for manipulations. While text-guided manipulations have shown\npotential in 3D editing, such approaches often lack locality. To overcome these\nproblems, we propose Local Editing NeRF (LENeRF), which only requires text\ninputs for fine-grained and localized manipulation. Specifically, we present\nthree add-on modules of LENeRF, the Latent Residual Mapper, the Attention Field\nNetwork, and the Deformation Network, which are jointly used for local\nmanipulations of 3D features by estimating a 3D attention field. The 3D\nattention field is learned in an unsupervised way, by distilling the zero-shot\nmask generation capability of CLIP to the 3D space with multi-view guidance. We\nconduct diverse experiments and thorough evaluations both quantitatively and\nqualitatively.\n","authors":["Junha Hyung","Sungwon Hwang","Daejin Kim","Hyunji Lee","Jaegul Choo"],"pdf_url":"https://arxiv.org/pdf/2306.12570v1.pdf","comment":"conference: CVPR 2023"},{"id":"http://arxiv.org/abs/2306.12562v1","updated":"2023-06-21T21:00:46Z","published":"2023-06-21T21:00:46Z","title":"Neural Spectro-polarimetric Fields","summary":"  Modeling the spatial radiance distribution of light rays in a scene has been\nextensively explored for applications, including view synthesis. Spectrum and\npolarization, the wave properties of light, are often neglected due to their\nintegration into three RGB spectral bands and their non-perceptibility to human\nvision. Despite this, these properties encompass substantial material and\ngeometric information about a scene. In this work, we propose to model\nspectro-polarimetric fields, the spatial Stokes-vector distribution of any\nlight ray at an arbitrary wavelength. We present Neural Spectro-polarimetric\nFields (NeSpoF), a neural representation that models the physically-valid\nStokes vector at given continuous variables of position, direction, and\nwavelength. NeSpoF manages inherently noisy raw measurements, showcases memory\nefficiency, and preserves physically vital signals, factors that are crucial\nfor representing the high-dimensional signal of a spectro-polarimetric field.\nTo validate NeSpoF, we introduce the first multi-view\nhyperspectral-polarimetric image dataset, comprised of both synthetic and\nreal-world scenes. These were captured using our compact\nhyperspectral-polarimetric imaging system, which has been calibrated for\nrobustness against system imperfections. We demonstrate the capabilities of\nNeSpoF on diverse scenes.\n","authors":["Youngchan Kim","Wonjoon Jin","Sunghyun Cho","Seung-Hwan Baek"],"pdf_url":"https://arxiv.org/pdf/2306.12562v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12559v1","updated":"2023-06-21T20:54:52Z","published":"2023-06-21T20:54:52Z","title":"Exploring the Role of Audio in Video Captioning","summary":"  Recent focus in video captioning has been on designing architectures that can\nconsume both video and text modalities, and using large-scale video datasets\nwith text transcripts for pre-training, such as HowTo100M. Though these\napproaches have achieved significant improvement, the audio modality is often\nignored in video captioning. In this work, we present an audio-visual\nframework, which aims to fully exploit the potential of the audio modality for\ncaptioning. Instead of relying on text transcripts extracted via automatic\nspeech recognition (ASR), we argue that learning with raw audio signals can be\nmore beneficial, as audio has additional information including acoustic events,\nspeaker identity, etc. Our contributions are twofold. First, we observed that\nthe model overspecializes to the audio modality when pre-training with both\nvideo and audio modality, since the ground truth (i.e., text transcripts) can\nbe solely predicted using audio. We proposed a Modality Balanced Pre-training\n(MBP) loss to mitigate this issue and significantly improve the performance on\ndownstream tasks. Second, we slice and dice different design choices of the\ncross-modal module, which may become an information bottleneck and generate\ninferior results. We proposed new local-global fusion mechanisms to improve\ninformation exchange across audio and video. We demonstrate significant\nimprovements by leveraging the audio modality on four datasets, and even\noutperform the state of the art on some metrics without relying on the text\nmodality as the input.\n","authors":["Yuhan Shen","Linjie Yang","Longyin Wen","Haichao Yu","Ehsan Elhamifar","Heng Wang"],"pdf_url":"https://arxiv.org/pdf/2306.12559v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12547v1","updated":"2023-06-21T20:21:15Z","published":"2023-06-21T20:21:15Z","title":"DGC-GNN: Descriptor-free Geometric-Color Graph Neural Network for 2D-3D\n  Matching","summary":"  Direct matching of 2D keypoints in an input image to a 3D point cloud of the\nscene without requiring visual descriptors has garnered increased interest due\nto its lower memory requirements, inherent privacy preservation, and reduced\nneed for expensive 3D model maintenance compared to visual descriptor-based\nmethods. However, existing algorithms often compromise on performance,\nresulting in a significant deterioration compared to their descriptor-based\ncounterparts. In this paper, we introduce DGC-GNN, a novel algorithm that\nemploys a global-to-local Graph Neural Network (GNN) that progressively\nexploits geometric and color cues to represent keypoints, thereby improving\nmatching robustness. Our global-to-local procedure encodes both Euclidean and\nangular relations at a coarse level, forming the geometric embedding to guide\nthe local point matching. We evaluate DGC-GNN on both indoor and outdoor\ndatasets, demonstrating that it not only doubles the accuracy of the\nstate-of-the-art descriptor-free algorithm but, also, substantially narrows the\nperformance gap between descriptor-based and descriptor-free methods. The code\nand trained models will be made publicly available.\n","authors":["Shuzhe Wang","Juho Kannala","Daniel Barath"],"pdf_url":"https://arxiv.org/pdf/2306.12547v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11360v2","updated":"2023-06-21T19:56:14Z","published":"2023-01-26T19:17:10Z","title":"The Power of Linear Combinations: Learning with Random Convolutions","summary":"  Following the traditional paradigm of convolutional neural networks (CNNs),\nmodern CNNs manage to keep pace with more recent, for example\ntransformer-based, models by not only increasing model depth and width but also\nthe kernel size. This results in large amounts of learnable model parameters\nthat need to be handled during training. While following the convolutional\nparadigm with the according spatial inductive bias, we question the\nsignificance of \\emph{learned} convolution filters. In fact, our findings\ndemonstrate that many contemporary CNN architectures can achieve high test\naccuracies without ever updating randomly initialized (spatial) convolution\nfilters. Instead, simple linear combinations (implemented through efficient\n$1\\times 1$ convolutions) suffice to effectively recombine even random filters\ninto expressive network operators. Furthermore, these combinations of random\nfilters can implicitly regularize the resulting operations, mitigating\noverfitting and enhancing overall performance and robustness. Conversely,\nretaining the ability to learn filter updates can impair network performance.\nLastly, although we only observe relatively small gains from learning $3\\times\n3$ convolutions, the learning gains increase proportionally with kernel size,\nowing to the non-idealities of the independent and identically distributed\n(\\textit{i.i.d.}) nature of default initialization techniques.\n","authors":["Paul Gavrikov","Janis Keuper"],"pdf_url":"https://arxiv.org/pdf/2301.11360v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12525v1","updated":"2023-06-21T19:20:15Z","published":"2023-06-21T19:20:15Z","title":"LPFormer: LiDAR Pose Estimation Transformer with Multi-Task Network","summary":"  In this technical report, we present the 1st place solution for the 2023\nWaymo Open Dataset Pose Estimation challenge. Due to the difficulty of\nacquiring large-scale 3D human keypoint annotation, previous methods have\ncommonly relied on 2D image features and 2D sequential annotations for 3D human\npose estimation. In contrast, our proposed method, named LPFormer, uses only\nLiDAR as its input along with its corresponding 3D annotations. LPFormer\nconsists of two stages: the first stage detects the human bounding box and\nextracts multi-level feature representations, while the second stage employs a\ntransformer-based network to regress the human keypoints using these features.\nExperimental results on the Waymo Open Dataset demonstrate the top performance,\nand improvements even compared to previous multi-modal solutions.\n","authors":["Dongqiangzi Ye","Yufei Xie","Weijia Chen","Zixiang Zhou","Hassan Foroosh"],"pdf_url":"https://arxiv.org/pdf/2306.12525v1.pdf","comment":"Technical report of the top solution for the Waymo Open Dataset\n  Challenges 2023 - Pose Estimation. CVPR 2023 Workshop on Autonomous Driving"},{"id":"http://arxiv.org/abs/2306.12517v1","updated":"2023-06-21T19:06:41Z","published":"2023-06-21T19:06:41Z","title":"FFCV: Accelerating Training by Removing Data Bottlenecks","summary":"  We present FFCV, a library for easy and fast machine learning model training.\nFFCV speeds up model training by eliminating (often subtle) data bottlenecks\nfrom the training process. In particular, we combine techniques such as an\nefficient file storage format, caching, data pre-loading, asynchronous data\ntransfer, and just-in-time compilation to (a) make data loading and transfer\nsignificantly more efficient, ensuring that GPUs can reach full utilization;\nand (b) offload as much data processing as possible to the CPU asynchronously,\nfreeing GPU cycles for training. Using FFCV, we train ResNet-18 and ResNet-50\non the ImageNet dataset with competitive tradeoff between accuracy and training\ntime. For example, we are able to train an ImageNet ResNet-50 model to 75\\% in\nonly 20 mins on a single machine. We demonstrate FFCV's performance,\nease-of-use, extensibility, and ability to adapt to resource constraints\nthrough several case studies. Detailed installation instructions,\ndocumentation, and Slack support channel are available at https://ffcv.io/ .\n","authors":["Guillaume Leclerc","Andrew Ilyas","Logan Engstrom","Sung Min Park","Hadi Salman","Aleksander Madry"],"pdf_url":"https://arxiv.org/pdf/2306.12517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12511v1","updated":"2023-06-21T18:49:22Z","published":"2023-06-21T18:49:22Z","title":"Semi-Implicit Denoising Diffusion Models (SIDDMs)","summary":"  Despite the proliferation of generative models, achieving fast sampling\nduring inference without compromising sample diversity and quality remains\nchallenging. Existing models such as Denoising Diffusion Probabilistic Models\n(DDPM) deliver high-quality, diverse samples but are slowed by an inherently\nhigh number of iterative steps. The Denoising Diffusion Generative Adversarial\nNetworks (DDGAN) attempted to circumvent this limitation by integrating a GAN\nmodel for larger jumps in the diffusion process. However, DDGAN encountered\nscalability limitations when applied to large datasets. To address these\nlimitations, we introduce a novel approach that tackles the problem by matching\nimplicit and explicit factors. More specifically, our approach involves\nutilizing an implicit model to match the marginal distributions of noisy data\nand the explicit conditional distribution of the forward diffusion. This\ncombination allows us to effectively match the joint denoising distributions.\nUnlike DDPM but similar to DDGAN, we do not enforce a parametric distribution\nfor the reverse step, enabling us to take large steps during inference. Similar\nto the DDPM but unlike DDGAN, we take advantage of the exact form of the\ndiffusion process. We demonstrate that our proposed method obtains comparable\ngenerative performance to diffusion-based models and vastly superior results to\nmodels with a small number of sampling steps.\n","authors":["Yanwu Xu","Mingming Gong","Shaoan Xie","Wei Wei","Matthias Grundmann","kayhan Batmanghelich","Tingbo Hou"],"pdf_url":"https://arxiv.org/pdf/2306.12511v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12510v1","updated":"2023-06-21T18:49:21Z","published":"2023-06-21T18:49:21Z","title":"Comparative Analysis of Segment Anything Model and U-Net for Breast\n  Tumor Detection in Ultrasound and Mammography Images","summary":"  In this study, the main objective is to develop an algorithm capable of\nidentifying and delineating tumor regions in breast ultrasound (BUS) and\nmammographic images. The technique employs two advanced deep learning\narchitectures, namely U-Net and pretrained SAM, for tumor segmentation. The\nU-Net model is specifically designed for medical image segmentation and\nleverages its deep convolutional neural network framework to extract meaningful\nfeatures from input images. On the other hand, the pretrained SAM architecture\nincorporates a mechanism to capture spatial dependencies and generate\nsegmentation results. Evaluation is conducted on a diverse dataset containing\nannotated tumor regions in BUS and mammographic images, covering both benign\nand malignant tumors. This dataset enables a comprehensive assessment of the\nalgorithm's performance across different tumor types. Results demonstrate that\nthe U-Net model outperforms the pretrained SAM architecture in accurately\nidentifying and segmenting tumor regions in both BUS and mammographic images.\nThe U-Net exhibits superior performance in challenging cases involving\nirregular shapes, indistinct boundaries, and high tumor heterogeneity. In\ncontrast, the pretrained SAM architecture exhibits limitations in accurately\nidentifying tumor areas, particularly for malignant tumors and objects with\nweak boundaries or complex shapes. These findings highlight the importance of\nselecting appropriate deep learning architectures tailored for medical image\nsegmentation. The U-Net model showcases its potential as a robust and accurate\ntool for tumor detection, while the pretrained SAM architecture suggests the\nneed for further improvements to enhance segmentation performance.\n","authors":["Mohsen Ahmadi","Masoumeh Farhadi Nia","Sara Asgarian","Kasra Danesh","Elyas Irankhah","Ahmad Gholizadeh Lonbar","Abbas Sharifi"],"pdf_url":"https://arxiv.org/pdf/2306.12510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.00132v2","updated":"2023-06-21T16:27:57Z","published":"2022-03-31T22:54:49Z","title":"Real-Time and Robust 3D Object Detection Within Road-Side LiDARs Using\n  Domain Adaptation","summary":"  This work aims to address the challenges in domain adaptation of 3D object\ndetection using infrastructure LiDARs. We design a model DASE-ProPillars that\ncan detect vehicles in infrastructure-based LiDARs in real-time. Our model uses\nPointPillars as the baseline model with additional modules to improve the 3D\ndetection performance. To prove the effectiveness of our proposed modules in\nDASE-ProPillars, we train and evaluate the model on two datasets, the open\nsource A9-Dataset and a semi-synthetic infrastructure dataset created within\nthe Regensburg Next project. We do several sets of experiments for each module\nin the DASE-ProPillars detector that show that our model outperforms the\nSE-ProPillars baseline on the real A9 test set and a semi-synthetic A9 test\nset, while maintaining an inference speed of 45 Hz (22 ms). We apply domain\nadaptation from the semi-synthetic A9-Dataset to the semi-synthetic dataset\nfrom the Regensburg Next project by applying transfer learning and achieve a 3D\nmAP@0.25 of 93.49% on the Car class of the target test set using 40 recall\npositions.\n","authors":["Walter Zimmer","Marcus Grabler","Alois Knoll"],"pdf_url":"https://arxiv.org/pdf/2204.00132v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12461v1","updated":"2023-06-21T12:16:36Z","published":"2023-06-21T12:16:36Z","title":"Lightweight learning from label proportions on satellite imagery","summary":"  This work addresses the challenge of producing chip level predictions on\nsatellite imagery when only label proportions at a coarser spatial geometry are\navailable, typically from statistical or aggregated data from administrative\ndivisions (such as municipalities or communes). This kind of tabular data is\nusually widely available in many regions of the world and application areas\nand, thus, its exploitation may contribute to leverage the endemic scarcity of\nfine grained labelled data in Earth Observation (EO). This can be framed as a\nLearning from Label Proportions (LLP) problem setup. LLP applied to EO data is\nstill an emerging field and performing comparative studies in applied scenarios\nremains a challenge due to the lack of standardized datasets. In this work,\nfirst, we show how simple deep learning and probabilistic methods generally\nperform better than standard more complex ones, providing a surprising level of\nfiner grained spatial detail when trained with much coarser label proportions.\nSecond, we provide a set of benchmarking datasets enabling comparative LLP\napplied to EO, providing both fine grained labels and aggregated data according\nto existing administrative divisions. Finally, we argue how this approach might\nbe valuable when considering on-orbit inference and training. Source code is\navailable at https://github.com/rramosp/llpeo\n","authors":["Raúl Ramos-Pollán","Fabio A. González"],"pdf_url":"https://arxiv.org/pdf/2306.12461v1.pdf","comment":"16 pages, 13 figures"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2306.12249v1","updated":"2023-06-21T13:12:12Z","published":"2023-06-21T13:12:12Z","title":"Knowledge-based Multimodal Music Similarity","summary":"  Music similarity is an essential aspect of music retrieval, recommendation\nsystems, and music analysis. Moreover, similarity is of vital interest for\nmusic experts, as it allows studying analogies and influences among composers\nand historical periods. Current approaches to musical similarity rely mainly on\nsymbolic content, which can be expensive to produce and is not always readily\navailable. Conversely, approaches using audio signals typically fail to provide\nany insight about the reasons behind the observed similarity. This research\naddresses the limitations of current approaches by focusing on the study of\nmusical similarity using both symbolic and audio content. The aim of this\nresearch is to develop a fully explainable and interpretable system that can\nprovide end-users with more control and understanding of music similarity and\nclassification systems.\n","authors":["Andrea Poltronieri"],"pdf_url":"https://arxiv.org/pdf/2306.12249v1.pdf","comment":"11 pages, 1 figure"},{"id":"http://arxiv.org/abs/2306.12235v1","updated":"2023-06-21T12:53:31Z","published":"2023-06-21T12:53:31Z","title":"CompMix: A Benchmark for Heterogeneous Question Answering","summary":"  Fact-centric question answering (QA) often requires access to multiple,\nheterogeneous, information sources. By jointly considering several sources like\na knowledge base (KB), a text collection, and tables from the web, QA systems\ncan enhance their answer coverage and confidence. However, existing QA\nbenchmarks are mostly constructed with a single source of knowledge in mind.\nThis limits capabilities of these benchmarks to fairly evaluate QA systems that\ncan tap into more than one information repository. To bridge this gap, we\nrelease CompMix, a crowdsourced QA benchmark which naturally demands the\nintegration of a mixture of input sources. CompMix has a total of 9,410\nquestions, and features several complex intents like joins and temporal\nconditions. Evaluation of a range of QA systems on CompMix highlights the need\nfor further research on leveraging information from heterogeneous sources.\n","authors":["Philipp Christmann","Rishiraj Saha Roy","Gerhard Weikum"],"pdf_url":"https://arxiv.org/pdf/2306.12235v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12232v1","updated":"2023-06-21T12:45:17Z","published":"2023-06-21T12:45:17Z","title":"STAN: Stage-Adaptive Network for Multi-Task Recommendation by Learning\n  User Lifecycle-Based Representation","summary":"  Recommendation systems play a vital role in many online platforms, with their\nprimary objective being to satisfy and retain users. As directly optimizing\nuser retention is challenging, multiple evaluation metrics are often employed.\nExisting methods generally formulate the optimization of these evaluation\nmetrics as a multitask learning problem, but often overlook the fact that user\npreferences for different tasks are personalized and change over time.\nIdentifying and tracking the evolution of user preferences can lead to better\nuser retention. To address this issue, we introduce the concept of \"user\nlifecycle\", consisting of multiple stages characterized by users' varying\npreferences for different tasks. We propose a novel Stage-Adaptive Network\n(STAN) framework for modeling user lifecycle stages. STAN first identifies\nlatent user lifecycle stages based on learned user preferences, and then\nemploys the stage representation to enhance multi-task learning performance.\nOur experimental results using both public and industrial datasets demonstrate\nthat the proposed model significantly improves multi-task prediction\nperformance compared to state-of-the-art methods, highlighting the importance\nof considering user lifecycle stages in recommendation systems. Furthermore,\nonline A/B testing reveals that our model outperforms the existing model,\nachieving a significant improvement of 3.05% in staytime per user and 0.88% in\nCVR. These results indicate that our approach effectively improves the overall\nefficiency of the multi-task recommendation system.\n","authors":["Wanda Li","Wenhao Zheng","Xuanji Xiao","Suhang Wang"],"pdf_url":"https://arxiv.org/pdf/2306.12232v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12165v1","updated":"2023-06-21T10:40:17Z","published":"2023-06-21T10:40:17Z","title":"Post-hoc Selection of Pareto-Optimal Solutions in Search and\n  Recommendation","summary":"  Information Retrieval (IR) and Recommender Systems (RS) tasks are moving from\ncomputing a ranking of final results based on a single metric to\nmulti-objective problems. Solving these problems leads to a set of\nPareto-optimal solutions, known as Pareto frontier, in which no objective can\nbe further improved without hurting the others. In principle, all the points on\nthe Pareto frontier are potential candidates to represent the best model\nselected with respect to the combination of two, or more, metrics. To our\nknowledge, there are no well-recognized strategies to decide which point should\nbe selected on the frontier. In this paper, we propose a novel, post-hoc,\ntheoretically-justified technique, named \"Population Distance from Utopia\"\n(PDU), to identify and select the one-best Pareto-optimal solution from the\nfrontier. In detail, PDU analyzes the distribution of the points by\ninvestigating how far each point is from its utopia point (the ideal\nperformance for the objectives). The possibility of considering fine-grained\nutopia points allows PDU to select solutions tailored to individual user\npreferences, a novel feature we call \"calibration\". We compare PDU against\nexisting state-of-the-art strategies through extensive experiments on tasks\nfrom both IR and RS. Experimental results show that PDU and combined with\ncalibration notably impact the solution selection. Furthermore, the results\nshow that the proposed framework selects a solution in a principled way,\nirrespective of its position on the frontier, thus overcoming the limits of\nother strategies.\n","authors":["Vincenzo Paparella","Vito Walter Anelli","Franco Maria Nardini","Raffaele Perego","Tommaso Di Noia"],"pdf_url":"https://arxiv.org/pdf/2306.12165v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12118v1","updated":"2023-06-21T09:01:53Z","published":"2023-06-21T09:01:53Z","title":"Visualizing Relation Between (De)Motivating Topics and Public Stance\n  toward COVID-19 Vaccine","summary":"  While social media plays a vital role in communication nowadays,\nmisinformation and trolls can easily take over the conversation and steer\npublic opinion on these platforms. We saw the effect of misinformation during\nthe {COVID-19} pandemic when public health officials faced significant\npush-back while trying to motivate the public to vaccinate. To tackle the\ncurrent and any future threats in emergencies and motivate the public towards a\ncommon goal, it is essential to understand how public motivation shifts and\nwhich topics resonate among the general population. In this study, we proposed\nan interactive visualization tool to inspect and analyze the topics that\nresonated among Twitter-sphere during the {COVID-19} pandemic and understand\nthe key factors that shifted public stance for vaccination. This tool can\neasily be generalized for any scenario for visual analysis and to increase the\ntransparency of social media data for researchers and the general population\nalike.\n","authors":["Ashiqur Rahman","Hamed Alhoori"],"pdf_url":"https://arxiv.org/pdf/2306.12118v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12027v1","updated":"2023-06-21T05:27:08Z","published":"2023-06-21T05:27:08Z","title":"Comparative analysis of various web crawler algorithms","summary":"  This presentation focuses on the importance of web crawling and page ranking\nalgorithms in dealing with the massive amount of data present on the World Wide\nWeb. As the web continues to grow exponentially, efficient search and retrieval\nmethods become crucial. Web crawling is a process that converts unstructured\ndata into structured data, enabling effective information retrieval.\nAdditionally, page ranking algorithms play a significant role in assessing the\nquality and popularity of web pages. The presentation explores the background\nof these algorithms and evaluates five different crawling algorithms: Shark\nSearch, Priority-Based Queue, Naive Bayes, Breadth-First, and Depth-First. The\ngoal is to identify the most effective algorithm for crawling web pages. By\nunderstanding these algorithms, we can enhance our ability to navigate the web\nand extract valuable information efficiently.\n","authors":["Nithin T K","Chandana S","Barani G","Chavva Dharani","M S Karishma"],"pdf_url":"https://arxiv.org/pdf/2306.12027v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11986v1","updated":"2023-06-21T02:42:37Z","published":"2023-06-21T02:42:37Z","title":"Addressing the Rank Degeneration in Sequential Recommendation via\n  Singular Spectrum Smoothing","summary":"  Sequential recommendation (SR) investigates the dynamic user preferences\nmodeling and generates the next-item prediction. The next item preference is\ntypically generated by the affinity between the sequence and item\nrepresentations. However, both sequence and item representations suffer from\nthe rank degeneration issue due to the data sparsity problem. The rank\ndegeneration issue significantly impairs the representations for SR. This\nmotivates us to measure how severe is the rank degeneration issue and alleviate\nthe sequence and item representation rank degeneration issues simultaneously\nfor SR.\n  In this work, we theoretically connect the sequence representation\ndegeneration issue with the item rank degeneration, particularly for short\nsequences and cold items. We also identify the connection between the fast\nsingular value decay phenomenon and the rank collapse issue in transformer\nsequence output and item embeddings. We propose the area under the singular\nvalue curve metric to evaluate the severity of the singular value decay\nphenomenon and use it as an indicator of rank degeneration. We further\nintroduce a novel singular spectrum smoothing regularization to alleviate the\nrank degeneration on both sequence and item sides, which is the Singular\nsPectrum sMoothing for sequential Recommendation (SPMRec). We also establish a\ncorrelation between the ranks of sequence and item embeddings and the rank of\nthe user-item preference prediction matrix, which can affect recommendation\ndiversity. We conduct experiments on four benchmark datasets to demonstrate the\nsuperiority of SPMRec over the state-of-the-art recommendation methods,\nespecially in short sequences. The experiments also demonstrate a strong\nconnection between our proposed singular spectrum smoothing and recommendation\ndiversity.\n","authors":["Ziwei Fan","Zhiwei Liu","Hao Peng","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2306.11986v1.pdf","comment":"18 pages, regularizations on preserving embedding rank are surrogates\n  of intra-list recommendation diversity (controllable diversity). The code is\n  in https://github.com/zfan20/SPMRec"},{"id":"http://arxiv.org/abs/2306.11964v1","updated":"2023-06-21T01:26:34Z","published":"2023-06-21T01:26:34Z","title":"Sampling Individually-Fair Rankings that are Always Group Fair","summary":"  Rankings on online platforms help their end-users find the relevant\ninformation -- people, news, media, and products -- quickly. Fair ranking\ntasks, which ask to rank a set of items to maximize utility subject to\nsatisfying group-fairness constraints, have gained significant interest in the\nAlgorithmic Fairness, Information Retrieval, and Machine Learning literature.\nRecent works, however, identify uncertainty in the utilities of items as a\nprimary cause of unfairness and propose introducing randomness in the output.\nThis randomness is carefully chosen to guarantee an adequate representation of\neach item (while accounting for the uncertainty). However, due to this\nrandomness, the output rankings may violate group fairness constraints. We give\nan efficient algorithm that samples rankings from an individually-fair\ndistribution while ensuring that every output ranking is group fair. The\nexpected utility of the output ranking is at least $\\alpha$ times the utility\nof the optimal fair solution. Here, $\\alpha$ depends on the utilities,\nposition-discounts, and constraints -- it approaches 1 as the range of\nutilities or the position-discounts shrinks, or when utilities satisfy\ndistributional assumptions. Empirically, we observe that our algorithm achieves\nindividual and group fairness and that Pareto dominates the state-of-the-art\nbaselines.\n","authors":["Sruthi Gorantla","Anay Mehrotra","Amit Deshpande","Anand Louis"],"pdf_url":"https://arxiv.org/pdf/2306.11964v1.pdf","comment":"Full version of a paper accepted for presentation in ACM AIES 2023"},{"id":"http://arxiv.org/abs/2306.11963v1","updated":"2023-06-21T01:22:43Z","published":"2023-06-21T01:22:43Z","title":"Multimodality Fusion for Smart Healthcare: a Journey from Data,\n  Information, Knowledge to Wisdom","summary":"  Multimodal medical data fusion has emerged as a transformative approach in\nsmart healthcare, enabling a comprehensive understanding of patient health and\npersonalized treatment plans. In this paper, a journey from data, information,\nand knowledge to wisdom (DIKW) is explored through multimodal fusion for smart\nhealthcare. A comprehensive review of multimodal medical data fusion focuses on\nthe integration of various data modalities are presented. It explores different\napproaches such as Feature selection, Rule-based systems, Machine learning,\nDeep learning, and Natural Language Processing for fusing and analyzing\nmultimodal data. The paper also highlights the challenges associated with\nmultimodal fusion in healthcare. By synthesizing the reviewed frameworks and\ninsights, a generic framework for multimodal medical data fusion is proposed\nwhile aligning with the DIKW mechanism. Moreover, it discusses future\ndirections aligned with the four pillars of healthcare: Predictive, Preventive,\nPersonalized, and Participatory approaches based on the DIKW and the generic\nframework. The components from this comprehensive survey form the foundation\nfor the successful implementation of multimodal fusion in smart healthcare. The\nfindings of this survey can guide researchers and practitioners in leveraging\nthe power of multimodal fusion with the approaches to revolutionize healthcare\nand improve patient outcomes.\n","authors":["Thanveer Shaik","Xiaohui Tao","Lin Li","Haoran Xie","Juan D. Velásquez"],"pdf_url":"https://arxiv.org/pdf/2306.11963v1.pdf","comment":"This work has been submitted to the ELSEVIER for possible\n  publication. Copyright may be transferred without notice, after which this\n  version may no longer be accessible"},{"id":"http://arxiv.org/abs/2302.13522v2","updated":"2023-06-21T23:30:52Z","published":"2023-02-27T05:21:35Z","title":"IGB: Addressing The Gaps In Labeling, Features, Heterogeneity, and Size\n  of Public Graph Datasets for Deep Learning Research","summary":"  Graph neural networks (GNNs) have shown high potential for a variety of\nreal-world, challenging applications, but one of the major obstacles in GNN\nresearch is the lack of large-scale flexible datasets. Most existing public\ndatasets for GNNs are relatively small, which limits the ability of GNNs to\ngeneralize to unseen data. The few existing large-scale graph datasets provide\nvery limited labeled data. This makes it difficult to determine if the GNN\nmodel's low accuracy for unseen data is inherently due to insufficient training\ndata or if the model failed to generalize. Additionally, datasets used to train\nGNNs need to offer flexibility to enable a thorough study of the impact of\nvarious factors while training GNN models.\n  In this work, we introduce the Illinois Graph Benchmark (IGB), a research\ndataset tool that the developers can use to train, scrutinize and\nsystematically evaluate GNN models with high fidelity. IGB includes both\nhomogeneous and heterogeneous academic graphs of enormous sizes, with more than\n40% of their nodes labeled. Compared to the largest graph datasets publicly\navailable, the IGB provides over 162X more labeled data for deep learning\npractitioners and developers to create and evaluate models with higher\naccuracy. The IGB dataset is a collection of academic graphs designed to be\nflexible, enabling the study of various GNN architectures, embedding generation\ntechniques, and analyzing system performance issues for node classification\ntasks. IGB is open-sourced, supports DGL and PyG frameworks, and comes with\nreleases of the raw text that we believe foster emerging language models and\nGNN research projects. An early public version of IGB is available at\nhttps://github.com/IllinoisGraphBenchmark/IGB-Datasets.\n","authors":["Arpandeep Khatua","Vikram Sharma Mailthody","Bhagyashree Taleka","Tengfei Ma","Xiang Song","Wen-mei Hwu"],"pdf_url":"https://arxiv.org/pdf/2302.13522v2.pdf","comment":"Accepted in KDD'23 conference. This is final preprint version"},{"id":"http://arxiv.org/abs/2306.12601v1","updated":"2023-06-21T22:58:10Z","published":"2023-06-21T22:58:10Z","title":"Resources and Evaluations for Multi-Distribution Dense Information\n  Retrieval","summary":"  We introduce and define the novel problem of multi-distribution information\nretrieval (IR) where given a query, systems need to retrieve passages from\nwithin multiple collections, each drawn from a different distribution. Some of\nthese collections and distributions might not be available at training time. To\nevaluate methods for multi-distribution retrieval, we design three benchmarks\nfor this task from existing single-distribution datasets, namely, a dataset\nbased on question answering and two based on entity matching. We propose simple\nmethods for this task which allocate the fixed retrieval budget (top-k\npassages) strategically across domains to prevent the known domains from\nconsuming most of the budget. We show that our methods lead to an average of\n3.8+ and up to 8.0 points improvements in Recall@100 across the datasets and\nthat improvements are consistent when fine-tuning different base retrieval\nmodels. Our benchmarks are made publicly available.\n","authors":["Soumya Chatterjee","Omar Khattab","Simran Arora"],"pdf_url":"https://arxiv.org/pdf/2306.12601v1.pdf","comment":"REML @ SIGIR 2023; 9 pages, 8 figures"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2306.12422v1","updated":"2023-06-21T17:59:45Z","published":"2023-06-21T17:59:45Z","title":"DreamTime: An Improved Optimization Strategy for Text-to-3D Content\n  Creation","summary":"  Text-to-image diffusion models pre-trained on billions of image-text pairs\nhave recently enabled text-to-3D content creation by optimizing a randomly\ninitialized Neural Radiance Fields (NeRF) with score distillation. However, the\nresultant 3D models exhibit two limitations: (a) quality concerns such as\nsaturated color and the Janus problem; (b) extremely low diversity comparing to\ntext-guided image synthesis. In this paper, we show that the conflict between\nNeRF optimization process and uniform timestep sampling in score distillation\nis the main reason for these limitations. To resolve this conflict, we propose\nto prioritize timestep sampling with monotonically non-increasing functions,\nwhich aligns NeRF optimization with the sampling process of diffusion model.\nExtensive experiments show that our simple redesign significantly improves\ntext-to-3D content creation with higher quality and diversity.\n","authors":["Yukun Huang","Jianan Wang","Yukai Shi","Xianbiao Qi","Zheng-Jun Zha","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.12422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.09633v3","updated":"2023-06-21T17:53:42Z","published":"2023-06-16T05:32:24Z","title":"The False Dawn: Reevaluating Google's Reinforcement Learning for Chip\n  Macro Placement","summary":"  Reinforcement learning (RL) for physical design of silicon chips in a Google\n2021 Nature paper stirred controversy due to poorly documented claims that\nraised eyebrows and attracted critical media coverage. The Nature paper\nwithheld most inputs needed to produce reported results and some critical steps\nin the methodology. But two separate evaluations filled in the gaps and\ndemonstrated that Google RL lags behind human designers, behind a well-known\nalgorithm (Simulated Annealing), and also behind generally-available commercial\nsoftware. Crosschecked data indicate that the integrity of the Nature paper is\nsubstantially undermined owing to errors in the conduct, analysis and\nreporting.\n","authors":["Igor L. Markov"],"pdf_url":"https://arxiv.org/pdf/2306.09633v3.pdf","comment":"14 pages, 1 figure, 3 tables (v3 clarifies the numbers of chip design\n  examples used in [1])"},{"id":"http://arxiv.org/abs/2306.12413v1","updated":"2023-06-21T17:51:32Z","published":"2023-06-21T17:51:32Z","title":"Addressing Discontinuous Root-Finding for Subsequent Differentiability\n  in Machine Learning, Inverse Problems, and Control","summary":"  There are many physical processes that have inherent discontinuities in their\nmathematical formulations. This paper is motivated by the specific case of\ncollisions between two rigid or deformable bodies and the intrinsic nature of\nthat discontinuity. The impulse response to a collision is discontinuous with\nthe lack of any response when no collision occurs, which causes difficulties\nfor numerical approaches that require differentiability which are typical in\nmachine learning, inverse problems, and control. We theoretically and\nnumerically demonstrate that the derivative of the collision time with respect\nto the parameters becomes infinite as one approaches the barrier separating\ncolliding from not colliding, and use lifting to complexify the solution space\nso that solutions on the other side of the barrier are directly attainable as\nprecise values. Subsequently, we mollify the barrier posed by the unbounded\nderivatives, so that one can tunnel back and forth in a smooth and reliable\nfashion facilitating the use of standard numerical approaches. Moreover, we\nillustrate that standard approaches fail in numerous ways mostly due to a lack\nof understanding of the mathematical nature of the problem (e.g. typical\nbackpropagation utilizes many rules of differentiation, but ignores L'Hopital's\nrule).\n","authors":["Daniel Johnson","Ronald Fedkiw"],"pdf_url":"https://arxiv.org/pdf/2306.12413v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05040v2","updated":"2023-06-21T17:44:58Z","published":"2023-02-10T04:05:24Z","title":"PATCorrect: Non-autoregressive Phoneme-augmented Transformer for ASR\n  Error Correction","summary":"  Speech-to-text errors made by automatic speech recognition (ASR) systems\nnegatively impact downstream models. Error correction models as a\npost-processing text editing method have been recently developed for refining\nthe ASR outputs. However, efficient models that meet the low latency\nrequirements of industrial grade production systems have not been well studied.\nWe propose PATCorrect-a novel non-autoregressive (NAR) approach based on\nmulti-modal fusion leveraging representations from both text and phoneme\nmodalities, to reduce word error rate (WER) and perform robustly with varying\ninput transcription quality. We demonstrate that PATCorrect consistently\noutperforms state-of-the-art NAR method on English corpus across different\nupstream ASR systems, with an overall 11.62% WER reduction (WERR) compared to\n9.46% WERR achieved by other methods using text only modality. Besides, its\ninference latency is at tens of milliseconds, making it ideal for systems with\nlow latency requirements.\n","authors":["Ziji Zhang","Zhehui Wang","Rajesh Kamma","Sharanya Eswaran","Narayanan Sadagopan"],"pdf_url":"https://arxiv.org/pdf/2302.05040v2.pdf","comment":"Accepted camera-ready version for INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2306.12400v1","updated":"2023-06-21T17:39:16Z","published":"2023-06-21T17:39:16Z","title":"Timely Asynchronous Hierarchical Federated Learning: Age of Convergence","summary":"  We consider an asynchronous hierarchical federated learning (AHFL) setting\nwith a client-edge-cloud framework. The clients exchange the trained parameters\nwith their corresponding edge servers, which update the locally aggregated\nmodel. This model is then transmitted to all the clients in the local cluster.\nThe edge servers communicate to the central cloud server for global model\naggregation. The goal of each client is to converge to the global model, while\nmaintaining timeliness of the clients, i.e., having optimum training iteration\ntime. We investigate the convergence criteria for such a system with dense\nclusters. Our analysis shows that for a system of $n$ clients with fixed\naverage timeliness, the convergence in finite time is probabilistically\nguaranteed, if the nodes are divided into $O(1)$ number of clusters, that is,\nif the system is built as a sparse set of edge servers with dense client bases\neach.\n","authors":["Purbesh Mitra","Sennur Ulukus"],"pdf_url":"https://arxiv.org/pdf/2306.12400v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12392v1","updated":"2023-06-21T17:26:11Z","published":"2023-06-21T17:26:11Z","title":"One-shot Imitation Learning via Interaction Warping","summary":"  Imitation learning of robot policies from few demonstrations is crucial in\nopen-ended applications. We propose a new method, Interaction Warping, for\nlearning SE(3) robotic manipulation policies from a single demonstration. We\ninfer the 3D mesh of each object in the environment using shape warping, a\ntechnique for aligning point clouds across object instances. Then, we represent\nmanipulation actions as keypoints on objects, which can be warped with the\nshape of the object. We show successful one-shot imitation learning on three\nsimulated and real-world object re-arrangement tasks. We also demonstrate the\nability of our method to predict object meshes and robot grasps in the wild.\n","authors":["Ondrej Biza","Skye Thompson","Kishore Reddy Pagidi","Abhinav Kumar","Elise van der Pol","Robin Walters","Thomas Kipf","Jan-Willem van de Meent","Lawson L. S. Wong","Robert Platt"],"pdf_url":"https://arxiv.org/pdf/2306.12392v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.10548v2","updated":"2023-06-21T17:18:39Z","published":"2023-06-18T12:56:46Z","title":"MARBLE: Music Audio Representation Benchmark for Universal Evaluation","summary":"  In the era of extensive intersection between art and Artificial Intelligence\n(AI), such as image generation and fiction co-creation, AI for music remains\nrelatively nascent, particularly in music understanding. This is evident in the\nlimited work on deep music representations, the scarcity of large-scale\ndatasets, and the absence of a universal and community-driven benchmark. To\naddress this issue, we introduce the Music Audio Representation Benchmark for\nuniversaL Evaluation, termed MARBLE. It aims to provide a benchmark for various\nMusic Information Retrieval (MIR) tasks by defining a comprehensive taxonomy\nwith four hierarchy levels, including acoustic, performance, score, and\nhigh-level description. We then establish a unified protocol based on 14 tasks\non 8 public-available datasets, providing a fair and standard assessment of\nrepresentations of all open-sourced pre-trained models developed on music\nrecordings as baselines. Besides, MARBLE offers an easy-to-use, extendable, and\nreproducible suite for the community, with a clear statement on copyright\nissues on datasets. Results suggest recently proposed large-scale pre-trained\nmusical language models perform the best in most tasks, with room for further\nimprovement. The leaderboard and toolkit repository are published at\nhttps://marble-bm.shef.ac.uk to promote future music AI research.\n","authors":["Ruibin Yuan","Yinghao Ma","Yizhi Li","Ge Zhang","Xingran Chen","Hanzhi Yin","Le Zhuo","Yiqi Liu","Jiawen Huang","Zeyue Tian","Binyue Deng","Ningzhi Wang","Chenghua Lin","Emmanouil Benetos","Anton Ragni","Norbert Gyenge","Roger Dannenbert","Wenhu Chen","Gus Xia","Wei Xue","Si Liu","Shi Wang","Ruibo Liu","Yike Guo","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2306.10548v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2010.13846v4","updated":"2023-06-21T17:15:09Z","published":"2020-10-26T19:01:49Z","title":"LEAD: Min-Max Optimization from a Physical Perspective","summary":"  Adversarial formulations such as generative adversarial networks (GANs) have\nrekindled interest in two-player min-max games. A central obstacle in the\noptimization of such games is the rotational dynamics that hinder their\nconvergence. In this paper, we show that game optimization shares dynamic\nproperties with particle systems subject to multiple forces, and one can\nleverage tools from physics to improve optimization dynamics. Inspired by the\nphysical framework, we propose LEAD, an optimizer for min-max games. Next,\nusing Lyapunov stability theory and spectral analysis, we study LEAD's\nconvergence properties in continuous and discrete time settings for a class of\nquadratic min-max games to demonstrate linear convergence to the Nash\nequilibrium. Finally, we empirically evaluate our method on synthetic setups\nand CIFAR-10 image generation to demonstrate improvements in GAN training.\n","authors":["Reyhane Askari Hemmat","Amartya Mitra","Guillaume Lajoie","Ioannis Mitliagkas"],"pdf_url":"https://arxiv.org/pdf/2010.13846v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12386v1","updated":"2023-06-21T17:11:35Z","published":"2023-06-21T17:11:35Z","title":"$\\mathbf{\\mathbb{E}^{FWI}}$: Multi-parameter Benchmark Datasets for\n  Elastic Full Waveform Inversion of Geophysical Properties","summary":"  Elastic geophysical properties (such as P- and S-wave velocities) are of\ngreat importance to various subsurface applications like CO$_2$ sequestration\nand energy exploration (e.g., hydrogen and geothermal). Elastic full waveform\ninversion (FWI) is widely applied for characterizing reservoir properties. In\nthis paper, we introduce $\\mathbf{\\mathbb{E}^{FWI}}$, a comprehensive benchmark\ndataset that is specifically designed for elastic FWI.\n$\\mathbf{\\mathbb{E}^{FWI}}$ encompasses 8 distinct datasets that cover diverse\nsubsurface geologic structures (flat, curve, faults, etc). The benchmark\nresults produced by three different deep learning methods are provided. In\ncontrast to our previously presented dataset (pressure recordings) for acoustic\nFWI (referred to as OpenFWI), the seismic dataset in\n$\\mathbf{\\mathbb{E}^{FWI}}$ has both vertical and horizontal components.\nMoreover, the velocity maps in $\\mathbf{\\mathbb{E}^{FWI}}$ incorporate both P-\nand S-wave velocities. While the multicomponent data and the added S-wave\nvelocity make the data more realistic, more challenges are introduced regarding\nthe convergence and computational cost of the inversion. We conduct\ncomprehensive numerical experiments to explore the relationship between P-wave\nand S-wave velocities in seismic data. The relation between P- and S-wave\nvelocities provides crucial insights into the subsurface properties such as\nlithology, porosity, fluid content, etc. We anticipate that\n$\\mathbf{\\mathbb{E}^{FWI}}$ will facilitate future research on multiparameter\ninversions and stimulate endeavors in several critical research topics of\ncarbon-zero and new energy exploration. All datasets, codes and relevant\ninformation can be accessed through our website at https://efwi-lanl.github.io/\n","authors":["Shihang Feng","Hanchen Wang","Chengyuan Deng","Yinan Feng","Yanhua Liu","Min Zhu","Peng Jin","Yinpeng Chen","Youzuo Lin"],"pdf_url":"https://arxiv.org/pdf/2306.12386v1.pdf","comment":"20 pages, 11 figures"},{"id":"http://arxiv.org/abs/2306.12384v1","updated":"2023-06-21T17:06:54Z","published":"2023-06-21T17:06:54Z","title":"Probing the limit of hydrologic predictability with the Transformer\n  network","summary":"  For a number of years since its introduction to hydrology, recurrent neural\nnetworks like long short-term memory (LSTM) have proven remarkably difficult to\nsurpass in terms of daily hydrograph metrics on known, comparable benchmarks.\nOutside of hydrology, Transformers have now become the model of choice for\nsequential prediction tasks, making it a curious architecture to investigate.\nHere, we first show that a vanilla Transformer architecture is not competitive\nagainst LSTM on the widely benchmarked CAMELS dataset, and lagged especially\nfor the high-flow metrics due to short-term processes. However, a\nrecurrence-free variant of Transformer can obtain mixed comparisons with LSTM,\nproducing the same Kling-Gupta efficiency coefficient (KGE), along with other\nmetrics. The lack of advantages for the Transformer is linked to the Markovian\nnature of the hydrologic prediction problem. Similar to LSTM, the Transformer\ncan also merge multiple forcing dataset to improve model performance. While the\nTransformer results are not higher than current state-of-the-art, we still\nlearned some valuable lessons: (1) the vanilla Transformer architecture is not\nsuitable for hydrologic modeling; (2) the proposed recurrence-free modification\ncan improve Transformer performance so future work can continue to test more of\nsuch modifications; and (3) the prediction limits on the dataset should be\nclose to the current state-of-the-art model. As a non-recurrent model, the\nTransformer may bear scale advantages for learning from bigger datasets and\nstoring knowledge. This work serves as a reference point for future\nmodifications of the model.\n","authors":["Jiangtao Liu","Yuchen Bian","Chaopeng Shen"],"pdf_url":"https://arxiv.org/pdf/2306.12384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12383v1","updated":"2023-06-21T17:03:22Z","published":"2023-06-21T17:03:22Z","title":"Sample Complexity for Quadratic Bandits: Hessian Dependent Bounds and\n  Optimal Algorithms","summary":"  In stochastic zeroth-order optimization, a problem of practical relevance is\nunderstanding how to fully exploit the local geometry of the underlying\nobjective function. We consider a fundamental setting in which the objective\nfunction is quadratic, and provide the first tight characterization of the\noptimal Hessian-dependent sample complexity. Our contribution is twofold.\nFirst, from an information-theoretic point of view, we prove tight lower bounds\non Hessian-dependent complexities by introducing a concept called energy\nallocation, which captures the interaction between the searching algorithm and\nthe geometry of objective functions. A matching upper bound is obtained by\nsolving the optimal energy spectrum. Then, algorithmically, we show the\nexistence of a Hessian-independent algorithm that universally achieves the\nasymptotic optimal sample complexities for all Hessian instances. The optimal\nsample complexities achieved by our algorithm remain valid for heavy-tailed\nnoise distributions, which are enabled by a truncation method.\n","authors":["Qian Yu","Yining Wang","Baihe Huang","Qi Lei","Jason D. Lee"],"pdf_url":"https://arxiv.org/pdf/2306.12383v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11529v2","updated":"2023-06-21T17:02:45Z","published":"2023-01-27T04:22:27Z","title":"PLay: Parametrically Conditioned Layout Generation using Latent\n  Diffusion","summary":"  Layout design is an important task in various design fields, including user\ninterface, document, and graphic design. As this task requires tedious manual\neffort by designers, prior works have attempted to automate this process using\ngenerative models, but commonly fell short of providing intuitive user controls\nand achieving design objectives. In this paper, we build a conditional latent\ndiffusion model, PLay, that generates parametrically conditioned layouts in\nvector graphic space from user-specified guidelines, which are commonly used by\ndesigners for representing their design intents in current practices. Our\nmethod outperforms prior works across three datasets on metrics including FID\nand FD-VG, and in user study. Moreover, it brings a novel and interactive\nexperience to professional layout design processes.\n","authors":["Chin-Yi Cheng","Forrest Huang","Gang Li","Yang Li"],"pdf_url":"https://arxiv.org/pdf/2301.11529v2.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2207.03442v2","updated":"2023-06-21T16:57:19Z","published":"2022-07-07T17:14:10Z","title":"Back to the Source: Diffusion-Driven Test-Time Adaptation","summary":"  Test-time adaptation harnesses test inputs to improve the accuracy of a model\ntrained on source data when tested on shifted target data. Existing methods\nupdate the source model by (re-)training on each target domain. While\neffective, re-training is sensitive to the amount and order of the data and the\nhyperparameters for optimization. We instead update the target data, by\nprojecting all test inputs toward the source domain with a generative diffusion\nmodel. Our diffusion-driven adaptation method, DDA, shares its models for\nclassification and generation across all domains. Both models are trained on\nthe source domain, then fixed during testing. We augment diffusion with image\nguidance and self-ensembling to automatically decide how much to adapt. Input\nadaptation by DDA is more robust than prior model adaptation approaches across\na variety of corruptions, architectures, and data regimes on the ImageNet-C\nbenchmark. With its input-wise updates, DDA succeeds where model adaptation\ndegrades on too little data in small batches, dependent data in non-uniform\norder, or mixed data with multiple corruptions.\n","authors":["Jin Gao","Jialing Zhang","Xihui Liu","Trevor Darrell","Evan Shelhamer","Dequan Wang"],"pdf_url":"https://arxiv.org/pdf/2207.03442v2.pdf","comment":"published at CVPR 2023"},{"id":"http://arxiv.org/abs/2306.12380v1","updated":"2023-06-21T16:51:50Z","published":"2023-06-21T16:51:50Z","title":"On the Validation of Gibbs Algorithms: Training Datasets, Test Datasets\n  and their Aggregation","summary":"  The dependence on training data of the Gibbs algorithm (GA) is analytically\ncharacterized. By adopting the expected empirical risk as the performance\nmetric, the sensitivity of the GA is obtained in closed form. In this case,\nsensitivity is the performance difference with respect to an arbitrary\nalternative algorithm. This description enables the development of explicit\nexpressions involving the training errors and test errors of GAs trained with\ndifferent datasets. Using these tools, dataset aggregation is studied and\ndifferent figures of merit to evaluate the generalization capabilities of GAs\nare introduced. For particular sizes of such datasets and parameters of the\nGAs, a connection between Jeffrey's divergence, training and test errors is\nestablished.\n","authors":["Samir M. Perlaza","Iñaki Esnaola","Gaetan Bisson","H. Vincent Poor"],"pdf_url":"https://arxiv.org/pdf/2306.12380v1.pdf","comment":"In Proc. IEEE International Symposium on Information Theory (ISIT),\n  Taipei, Taiwan, Jun., 2023. arXiv admin note: text overlap with\n  arXiv:2211.06617"},{"id":"http://arxiv.org/abs/2306.12377v1","updated":"2023-06-21T16:42:02Z","published":"2023-06-21T16:42:02Z","title":"Geometric Algorithms for $k$-NN Poisoning","summary":"  We propose a label poisoning attack on geometric data sets against\n$k$-nearest neighbor classification. We provide an algorithm that can compute\nan $\\varepsilon n$-additive approximation of the optimal poisoning in $n\\cdot\n2^{2^{O(d+k/\\varepsilon)}}$ time for a given data set $X \\in \\mathbb{R}^d$,\nwhere $|X| = n$. Our algorithm achieves its objectives through the application\nof multi-scale random partitions.\n","authors":["Diego Ihara Centurion","Karine Chubarian","Bohan Fan","Francesco Sgherzi","Thiruvenkadam S Radhakrishnan","Anastasios Sidiropoulos","Angelo Straight"],"pdf_url":"https://arxiv.org/pdf/2306.12377v1.pdf","comment":"14 pages, 1 figure"},{"id":"http://arxiv.org/abs/2306.10404v2","updated":"2023-06-21T16:38:04Z","published":"2023-06-17T18:16:51Z","title":"The RL Perceptron: Generalisation Dynamics of Policy Learning in High\n  Dimensions","summary":"  Reinforcement learning (RL) algorithms have proven transformative in a range\nof domains. To tackle real-world domains, these systems often use neural\nnetworks to learn policies directly from pixels or other high-dimensional\nsensory input. By contrast, much theory of RL has focused on discrete state\nspaces or worst-case analysis, and fundamental questions remain about the\ndynamics of policy learning in high-dimensional settings. Here, we propose a\nsolvable high-dimensional model of RL that can capture a variety of learning\nprotocols, and derive its typical dynamics as a set of closed-form ordinary\ndifferential equations (ODEs). We derive optimal schedules for the learning\nrates and task difficulty - analogous to annealing schemes and curricula during\ntraining in RL - and show that the model exhibits rich behaviour, including\ndelayed learning under sparse rewards; a variety of learning regimes depending\non reward baselines; and a speed-accuracy trade-off driven by reward\nstringency. Experiments on variants of the Procgen game \"Bossfight\" and Arcade\nLearning Environment game \"Pong\" also show such a speed-accuracy trade-off in\npractice. Together, these results take a step towards closing the gap between\ntheory and practice in high-dimensional RL.\n","authors":["Nishil Patel","Sebastian Lee","Stefano Sarao Mannelli","Sebastian Goldt","Adrew Saxe"],"pdf_url":"https://arxiv.org/pdf/2306.10404v2.pdf","comment":"10 pages, 6 figures, Preprint"},{"id":"http://arxiv.org/abs/2303.03389v2","updated":"2023-06-21T16:37:11Z","published":"2023-03-03T07:54:19Z","title":"Contrastive Hierarchical Clustering","summary":"  Deep clustering has been dominated by flat models, which split a dataset into\na predefined number of groups. Although recent methods achieve an extremely\nhigh similarity with the ground truth on popular benchmarks, the information\ncontained in the flat partition is limited. In this paper, we introduce\nCoHiClust, a Contrastive Hierarchical Clustering model based on deep neural\nnetworks, which can be applied to typical image data. By employing a\nself-supervised learning approach, CoHiClust distills the base network into a\nbinary tree without access to any labeled data. The hierarchical clustering\nstructure can be used to analyze the relationship between clusters, as well as\nto measure the similarity between data points. Experiments demonstrate that\nCoHiClust generates a reasonable structure of clusters, which is consistent\nwith our intuition and image semantics. Moreover, it obtains superior\nclustering accuracy on most of the image datasets compared to the\nstate-of-the-art flat clustering models.\n","authors":["Michał Znaleźniak","Przemysław Rola","Patryk Kaszuba","Jacek Tabor","Marek Śmieja"],"pdf_url":"https://arxiv.org/pdf/2303.03389v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12371v1","updated":"2023-06-21T16:26:59Z","published":"2023-06-21T16:26:59Z","title":"Optimistic Active Exploration of Dynamical Systems","summary":"  Reinforcement learning algorithms commonly seek to optimize policies for\nsolving one particular task. How should we explore an unknown dynamical system\nsuch that the estimated model allows us to solve multiple downstream tasks in a\nzero-shot manner? In this paper, we address this challenge, by developing an\nalgorithm -- OPAX -- for active exploration. OPAX uses well-calibrated\nprobabilistic models to quantify the epistemic uncertainty about the unknown\ndynamics. It optimistically -- w.r.t. to plausible dynamics -- maximizes the\ninformation gain between the unknown dynamics and state observations. We show\nhow the resulting optimization problem can be reduced to an optimal control\nproblem that can be solved at each episode using standard approaches. We\nanalyze our algorithm for general models, and, in the case of Gaussian process\ndynamics, we give a sample complexity bound and show that the epistemic\nuncertainty converges to zero. In our experiments, we compare OPAX with other\nheuristic active exploration approaches on several environments. Our\nexperiments show that OPAX is not only theoretically sound but also performs\nwell for zero-shot planning on novel downstream tasks.\n","authors":["Bhavya Sukhija","Lenart Treven","Cansu Sancaktar","Sebastian Blaes","Stelian Coros","Andreas Krause"],"pdf_url":"https://arxiv.org/pdf/2306.12371v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12370v1","updated":"2023-06-21T16:26:14Z","published":"2023-06-21T16:26:14Z","title":"PriorBand: Practical Hyperparameter Optimization in the Age of Deep\n  Learning","summary":"  Hyperparameters of Deep Learning (DL) pipelines are crucial for their\ndownstream performance. While a large number of methods for Hyperparameter\nOptimization (HPO) have been developed, their incurred costs are often\nuntenable for modern DL. Consequently, manual experimentation is still the most\nprevalent approach to optimize hyperparameters, relying on the researcher's\nintuition, domain knowledge, and cheap preliminary explorations. To resolve\nthis misalignment between HPO algorithms and DL researchers, we propose\nPriorBand, an HPO algorithm tailored to DL, able to utilize both expert beliefs\nand cheap proxy tasks. Empirically, we demonstrate PriorBand's efficiency\nacross a range of DL benchmarks and show its gains under informative expert\ninput and robustness against poor expert beliefs\n","authors":["Neeratyoy Mallik","Edward Bergman","Carl Hvarfner","Danny Stoll","Maciej Janowski","Marius Lindauer","Luigi Nardi","Frank Hutter"],"pdf_url":"https://arxiv.org/pdf/2306.12370v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12365v1","updated":"2023-06-21T16:19:07Z","published":"2023-06-21T16:19:07Z","title":"Attention Hybrid Variational Net for Accelerated MRI Reconstruction","summary":"  The application of compressed sensing (CS)-enabled data reconstruction for\naccelerating magnetic resonance imaging (MRI) remains a challenging problem.\nThis is due to the fact that the information lost in k-space from the\nacceleration mask makes it difficult to reconstruct an image similar to the\nquality of a fully sampled image. Multiple deep learning-based structures have\nbeen proposed for MRI reconstruction using CS, both in the k-space and image\ndomains as well as using unrolled optimization methods. However, the drawback\nof these structures is that they are not fully utilizing the information from\nboth domains (k-space and image). Herein, we propose a deep learning-based\nattention hybrid variational network that performs learning in both the k-space\nand image domain. We evaluate our method on a well-known open-source MRI\ndataset and a clinical MRI dataset of patients diagnosed with strokes from our\ninstitution to demonstrate the performance of our network. In addition to\nquantitative evaluation, we undertook a blinded comparison of image quality\nacross networks performed by a subspecialty trained radiologist. Overall, we\ndemonstrate that our network achieves a superior performance among others under\nmultiple reconstruction tasks.\n","authors":["Guoyao Shen","Boran Hao","Mengyu Li","Chad W. Farris","Ioannis Ch. Paschalidis","Stephan W. Anderson","Xin Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.12365v1.pdf","comment":"22 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2306.12361v1","updated":"2023-06-21T16:14:21Z","published":"2023-06-21T16:14:21Z","title":"Sigma-point Kalman Filter with Nonlinear Unknown Input Estimation via\n  Optimization and Data-driven Approach for Dynamic Systems","summary":"  Most works on joint state and unknown input (UI) estimation require the\nassumption that the UIs are linear; this is potentially restrictive as it does\nnot hold in many intelligent autonomous systems. To overcome this restriction\nand circumvent the need to linearize the system, we propose a derivative-free\nUnknown Input Sigma-point Kalman Filter (SPKF-nUI) where the SPKF is\ninterconnected with a general nonlinear UI estimator that can be implemented\nvia nonlinear optimization and data-driven approaches. The nonlinear UI\nestimator uses the posterior state estimate which is less susceptible to state\nprediction error. In addition, we introduce a joint sigma-point transformation\nscheme to incorporate both the state and UI uncertainties in the estimation of\nSPKF-nUI. An in-depth stochastic stability analysis proves that the proposed\nSPKF-nUI yields exponentially converging estimation error bounds under\nreasonable assumptions. Finally, two case studies are carried out on a\nsimulation-based rigid robot and a physical soft robot, i.e., robots made of\nsoft materials with complex dynamics to validate effectiveness of the proposed\nfilter on nonlinear dynamic systems. Our results demonstrate that the proposed\nSPKF-nUI achieves the lowest state and UI estimation errors when compared to\nthe existing nonlinear state-UI filters.\n","authors":["Junn Yong Loo","Ze Yang Ding","Vishnu Monn Baskaran","Surya Girinatha Nurzaman","Chee Pin Tan"],"pdf_url":"https://arxiv.org/pdf/2306.12361v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12356v1","updated":"2023-06-21T16:04:03Z","published":"2023-06-21T16:04:03Z","title":"Provably Efficient Representation Learning with Tractable Planning in\n  Low-Rank POMDP","summary":"  In this paper, we study representation learning in partially observable\nMarkov Decision Processes (POMDPs), where the agent learns a decoder function\nthat maps a series of high-dimensional raw observations to a compact\nrepresentation and uses it for more efficient exploration and planning.\n  We focus our attention on the sub-classes of \\textit{$\\gamma$-observable} and\n\\textit{decodable POMDPs}, for which it has been shown that statistically\ntractable learning is possible, but there has not been any computationally\nefficient algorithm. We first present an algorithm for decodable POMDPs that\ncombines maximum likelihood estimation (MLE) and optimism in the face of\nuncertainty (OFU) to perform representation learning and achieve efficient\nsample complexity, while only calling supervised learning computational\noracles. We then show how to adapt this algorithm to also work in the broader\nclass of $\\gamma$-observable POMDPs.\n","authors":["Jiacheng Guo","Zihao Li","Huazheng Wang","Mengdi Wang","Zhuoran Yang","Xuezhou Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.12356v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04719v2","updated":"2023-06-21T15:52:05Z","published":"2023-06-07T18:31:39Z","title":"Don't trust your eyes: on the (un)reliability of feature visualizations","summary":"  How do neural networks extract patterns from pixels? Feature visualizations\nattempt to answer this important question by visualizing highly activating\npatterns through optimization. Today, visualization methods form the foundation\nof our knowledge about the internal workings of neural networks, as a type of\nmechanistic interpretability. Here we ask: How reliable are feature\nvisualizations? We start our investigation by developing network circuits that\ntrick feature visualizations into showing arbitrary patterns that are\ncompletely disconnected from normal network behavior on natural input. We then\nprovide evidence for a similar phenomenon occurring in standard, unmanipulated\nnetworks: feature visualizations are processed very differently from standard\ninput, casting doubt on their ability to \"explain\" how neural networks process\nnatural images. We underpin this empirical finding by theory proving that the\nset of functions that can be reliably understood by feature visualization is\nextremely small and does not include general black-box neural networks.\nTherefore, a promising way forward could be the development of networks that\nenforce certain structures in order to ensure more reliable feature\nvisualizations.\n","authors":["Robert Geirhos","Roland S. Zimmermann","Blair Bilodeau","Wieland Brendel","Been Kim"],"pdf_url":"https://arxiv.org/pdf/2306.04719v2.pdf","comment":"Added github link to\n  https://github.com/google-research/fooling-feature-visualizations/"},{"id":"http://arxiv.org/abs/2305.18944v2","updated":"2023-06-21T15:50:08Z","published":"2023-05-30T11:20:14Z","title":"Fast Dynamic 1D Simulation of Divertor Plasmas with Neural PDE\n  Surrogates","summary":"  Managing divertor plasmas is crucial for operating reactor scale tokamak\ndevices due to heat and particle flux constraints on the divertor target.\nSimulation is an important tool to understand and control these plasmas,\nhowever, for real-time applications or exhaustive parameter scans only simple\napproximations are currently fast enough. We address this lack of fast\nsimulators using neural PDE surrogates, data-driven neural network-based\nsurrogate models trained using solutions generated with a classical numerical\nmethod. The surrogate approximates a time-stepping operator that evolves the\nfull spatial solution of a reference physics-based model over time. We use\nDIV1D, a 1D dynamic model of the divertor plasma, as reference model to\ngenerate data. DIV1D's domain covers a 1D heat flux tube from the X-point\n(upstream) to the target. We simulate a realistic TCV divertor plasma with\ndynamics induced by upstream density ramps and provide an exploratory outlook\ntowards fast transients. State-of-the-art neural PDE surrogates are evaluated\nin a common framework and extended for properties of the DIV1D data. We\nevaluate (1) the speed-accuracy trade-off; (2) recreating non-linear behavior;\n(3) data efficiency; and (4) parameter inter- and extrapolation. Once trained,\nneural PDE surrogates can faithfully approximate DIV1D's divertor plasma\ndynamics at sub real-time computation speeds: In the proposed configuration,\n2ms of plasma dynamics can be computed in $\\approx$0.63ms of wall-clock time,\nseveral orders of magnitude faster than DIV1D.\n","authors":["Yoeri Poels","Gijs Derks","Egbert Westerhof","Koen Minartz","Sven Wiesen","Vlado Menkovski"],"pdf_url":"https://arxiv.org/pdf/2305.18944v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09851v2","updated":"2023-06-21T15:44:49Z","published":"2023-01-24T07:56:44Z","title":"Neighborhood Homophily-based Graph Convolutional Network","summary":"  Graph neural networks (GNNs) have been proved powerful in graph-oriented\ntasks. However, many real-world graphs are heterophilous, challenging the\nhomophily assumption of classical GNNs. To solve the universality problem, many\nstudies deepen networks or concatenate intermediate representations, which does\nnot inherently change neighbor aggregation and introduces noise. Recent studies\npropose new metrics to characterize the homophily, but rarely consider the\ncorrelation of the proposed metrics and models. In this paper, we first design\na new metric, Neighborhood Homophily (\\textit{NH}), to measure the label\ncomplexity or purity in node neighborhoods. Furthermore, we incorporate the\nmetric into the classical graph convolutional network (GCN) architecture and\npropose \\textbf{N}eighborhood \\textbf{H}omophily-based \\textbf{G}raph\n\\textbf{C}onvolutional \\textbf{N}etwork (\\textbf{NHGCN}). In this framework,\nneighbors are grouped by estimated \\textit{NH} values and aggregated from\ndifferent channels, and the resulting node predictions are then used in turn to\nestimate and update \\textit{NH} values. The two processes of metric estimation\nand model inference are alternately optimized to achieve better node\nclassification. NHGCN achieves top overall performance on both homophilous and\nheterophilous benchmarks, with an improvement of up to 7.4\\% compared to the\ncurrent SOTA methods.\n","authors":["Shengbo Gong","Jiajun Zhou","Chenxuan Xie","Qi Xuan"],"pdf_url":"https://arxiv.org/pdf/2301.09851v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.01457v2","updated":"2023-06-21T15:44:19Z","published":"2023-04-04T01:56:16Z","title":"Exploring Vision-Language Models for Imbalanced Learning","summary":"  Vision-Language models (VLMs) that use contrastive language-image\npre-training have shown promising zero-shot classification performance.\nHowever, their performance on imbalanced dataset is relatively poor, where the\ndistribution of classes in the training dataset is skewed, leading to poor\nperformance in predicting minority classes. For instance, CLIP achieved only 5%\naccuracy on the iNaturalist18 dataset. We propose to add a lightweight decoder\nto VLMs to avoid OOM (out of memory) problem caused by large number of classes\nand capture nuanced features for tail classes. Then, we explore improvements of\nVLMs using prompt tuning, fine-tuning, and incorporating imbalanced algorithms\nsuch as Focal Loss, Balanced SoftMax and Distribution Alignment. Experiments\ndemonstrate that the performance of VLMs can be further boosted when used with\ndecoder and imbalanced methods. Specifically, our improved VLMs significantly\noutperforms zero-shot classification by an average accuracy of 6.58%, 69.82%,\nand 6.17%, on ImageNet-LT, iNaturalist18, and Places-LT, respectively. We\nfurther analyze the influence of pre-training data size, backbones, and\ntraining cost. Our study highlights the significance of imbalanced learning\nalgorithms in face of VLMs pre-trained by huge data. We release our code at\nhttps://github.com/Imbalance-VLM/Imbalance-VLM.\n","authors":["Yidong Wang","Zhuohao Yu","Jindong Wang","Qiang Heng","Hao Chen","Wei Ye","Rui Xie","Xing Xie","Shikun Zhang"],"pdf_url":"https://arxiv.org/pdf/2304.01457v2.pdf","comment":"IJCV minor revision; 16 pages; code:\n  https://github.com/Imbalance-VLM/Imbalance-VLM"},{"id":"http://arxiv.org/abs/2306.12344v1","updated":"2023-06-21T15:41:34Z","published":"2023-06-21T15:41:34Z","title":"An efficient, provably exact algorithm for the 0-1 loss linear\n  classification problem","summary":"  Algorithms for solving the linear classification problem have a long history,\ndating back at least to 1936 with linear discriminant analysis. For linearly\nseparable data, many algorithms can obtain the exact solution to the\ncorresponding 0-1 loss classification problem efficiently, but for data which\nis not linearly separable, it has been shown that this problem, in full\ngenerality, is NP-hard. Alternative approaches all involve approximations of\nsome kind, including the use of surrogates for the 0-1 loss (for example, the\nhinge or logistic loss) or approximate combinatorial search, none of which can\nbe guaranteed to solve the problem exactly. Finding efficient algorithms to\nobtain an exact i.e. globally optimal solution for the 0-1 loss linear\nclassification problem with fixed dimension, remains an open problem. In\nresearch we report here, we detail the construction of a new algorithm,\nincremental cell enumeration (ICE), that can solve the 0-1 loss classification\nproblem exactly in polynomial time. To our knowledge, this is the first,\nrigorously-proven polynomial time algorithm for this long-standing problem.\n","authors":["Xi He","Max A. Little"],"pdf_url":"https://arxiv.org/pdf/2306.12344v1.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2306.12330v1","updated":"2023-06-21T15:17:39Z","published":"2023-06-21T15:17:39Z","title":"ProtoGate: Prototype-based Neural Networks with Local Feature Selection\n  for Tabular Biomedical Data","summary":"  Tabular biomedical data poses challenges in machine learning because it is\noften high-dimensional and typically low-sample-size. Previous research has\nattempted to address these challenges via feature selection approaches, which\ncan lead to unstable performance on real-world data. This suggests that current\nmethods lack appropriate inductive biases that capture patterns common to\ndifferent samples. In this paper, we propose ProtoGate, a prototype-based\nneural model that introduces an inductive bias by attending to both homogeneity\nand heterogeneity across samples. ProtoGate selects features in a\nglobal-to-local manner and leverages them to produce explainable predictions\nvia an interpretable prototype-based model. We conduct comprehensive\nexperiments to evaluate the performance of ProtoGate on synthetic and\nreal-world datasets. Our results show that exploiting the homogeneous and\nheterogeneous patterns in the data can improve prediction accuracy while\nprototypes imbue interpretability.\n","authors":["Xiangjian Jiang","Andrei Margeloiu","Nikola Simidjievski","Mateja Jamnik"],"pdf_url":"https://arxiv.org/pdf/2306.12330v1.pdf","comment":"Early version presented at the 3rd Interpretable Machine Learning in\n  Healthcare (IMLH) workshop, 2023"},{"id":"http://arxiv.org/abs/2306.12314v1","updated":"2023-06-21T14:53:33Z","published":"2023-06-21T14:53:33Z","title":"Introspective Action Advising for Interpretable Transfer Learning","summary":"  Transfer learning can be applied in deep reinforcement learning to accelerate\nthe training of a policy in a target task by transferring knowledge from a\npolicy learned in a related source task. This is commonly achieved by copying\npretrained weights from the source policy to the target policy prior to\ntraining, under the constraint that they use the same model architecture.\nHowever, not only does this require a robust representation learned over a wide\ndistribution of states -- often failing to transfer between specialist models\ntrained over single tasks -- but it is largely uninterpretable and provides\nlittle indication of what knowledge is transferred. In this work, we propose an\nalternative approach to transfer learning between tasks based on action\nadvising, in which a teacher trained in a source task actively guides a\nstudent's exploration in a target task. Through introspection, the teacher is\ncapable of identifying when advice is beneficial to the student and should be\ngiven, and when it is not. Our approach allows knowledge transfer between\npolicies agnostic of the underlying representations, and we empirically show\nthat this leads to improved convergence rates in Gridworld and Atari\nenvironments while providing insight into what knowledge is transferred.\n","authors":["Joseph Campbell","Yue Guo","Fiona Xie","Simon Stepputtis","Katia Sycara"],"pdf_url":"https://arxiv.org/pdf/2306.12314v1.pdf","comment":"Accepted to CoLLAs 2023"},{"id":"http://arxiv.org/abs/2306.09595v2","updated":"2023-06-21T14:43:27Z","published":"2023-06-16T02:41:31Z","title":"Structured Cooperative Learning with Graphical Model Priors","summary":"  We study how to train personalized models for different tasks on\ndecentralized devices with limited local data. We propose \"Structured\nCooperative Learning (SCooL)\", in which a cooperation graph across devices is\ngenerated by a graphical model prior to automatically coordinate mutual\nlearning between devices. By choosing graphical models enforcing different\nstructures, we can derive a rich class of existing and novel decentralized\nlearning algorithms via variational inference. In particular, we show three\ninstantiations of SCooL that adopt Dirac distribution, stochastic block model\n(SBM), and attention as the prior generating cooperation graphs. These EM-type\nalgorithms alternate between updating the cooperation graph and cooperative\nlearning of local models. They can automatically capture the cross-task\ncorrelations among devices by only monitoring their model updating in order to\noptimize the cooperation graph. We evaluate SCooL and compare it with existing\ndecentralized learning methods on an extensive set of benchmarks, on which\nSCooL always achieves the highest accuracy of personalized models and\nsignificantly outperforms other baselines on communication efficiency. Our code\nis available at https://github.com/ShuangtongLi/SCooL.\n","authors":["Shuangtong Li","Tianyi Zhou","Xinmei Tian","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2306.09595v2.pdf","comment":"Accepted by icml 2023"},{"id":"http://arxiv.org/abs/2306.12306v1","updated":"2023-06-21T14:36:03Z","published":"2023-06-21T14:36:03Z","title":"Beyond Deep Ensembles -- A Large-Scale Evaluation of Bayesian Deep\n  Learning under Distribution Shift","summary":"  Bayesian deep learning (BDL) is a promising approach to achieve\nwell-calibrated predictions on distribution-shifted data. Nevertheless, there\nexists no large-scale survey that evaluates recent SOTA methods on diverse,\nrealistic, and challenging benchmark tasks in a systematic manner. To provide a\nclear picture of the current state of BDL research, we evaluate modern BDL\nalgorithms on real-world datasets from the WILDS collection containing\nchallenging classification and regression tasks, with a focus on generalization\ncapability and calibration under distribution shift. We compare the algorithms\non a wide range of large, convolutional and transformer-based neural network\narchitectures. In particular, we investigate a signed version of the expected\ncalibration error that reveals whether the methods are over- or\nunder-confident, providing further insight into the behavior of the methods.\nFurther, we provide the first systematic evaluation of BDL for fine-tuning\nlarge pre-trained models, where training from scratch is prohibitively\nexpensive. Finally, given the recent success of Deep Ensembles, we extend\npopular single-mode posterior approximations to multiple modes by the use of\nensembles. While we find that ensembling single-mode approximations generally\nimproves the generalization capability and calibration of the models by a\nsignificant margin, we also identify a failure mode of ensembles when\nfinetuning large transformer-based language models. In this setting,\nvariational inference based approaches such as last-layer Bayes By Backprop\noutperform other methods in terms of accuracy by a large margin, while modern\napproximate inference algorithms such as SWAG achieve the best calibration.\n","authors":["Florian Seligmann","Philipp Becker","Michael Volpp","Gerhard Neumann"],"pdf_url":"https://arxiv.org/pdf/2306.12306v1.pdf","comment":"Code at https://github.com/Feuermagier/Beyond_Deep_Ensembles"},{"id":"http://arxiv.org/abs/2306.12298v1","updated":"2023-06-21T14:27:31Z","published":"2023-06-21T14:27:31Z","title":"StarVQA+: Co-training Space-Time Attention for Video Quality Assessment","summary":"  Self-attention based Transformer has achieved great success in many computer\nvision tasks. However, its application to video quality assessment (VQA) has\nnot been satisfactory so far. Evaluating the quality of in-the-wild videos is\nchallenging due to the unknown of pristine reference and shooting distortion.\nThis paper presents a co-trained Space-Time Attention network for the VQA\nproblem, termed StarVQA+. Specifically, we first build StarVQA+ by alternately\nconcatenating the divided space-time attention. Then, to facilitate the\ntraining of StarVQA+, we design a vectorized regression loss by encoding the\nmean opinion score (MOS) to the probability vector and embedding a special\ntoken as the learnable variable of MOS, leading to better fitting of human's\nrating process. Finally, to solve the data hungry problem with Transformer, we\npropose to co-train the spatial and temporal attention weights using both\nimages and videos. Various experiments are conducted on the de-facto\nin-the-wild video datasets, including LIVE-Qualcomm, LIVE-VQC, KoNViD-1k,\nYouTube-UGC, LSVQ, LSVQ-1080p, and DVL2021. Experimental results demonstrate\nthe superiority of the proposed StarVQA+ over the state-of-the-art.\n","authors":["Fengchuang Xing","Yuan-Gen Wang","Weixuan Tang","Guopu Zhu","Sam Kwong"],"pdf_url":"https://arxiv.org/pdf/2306.12298v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.08303v2","updated":"2023-06-21T14:26:28Z","published":"2022-06-16T17:04:55Z","title":"On Scaled Methods for Saddle Point Problems","summary":"  Methods with adaptive scaling of different features play a key role in\nsolving saddle point problems, primarily due to Adam's popularity for solving\nadversarial machine learning problems, including GANS training. This paper\ncarries out a theoretical analysis of the following scaling techniques for\nsolving SPPs: the well-known Adam and RmsProp scaling and the newer AdaHessian\nand OASIS based on Hutchison approximation. We use the Extra Gradient and its\nimproved version with negative momentum as the basic method. Experimental\nstudies on GANs show good applicability not only for Adam, but also for other\nless popular methods.\n","authors":["Aleksandr Beznosikov","Aibek Alanov","Dmitry Kovalev","Martin Takáč","Alexander Gasnikov"],"pdf_url":"https://arxiv.org/pdf/2206.08303v2.pdf","comment":"54 pages, 2 algorithms with 4 options for each, 12 figures, 5 tables,\n  2 theorems"},{"id":"http://arxiv.org/abs/2306.12286v1","updated":"2023-06-21T14:14:05Z","published":"2023-06-21T14:14:05Z","title":"Diffusion Posterior Sampling for Informed Single-Channel Dereverberation","summary":"  We present in this paper an informed single-channel dereverberation method\nbased on conditional generation with diffusion models. With knowledge of the\nroom impulse response, the anechoic utterance is generated via reverse\ndiffusion using a measurement consistency criterion coupled with a neural\nnetwork that represents the clean speech prior. The proposed approach is\nlargely more robust to measurement noise compared to a state-of-the-art\ninformed single-channel dereverberation method, especially for non-stationary\nnoise. Furthermore, we compare to other blind dereverberation methods using\ndiffusion models and show superiority of the proposed approach for large\nreverberation times. We motivate the presented algorithm by introducing an\nextension for blind dereverberation allowing joint estimation of the room\nimpulse response and anechoic speech. Audio samples and code can be found\nonline (https://uhh.de/inf-sp-derev-dps).\n","authors":["Jean-Marie Lemercier","Simon Welker","Timo Gerkmann"],"pdf_url":"https://arxiv.org/pdf/2306.12286v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12285v1","updated":"2023-06-21T14:13:56Z","published":"2023-06-21T14:13:56Z","title":"Resilient Sparse Array Radar with the Aid of Deep Learning","summary":"  In this paper, we address the problem of direction of arrival (DOA)\nestimation for multiple targets in the presence of sensor failures in a sparse\narray. Generally, sparse arrays are known with very high-resolution\ncapabilities, where N physical sensors can resolve up to $\\mathcal{O}(N^2)$\nuncorrelated sources. However, among the many configurations introduced in the\nliterature, the arrays that provide the largest hole-free co-array are the most\nsusceptible to sensor failures. We propose here two machine learning (ML)\nmethods to mitigate the effect of sensor failures and maintain the DOA\nestimation performance and resolution. The first method enhances the\nconventional spatial smoothing using deep neural network (DNN), while the\nsecond one is an end-to-end data-driven method. Numerical results show that\nboth approaches can significantly improve the performance of MRA with two\nfailed sensors. The data-driven method can maintain the performance of the\narray with no failures at high signal-tonoise ratio (SNR). Moreover, both\napproaches can even perform better than the original array at low SNR thanks to\nthe denoising effect of the proposed DNN\n","authors":["Aya Mostafa Ahmed","Udaya S. K. P. Miriya Thanthrige","Aydin Sezgin","Fulvio Gini"],"pdf_url":"https://arxiv.org/pdf/2306.12285v1.pdf","comment":"Accepted to be published in 2023 IEEE 97th Vehicular Technology\n  Conference: VTC2023-Spring, 2023"},{"id":"http://arxiv.org/abs/2306.12282v1","updated":"2023-06-21T14:09:33Z","published":"2023-06-21T14:09:33Z","title":"Online Resource Allocation with Convex-set Machine-Learned Advice","summary":"  Decision-makers often have access to a machine-learned prediction about\ndemand, referred to as advice, which can potentially be utilized in online\ndecision-making processes for resource allocation. However, exploiting such\nadvice poses challenges due to its potential inaccuracy. To address this issue,\nwe propose a framework that enhances online resource allocation decisions with\npotentially unreliable machine-learned (ML) advice. We assume here that this\nadvice is represented by a general convex uncertainty set for the demand\nvector.\n  We introduce a parameterized class of Pareto optimal online resource\nallocation algorithms that strike a balance between consistent and robust\nratios. The consistent ratio measures the algorithm's performance (compared to\nthe optimal hindsight solution) when the ML advice is accurate, while the\nrobust ratio captures performance under an adversarial demand process when the\nadvice is inaccurate. Specifically, in a C-Pareto optimal setting, we maximize\nthe robust ratio while ensuring that the consistent ratio is at least C. Our\nproposed C-Pareto optimal algorithm is an adaptive protection level algorithm,\nwhich extends the classical fixed protection level algorithm introduced in\nLittlewood (2005) and Ball and Queyranne (2009). Solving a complex non-convex\ncontinuous optimization problem characterizes the adaptive protection level\nalgorithm. To complement our algorithms, we present a simple method for\ncomputing the maximum achievable consistent ratio, which serves as an estimate\nfor the maximum value of the ML advice. Additionally, we present numerical\nstudies to evaluate the performance of our algorithm in comparison to benchmark\nalgorithms. The results demonstrate that by adjusting the parameter C, our\nalgorithms effectively strike a balance between worst-case and average\nperformance, outperforming the benchmark algorithms.\n","authors":["Negin Golrezaei","Patrick Jaillet","Zijie Zhou"],"pdf_url":"https://arxiv.org/pdf/2306.12282v1.pdf","comment":"74 pages, 5 figures"},{"id":"http://arxiv.org/abs/2304.11332v2","updated":"2023-06-21T14:04:45Z","published":"2023-04-22T07:11:53Z","title":"Input Augmentation with SAM: Boosting Medical Image Segmentation with\n  Segmentation Foundation Model","summary":"  The Segment Anything Model (SAM) is a recently developed large model for\ngeneral-purpose segmentation for computer vision tasks. SAM was trained using\n11 million images with over 1 billion masks and can produce segmentation\nresults for a wide range of objects in natural scene images. SAM can be viewed\nas a general perception model for segmentation (partitioning images into\nsemantically meaningful regions). Thus, how to utilize such a large foundation\nmodel for medical image segmentation is an emerging research target. This paper\nshows that although SAM does not immediately give high-quality segmentation for\nmedical image data, its generated masks, features, and stability scores are\nuseful for building and training better medical image segmentation models. In\nparticular, we demonstrate how to use SAM to augment image input for\ncommonly-used medical image segmentation models (e.g., U-Net). Experiments on\nthree segmentation tasks show the effectiveness of our proposed SAMAug method.\nThe code is available at \\url{https://github.com/yizhezhang2000/SAMAug}.\n","authors":["Yizhe Zhang","Tao Zhou","Shuo Wang","Peixian Liang","Danny Z. Chen"],"pdf_url":"https://arxiv.org/pdf/2304.11332v2.pdf","comment":"GitHub: https://github.com/yizhezhang2000/SAMAug. Comments and\n  questions are welcome"},{"id":"http://arxiv.org/abs/2306.11547v2","updated":"2023-06-21T14:02:02Z","published":"2023-06-20T14:01:29Z","title":"Event Stream GPT: A Data Pre-processing and Modeling Library for\n  Generative, Pre-trained Transformers over Continuous-time Sequences of\n  Complex Events","summary":"  Generative, pre-trained transformers (GPTs, a.k.a. \"Foundation Models\") have\nreshaped natural language processing (NLP) through their versatility in diverse\ndownstream tasks. However, their potential extends far beyond NLP. This paper\nprovides a software utility to help realize this potential, extending the\napplicability of GPTs to continuous-time sequences of complex events with\ninternal dependencies, such as medical record datasets. Despite their\npotential, the adoption of foundation models in these domains has been hampered\nby the lack of suitable tools for model construction and evaluation. To bridge\nthis gap, we introduce Event Stream GPT (ESGPT), an open-source library\ndesigned to streamline the end-to-end process for building GPTs for\ncontinuous-time event sequences. ESGPT allows users to (1) build flexible,\nfoundation-model scale input datasets by specifying only a minimal\nconfiguration file, (2) leverage a Hugging Face compatible modeling API for\nGPTs over this modality that incorporates intra-event causal dependency\nstructures and autoregressive generation capabilities, and (3) evaluate models\nvia standardized processes that can assess few and even zero-shot performance\nof pre-trained models on user-specified fine-tuning tasks.\n","authors":["Matthew B. A. McDermott","Bret Nestor","Peniel Argaw","Isaac Kohane"],"pdf_url":"https://arxiv.org/pdf/2306.11547v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.01288v4","updated":"2023-06-21T13:59:20Z","published":"2022-06-02T20:19:51Z","title":"Decentralized Training of Foundation Models in Heterogeneous\n  Environments","summary":"  Training foundation models, such as GPT-3 and PaLM, can be extremely\nexpensive, often involving tens of thousands of GPUs running continuously for\nmonths. These models are typically trained in specialized clusters featuring\nfast, homogeneous interconnects and using carefully designed software systems\nthat support both data parallelism and model/pipeline parallelism. Such\ndedicated clusters can be costly and difficult to obtain. Can we instead\nleverage the much greater amount of decentralized, heterogeneous, and\nlower-bandwidth interconnected compute? Previous works examining the\nheterogeneous, decentralized setting focus on relatively small models that can\nbe trained in a purely data parallel manner. State-of-the-art schemes for model\nparallel foundation model training, such as Megatron, only consider the\nhomogeneous data center setting. In this paper, we present the first study of\ntraining large foundation models with model parallelism in a decentralized\nregime over a heterogeneous network. Our key technical contribution is a\nscheduling algorithm that allocates different computational \"tasklets\" in the\ntraining of foundation models to a group of decentralized GPU devices connected\nby a slow heterogeneous network. We provide a formal cost model and further\npropose an efficient evolutionary algorithm to find the optimal allocation\nstrategy. We conduct extensive experiments that represent different scenarios\nfor learning over geo-distributed devices simulated using real-world network\nmeasurements. In the most extreme case, across 8 different cities spanning 3\ncontinents, our approach is 4.8X faster than prior state-of-the-art training\nsystems (Megatron).\n","authors":["Binhang Yuan","Yongjun He","Jared Quincy Davis","Tianyi Zhang","Tri Dao","Beidi Chen","Percy Liang","Christopher Re","Ce Zhang"],"pdf_url":"https://arxiv.org/pdf/2206.01288v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12272v1","updated":"2023-06-21T13:49:35Z","published":"2023-06-21T13:49:35Z","title":"From structure mining to unsupervised exploration of atomic octahedral\n  networks","summary":"  Networks of atom-centered coordination octahedra commonly occur in inorganic\nand hybrid solid-state materials. Characterizing their spatial arrangements and\ncharacteristics is crucial for relating structures to properties for many\nmaterials families. The traditional method using case-by-case inspection\nbecomes prohibitive for discovering trends and similarities in large datasets.\nHere, we operationalize chemical intuition to automate the geometric parsing,\nquantification, and classification of coordination octahedral networks. We find\naxis-resolved tilting trends in ABO$_{3}$ perovskite polymorphs, which assist\nin detecting oxidation state changes. Moreover, we develop a scale-invariant\nencoding scheme to represent these networks, which, combined with\nhuman-assisted unsupervised machine learning, allows us to taxonomize the\ninorganic framework polytypes in hybrid iodoplumbates (A$_x$Pb$_y$I$_z$).\nConsequently, we uncover a violation of Pauling's third rule and the design\nprinciples underpinning their topological diversity. Our results offer a\nglimpse into the vast design space of atomic octahedral networks and inform\nhigh-throughput, targeted screening of specific structure types.\n","authors":["R. Patrick Xian","Ryan J. Morelock","Ido Hadar","Charles B. Musgrave","Christopher Sutton"],"pdf_url":"https://arxiv.org/pdf/2306.12272v1.pdf","comment":"56 pages"},{"id":"http://arxiv.org/abs/2306.12268v1","updated":"2023-06-21T13:43:59Z","published":"2023-06-21T13:43:59Z","title":"A Finite Expression Method for Solving High-Dimensional Committor\n  Problems","summary":"  Transition path theory (TPT) is a mathematical framework for quantifying rare\ntransition events between a pair of selected metastable states $A$ and $B$.\nCentral to TPT is the committor function, which describes the probability to\nhit the metastable state $B$ prior to $A$ from any given starting point of the\nphase space. Once the committor is computed, the transition channels and the\ntransition rate can be readily found. The committor is the solution to the\nbackward Kolmogorov equation with appropriate boundary conditions. However,\nsolving it is a challenging task in high dimensions due to the need to mesh a\nwhole region of the ambient space. In this work, we explore the finite\nexpression method (FEX, Liang and Yang (2022)) as a tool for computing the\ncommittor. FEX approximates the committor by an algebraic expression involving\na fixed finite number of nonlinear functions and binary arithmetic operations.\nThe optimal nonlinear functions, the binary operations, and the numerical\ncoefficients in the expression template are found via reinforcement learning.\nThe FEX-based committor solver is tested on several high-dimensional benchmark\nproblems. It gives comparable or better results than neural network-based\nsolvers. Most importantly, FEX is capable of correctly identifying the\nalgebraic structure of the solution which allows one to reduce the committor\nproblem to a low-dimensional one and find the committor with any desired\naccuracy.\n","authors":["Zezheng Song","Maria K. Cameron","Haizhao Yang"],"pdf_url":"https://arxiv.org/pdf/2306.12268v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12266v1","updated":"2023-06-21T13:42:07Z","published":"2023-06-21T13:42:07Z","title":"Combining multi-spectral data with statistical and deep-learning models\n  for improved exoplanet detection in direct imaging at high contrast","summary":"  Exoplanet detection by direct imaging is a difficult task: the faint signals\nfrom the objects of interest are buried under a spatially structured nuisance\ncomponent induced by the host star. The exoplanet signals can only be\nidentified when combining several observations with dedicated detection\nalgorithms. In contrast to most of existing methods, we propose to learn a\nmodel of the spatial, temporal and spectral characteristics of the nuisance,\ndirectly from the observations. In a pre-processing step, a statistical model\nof their correlations is built locally, and the data are centered and whitened\nto improve both their stationarity and signal-to-noise ratio (SNR). A\nconvolutional neural network (CNN) is then trained in a supervised fashion to\ndetect the residual signature of synthetic sources in the pre-processed images.\nOur method leads to a better trade-off between precision and recall than\nstandard approaches in the field. It also outperforms a state-of-the-art\nalgorithm based solely on a statistical framework. Besides, the exploitation of\nthe spectral diversity improves the performance compared to a similar model\nbuilt solely from spatio-temporal data.\n","authors":["Olivier Flasseur","Théo Bodrito","Julien Mairal","Jean Ponce","Maud Langlois","Anne-Marie Lagrange"],"pdf_url":"https://arxiv.org/pdf/2306.12266v1.pdf","comment":"accepted to EUSIPCO 2023"},{"id":"http://arxiv.org/abs/2306.12259v1","updated":"2023-06-21T13:28:06Z","published":"2023-06-21T13:28:06Z","title":"Automatic Speech Disentanglement for Voice Conversion using Rank Module\n  and Speech Augmentation","summary":"  Voice Conversion (VC) converts the voice of a source speech to that of a\ntarget while maintaining the source's content. Speech can be mainly decomposed\ninto four components: content, timbre, rhythm and pitch. Unfortunately, most\nrelated works only take into account content and timbre, which results in less\nnatural speech. Some recent works are able to disentangle speech into several\ncomponents, but they require laborious bottleneck tuning or various\nhand-crafted features, each assumed to contain disentangled speech information.\nIn this paper, we propose a VC model that can automatically disentangle speech\ninto four components using only two augmentation functions, without the\nrequirement of multiple hand-crafted features or laborious bottleneck tuning.\nThe proposed model is straightforward yet efficient, and the empirical results\ndemonstrate that our model can achieve a better performance than the baseline,\nregarding disentanglement effectiveness and speech naturalness.\n","authors":["Zhonghua Liu","Shijun Wang","Ning Chen"],"pdf_url":"https://arxiv.org/pdf/2306.12259v1.pdf","comment":"Accepted by INTERSPEECH2023"},{"id":"http://arxiv.org/abs/2306.12251v1","updated":"2023-06-21T13:16:10Z","published":"2023-06-21T13:16:10Z","title":"GADBench: Revisiting and Benchmarking Supervised Graph Anomaly Detection","summary":"  With a long history of traditional Graph Anomaly Detection (GAD) algorithms\nand recently popular Graph Neural Networks (GNNs), it is still not clear (1)\nhow they perform under a standard comprehensive setting, (2) whether GNNs\noutperform traditional algorithms such as tree ensembles, and (3) their\nefficiency on large-scale graphs. In response, we present GADBench -- a\ncomprehensive benchmark for supervised anomalous node detection on static\ngraphs. GADBench provides a thorough comparison across 23 distinct models on\nten real-world GAD datasets ranging from thousands to millions of nodes\n($\\sim$6M). Our main finding is that tree ensembles with simple neighborhood\naggregation outperform all other baselines, including the latest GNNs tailored\nfor the GAD task. By making GADBench available as an open-source tool, we offer\npivotal insights into the current advancements of GAD and establish a solid\nfoundation for future research. Our code is available at\nhttps://github.com/squareRoot3/GADBench.\n","authors":["Jianheng Tang","Fengrui Hua","Ziqi Gao","Peilin Zhao","Jia Li"],"pdf_url":"https://arxiv.org/pdf/2306.12251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12249v1","updated":"2023-06-21T13:12:12Z","published":"2023-06-21T13:12:12Z","title":"Knowledge-based Multimodal Music Similarity","summary":"  Music similarity is an essential aspect of music retrieval, recommendation\nsystems, and music analysis. Moreover, similarity is of vital interest for\nmusic experts, as it allows studying analogies and influences among composers\nand historical periods. Current approaches to musical similarity rely mainly on\nsymbolic content, which can be expensive to produce and is not always readily\navailable. Conversely, approaches using audio signals typically fail to provide\nany insight about the reasons behind the observed similarity. This research\naddresses the limitations of current approaches by focusing on the study of\nmusical similarity using both symbolic and audio content. The aim of this\nresearch is to develop a fully explainable and interpretable system that can\nprovide end-users with more control and understanding of music similarity and\nclassification systems.\n","authors":["Andrea Poltronieri"],"pdf_url":"https://arxiv.org/pdf/2306.12249v1.pdf","comment":"11 pages, 1 figure"},{"id":"http://arxiv.org/abs/2306.12242v1","updated":"2023-06-21T13:00:49Z","published":"2023-06-21T13:00:49Z","title":"Concurrent ischemic lesion age estimation and segmentation of CT brain\n  using a Transformer-based network","summary":"  The cornerstone of stroke care is expedient management that varies depending\non the time since stroke onset. Consequently, clinical decision making is\ncentered on accurate knowledge of timing and often requires a radiologist to\ninterpret Computed Tomography (CT) of the brain to confirm the occurrence and\nage of an event. These tasks are particularly challenging due to the subtle\nexpression of acute ischemic lesions and the dynamic nature of their\nappearance. Automation efforts have not yet applied deep learning to estimate\nlesion age and treated these two tasks independently, so, have overlooked their\ninherent complementary relationship. To leverage this, we propose a novel\nend-to-end multi-task transformer-based network optimized for concurrent\nsegmentation and age estimation of cerebral ischemic lesions. By utilizing\ngated positional self-attention and CT-specific data augmentation, the proposed\nmethod can capture long-range spatial dependencies while maintaining its\nability to be trained from scratch under low-data regimes commonly found in\nmedical imaging. Furthermore, to better combine multiple predictions, we\nincorporate uncertainty by utilizing quantile loss to facilitate estimating a\nprobability density function of lesion age. The effectiveness of our model is\nthen extensively evaluated on a clinical dataset consisting of 776 CT images\nfrom two medical centers. Experimental results demonstrate that our method\nobtains promising performance, with an area under the curve (AUC) of 0.933 for\nclassifying lesion ages <=4.5 hours compared to 0.858 using a conventional\napproach, and outperforms task-specific state-of-the-art algorithms.\n","authors":["Adam Marcus","Paul Bentley","Daniel Rueckert"],"pdf_url":"https://arxiv.org/pdf/2306.12242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12231v1","updated":"2023-06-21T12:44:52Z","published":"2023-06-21T12:44:52Z","title":"Predicting protein variants with equivariant graph neural networks","summary":"  Pre-trained models have been successful in many protein engineering tasks.\nMost notably, sequence-based models have achieved state-of-the-art performance\non protein fitness prediction while structure-based models have been used\nexperimentally to develop proteins with enhanced functions. However, there is a\nresearch gap in comparing structure- and sequence-based methods for predicting\nprotein variants that are better than the wildtype protein. This paper aims to\naddress this gap by conducting a comparative study between the abilities of\nequivariant graph neural networks (EGNNs) and sequence-based approaches to\nidentify promising amino-acid mutations. The results show that our proposed\nstructural approach achieves a competitive performance to sequence-based\nmethods while being trained on significantly fewer molecules. Additionally, we\nfind that combining assay labelled data with structure pre-trained models\nyields similar trends as with sequence pre-trained models.\n","authors":["Antonia Boca","Simon Mathis"],"pdf_url":"https://arxiv.org/pdf/2306.12231v1.pdf","comment":"4 pages, 2 figures, accepted to the 2023 ICML Workshop on\n  Computational Biology"},{"id":"http://arxiv.org/abs/2306.12230v1","updated":"2023-06-21T12:43:55Z","published":"2023-06-21T12:43:55Z","title":"Fantastic Weights and How to Find Them: Where to Prune in Dynamic Sparse\n  Training","summary":"  Dynamic Sparse Training (DST) is a rapidly evolving area of research that\nseeks to optimize the sparse initialization of a neural network by adapting its\ntopology during training. It has been shown that under specific conditions, DST\nis able to outperform dense models. The key components of this framework are\nthe pruning and growing criteria, which are repeatedly applied during the\ntraining process to adjust the network's sparse connectivity. While the growing\ncriterion's impact on DST performance is relatively well studied, the influence\nof the pruning criterion remains overlooked. To address this issue, we design\nand perform an extensive empirical analysis of various pruning criteria to\nbetter understand their effect on the dynamics of DST solutions. Surprisingly,\nwe find that most of the studied methods yield similar results. The differences\nbecome more significant in the low-density regime, where the best performance\nis predominantly given by the simplest technique: magnitude-based pruning. The\ncode is provided at https://github.com/alooow/fantastic_weights_paper\n","authors":["Aleksandra I. Nowak","Bram Grooten","Decebal Constantin Mocanu","Jacek Tabor"],"pdf_url":"https://arxiv.org/pdf/2306.12230v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.13224v2","updated":"2023-06-21T12:35:16Z","published":"2022-11-23T18:59:05Z","title":"Peekaboo: Text to Image Diffusion Models are Zero-Shot Segmentors","summary":"  Recently, text-to-image diffusion models have shown remarkable capabilities\nin creating realistic images from natural language prompts. However, few works\nhave explored using these models for semantic localization or grounding. In\nthis work, we explore how an off-the-shelf text-to-image diffusion model,\ntrained without exposure to localization information, can ground various\nsemantic phrases without segmentation-specific re-training. We introduce an\ninference time optimization process capable of generating segmentation masks\nconditioned on natural language prompts. Our proposal, Peekaboo, is a\nfirst-of-its-kind zero-shot, open-vocabulary, unsupervised semantic grounding\ntechnique leveraging diffusion models without any training. We evaluate\nPeekaboo on the Pascal VOC dataset for unsupervised semantic segmentation and\nthe RefCOCO dataset for referring segmentation, showing results competitive\nwith promising results. We also demonstrate how Peekaboo can be used to\ngenerate images with transparency, even though the underlying diffusion model\nwas only trained on RGB images - which to our knowledge we are the first to\nattempt. Please see our project page, including our code:\nhttps://ryanndagreat.github.io/peekaboo\n","authors":["Ryan Burgert","Kanchana Ranasinghe","Xiang Li","Michael S. Ryoo"],"pdf_url":"https://arxiv.org/pdf/2211.13224v2.pdf","comment":"19 pages; contains appendix"},{"id":"http://arxiv.org/abs/2306.01697v2","updated":"2023-06-21T12:27:44Z","published":"2023-06-02T17:15:19Z","title":"MutateNN: Mutation Testing of Image Recognition Models Deployed on\n  Hardware Accelerators","summary":"  With the research advancement of Artificial Intelligence in the last years,\nthere are new opportunities to mitigate real-world problems and advance\ntechnologically. Image recognition models in particular, are assigned with\nperception tasks to mitigate complex real-world challenges and lead to new\nsolutions. Furthermore, the computational complexity and demand for resources\nof such models has also increased. To mitigate this, model optimization and\nhardware acceleration has come into play, but effectively integrating such\nconcepts is a challenging and error-prone process.\n  In order to allow developers and researchers to explore the robustness of\ndeep learning image recognition models deployed on different hardware\nacceleration devices, we propose MutateNN, a tool that provides mutation\ntesting and analysis capabilities for that purpose. To showcase its\ncapabilities, we utilized 21 mutations for 7 widely-known pre-trained deep\nneural network models. We deployed our mutants on 4 different devices of\nvarying computational capabilities and observed discrepancies in mutants\nrelated to conditional operations, as well as some unstable behaviour with\nthose related to arithmetic types.\n","authors":["Nikolaos Louloudakis","Perry Gibson","José Cano","Ajitha Rajan"],"pdf_url":"https://arxiv.org/pdf/2306.01697v2.pdf","comment":"7 pages, 8 figures"},{"id":"http://arxiv.org/abs/2302.00375v2","updated":"2023-06-21T12:24:57Z","published":"2023-02-01T11:14:08Z","title":"Bayes-optimal Learning of Deep Random Networks of Extensive-width","summary":"  We consider the problem of learning a target function corresponding to a\ndeep, extensive-width, non-linear neural network with random Gaussian weights.\nWe consider the asymptotic limit where the number of samples, the input\ndimension and the network width are proportionally large. We propose a\nclosed-form expression for the Bayes-optimal test error, for regression and\nclassification tasks. We further compute closed-form expressions for the test\nerrors of ridge regression, kernel and random features regression. We find, in\nparticular, that optimally regularized ridge regression, as well as kernel\nregression, achieve Bayes-optimal performances, while the logistic loss yields\na near-optimal test error for classification. We further show numerically that\nwhen the number of samples grows faster than the dimension, ridge and kernel\nmethods become suboptimal, while neural networks achieve test error close to\nzero from quadratically many samples.\n","authors":["Hugo Cui","Florent Krzakala","Lenka Zdeborová"],"pdf_url":"https://arxiv.org/pdf/2302.00375v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12215v1","updated":"2023-06-21T12:15:57Z","published":"2023-06-21T12:15:57Z","title":"Automated Machine Learning for Remaining Useful Life Predictions","summary":"  Being able to predict the remaining useful life (RUL) of an engineering\nsystem is an important task in prognostics and health management. Recently,\ndata-driven approaches to RUL predictions are becoming prevalent over\nmodel-based approaches since no underlying physical knowledge of the\nengineering system is required. Yet, this just replaces required expertise of\nthe underlying physics with machine learning (ML) expertise, which is often\nalso not available. Automated machine learning (AutoML) promises to build\nend-to-end ML pipelines automatically enabling domain experts without ML\nexpertise to create their own models. This paper introduces AutoRUL, an\nAutoML-driven end-to-end approach for automatic RUL predictions. AutoRUL\ncombines fine-tuned standard regression methods to an ensemble with high\npredictive power. By evaluating the proposed method on eight real-world and\nsynthetic datasets against state-of-the-art hand-crafted models, we show that\nAutoML provides a viable alternative to hand-crafted data-driven RUL\npredictions. Consequently, creating RUL predictions can be made more accessible\nfor domain experts using AutoML by eliminating ML expertise from data-driven\nmodel construction.\n","authors":["Marc-André Zöller","Fabian Mauthe","Peter Zeiler","Marius Lindauer","Marco F. Huber"],"pdf_url":"https://arxiv.org/pdf/2306.12215v1.pdf","comment":"Manuscript accepted at IEEE SMC 2023"},{"id":"http://arxiv.org/abs/2306.12214v1","updated":"2023-06-21T12:13:46Z","published":"2023-06-21T12:13:46Z","title":"More PAC-Bayes bounds: From bounded losses, to losses with general tail\n  behaviors, to anytime-validity","summary":"  In this paper, we present new high-probability PAC-Bayes bounds for different\ntypes of losses. Firstly, for losses with a bounded range, we present a\nstrengthened version of Catoni's bound that holds uniformly for all parameter\nvalues. This leads to new fast rate and mixed rate bounds that are\ninterpretable and tighter than previous bounds in the literature. Secondly, for\nlosses with more general tail behaviors, we introduce two new parameter-free\nbounds: a PAC-Bayes Chernoff analogue when the loss' cumulative generating\nfunction is bounded, and a bound when the loss' second moment is bounded. These\ntwo bounds are obtained using a new technique based on a discretization of the\nspace of possible events for the \"in probability\" parameter optimization\nproblem. Finally, we extend all previous results to anytime-valid bounds using\na simple technique applicable to any existing bound.\n","authors":["Borja Rodríguez-Gálvez","Ragnar Thobaben","Mikael Skoglund"],"pdf_url":"https://arxiv.org/pdf/2306.12214v1.pdf","comment":"25 pages: ~10 of main text, ~4 of references, and ~11 of appendices.\n  Sections 2 and 3 are presented as short papers in the \"PAC-Bayes Meets\n  Interactive Learning\" workshop at ICML 2023"},{"id":"http://arxiv.org/abs/2306.12212v1","updated":"2023-06-21T12:11:02Z","published":"2023-06-21T12:11:02Z","title":"MimiC: Combating Client Dropouts in Federated Learning by Mimicking\n  Central Updates","summary":"  Federated learning (FL) is a promising framework for privacy-preserving\ncollaborative learning. In FL, the model training tasks are distributed to\nclients and only the model updates need to be collected at a central server.\nHowever, when being deployed at the mobile edge network, clients (e.g.,\nsmartphones and wearables) may have unpredictable availability and randomly\ndrop out of any training iteration, which hinders FL from achieving the\nconvergence. This paper tackles such a critical challenge of FL. In particular,\nwe first investigate the convergence of the classical FedAvg algorithm with\narbitrary client dropouts. We find that with the common choice of a decaying\nlearning rate, FedAvg can only oscillate within the neighborhood of a\nstationary point of the global loss function, which is caused by the divergence\nbetween the aggregated update and the desired central update. Motivated by this\nnew observation, we then design a novel training algorithm named MimiC, where\nthe server modifies each received model update based on the previous ones. The\nproposed modification of the received model updates is able to mimic the\nimaginary central update irrespective of the dropout clients. The theoretical\nanalysis of MimiC shows that the divergence between the aggregated update and\nthe central update diminishes with a proper choice of the learning rates,\nleading to its convergence. Simulation results further demonstrate that MimiC\nmaintains stable convergence performance in the presence of client dropouts and\nlearns better models than the baseline methods.\n","authors":["Yuchang Sun","Yuyi Mao","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.12212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13104v2","updated":"2023-06-21T12:03:57Z","published":"2023-01-30T17:43:47Z","title":"Equivariant Differentially Private Deep Learning: Why DP-SGD Needs\n  Sparser Models","summary":"  Differentially Private Stochastic Gradient Descent (DP-SGD) limits the amount\nof private information deep learning models can memorize during training. This\nis achieved by clipping and adding noise to the model's gradients, and thus\nnetworks with more parameters require proportionally stronger perturbation. As\na result, large models have difficulties learning useful information, rendering\ntraining with DP-SGD exceedingly difficult on more challenging training tasks.\nRecent research has focused on combating this challenge through training\nadaptations such as heavy data augmentation and large batch sizes. However,\nthese techniques further increase the computational overhead of DP-SGD and\nreduce its practical applicability. In this work, we propose using the\nprinciple of sparse model design to solve precisely such complex tasks with\nfewer parameters, higher accuracy, and in less time, thus serving as a\npromising direction for DP-SGD. We achieve such sparsity by design by\nintroducing equivariant convolutional networks for model training with\nDifferential Privacy. Using equivariant networks, we show that small and\nefficient architecture design can outperform current state-of-the-art models\nwith substantially lower computational requirements. On CIFAR-10, we achieve an\nincrease of up to $9\\%$ in accuracy while reducing the computation time by more\nthan $85\\%$. Our results are a step towards efficient model architectures that\nmake optimal use of their parameters and bridge the privacy-utility gap between\nprivate and non-private deep learning for computer vision.\n","authors":["Florian A. Hölzl","Daniel Rueckert","Georgios Kaissis"],"pdf_url":"https://arxiv.org/pdf/2301.13104v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12198v1","updated":"2023-06-21T11:48:07Z","published":"2023-06-21T11:48:07Z","title":"Opening the Black Box: Analyzing Attention Weights and Hidden States in\n  Pre-trained Language Models for Non-language Tasks","summary":"  Investigating deep learning language models has always been a significant\nresearch area due to the ``black box\" nature of most advanced models. With the\nrecent advancements in pre-trained language models based on transformers and\ntheir increasing integration into daily life, addressing this issue has become\nmore pressing. In order to achieve an explainable AI model, it is essential to\ncomprehend the procedural steps involved and compare them with human thought\nprocesses. Thus, in this paper, we use simple, well-understood non-language\ntasks to explore these models' inner workings. Specifically, we apply a\npre-trained language model to constrained arithmetic problems with hierarchical\nstructure, to analyze their attention weight scores and hidden states. The\ninvestigation reveals promising results, with the model addressing hierarchical\nproblems in a moderately structured manner, similar to human problem-solving\nstrategies. Additionally, by inspecting the attention weights layer by layer,\nwe uncover an unconventional finding that layer 10, rather than the model's\nfinal layer, is the optimal layer to unfreeze for the least parameter-intensive\napproach to fine-tune the model. We support these findings with entropy\nanalysis and token embeddings similarity analysis. The attention analysis\nallows us to hypothesize that the model can generalize to longer sequences in\nListOps dataset, a conclusion later confirmed through testing on sequences\nlonger than those in the training set. Lastly, by utilizing a straightforward\ntask in which the model predicts the winner of a Tic Tac Toe game, we identify\nlimitations in attention analysis, particularly its inability to capture 2D\npatterns.\n","authors":["Mohamad Ballout","Ulf Krumnack","Gunther Heidemann","Kai-Uwe Kühnberger"],"pdf_url":"https://arxiv.org/pdf/2306.12198v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12194v1","updated":"2023-06-21T11:42:23Z","published":"2023-06-21T11:42:23Z","title":"Split Learning in 6G Edge Networks","summary":"  With the proliferation of distributed edge computing resources, the 6G mobile\nnetwork will evolve into a network for connected intelligence. Along this line,\nthe proposal to incorporate federated learning into the mobile edge has gained\nconsiderable interest in recent years. However, the deployment of federated\nlearning faces substantial challenges as massive resource-limited IoT devices\ncan hardly support on-device model training. This leads to the emergence of\nsplit learning (SL) which enables servers to handle the major training workload\nwhile still enhancing data privacy. In this article, we offer a brief overview\nof key advancements in SL and articulate its seamless integration with wireless\nedge networks. We begin by illustrating the tailored 6G architecture to support\nedge SL. Then, we examine the critical design issues for edge SL, including\ninnovative resource-efficient learning frameworks and resource management\nstrategies under a single edge server. Additionally, we expand the scope to\nmulti-edge scenarios, exploring multi-edge collaboration and mobility\nmanagement from a networking perspective. Finally, we discuss open problems for\nedge SL, including convergence analysis, asynchronous SL and U-shaped SL.\n","authors":["Zheng Lin","Guanqiao Qu","Xianhao Chen","Kaibin Huang"],"pdf_url":"https://arxiv.org/pdf/2306.12194v1.pdf","comment":"7 pages, 6 figures"},{"id":"http://arxiv.org/abs/2306.12190v1","updated":"2023-06-21T11:35:59Z","published":"2023-06-21T11:35:59Z","title":"Quantifying lottery tickets under label noise: accuracy, calibration,\n  and complexity","summary":"  Pruning deep neural networks is a widely used strategy to alleviate the\ncomputational burden in machine learning. Overwhelming empirical evidence\nsuggests that pruned models retain very high accuracy even with a tiny fraction\nof parameters. However, relatively little work has gone into characterising the\nsmall pruned networks obtained, beyond a measure of their accuracy. In this\npaper, we use the sparse double descent approach to identify univocally and\ncharacterise pruned models associated with classification tasks. We observe\nempirically that, for a given task, iterative magnitude pruning (IMP) tends to\nconverge to networks of comparable sizes even when starting from full networks\nwith sizes ranging over orders of magnitude. We analyse the best pruned models\nin a controlled experimental setup and show that their number of parameters\nreflects task difficulty and that they are much better than full networks at\ncapturing the true conditional probability distribution of the labels. On real\ndata, we similarly observe that pruned models are less prone to overconfident\npredictions. Our results suggest that pruned models obtained via IMP not only\nhave advantageous computational properties but also provide a better\nrepresentation of uncertainty in learning.\n","authors":["Viplove Arora","Daniele Irto","Sebastian Goldt","Guido Sanguinetti"],"pdf_url":"https://arxiv.org/pdf/2306.12190v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12185v1","updated":"2023-06-21T11:32:28Z","published":"2023-06-21T11:32:28Z","title":"Adaptive DNN Surgery for Selfish Inference Acceleration with On-demand\n  Edge Resource","summary":"  Deep Neural Networks (DNNs) have significantly improved the accuracy of\nintelligent applications on mobile devices. DNN surgery, which partitions DNN\nprocessing between mobile devices and multi-access edge computing (MEC)\nservers, can enable real-time inference despite the computational limitations\nof mobile devices. However, DNN surgery faces a critical challenge: determining\nthe optimal computing resource demand from the server and the corresponding\npartition strategy, while considering both inference latency and MEC server\nusage costs. This problem is compounded by two factors: (1) the finite\ncomputing capacity of the MEC server, which is shared among multiple devices,\nleading to inter-dependent demands, and (2) the shift in modern DNN\narchitecture from chains to directed acyclic graphs (DAGs), which complicates\npotential solutions.\n  In this paper, we introduce a novel Decentralized DNN Surgery (DDS)\nframework. We formulate the partition strategy as a min-cut and propose a\nresource allocation game to adaptively schedule the demands of mobile devices\nin an MEC environment. We prove the existence of a Nash Equilibrium (NE), and\ndevelop an iterative algorithm to efficiently reach the NE for each device. Our\nextensive experiments demonstrate that DDS can effectively handle varying MEC\nscenarios, achieving up to 1.25$\\times$ acceleration compared to the\nstate-of-the-art algorithm.\n","authors":["Xiang Yang","Dezhi Chen","Qi Qi","Jingyu Wang","Haifeng Sun","Jianxin Liao","Song Guo"],"pdf_url":"https://arxiv.org/pdf/2306.12185v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2306.01981v4","updated":"2023-06-21T11:13:47Z","published":"2023-06-03T02:27:08Z","title":"SGEM: Test-Time Adaptation for Automatic Speech Recognition via\n  Sequential-Level Generalized Entropy Minimization","summary":"  Automatic speech recognition (ASR) models are frequently exposed to data\ndistribution shifts in many real-world scenarios, leading to erroneous\npredictions. To tackle this issue, an existing test-time adaptation (TTA)\nmethod has recently been proposed to adapt the pre-trained ASR model on\nunlabeled test instances without source data. Despite decent performance gain,\nthis work relies solely on naive greedy decoding and performs adaptation across\ntimesteps at a frame level, which may not be optimal given the sequential\nnature of the model output. Motivated by this, we propose a novel TTA\nframework, dubbed SGEM, for general ASR models. To treat the sequential output,\nSGEM first exploits beam search to explore candidate output logits and selects\nthe most plausible one. Then, it utilizes generalized entropy minimization and\nnegative sampling as unsupervised objectives to adapt the model. SGEM achieves\nstate-of-the-art performance for three mainstream ASR models under various\ndomain shifts.\n","authors":["Changhun Kim","Joonhyung Park","Hajin Shim","Eunho Yang"],"pdf_url":"https://arxiv.org/pdf/2306.01981v4.pdf","comment":"INTERSPEECH 2023 Oral Presentation; Code is available at\n  https://github.com/drumpt/SGEM"},{"id":"http://arxiv.org/abs/2306.12173v1","updated":"2023-06-21T11:01:31Z","published":"2023-06-21T11:01:31Z","title":"Mixture Encoder for Joint Speech Separation and Recognition","summary":"  Multi-speaker automatic speech recognition (ASR) is crucial for many\nreal-world applications, but it requires dedicated modeling techniques.\nExisting approaches can be divided into modular and end-to-end methods. Modular\napproaches separate speakers and recognize each of them with a single-speaker\nASR system. End-to-end models process overlapped speech directly in a single,\npowerful neural network. This work proposes a middle-ground approach that\nleverages explicit speech separation similarly to the modular approach but also\nincorporates mixture speech information directly into the ASR module in order\nto mitigate the propagation of errors made by the speech separator. We also\nexplore a way to exchange cross-speaker context information through a layer\nthat combines information of the individual speakers. Our system is optimized\nthrough separate and joint training stages and achieves a relative improvement\nof 7% in word error rate over a purely modular setup on the SMS-WSJ task.\n","authors":["Simon Berger","Peter Vieting","Christoph Boeddeker","Ralf Schlüter","Reinhold Haeb-Umbach"],"pdf_url":"https://arxiv.org/pdf/2306.12173v1.pdf","comment":"Accepted at Interspeech 2023"},{"id":"http://arxiv.org/abs/2306.12165v1","updated":"2023-06-21T10:40:17Z","published":"2023-06-21T10:40:17Z","title":"Post-hoc Selection of Pareto-Optimal Solutions in Search and\n  Recommendation","summary":"  Information Retrieval (IR) and Recommender Systems (RS) tasks are moving from\ncomputing a ranking of final results based on a single metric to\nmulti-objective problems. Solving these problems leads to a set of\nPareto-optimal solutions, known as Pareto frontier, in which no objective can\nbe further improved without hurting the others. In principle, all the points on\nthe Pareto frontier are potential candidates to represent the best model\nselected with respect to the combination of two, or more, metrics. To our\nknowledge, there are no well-recognized strategies to decide which point should\nbe selected on the frontier. In this paper, we propose a novel, post-hoc,\ntheoretically-justified technique, named \"Population Distance from Utopia\"\n(PDU), to identify and select the one-best Pareto-optimal solution from the\nfrontier. In detail, PDU analyzes the distribution of the points by\ninvestigating how far each point is from its utopia point (the ideal\nperformance for the objectives). The possibility of considering fine-grained\nutopia points allows PDU to select solutions tailored to individual user\npreferences, a novel feature we call \"calibration\". We compare PDU against\nexisting state-of-the-art strategies through extensive experiments on tasks\nfrom both IR and RS. Experimental results show that PDU and combined with\ncalibration notably impact the solution selection. Furthermore, the results\nshow that the proposed framework selects a solution in a principled way,\nirrespective of its position on the frontier, thus overcoming the limits of\nother strategies.\n","authors":["Vincenzo Paparella","Vito Walter Anelli","Franco Maria Nardini","Raffaele Perego","Tommaso Di Noia"],"pdf_url":"https://arxiv.org/pdf/2306.12165v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.12263v2","updated":"2023-06-21T10:22:56Z","published":"2022-01-28T17:25:43Z","title":"RiskNet: Neural Risk Assessment in Networks of Unreliable Resources","summary":"  We propose a graph neural network (GNN)-based method to predict the\ndistribution of penalties induced by outages in communication networks, where\nconnections are protected by resources shared between working and backup paths.\nThe GNN-based algorithm is trained only with random graphs generated with the\nBarab\\'asi-Albert model. Even though, the obtained test results show that we\ncan precisely model the penalties in a wide range of various existing\ntopologies. GNNs eliminate the need to simulate complex outage scenarios for\nthe network topologies under study. In practice, the whole design operation is\nlimited by 4ms on modern hardware. This way, we can gain as much as over 12,000\ntimes in the speed improvement.\n","authors":["Krzysztof Rusek","Piotr Boryło","Piotr Jaglarz","Fabien Geyer","Albert Cabellos","Piotr Chołda"],"pdf_url":"https://arxiv.org/pdf/2201.12263v2.pdf","comment":"This paper is under consideration at Journal of Network and Systems\n  Management"},{"id":"http://arxiv.org/abs/2306.12161v1","updated":"2023-06-21T10:17:55Z","published":"2023-06-21T10:17:55Z","title":"Adversarial Attacks Neutralization via Data Set Randomization","summary":"  Adversarial attacks on deep-learning models pose a serious threat to their\nreliability and security. Existing defense mechanisms are narrow addressing a\nspecific type of attack or being vulnerable to sophisticated attacks. We\npropose a new defense mechanism that, while being focused on image-based\nclassifiers, is general with respect to the cited category. It is rooted on\nhyperspace projection. In particular, our solution provides a pseudo-random\nprojection of the original dataset into a new dataset. The proposed defense\nmechanism creates a set of diverse projected datasets, where each projected\ndataset is used to train a specific classifier, resulting in different trained\nclassifiers with different decision boundaries. During testing, it randomly\nselects a classifier to test the input. Our approach does not sacrifice\naccuracy over legitimate input. Other than detailing and providing a thorough\ncharacterization of our defense mechanism, we also provide a proof of concept\nof using four optimization-based adversarial attacks (PGD, FGSM, IGSM, and\nC\\&W) and a generative adversarial attack testing them on the MNIST dataset.\nOur experimental results show that our solution increases the robustness of\ndeep learning models against adversarial attacks and significantly reduces the\nattack success rate by at least 89% for optimization attacks and 78% for\ngenerative attacks. We also analyze the relationship between the number of used\nhyperspaces and the efficacy of the defense mechanism. As expected, the two are\npositively correlated, offering an easy-to-tune parameter to enforce the\ndesired level of security. The generality and scalability of our solution and\nadaptability to different attack scenarios, combined with the excellent\nachieved results, other than providing a robust defense against adversarial\nattacks on deep learning networks, also lay the groundwork for future research\nin the field.\n","authors":["Mouna Rabhi","Roberto Di Pietro"],"pdf_url":"https://arxiv.org/pdf/2306.12161v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12155v1","updated":"2023-06-21T10:07:17Z","published":"2023-06-21T10:07:17Z","title":"Joint Dense-Point Representation for Contour-Aware Graph Segmentation","summary":"  We present a novel methodology that combines graph and dense segmentation\ntechniques by jointly learning both point and pixel contour representations,\nthereby leveraging the benefits of each approach. This addresses deficiencies\nin typical graph segmentation methods where misaligned objectives restrict the\nnetwork from learning discriminative vertex and contour features. Our joint\nlearning strategy allows for rich and diverse semantic features to be encoded,\nwhile alleviating common contour stability issues in dense-based approaches,\nwhere pixel-level objectives can lead to anatomically implausible topologies.\nIn addition, we identify scenarios where correct predictions that fall on the\ncontour boundary are penalised and address this with a novel hybrid contour\ndistance loss. Our approach is validated on several Chest X-ray datasets,\ndemonstrating clear improvements in segmentation stability and accuracy against\na variety of dense- and point-based methods. Our source code is freely\navailable at: www.github.com/kitbransby/Joint_Graph_Segmentation\n","authors":["Kit Mills Bransby","Greg Slabaugh","Christos Bourantas","Qianni Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.12155v1.pdf","comment":"MICCAI 2023 pre-print"},{"id":"http://arxiv.org/abs/2301.11214v2","updated":"2023-06-21T09:56:21Z","published":"2023-01-26T16:44:15Z","title":"Returning The Favour: When Regression Benefits From Probabilistic Causal\n  Knowledge","summary":"  A directed acyclic graph (DAG) provides valuable prior knowledge that is\noften discarded in regression tasks in machine learning. We show that the\nindependences arising from the presence of collider structures in DAGs provide\nmeaningful inductive biases, which constrain the regression hypothesis space\nand improve predictive performance. We introduce collider regression, a\nframework to incorporate probabilistic causal knowledge from a collider in a\nregression problem. When the hypothesis space is a reproducing kernel Hilbert\nspace, we prove a strictly positive generalisation benefit under mild\nassumptions and provide closed-form estimators of the empirical risk minimiser.\nExperiments on synthetic and climate model data demonstrate performance gains\nof the proposed methodology.\n","authors":["Shahine Bouabid","Jake Fawkes","Dino Sejdinovic"],"pdf_url":"https://arxiv.org/pdf/2301.11214v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12150v1","updated":"2023-06-21T09:53:37Z","published":"2023-06-21T09:53:37Z","title":"Benchmark data to study the influence of pre-training on explanation\n  performance in MR image classification","summary":"  Convolutional Neural Networks (CNNs) are frequently and successfully used in\nmedical prediction tasks. They are often used in combination with transfer\nlearning, leading to improved performance when training data for the task are\nscarce. The resulting models are highly complex and typically do not provide\nany insight into their predictive mechanisms, motivating the field of\n'explainable' artificial intelligence (XAI). However, previous studies have\nrarely quantitatively evaluated the 'explanation performance' of XAI methods\nagainst ground-truth data, and transfer learning and its influence on objective\nmeasures of explanation performance has not been investigated. Here, we propose\na benchmark dataset that allows for quantifying explanation performance in a\nrealistic magnetic resonance imaging (MRI) classification task. We employ this\nbenchmark to understand the influence of transfer learning on the quality of\nexplanations. Experimental results show that popular XAI methods applied to the\nsame underlying model differ vastly in performance, even when considering only\ncorrectly classified examples. We further observe that explanation performance\nstrongly depends on the task used for pre-training and the number of CNN layers\npre-trained. These results hold after correcting for a substantial correlation\nbetween explanation and classification performance.\n","authors":["Marta Oliveira","Rick Wilming","Benedict Clark","Céline Budding","Fabian Eitel","Kerstin Ritter","Stefan Haufe"],"pdf_url":"https://arxiv.org/pdf/2306.12150v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2305.06789v2","updated":"2023-06-21T09:43:40Z","published":"2023-05-11T13:24:10Z","title":"Integrating Nearest Neighbors with Neural Network Models for Treatment\n  Effect Estimation","summary":"  Treatment effect estimation is of high-importance for both researchers and\npractitioners across many scientific and industrial domains. The abundance of\nobservational data makes them increasingly used by researchers for the\nestimation of causal effects. However, these data suffer from biases, from\nseveral weaknesses, leading to inaccurate causal effect estimations, if not\nhandled properly. Therefore, several machine learning techniques have been\nproposed, most of them focusing on leveraging the predictive power of neural\nnetwork models to attain more precise estimation of causal effects. In this\nwork, we propose a new methodology, named Nearest Neighboring Information for\nCausal Inference (NNCI), for integrating valuable nearest neighboring\ninformation on neural network-based models for estimating treatment effects.\nThe proposed NNCI methodology is applied to some of the most well established\nneural network-based models for treatment effect estimation with the use of\nobservational data. Numerical experiments and analysis provide empirical and\nstatistical evidence that the integration of NNCI with state-of-the-art neural\nnetwork models leads to considerably improved treatment effect estimations on a\nvariety of well-known challenging benchmarks.\n","authors":["Niki Kiriakidou","Christos Diou"],"pdf_url":"https://arxiv.org/pdf/2305.06789v2.pdf","comment":"Published in the \"International Journal of Neural Systems\", World\n  Scientific Publishing Company"},{"id":"http://arxiv.org/abs/2306.12139v1","updated":"2023-06-21T09:35:50Z","published":"2023-06-21T09:35:50Z","title":"Spatial Heterophily Aware Graph Neural Networks","summary":"  Graph Neural Networks (GNNs) have been broadly applied in many urban\napplications upon formulating a city as an urban graph whose nodes are urban\nobjects like regions or points of interest. Recently, a few enhanced GNN\narchitectures have been developed to tackle heterophily graphs where connected\nnodes are dissimilar. However, urban graphs usually can be observed to possess\na unique spatial heterophily property; that is, the dissimilarity of neighbors\nat different spatial distances can exhibit great diversity. This property has\nnot been explored, while it often exists. To this end, in this paper, we\npropose a metric, named Spatial Diversity Score, to quantitatively measure the\nspatial heterophily and show how it can influence the performance of GNNs.\nIndeed, our experimental investigation clearly shows that existing heterophilic\nGNNs are still deficient in handling the urban graph with high spatial\ndiversity score. This, in turn, may degrade their effectiveness in urban\napplications. Along this line, we propose a Spatial Heterophily Aware Graph\nNeural Network (SHGNN), to tackle the spatial diversity of heterophily of urban\ngraphs. Based on the key observation that spatially close neighbors on the\nurban graph present a more similar mode of difference to the central node, we\nfirst design a rotation-scaling spatial aggregation module, whose core idea is\nto properly group the spatially close neighbors and separately process each\ngroup with less diversity inside. Then, a heterophily-sensitive spatial\ninteraction module is designed to adaptively capture the commonality and\ndiverse dissimilarity in different spatial groups. Extensive experiments on\nthree real-world urban datasets demonstrate the superiority of our SHGNN over\nseveral its competitors.\n","authors":["Congxi Xiao","Jingbo Zhou","Jizhou Huang","Tong Xu","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2306.12139v1.pdf","comment":"Accepted by KDD 2023"},{"id":"http://arxiv.org/abs/2205.06978v3","updated":"2023-06-21T09:29:11Z","published":"2022-05-14T05:50:54Z","title":"Efficient Off-Policy Reinforcement Learning via Brain-Inspired Computing","summary":"  Reinforcement Learning (RL) has opened up new opportunities to enhance\nexisting smart systems that generally include a complex decision-making\nprocess. However, modern RL algorithms, e.g., Deep Q-Networks (DQN), are based\non deep neural networks, resulting in high computational costs. In this paper,\nwe propose QHD, an off-policy value-based Hyperdimensional Reinforcement\nLearning, that mimics brain properties toward robust and real-time learning.\nQHD relies on a lightweight brain-inspired model to learn an optimal policy in\nan unknown environment. On both desktop and power-limited embedded platforms,\nQHD achieves significantly better overall efficiency than DQN while providing\nhigher or comparable rewards. QHD is also suitable for highly-efficient\nreinforcement learning with great potential for online and real-time learning.\nOur solution supports a small experience replay batch size that provides 12.3\ntimes speedup compared to DQN while ensuring minimal quality loss. Our\nevaluation shows QHD capability for real-time learning, providing 34.6 times\nspeedup and significantly better quality of learning than DQN.\n","authors":["Yang Ni","Danny Abraham","Mariam Issa","Yeseong Kim","Pietro Mercati","Mohsen Imani"],"pdf_url":"https://arxiv.org/pdf/2205.06978v3.pdf","comment":"In Proceedings of the Great Lakes Symposium on VLSI 2023(GLSVLSI\n  2023)"},{"id":"http://arxiv.org/abs/2306.12129v1","updated":"2023-06-21T09:19:33Z","published":"2023-06-21T09:19:33Z","title":"Machine Learning Based Compensation for Inconsistencies in Knitted Force\n  Sensors","summary":"  Knitted sensors frequently suffer from inconsistencies due to innate effects\nsuch as offset, relaxation, and drift. These properties, in combination, make\nit challenging to reliably map from sensor data to physical actuation. In this\npaper, we demonstrate a method for counteracting this by applying processing\nusing a minimal artificial neural network (ANN) in combination with\nstraightforward pre-processing. We apply a number of exponential smoothing\nfilters on a re-sampled sensor signal, to produce features that preserve\ndifferent levels of historical sensor data and, in combination, represent an\nadequate state of previous sensor actuation. By training a three-layer ANN with\na total of 8 neurons, we manage to significantly improve the mapping between\nsensor reading and actuation force. Our findings also show that our technique\ntranslates to sensors of reasonably different composition in terms of material\nand structure, and it can furthermore be applied to related physical features\nsuch as strain.\n","authors":["Roland Aigner","Andreas Stöckl"],"pdf_url":"https://arxiv.org/pdf/2306.12129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/1511.05240v2","updated":"2023-06-21T09:11:11Z","published":"2015-11-17T01:14:51Z","title":"An extension of McDiarmid's inequality","summary":"  We generalize McDiarmid's inequality for functions with bounded differences\non a high probability set, using an extension argument. Those functions\nconcentrate around their conditional expectations. We further extend the\nresults to concentration in general metric spaces.\n","authors":["Richard Combes"],"pdf_url":"https://arxiv.org/pdf/1511.05240v2.pdf","comment":"Note (8 pages)"},{"id":"http://arxiv.org/abs/2302.11419v2","updated":"2023-06-21T09:09:05Z","published":"2023-02-22T14:55:57Z","title":"Aligned Diffusion Schrödinger Bridges","summary":"  Diffusion Schr\\\"odinger bridges (DSB) have recently emerged as a powerful\nframework for recovering stochastic dynamics via their marginal observations at\ndifferent time points. Despite numerous successful applications, existing\nalgorithms for solving DSBs have so far failed to utilize the structure of\naligned data, which naturally arises in many biological phenomena. In this\npaper, we propose a novel algorithmic framework that, for the first time,\nsolves DSBs while respecting the data alignment. Our approach hinges on a\ncombination of two decades-old ideas: The classical Schr\\\"odinger bridge theory\nand Doob's $h$-transform. Compared to prior methods, our approach leads to a\nsimpler training procedure with lower variance, which we further augment with\nprincipled regularization schemes. This ultimately leads to sizeable\nimprovements across experiments on synthetic and real data, including the tasks\nof rigid protein docking and temporal evolution of cellular differentiation\nprocesses.\n","authors":["Vignesh Ram Somnath","Matteo Pariset","Ya-Ping Hsieh","Maria Rodriguez Martinez","Andreas Krause","Charlotte Bunne"],"pdf_url":"https://arxiv.org/pdf/2302.11419v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12105v1","updated":"2023-06-21T08:43:29Z","published":"2023-06-21T08:43:29Z","title":"Mass-Producing Failures of Multimodal Systems with Language Models","summary":"  Deployed multimodal systems can fail in ways that evaluators did not\nanticipate. In order to find these failures before deployment, we introduce\nMultiMon, a system that automatically identifies systematic failures --\ngeneralizable, natural-language descriptions of patterns of model failures. To\nuncover systematic failures, MultiMon scrapes a corpus for examples of\nerroneous agreement: inputs that produce the same output, but should not. It\nthen prompts a language model (e.g., GPT-4) to find systematic patterns of\nfailure and describe them in natural language. We use MultiMon to find 14\nsystematic failures (e.g., \"ignores quantifiers\") of the CLIP text-encoder,\neach comprising hundreds of distinct inputs (e.g., \"a shelf with a few/many\nbooks\"). Because CLIP is the backbone for most state-of-the-art multimodal\nsystems, these inputs produce failures in Midjourney 5.1, DALL-E, VideoFusion,\nand others. MultiMon can also steer towards failures relevant to specific use\ncases, such as self-driving cars. We see MultiMon as a step towards evaluation\nthat autonomously explores the long tail of potential system failures. Code for\nMULTIMON is available at https://github.com/tsb0601/MultiMon.\n","authors":["Shengbang Tong","Erik Jones","Jacob Steinhardt"],"pdf_url":"https://arxiv.org/pdf/2306.12105v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2306.10698v2","updated":"2023-06-21T08:41:27Z","published":"2023-06-19T04:48:36Z","title":"Deep Reinforcement Learning with Multitask Episodic Memory Based on\n  Task-Conditioned Hypernetwork","summary":"  Deep reinforcement learning algorithms are usually impeded by sampling\ninefficiency, heavily depending on multiple interactions with the environment\nto acquire accurate decision-making capabilities. In contrast, humans seem to\nrely on their hippocampus to retrieve relevant information from past\nexperiences of relevant tasks, which guides their decision-making when learning\na new task, rather than exclusively depending on environmental interactions.\nNevertheless, designing a hippocampus-like module for an agent to incorporate\npast experiences into established reinforcement learning algorithms presents\ntwo challenges. The first challenge involves selecting the most relevant past\nexperiences for the current task, and the second is integrating such\nexperiences into the decision network. To address these challenges, we propose\na novel algorithm that utilizes a retrieval network based on a task-conditioned\nhypernetwork, which adapts the retrieval network's parameters depending on the\ntask. At the same time, a dynamic modification mechanism enhances the\ncollaborative efforts between the retrieval and decision networks. We evaluate\nthe proposed algorithm on the challenging MiniGrid environment. The\nexperimental results demonstrate that our proposed method significantly\noutperforms strong baselines.\n","authors":["Yonggang Jin","Chenxu Wang","Liuyu Xiang","Yaodong Yang","Jie Fu","Zhaofeng He"],"pdf_url":"https://arxiv.org/pdf/2306.10698v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12100v1","updated":"2023-06-21T08:28:51Z","published":"2023-06-21T08:28:51Z","title":"Efficient ResNets: Residual Network Design","summary":"  ResNets (or Residual Networks) are one of the most commonly used models for\nimage classification tasks. In this project, we design and train a modified\nResNet model for CIFAR-10 image classification. In particular, we aimed at\nmaximizing the test accuracy on the CIFAR-10 benchmark while keeping the size\nof our ResNet model under the specified fixed budget of 5 million trainable\nparameters. Model size, typically measured as the number of trainable\nparameters, is important when models need to be stored on devices with limited\nstorage capacity (e.g. IoT/edge devices). In this article, we present our\nresidual network design which has less than 5 million parameters. We show that\nour ResNet achieves a test accuracy of 96.04% on CIFAR-10 which is much higher\nthan ResNet18 (which has greater than 11 million trainable parameters) when\nequipped with a number of training strategies and suitable ResNet\nhyperparameters. Models and code are available at\nhttps://github.com/Nikunj-Gupta/Efficient_ResNets.\n","authors":["Aditya Thakur","Harish Chauhan","Nikunj Gupta"],"pdf_url":"https://arxiv.org/pdf/2306.12100v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12098v1","updated":"2023-06-21T08:27:26Z","published":"2023-06-21T08:27:26Z","title":"MSW-Transformer: Multi-Scale Shifted Windows Transformer Networks for\n  12-Lead ECG Classification","summary":"  Automatic classification of electrocardiogram (ECG) signals plays a crucial\nrole in the early prevention and diagnosis of cardiovascular diseases. While\nECG signals can be used for the diagnosis of various diseases, their\npathological characteristics exhibit minimal variations, posing a challenge to\nautomatic classification models. Existing methods primarily utilize\nconvolutional neural networks to extract ECG signal features for\nclassification, which may not fully capture the pathological feature\ndifferences of different diseases. Transformer networks have advantages in\nfeature extraction for sequence data, but the complete network is complex and\nrelies on large-scale datasets. To address these challenges, we propose a\nsingle-layer Transformer network called Multi-Scale Shifted Windows Transformer\nNetworks (MSW-Transformer), which uses a multi-window sliding attention\nmechanism at different scales to capture features in different dimensions. The\nself-attention is restricted to non-overlapping local windows via shifted\nwindows, and different window scales have different receptive fields. A\nlearnable feature fusion method is then proposed to integrate features from\ndifferent windows to further enhance model performance. Furthermore, we\nvisualize the attention mechanism of the multi-window shifted mechanism to\nachieve better clinical interpretation in the ECG classification task. The\nproposed model achieves state-of-the-art performance on five classification\ntasks of the PTBXL-2020 12-lead ECG dataset, which includes 5 diagnostic\nsuperclasses, 23 diagnostic subclasses, 12 rhythm classes, 17 morphology\nclasses, and 44 diagnosis classes, with average macro-F1 scores of 77.85%,\n47.57%, 66.13%, 34.60%, and 34.29%, and average sample-F1 scores of 81.26%,\n68.27%, 91.32%, 50.07%, and 63.19%, respectively.\n","authors":["Renjie Cheng","Zhemin Zhuang","Shuxin Zhuang","Lei Xie","Jingfeng Guo"],"pdf_url":"https://arxiv.org/pdf/2306.12098v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.12482v3","updated":"2023-06-21T08:25:30Z","published":"2021-12-23T12:17:47Z","title":"Self-Supervised Graph Representation Learning for Neuronal Morphologies","summary":"  Unsupervised graph representation learning has recently gained interest in\nseveral application domains such as neuroscience, where modeling the diverse\nmorphology of cell types in the brain is one of the key challenges. It is\ncurrently unknown how many excitatory cortical cell types exist and what their\ndefining morphological features are. Here we present GraphDINO, a purely\ndata-driven approach to learn low-dimensional representations of 3D neuronal\nmorphologies from unlabeled large-scale datasets. GraphDINO is a novel\ntransformer-based representation learning method for spatially-embedded graphs.\nTo enable self-supervised learning on transformers, we (1) developed data\naugmentation strategies for spatially-embedded graphs, (2) adapted the\npositional encoding and (3) introduced a novel attention mechanism,\nAC-Attention, which combines attention-based global interaction between nodes\nand classic graph convolutional processing. We show, in two different species\nand across multiple brain areas, that this method yields morphological cell\ntype clusterings that are on par with manual feature-based classification by\nexperts, but without using prior knowledge about the structural features of\nneurons. Moreover, it outperforms previous approaches on quantitative\nbenchmarks predicting expert labels. Our method could potentially enable\ndata-driven discovery of novel morphological features and cell types in\nlarge-scale datasets. It is applicable beyond neuroscience in settings where\nsamples in a dataset are graphs and graph-level embeddings are desired.\n","authors":["Marissa A. Weis","Laura Hansel","Timo Lüddecke","Alexander S. Ecker"],"pdf_url":"https://arxiv.org/pdf/2112.12482v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12094v1","updated":"2023-06-21T08:14:52Z","published":"2023-06-21T08:14:52Z","title":"Understanding human mobility patterns in Chicago: an analysis of taxi\n  data using clustering techniques","summary":"  Understanding human mobility patterns is important in applications as diverse\nas urban planning, public health, and political organizing. One rich source of\ndata on human mobility is taxi ride data. Using the city of Chicago as a case\nstudy, we examine data from taxi rides in 2016 with the goal of understanding\nhow neighborhoods are interconnected. This analysis will provide a sense of\nwhich neighborhoods individuals are using taxis to travel between, suggesting\nregions to focus new public transit development efforts. Additionally, this\nanalysis will map traffic circulation patterns and provide an understanding of\nwhere in the city people are traveling from and where they are heading to -\nperhaps informing traffic or road pollution mitigation efforts. For the first\napplication, representing the data as an undirected graph will suffice. Transit\nlines run in both directions so simply a knowledge of which neighborhoods have\nhigh rates of taxi travel between them provides an argument for placing public\ntransit along those routes. However, in order to understand the flow of people\nthroughout a city, we must make a distinction between the neighborhood from\nwhich people are departing and the areas to which they are arriving - this\nrequires methods that can deal with directed graphs. All developed codes can be\nfound at https://github.com/Nikunj-Gupta/Spectral-Clustering-Directed-Graphs.\n","authors":["Harish Chauhan","Nikunj Gupta","Zoe Haskell-Craig"],"pdf_url":"https://arxiv.org/pdf/2306.12094v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12093v1","updated":"2023-06-21T08:13:41Z","published":"2023-06-21T08:13:41Z","title":"Edge Devices Inference Performance Comparison","summary":"  In this work, we investigate the inference time of the MobileNet family,\nEfficientNet V1 and V2 family, VGG models, Resnet family, and InceptionV3 on\nfour edge platforms. Specifically NVIDIA Jetson Nano, Intel Neural Stick,\nGoogle Coral USB Dongle, and Google Coral PCIe. Our main contribution is a\nthorough analysis of the aforementioned models in multiple settings, especially\nas a function of input size, the presence of the classification head, its size,\nand the scale of the model. Since throughout the industry, those architectures\nare mainly utilized as feature extractors we put our main focus on analyzing\nthem as such. We show that Google platforms offer the fastest average inference\ntime, especially for newer models like MobileNet or EfficientNet family, while\nIntel Neural Stick is the most universal accelerator allowing to run most\narchitectures. These results should provide guidance for engineers in the early\nstages of AI edge systems development. All of them are accessible at\nhttps://bulletprove.com/research/edge_inference_results.csv\n","authors":["R. Tobiasz","G. Wilczyński","P. Graszka","N. Czechowski","S. Łuczak"],"pdf_url":"https://arxiv.org/pdf/2306.12093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12091v1","updated":"2023-06-21T08:11:40Z","published":"2023-06-21T08:11:40Z","title":"Structure-Aware DropEdge Towards Deep Graph Convolutional Networks","summary":"  It has been discovered that Graph Convolutional Networks (GCNs) encounter a\nremarkable drop in performance when multiple layers are piled up. The main\nfactor that accounts for why deep GCNs fail lies in over-smoothing, which\nisolates the network output from the input with the increase of network depth,\nweakening expressivity and trainability. In this paper, we start by\ninvestigating refined measures upon DropEdge -- an existing simple yet\neffective technique to relieve over-smoothing. We term our method as DropEdge++\nfor its two structure-aware samplers in contrast to DropEdge: layer-dependent\nsampler and feature-dependent sampler. Regarding the layer-dependent sampler,\nwe interestingly find that increasingly sampling edges from the bottom layer\nyields superior performance than the decreasing counterpart as well as\nDropEdge. We theoretically reveal this phenomenon with Mean-Edge-Number (MEN),\na metric closely related to over-smoothing. For the feature-dependent sampler,\nwe associate the edge sampling probability with the feature similarity of node\npairs, and prove that it further correlates the convergence subspace of the\noutput layer with the input features. Extensive experiments on several node\nclassification benchmarks, including both full- and semi- supervised tasks,\nillustrate the efficacy of DropEdge++ and its compatibility with a variety of\nbackbones by achieving generally better performance over DropEdge and the\nno-drop version.\n","authors":["Jiaqi Han","Wenbing Huang","Yu Rong","Tingyang Xu","Fuchun Sun","Junzhou Huang"],"pdf_url":"https://arxiv.org/pdf/2306.12091v1.pdf","comment":"IEEE Transactions on Neural Networks and Learning Systems, 2023"},{"id":"http://arxiv.org/abs/2306.12088v1","updated":"2023-06-21T08:07:07Z","published":"2023-06-21T08:07:07Z","title":"An Efficient Virtual Data Generation Method for Reducing Communication\n  in Federated Learning","summary":"  Communication overhead is one of the major challenges in Federated\nLearning(FL). A few classical schemes assume the server can extract the\nauxiliary information about training data of the participants from the local\nmodels to construct a central dummy dataset. The server uses the dummy dataset\nto finetune aggregated global model to achieve the target test accuracy in\nfewer communication rounds. In this paper, we summarize the above solutions\ninto a data-based communication-efficient FL framework. The key of the proposed\nframework is to design an efficient extraction module(EM) which ensures the\ndummy dataset has a positive effect on finetuning aggregated global model.\nDifferent from the existing methods that use generator to design EM, our\nproposed method, FedINIBoost borrows the idea of gradient match to construct\nEM. Specifically, FedINIBoost builds a proxy dataset of the real dataset in two\nsteps for each participant at each communication round. Then the server\naggregates all the proxy datasets to form a central dummy dataset, which is\nused to finetune aggregated global model. Extensive experiments verify the\nsuperiority of our method compared with the existing classical method, FedAVG,\nFedProx, Moon and FedFTG. Moreover, FedINIBoost plays a significant role in\nfinetuning the performance of aggregated global model at the initial stage of\nFL.\n","authors":["Cheng Yang","Xue Yang","Dongxian Wu","Xiaohu Tang"],"pdf_url":"https://arxiv.org/pdf/2306.12088v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12086v1","updated":"2023-06-21T08:05:05Z","published":"2023-06-21T08:05:05Z","title":"What Constitutes Good Contrastive Learning in Time-Series Forecasting?","summary":"  In recent years, the introduction of self-supervised contrastive learning\n(SSCL) has demonstrated remarkable improvements in representation learning\nacross various domains, including natural language processing and computer\nvision. By leveraging the inherent benefits of self-supervision, SSCL enables\nthe pre-training of representation models using vast amounts of unlabeled data.\nDespite these advances, there remains a significant gap in understanding the\nimpact of different SSCL strategies on time series forecasting performance, as\nwell as the specific benefits that SSCL can bring. This paper aims to address\nthese gaps by conducting a comprehensive analysis of the effectiveness of\nvarious training variables, including different SSCL algorithms, learning\nstrategies, model architectures, and their interplay. Additionally, to gain\ndeeper insights into the improvements brought about by SSCL in the context of\ntime-series forecasting, a qualitative analysis of the empirical receptive\nfield is performed. Through our experiments, we demonstrate that the end-to-end\ntraining of a Transformer model using the Mean Squared Error (MSE) loss and\nSSCL emerges as the most effective approach in time series forecasting.\nNotably, the incorporation of the contrastive objective enables the model to\nprioritize more pertinent information for forecasting, such as scale and\nperiodic relationships. These findings contribute to a better understanding of\nthe benefits of SSCL in time series forecasting and provide valuable insights\nfor future research in this area.\n","authors":["Chiyu Zhang","Qi Yan","Lili Meng","Tristan Sylvain"],"pdf_url":"https://arxiv.org/pdf/2306.12086v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12079v1","updated":"2023-06-21T07:55:29Z","published":"2023-06-21T07:55:29Z","title":"FLGo: A Fully Customizable Federated Learning Platform","summary":"  Federated learning (FL) has found numerous applications in healthcare,\nfinance, and IoT scenarios. Many existing FL frameworks offer a range of\nbenchmarks to evaluate the performance of FL under realistic conditions.\nHowever, the process of customizing simulations to accommodate\napplication-specific settings, data heterogeneity, and system heterogeneity\ntypically remains unnecessarily complicated. This creates significant hurdles\nfor traditional ML researchers in exploring the usage of FL, while also\ncompromising the shareability of codes across FL frameworks. To address this\nissue, we propose a novel lightweight FL platform called FLGo, to facilitate\ncross-application FL studies with a high degree of shareability. Our platform\noffers 40+ benchmarks, 20+ algorithms, and 2 system simulators as\nout-of-the-box plugins. We also provide user-friendly APIs for quickly\ncustomizing new plugins that can be readily shared and reused for improved\nreproducibility. Finally, we develop a range of experimental tools, including\nparallel acceleration, experiment tracker and analyzer, and parameters\nauto-tuning. FLGo is maintained at \\url{flgo-xmu.github.io}.\n","authors":["Zheng Wang","Xiaoliang Fan","Zhaopeng Peng","Xueheng Li","Ziqi Yang","Mingkuan Feng","Zhicheng Yang","Xiao Liu","Cheng Wang"],"pdf_url":"https://arxiv.org/pdf/2306.12079v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12077v1","updated":"2023-06-21T07:52:07Z","published":"2023-06-21T07:52:07Z","title":"Learning Latent Dynamics via Invariant Decomposition and\n  (Spatio-)Temporal Transformers","summary":"  We propose a method for learning dynamical systems from high-dimensional\nempirical data that combines variational autoencoders and (spatio-)temporal\nattention within a framework designed to enforce certain\nscientifically-motivated invariances. We focus on the setting in which data are\navailable from multiple different instances of a system whose underlying\ndynamical model is entirely unknown at the outset. The approach rests on a\nseparation into an instance-specific encoding (capturing initial conditions,\nconstants etc.) and a latent dynamics model that is itself universal across all\ninstances/realizations of the system. The separation is achieved in an\nautomated, data-driven manner and only empirical data are required as inputs to\nthe model. The approach allows effective inference of system behaviour at any\ncontinuous time but does not require an explicit neural ODE formulation, which\nmakes it efficient and highly scalable. We study behaviour through simple\ntheoretical analyses and extensive experiments on synthetic and real-world\ndatasets. The latter investigate learning the dynamics of complex systems based\non finite data and show that the proposed approach can outperform\nstate-of-the-art neural-dynamical models. We study also more general inductive\nbias in the context of transfer to data obtained under entirely novel system\ninterventions. Overall, our results provide a promising new framework for\nefficiently learning dynamical models from heterogeneous data with potential\napplications in a wide range of fields including physics, medicine, biology and\nengineering.\n","authors":["Kai Lagemann","Christian Lagemann","Sach Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2306.12077v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.08013v2","updated":"2023-06-21T07:51:07Z","published":"2023-06-13T11:46:00Z","title":"TopP&R: Robust Support Estimation Approach for Evaluating Fidelity and\n  Diversity in Generative Models","summary":"  We propose a robust and reliable evaluation metric for generative models by\nintroducing topological and statistical treatments for rigorous support\nestimation. Existing metrics, such as Inception Score (IS), Frechet Inception\nDistance (FID), and the variants of Precision and Recall (P&R), heavily rely on\nsupports that are estimated from sample features. However, the reliability of\ntheir estimation has not been seriously discussed (and overlooked) even though\nthe quality of the evaluation entirely depends on it. In this paper, we propose\nTopological Precision and Recall (TopP&R, pronounced 'topper'), which provides\na systematic approach to estimating supports, retaining only topologically and\nstatistically important features with a certain level of confidence. This not\nonly makes TopP&R strong for noisy features, but also provides statistical\nconsistency. Our theoretical and experimental results show that TopP&R is\nrobust to outliers and non-independent and identically distributed (Non-IID)\nperturbations, while accurately capturing the true trend of change in samples.\nTo the best of our knowledge, this is the first evaluation metric focused on\nthe robust estimation of the support and provides its statistical consistency\nunder noise.\n","authors":["Pum Jun Kim","Yoojin Jang","Jisu Kim","Jaejun Yoo"],"pdf_url":"https://arxiv.org/pdf/2306.08013v2.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2306.12070v1","updated":"2023-06-21T07:43:23Z","published":"2023-06-21T07:43:23Z","title":"Task-Robust Pre-Training for Worst-Case Downstream Adaptation","summary":"  Pre-training has achieved remarkable success when transferred to downstream\ntasks. In machine learning, we care about not only the good performance of a\nmodel but also its behavior under reasonable shifts of condition. The same\nphilosophy holds when pre-training a foundation model. However, the foundation\nmodel may not uniformly behave well for a series of related downstream tasks.\nThis happens, for example, when conducting mask recovery regression where the\nrecovery ability or the training instances diverge like pattern features are\nextracted dominantly on pre-training, but semantic features are also required\non a downstream task. This paper considers pre-training a model that guarantees\na uniformly good performance over the downstream tasks. We call this goal as\n$\\textit{downstream-task robustness}$. Our method first separates the upstream\ntask into several representative ones and applies a simple minimax loss for\npre-training. We then design an efficient algorithm to solve the minimax loss\nand prove its convergence in the convex setting. In the experiments, we show\nboth on large-scale natural language processing and computer vision datasets\nour method increases the metrics on worse-case downstream tasks. Additionally,\nsome theoretical explanations for why our loss is beneficial are provided.\nSpecifically, we show fewer samples are inherently required for the most\nchallenging downstream task in some cases.\n","authors":["Jianghui Wang","Cheng Yang","Xingyu Xie","Cong Fang","Zhouchen Lin"],"pdf_url":"https://arxiv.org/pdf/2306.12070v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12069v1","updated":"2023-06-21T07:34:27Z","published":"2023-06-21T07:34:27Z","title":"Modeling Hierarchical Reasoning Chains by Linking Discourse Units and\n  Key Phrases for Reading Comprehension","summary":"  Machine reading comprehension (MRC) poses new challenges over logical\nreasoning, which aims to understand the implicit logical relations entailed in\nthe given contexts and perform inference over them. Due to the complexity of\nlogic, logical relations exist at different granularity levels. However, most\nexisting methods of logical reasoning individually focus on either entity-aware\nor discourse-based information but ignore the hierarchical relations that may\neven have mutual effects. In this paper, we propose a holistic graph network\n(HGN) which deals with context at both discourse level and word level, as the\nbasis for logical reasoning, to provide a more fine-grained relation\nextraction. Specifically, node-level and type-level relations, which can be\ninterpreted as bridges in the reasoning process, are modeled by a hierarchical\ninteraction mechanism to improve the interpretation of MRC systems.\nExperimental results on logical reasoning QA datasets (ReClor and LogiQA) and\nnatural language inference datasets (SNLI and ANLI) show the effectiveness and\ngeneralization of our method, and in-depth analysis verifies its capability to\nunderstand complex logical relations.\n","authors":["Jialin Chen","Zhuosheng Zhang","Hai Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.12069v1.pdf","comment":"Accepted at COLING 2022, 9 pages"},{"id":"http://arxiv.org/abs/2304.01561v2","updated":"2023-06-21T07:33:16Z","published":"2023-04-04T06:35:02Z","title":"Optimal rates of approximation by shallow ReLU$^k$ neural networks and\n  applications to nonparametric regression","summary":"  We study the approximation capacity of some variation spaces corresponding to\nshallow ReLU$^k$ neural networks. It is shown that sufficiently smooth\nfunctions are contained in these spaces with finite variation norms. For\nfunctions with less smoothness, the approximation rates in terms of the\nvariation norm are established. Using these results, we are able to prove the\noptimal approximation rates in terms of the number of neurons for shallow\nReLU$^k$ neural networks. It is also shown how these results can be used to\nderive approximation bounds for deep neural networks and convolutional neural\nnetworks (CNNs). As applications, we study convergence rates for nonparametric\nregression using three ReLU neural network models: shallow neural network,\nover-parameterized neural network, and CNN. In particular, we show that shallow\nneural networks can achieve the minimax optimal rates for learning H\\\"older\nfunctions, which complements recent results for deep neural networks. It is\nalso proven that over-parameterized (deep or shallow) neural networks can\nachieve nearly optimal rates for nonparametric regression.\n","authors":["Yunfei Yang","Ding-Xuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2304.01561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12067v1","updated":"2023-06-21T07:32:29Z","published":"2023-06-21T07:32:29Z","title":"Optimal Algorithms for Stochastic Bilevel Optimization under Relaxed\n  Smoothness Conditions","summary":"  Stochastic Bilevel optimization usually involves minimizing an upper-level\n(UL) function that is dependent on the arg-min of a strongly-convex lower-level\n(LL) function. Several algorithms utilize Neumann series to approximate certain\nmatrix inverses involved in estimating the implicit gradient of the UL function\n(hypergradient). The state-of-the-art StOchastic Bilevel Algorithm (SOBA) [16]\ninstead uses stochastic gradient descent steps to solve the linear system\nassociated with the explicit matrix inversion. This modification enables SOBA\nto match the lower bound of sample complexity for the single-level counterpart\nin non-convex settings. Unfortunately, the current analysis of SOBA relies on\nthe assumption of higher-order smoothness for the UL and LL functions to\nachieve optimality. In this paper, we introduce a novel fully single-loop and\nHessian-inversion-free algorithmic framework for stochastic bilevel\noptimization and present a tighter analysis under standard smoothness\nassumptions (first-order Lipschitzness of the UL function and second-order\nLipschitzness of the LL function). Furthermore, we show that by a slight\nmodification of our approach, our algorithm can handle a more general\nmulti-objective robust bilevel optimization problem. For this case, we obtain\nthe state-of-the-art oracle complexity results demonstrating the generality of\nboth the proposed algorithmic and analytic frameworks. Numerical experiments\ndemonstrate the performance gain of the proposed algorithms over existing ones.\n","authors":["Xuxing Chen","Tesi Xiao","Krishnakumar Balasubramanian"],"pdf_url":"https://arxiv.org/pdf/2306.12067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2103.01600v3","updated":"2023-06-21T07:13:14Z","published":"2021-03-02T09:55:05Z","title":"Missing Value Imputation on Multidimensional Time Series","summary":"  We present DeepMVI, a deep learning method for missing value imputation in\nmultidimensional time-series datasets. Missing values are commonplace in\ndecision support platforms that aggregate data over long time stretches from\ndisparate sources, and reliable data analytics calls for careful handling of\nmissing data. One strategy is imputing the missing values, and a wide variety\nof algorithms exist spanning simple interpolation, matrix factorization methods\nlike SVD, statistical models like Kalman filters, and recent deep learning\nmethods. We show that often these provide worse results on aggregate analytics\ncompared to just excluding the missing data. DeepMVI uses a neural network to\ncombine fine-grained and coarse-grained patterns along a time series, and\ntrends from related series across categorical dimensions. After failing with\noff-the-shelf neural architectures, we design our own network that includes a\ntemporal transformer with a novel convolutional window feature, and kernel\nregression with learned embeddings. The parameters and their training are\ndesigned carefully to generalize across different placements of missing blocks\nand data characteristics. Experiments across nine real datasets, four different\nmissing scenarios, comparing seven existing methods show that DeepMVI is\nsignificantly more accurate, reducing error by more than 50% in more than half\nthe cases, compared to the best existing method. Although slower than simpler\nmatrix factorization methods, we justify the increased time overheads by\nshowing that DeepMVI is the only option that provided overall more accurate\nanalytics than dropping missing values.\n","authors":["Parikshit Bansal","Prathamesh Deshpande","Sunita Sarawagi"],"pdf_url":"https://arxiv.org/pdf/2103.01600v3.pdf","comment":"Accepted to VLDB 2021"},{"id":"http://arxiv.org/abs/2305.16863v2","updated":"2023-06-21T07:06:15Z","published":"2023-05-26T12:15:54Z","title":"Controlling Learned Effects to Reduce Spurious Correlations in Text\n  Classifiers","summary":"  To address the problem of NLP classifiers learning spurious correlations\nbetween training features and target labels, a common approach is to make the\nmodel's predictions invariant to these features. However, this can be\ncounter-productive when the features have a non-zero causal effect on the\ntarget label and thus are important for prediction. Therefore, using methods\nfrom the causal inference literature, we propose an algorithm to regularize the\nlearnt effect of the features on the model's prediction to the estimated effect\nof feature on label. This results in an automated augmentation method that\nleverages the estimated effect of a feature to appropriately change the labels\nfor new augmented inputs. On toxicity and IMDB review datasets, the proposed\nalgorithm minimises spurious correlations and improves the minority group\n(i.e., samples breaking spurious correlations) accuracy, while also improving\nthe total accuracy compared to standard training.\n","authors":["Parikshit Bansal","Amit Sharma"],"pdf_url":"https://arxiv.org/pdf/2305.16863v2.pdf","comment":"Accepted to ACL 2023"},{"id":"http://arxiv.org/abs/2303.09989v3","updated":"2023-06-21T07:06:01Z","published":"2023-03-17T14:04:51Z","title":"Finding Competence Regions in Domain Generalization","summary":"  We investigate a \"learning to reject\" framework to address the problem of\nsilent failures in Domain Generalization (DG), where the test distribution\ndiffers from the training distribution. Assuming a mild distribution shift, we\nwish to accept out-of-distribution (OOD) data from a new domain whenever a\nmodel's estimated competence foresees trustworthy responses, instead of\nrejecting OOD data outright. Trustworthiness is then predicted via a proxy\nincompetence score that is tightly linked to the performance of a classifier.\nWe present a comprehensive experimental evaluation of existing proxy scores as\nincompetence scores for classification and highlight the resulting trade-offs\nbetween rejection rate and accuracy gain. For comparability with prior work, we\nfocus on standard DG benchmarks and consider the effect of measuring\nincompetence via different learned representations in a closed versus an open\nworld setting. Our results suggest that increasing incompetence scores are\nindeed predictive of reduced accuracy, leading to significant improvements of\nthe average accuracy below a suitable incompetence threshold. However, the\nscores are not yet good enough to allow for a favorable accuracy/rejection\ntrade-off in all tested domains. Surprisingly, our results also indicate that\nclassifiers optimized for DG robustness do not outperform a naive Empirical\nRisk Minimization (ERM) baseline in the competence region, that is, where test\nsamples elicit low incompetence scores.\n","authors":["Jens Müller","Stefan T. Radev","Robert Schmier","Felix Draxler","Carsten Rother","Ullrich Köthe"],"pdf_url":"https://arxiv.org/pdf/2303.09989v3.pdf","comment":"The paper has been published at TMLR (see\n  https://openreview.net/forum?id=TSy0vuwQFN)"},{"id":"http://arxiv.org/abs/2306.12059v1","updated":"2023-06-21T07:01:38Z","published":"2023-06-21T07:01:38Z","title":"EquiformerV2: Improved Equivariant Transformer for Scaling to\n  Higher-Degree Representations","summary":"  Equivariant Transformers such as Equiformer have demonstrated the efficacy of\napplying Transformers to the domain of 3D atomistic systems. However, they are\nstill limited to small degrees of equivariant representations due to their\ncomputational complexity. In this paper, we investigate whether these\narchitectures can scale well to higher degrees. Starting from Equiformer, we\nfirst replace $SO(3)$ convolutions with eSCN convolutions to efficiently\nincorporate higher-degree tensors. Then, to better leverage the power of higher\ndegrees, we propose three architectural improvements -- attention\nre-normalization, separable $S^2$ activation and separable layer normalization.\nPutting this all together, we propose EquiformerV2, which outperforms previous\nstate-of-the-art methods on the large-scale OC20 dataset by up to $12\\%$ on\nforces, $4\\%$ on energies, offers better speed-accuracy trade-offs, and\n$2\\times$ reduction in DFT calculations needed for computing adsorption\nenergies.\n","authors":["Yi-Lun Liao","Brandon Wood","Abhishek Das","Tess Smidt"],"pdf_url":"https://arxiv.org/pdf/2306.12059v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11335v2","updated":"2023-06-21T06:56:47Z","published":"2023-06-20T07:06:04Z","title":"RM-PRT: Realistic Robotic Manipulation Simulator and Benchmark with\n  Progressive Reasoning Tasks","summary":"  Recently, the advent of pre-trained large-scale language models (LLMs) like\nChatGPT and GPT-4 have significantly advanced the machine's natural language\nunderstanding capabilities. This breakthrough has allowed us to seamlessly\nintegrate these open-source LLMs into a unified robot simulator environment to\nhelp robots accurately understand and execute human natural language\ninstructions. To this end, in this work, we introduce a realistic robotic\nmanipulation simulator and build a Robotic Manipulation with Progressive\nReasoning Tasks (RM-PRT) benchmark on this basis. Specifically, the RM-PRT\nbenchmark builds a new high-fidelity digital twin scene based on Unreal Engine\n5, which includes 782 categories, 2023 objects, and 15K natural language\ninstructions generated by ChatGPT for a detailed evaluation of robot\nmanipulation. We propose a general pipeline for the RM-PRT benchmark that takes\nas input multimodal prompts containing natural language instructions and\nautomatically outputs actions containing the movement and position transitions.\nWe set four natural language understanding tasks with progressive reasoning\nlevels and evaluate the robot's ability to understand natural language\ninstructions in two modes of adsorption and grasping. In addition, we also\nconduct a comprehensive analysis and comparison of the differences and\nadvantages of 10 different LLMs in instruction understanding and generation\nquality. We hope the new simulator and benchmark will facilitate future\nresearch on language-guided robotic manipulation. Project website:\nhttps://necolizer.github.io/RM-PRT/ .\n","authors":["Pengzhen Ren","Kaidong Zhang","Hetao Zheng","Zixuan Li","Yuhang Wen","Fengda Zhu","Mas Ma","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2306.11335v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12047v1","updated":"2023-06-21T06:30:56Z","published":"2023-06-21T06:30:56Z","title":"Corrector Operator to Enhance Accuracy and Reliability of Neural\n  Operator Surrogates of Nonlinear Variational Boundary-Value Problems","summary":"  This work focuses on developing methods for approximating the solution\noperators of a class of parametric partial differential equations via neural\noperators. Neural operators have several challenges, including the issue of\ngenerating appropriate training data, cost-accuracy trade-offs, and nontrivial\nhyperparameter tuning. The unpredictability of the accuracy of neural operators\nimpacts their applications in downstream problems of inference, optimization,\nand control. A framework is proposed based on the linear variational problem\nthat gives the correction to the prediction furnished by neural operators. The\noperator associated with the corrector problem is referred to as the corrector\noperator. Numerical results involving a nonlinear diffusion model in two\ndimensions with PCANet-type neural operators show almost two orders of increase\nin the accuracy of approximations when neural operators are corrected using the\nproposed scheme. Further, topology optimization involving a nonlinear diffusion\nmodel is considered to highlight the limitations of neural operators and the\nefficacy of the correction scheme. Optimizers with neural operator surrogates\nare seen to make significant errors (as high as 80 percent). However, the\nerrors are much lower (below 7 percent) when neural operators are corrected\nfollowing the proposed method.\n","authors":["Prashant K. Jha","J. Tinsley Oden"],"pdf_url":"https://arxiv.org/pdf/2306.12047v1.pdf","comment":"34 pages, 14 figures"},{"id":"http://arxiv.org/abs/2306.12045v1","updated":"2023-06-21T06:30:18Z","published":"2023-06-21T06:30:18Z","title":"Temporal Conditioning Spiking Latent Variable Models of the Neural\n  Response to Natural Visual Scenes","summary":"  Developing computational models of neural response is crucial for\nunderstanding sensory processing and neural computations. Current\nstate-of-the-art neural network methods use temporal filters to handle temporal\ndependencies, resulting in an unrealistic and inflexible processing flow.\nMeanwhile, these methods target trial-averaged firing rates and fail to capture\nimportant features in spike trains. This work presents the temporal\nconditioning spiking latent variable models (TeCoS-LVM) to simulate the neural\nresponse to natural visual stimuli. We use spiking neurons to produce spike\noutputs that directly match the recorded trains. This approach helps to avoid\nlosing information embedded in the original spike trains. We exclude the\ntemporal dimension from the model parameter space and introduce a temporal\nconditioning operation to allow the model to adaptively explore and exploit\ntemporal dependencies in stimuli sequences in a natural paradigm. We show that\nTeCoS-LVM models can produce more realistic spike activities and accurately fit\nspike statistics than powerful alternatives. Additionally, learned TeCoS-LVM\nmodels can generalize well to longer time scales. Overall, while remaining\ncomputationally tractable, our model effectively captures key features of\nneural coding systems. It thus provides a useful tool for building accurate\npredictive computational accounts for various sensory perception circuits.\n","authors":["Gehua Ma","Runhao Jiang","Rui Yan","Huajin Tang"],"pdf_url":"https://arxiv.org/pdf/2306.12045v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12041v1","updated":"2023-06-21T06:18:05Z","published":"2023-06-21T06:18:05Z","title":"Self-Distilled Masked Auto-Encoders are Efficient Video Anomaly\n  Detectors","summary":"  We propose an efficient abnormal event detection model based on a lightweight\nmasked auto-encoder (AE) applied at the video frame level. The novelty of the\nproposed model is threefold. First, we introduce an approach to weight tokens\nbased on motion gradients, thus avoiding learning to reconstruct the static\nbackground scene. Second, we integrate a teacher decoder and a student decoder\ninto our architecture, leveraging the discrepancy between the outputs given by\nthe two decoders to improve anomaly detection. Third, we generate synthetic\nabnormal events to augment the training videos, and task the masked AE model to\njointly reconstruct the original frames (without anomalies) and the\ncorresponding pixel-level anomaly maps. Our design leads to an efficient and\neffective model, as demonstrated by the extensive experiments carried out on\nthree benchmarks: Avenue, ShanghaiTech and UCSD Ped2. The empirical results\nshow that our model achieves an excellent trade-off between speed and accuracy,\nobtaining competitive AUC scores, while processing 1670 FPS. Hence, our model\nis between 8 and 70 times faster than competing methods. We also conduct an\nablation study to justify our design.\n","authors":["Nicolae-Catalin Ristea","Florinel-Alin Croitoru","Radu Tudor Ionescu","Marius Popescu","Fahad Shahbaz Khan","Mubarak Shah"],"pdf_url":"https://arxiv.org/pdf/2306.12041v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.07351v2","updated":"2023-06-21T06:07:22Z","published":"2023-02-14T21:27:10Z","title":"Constrained Decision Transformer for Offline Safe Reinforcement Learning","summary":"  Safe reinforcement learning (RL) trains a constraint satisfaction policy by\ninteracting with the environment. We aim to tackle a more challenging problem:\nlearning a safe policy from an offline dataset. We study the offline safe RL\nproblem from a novel multi-objective optimization perspective and propose the\n$\\epsilon$-reducible concept to characterize problem difficulties. The inherent\ntrade-offs between safety and task performance inspire us to propose the\nconstrained decision transformer (CDT) approach, which can dynamically adjust\nthe trade-offs during deployment. Extensive experiments show the advantages of\nthe proposed method in learning an adaptive, safe, robust, and high-reward\npolicy. CDT outperforms its variants and strong offline safe RL baselines by a\nlarge margin with the same hyperparameters across all tasks, while keeping the\nzero-shot adaptation capability to different constraint thresholds, making our\napproach more suitable for real-world RL under constraints. The code is\navailable at https://github.com/liuzuxin/OSRL.\n","authors":["Zuxin Liu","Zijian Guo","Yihang Yao","Zhepeng Cen","Wenhao Yu","Tingnan Zhang","Ding Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.07351v2.pdf","comment":"Published at ICML 2023"},{"id":"http://arxiv.org/abs/2306.12037v1","updated":"2023-06-21T06:05:34Z","published":"2023-06-21T06:05:34Z","title":"Distributed Random Reshuffling Methods with Improved Convergence","summary":"  This paper proposes two distributed random reshuffling methods, namely\nGradient Tracking with Random Reshuffling (GT-RR) and Exact Diffusion with\nRandom Reshuffling (ED-RR), to solve the distributed optimization problem over\na connected network, where a set of agents aim to minimize the average of their\nlocal cost functions. Both algorithms invoke random reshuffling (RR) update for\neach agent, inherit favorable characteristics of RR for minimizing smooth\nnonconvex objective functions, and improve the performance of previous\ndistributed random reshuffling methods both theoretically and empirically.\nSpecifically, both GT-RR and ED-RR achieve the convergence rate of\n$O(1/[(1-\\lambda)^{1/3}m^{1/3}T^{2/3}])$ in driving the (minimum) expected\nsquared norm of the gradient to zero, where $T$ denotes the number of epochs,\n$m$ is the sample size for each agent, and $1-\\lambda$ represents the spectral\ngap of the mixing matrix. When the objective functions further satisfy the\nPolyak-{\\L}ojasiewicz (PL) condition, we show GT-RR and ED-RR both achieve\n$O(1/[(1-\\lambda)mT^2])$ convergence rate in terms of the averaged expected\ndifferences between the agents' function values and the global minimum value.\nNotably, both results are comparable to the convergence rates of centralized RR\nmethods (up to constant factors depending on the network topology) and\noutperform those of previous distributed random reshuffling algorithms.\nMoreover, we support the theoretical findings with a set of numerical\nexperiments.\n","authors":["Kun Huang","Linli Zhou","Shi Pu"],"pdf_url":"https://arxiv.org/pdf/2306.12037v1.pdf","comment":"34 pages, 8 figures"},{"id":"http://arxiv.org/abs/2302.04262v2","updated":"2023-06-21T05:54:37Z","published":"2023-02-08T18:55:49Z","title":"Algorithmic Collective Action in Machine Learning","summary":"  We initiate a principled study of algorithmic collective action on digital\nplatforms that deploy machine learning algorithms. We propose a simple\ntheoretical model of a collective interacting with a firm's learning algorithm.\nThe collective pools the data of participating individuals and executes an\nalgorithmic strategy by instructing participants how to modify their own data\nto achieve a collective goal. We investigate the consequences of this model in\nthree fundamental learning-theoretic settings: the case of a nonparametric\noptimal learning algorithm, a parametric risk minimizer, and gradient-based\noptimization. In each setting, we come up with coordinated algorithmic\nstrategies and characterize natural success criteria as a function of the\ncollective's size. Complementing our theory, we conduct systematic experiments\non a skill classification task involving tens of thousands of resumes from a\ngig platform for freelancers. Through more than two thousand model training\nruns of a BERT-like language model, we see a striking correspondence emerge\nbetween our empirical observations and the predictions made by our theory.\nTaken together, our theory and experiments broadly support the conclusion that\nalgorithmic collectives of exceedingly small fractional size can exert\nsignificant control over a platform's learning algorithm.\n","authors":["Moritz Hardt","Eric Mazumdar","Celestine Mendler-Dünner","Tijana Zrnic"],"pdf_url":"https://arxiv.org/pdf/2302.04262v2.pdf","comment":"accepted at ICML 2023, camera-ready updates"},{"id":"http://arxiv.org/abs/2306.11375v2","updated":"2023-06-21T05:49:49Z","published":"2023-06-20T08:31:24Z","title":"Top-down machine learning of coarse-grained protein force-fields","summary":"  Developing accurate and efficient coarse-grained representations of proteins\nis crucial for understanding their folding, function, and interactions over\nextended timescales. Our methodology involves simulating proteins with\nmolecular dynamics and utilizing the resulting trajectories to train a neural\nnetwork potential through differentiable trajectory reweighting. Remarkably,\nthis method requires only the native conformation of proteins, eliminating the\nneed for labeled data derived from extensive simulations or memory-intensive\nend-to-end differentiable simulations. Once trained, the model can be employed\nto run parallel molecular dynamics simulations and sample folding events for\nproteins both within and beyond the training distribution, showcasing its\nextrapolation capabilities. By applying Markov State Models, native-like\nconformations of the simulated proteins can be predicted from the\ncoarse-grained simulations. Owing to its theoretical transferability and\nability to use solely experimental static structures as training data, we\nanticipate that this approach will prove advantageous for developing new\nprotein force fields and further advancing the study of protein dynamics,\nfolding, and interactions.\n","authors":["Carles Navarro","Maciej Majewski","Gianni de Fabritiis"],"pdf_url":"https://arxiv.org/pdf/2306.11375v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12033v1","updated":"2023-06-21T05:48:51Z","published":"2023-06-21T05:48:51Z","title":"End-to-End Augmentation Hyperparameter Tuning for Self-Supervised\n  Anomaly Detection","summary":"  Self-supervised learning (SSL) has emerged as a promising paradigm that\npresents self-generated supervisory signals to real-world problems, bypassing\nthe extensive manual labeling burden. SSL is especially attractive for\nunsupervised tasks such as anomaly detection, where labeled anomalies are often\nnonexistent and costly to obtain. While self-supervised anomaly detection\n(SSAD) has seen a recent surge of interest, the literature has failed to treat\ndata augmentation as a hyperparameter. Meanwhile, recent works have reported\nthat the choice of augmentation has significant impact on detection\nperformance. In this paper, we introduce ST-SSAD (Self-Tuning Self-Supervised\nAnomaly Detection), the first systematic approach to SSAD in regards to\nrigorously tuning augmentation. To this end, our work presents two key\ncontributions. The first is a new unsupervised validation loss that quantifies\nthe alignment between the augmented training data and the (unlabeled) test\ndata. In principle we adopt transduction, quantifying the extent to which\naugmentation mimics the true anomaly-generating mechanism, in contrast to\naugmenting data with arbitrary pseudo anomalies without regard to test data.\nSecond, we present new differentiable augmentation functions, allowing data\naugmentation hyperparameter(s) to be tuned end-to-end via our proposed\nvalidation loss. Experiments on two testbeds with semantic class anomalies and\nsubtle industrial defects show that systematically tuning augmentation offers\nsignificant performance gains over current practices.\n","authors":["Jaemin Yoo","Lingxiao Zhao","Leman Akoglu"],"pdf_url":"https://arxiv.org/pdf/2306.12033v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.10180v2","updated":"2023-06-21T05:31:32Z","published":"2023-06-16T21:20:49Z","title":"Samplet basis pursuit","summary":"  We consider kernel-based learning in samplet coordinates with\nl1-regularization. The application of an l1-regularization term enforces\nsparsity of the coefficients with respect to the samplet basis. Therefore, we\ncall this approach samplet basis pursuit. Samplets are wavelet-type signed\nmeasures, which are tailored to scattered data. They provide similar properties\nas wavelets in terms of localization, multiresolution analysis, and data\ncompression. The class of signals that can sparsely be represented in a samplet\nbasis is considerably larger than the class of signals which exhibit a sparse\nrepresentation in the single-scale basis. In particular, every signal that can\nbe represented by the superposition of only a few features of the canonical\nfeature map is also sparse in samplet coordinates. We propose the efficient\nsolution of the problem under consideration by combining soft-shrinkage with\nthe semi-smooth Newton method and compare the approach to the fast iterative\nshrinkage thresholding algorithm. We present numerical benchmarks as well as\napplications to surface reconstruction from noisy data and to the\nreconstruction of temperature data using a dictionary of multiple kernels.\n","authors":["Davide Baroli","Helmut Harbrecht","Michael Multerer"],"pdf_url":"https://arxiv.org/pdf/2306.10180v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12027v1","updated":"2023-06-21T05:27:08Z","published":"2023-06-21T05:27:08Z","title":"Comparative analysis of various web crawler algorithms","summary":"  This presentation focuses on the importance of web crawling and page ranking\nalgorithms in dealing with the massive amount of data present on the World Wide\nWeb. As the web continues to grow exponentially, efficient search and retrieval\nmethods become crucial. Web crawling is a process that converts unstructured\ndata into structured data, enabling effective information retrieval.\nAdditionally, page ranking algorithms play a significant role in assessing the\nquality and popularity of web pages. The presentation explores the background\nof these algorithms and evaluates five different crawling algorithms: Shark\nSearch, Priority-Based Queue, Naive Bayes, Breadth-First, and Depth-First. The\ngoal is to identify the most effective algorithm for crawling web pages. By\nunderstanding these algorithms, we can enhance our ability to navigate the web\nand extract valuable information efficiently.\n","authors":["Nithin T K","Chandana S","Barani G","Chavva Dharani","M S Karishma"],"pdf_url":"https://arxiv.org/pdf/2306.12027v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12026v1","updated":"2023-06-21T05:26:28Z","published":"2023-06-21T05:26:28Z","title":"Continual Learners are Incremental Model Generalizers","summary":"  Motivated by the efficiency and rapid convergence of pre-trained models for\nsolving downstream tasks, this paper extensively studies the impact of\nContinual Learning (CL) models as pre-trainers. In both supervised and\nunsupervised CL, we find that the transfer quality of the representation often\nincreases gradually without noticeable degradation in fine-tuning performance.\nThis is because CL models can learn improved task-general features when easily\nforgetting task-specific knowledge. Based on this observation, we suggest a new\nunsupervised CL framework with masked modeling, which aims to capture fluent\ntask-generic representation during training. Furthermore, we propose a new\nfine-tuning scheme, GLobal Attention Discretization (GLAD), that preserves rich\ntask-generic representation during solving downstream tasks. The model\nfine-tuned with GLAD achieves competitive performance and can also be used as a\ngood pre-trained model itself. We believe this paper breaks the barriers\nbetween pre-training and fine-tuning steps and leads to a sustainable learning\nframework in which the continual learner incrementally improves model\ngeneralization, yielding better transfer to unseen tasks.\n","authors":["Jaehong Yoon","Sung Ju Hwang","Yue Cao"],"pdf_url":"https://arxiv.org/pdf/2306.12026v1.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2211.01021v2","updated":"2023-06-21T05:26:10Z","published":"2022-11-02T10:33:38Z","title":"Data-Driven Modeling of Landau Damping by Physics-Informed Neural\n  Networks","summary":"  Kinetic approaches are generally accurate in dealing with microscale plasma\nphysics problems but are computationally expensive for large-scale or\nmultiscale systems. One of the long-standing problems in plasma physics is the\nintegration of kinetic physics into fluid models, which is often achieved\nthrough sophisticated analytical closure terms. In this study, we successfully\nconstruct a multi-moment fluid model with an implicit fluid closure included in\nthe neural network using machine learning. The multi-moment fluid model is\ntrained with a small fraction of sparsely sampled data from kinetic simulations\nof Landau damping, using the physics-informed neural network (PINN) and the\ngradient-enhanced physics-informed neural network (gPINN). The multi-moment\nfluid model constructed using either PINN or gPINN reproduces the time\nevolution of the electric field energy, including its damping rate, and the\nplasma dynamics from the kinetic simulations. For the first time, we introduce\na new variant of the gPINN architecture, namely, gPINN$p$ to capture the Landau\ndamping process. Instead of including the gradients of all the equation\nresiduals, gPINN$p$ only adds the gradient of the pressure equation residual as\none additional constraint. Among the three approaches, the gPINN$p$-constructed\nmulti-moment fluid model offers the most accurate results. This work sheds new\nlight on the accurate and efficient modeling of large-scale systems, which can\nbe extended to complex multiscale laboratory, space, and astrophysical plasma\nphysics problems.\n","authors":["Yilan Qin","Jiayu Ma","Mingle Jiang","Chuanfei Dong","Haiyang Fu","Liang Wang","Wenjie Cheng","Yaqiu Jin"],"pdf_url":"https://arxiv.org/pdf/2211.01021v2.pdf","comment":"11 pages, 7 figures, accepted for publication in Physical Review\n  Research"},{"id":"http://arxiv.org/abs/2306.10075v2","updated":"2023-06-21T05:05:42Z","published":"2023-06-16T03:31:58Z","title":"Matrix Diagonalization as a Board Game: Teaching an Eigensolver the\n  Fastest Path to Solution","summary":"  Matrix diagonalization is at the cornerstone of numerous fields of scientific\ncomputing. Diagonalizing a matrix to solve an eigenvalue problem requires a\nsequential path of iterations that eventually reaches a sufficiently converged\nand accurate solution for all the eigenvalues and eigenvectors. This typically\ntranslates into a high computational cost. Here we demonstrate how\nreinforcement learning, using the AlphaZero framework, can accelerate Jacobi\nmatrix diagonalizations by viewing the selection of the fastest path to\nsolution as a board game. To demonstrate the viability of our approach we apply\nthe Jacobi diagonalization algorithm to symmetric Hamiltonian matrices that\nappear in quantum chemistry calculations. We find that a significant\nacceleration can often be achieved. Our findings highlight the opportunity to\nuse machine learning as a promising tool to improve the performance of\nnumerical linear algebra.\n","authors":["Phil Romero","Manish Bhattarai","Christian F. A. Negre","Anders M. N. Niklasson","Adetokunbo Adedoyin"],"pdf_url":"https://arxiv.org/pdf/2306.10075v2.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2306.12014v1","updated":"2023-06-21T04:34:27Z","published":"2023-06-21T04:34:27Z","title":"3HAN: A Deep Neural Network for Fake News Detection","summary":"  The rapid spread of fake news is a serious problem calling for AI solutions.\nWe employ a deep learning based automated detector through a three level\nhierarchical attention network (3HAN) for fast, accurate detection of fake\nnews. 3HAN has three levels, one each for words, sentences, and the headline,\nand constructs a news vector: an effective representation of an input news\narticle, by processing an article in an hierarchical bottom-up manner. The\nheadline is known to be a distinguishing feature of fake news, and furthermore,\nrelatively few words and sentences in an article are more important than the\nrest. 3HAN gives a differential importance to parts of an article, on account\nof its three layers of attention. By experiments on a large real-world data\nset, we observe the effectiveness of 3HAN with an accuracy of 96.77%. Unlike\nsome other deep learning models, 3HAN provides an understandable output through\nthe attention weights given to different parts of an article, which can be\nvisualized through a heatmap to enable further manual fact checking.\n","authors":["Sneha Singhania","Nigel Fernandez","Shrisha Rao"],"pdf_url":"https://arxiv.org/pdf/2306.12014v1.pdf","comment":"Published as a conference paper at ICONIP 2017"},{"id":"http://arxiv.org/abs/2212.05949v2","updated":"2023-06-21T04:21:08Z","published":"2022-12-12T15:04:56Z","title":"Corruption-Robust Algorithms with Uncertainty Weighting for Nonlinear\n  Contextual Bandits and Markov Decision Processes","summary":"  Despite the significant interest and progress in reinforcement learning (RL)\nproblems with adversarial corruption, current works are either confined to the\nlinear setting or lead to an undesired $\\tilde{O}(\\sqrt{T}\\zeta)$ regret bound,\nwhere $T$ is the number of rounds and $\\zeta$ is the total amount of\ncorruption. In this paper, we consider the contextual bandit with general\nfunction approximation and propose a computationally efficient algorithm to\nachieve a regret of $\\tilde{O}(\\sqrt{T}+\\zeta)$. The proposed algorithm relies\non the recently developed uncertainty-weighted least-squares regression from\nlinear contextual bandit and a new weighted estimator of uncertainty for the\ngeneral function class. In contrast to the existing analysis that heavily\nrelies on the linear structure, we develop a novel technique to control the sum\nof weighted uncertainty, thus establishing the final regret bounds. We then\ngeneralize our algorithm to the episodic MDP setting and first achieve an\nadditive dependence on the corruption level $\\zeta$ in the scenario of general\nfunction approximation. Notably, our algorithms achieve regret bounds either\nnearly match the performance lower bound or improve the existing methods for\nall the corruption levels and in both known and unknown $\\zeta$ cases.\n","authors":["Chenlu Ye","Wei Xiong","Quanquan Gu","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.05949v2.pdf","comment":"We study the corruption-robust MDPs and contextual bandits with\n  general function approximation"},{"id":"http://arxiv.org/abs/2306.12006v1","updated":"2023-06-21T04:05:10Z","published":"2023-06-21T04:05:10Z","title":"Learning Homogenization for Elliptic Operators","summary":"  Multiscale partial differential equations (PDEs) arise in various\napplications, and several schemes have been developed to solve them\nefficiently. Homogenization theory is a powerful methodology that eliminates\nthe small-scale dependence, resulting in simplified equations that are\ncomputationally tractable. In the field of continuum mechanics, homogenization\nis crucial for deriving constitutive laws that incorporate microscale physics\nin order to formulate balance laws for the macroscopic quantities of interest.\nHowever, obtaining homogenized constitutive laws is often challenging as they\ndo not in general have an analytic form and can exhibit phenomena not present\non the microscale. In response, data-driven learning of the constitutive law\nhas been proposed as appropriate for this task. However, a major challenge in\ndata-driven learning approaches for this problem has remained unexplored: the\nimpact of discontinuities and corner interfaces in the underlying material.\nThese discontinuities in the coefficients affect the smoothness of the\nsolutions of the underlying equations. Given the prevalence of discontinuous\nmaterials in continuum mechanics applications, it is important to address the\nchallenge of learning in this context; in particular to develop underpinning\ntheory to establish the reliability of data-driven methods in this scientific\ndomain. The paper addresses this unexplored challenge by investigating the\nlearnability of homogenized constitutive laws for elliptic operators in the\npresence of such complexities. Approximation theory is presented, and numerical\nexperiments are performed which validate the theory for the solution operator\ndefined by the cell-problem arising in homogenization for elliptic PDEs.\n","authors":["Kaushik Bhattacharya","Nikola Kovachki","Aakila Rajan","Andrew M. Stuart","Margaret Trautner"],"pdf_url":"https://arxiv.org/pdf/2306.12006v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11066v2","updated":"2023-06-21T03:56:39Z","published":"2023-06-19T17:01:13Z","title":"Adversarial Robustness of Prompt-based Few-Shot Learning for Natural\n  Language Understanding","summary":"  State-of-the-art few-shot learning (FSL) methods leverage prompt-based\nfine-tuning to obtain remarkable results for natural language understanding\n(NLU) tasks. While much of the prior FSL methods focus on improving downstream\ntask performance, there is a limited understanding of the adversarial\nrobustness of such methods. In this work, we conduct an extensive study of\nseveral state-of-the-art FSL methods to assess their robustness to adversarial\nperturbations. To better understand the impact of various factors towards\nrobustness (or the lack of it), we evaluate prompt-based FSL methods against\nfully fine-tuned models for aspects such as the use of unlabeled data, multiple\nprompts, number of few-shot examples, model size and type. Our results on six\nGLUE tasks indicate that compared to fully fine-tuned models, vanilla FSL\nmethods lead to a notable relative drop in task performance (i.e., are less\nrobust) in the face of adversarial perturbations. However, using (i) unlabeled\ndata for prompt-based FSL and (ii) multiple prompts flip the trend. We further\ndemonstrate that increasing the number of few-shot examples and model size lead\nto increased adversarial robustness of vanilla FSL methods. Broadly, our work\nsheds light on the adversarial robustness evaluation of prompt-based FSL\nmethods for NLU tasks.\n","authors":["Venkata Prabhakara Sarath Nookala","Gaurav Verma","Subhabrata Mukherjee","Srijan Kumar"],"pdf_url":"https://arxiv.org/pdf/2306.11066v2.pdf","comment":"Accepted full paper at Findings of ACL 2023; Code available at\n  https://github.com/claws-lab/few-shot-adversarial-robustness"},{"id":"http://arxiv.org/abs/2301.11956v4","updated":"2023-06-21T03:52:06Z","published":"2023-01-27T19:15:31Z","title":"On the Connection Between MPNN and Graph Transformer","summary":"  Graph Transformer (GT) recently has emerged as a new paradigm of graph\nlearning algorithms, outperforming the previously popular Message Passing\nNeural Network (MPNN) on multiple benchmarks. Previous work (Kim et al., 2022)\nshows that with proper position embedding, GT can approximate MPNN arbitrarily\nwell, implying that GT is at least as powerful as MPNN. In this paper, we study\nthe inverse connection and show that MPNN with virtual node (VN), a commonly\nused heuristic with little theoretical understanding, is powerful enough to\narbitrarily approximate the self-attention layer of GT.\n  In particular, we first show that if we consider one type of linear\ntransformer, the so-called Performer/Linear Transformer (Choromanski et al.,\n2020; Katharopoulos et al., 2020), then MPNN + VN with only O(1) depth and O(1)\nwidth can approximate a self-attention layer in Performer/Linear Transformer.\nNext, via a connection between MPNN + VN and DeepSets, we prove the MPNN + VN\nwith O(n^d) width and O(1) depth can approximate the self-attention layer\narbitrarily well, where d is the input feature dimension. Lastly, under some\nassumptions, we provide an explicit construction of MPNN + VN with O(1) width\nand O(n) depth approximating the self-attention layer in GT arbitrarily well.\nOn the empirical side, we demonstrate that 1) MPNN + VN is a surprisingly\nstrong baseline, outperforming GT on the recently proposed Long Range Graph\nBenchmark (LRGB) dataset, 2) our MPNN + VN improves over early implementation\non a wide range of OGB datasets and 3) MPNN + VN outperforms Linear Transformer\nand MPNN on the climate modeling task.\n","authors":["Chen Cai","Truong Son Hy","Rose Yu","Yusu Wang"],"pdf_url":"https://arxiv.org/pdf/2301.11956v4.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2306.10456v2","updated":"2023-06-21T03:46:52Z","published":"2023-06-18T02:36:22Z","title":"Advancing Biomedicine with Graph Representation Learning: Recent\n  Progress, Challenges, and Future Directions","summary":"  Graph representation learning (GRL) has emerged as a pivotal field that has\ncontributed significantly to breakthroughs in various fields, including\nbiomedicine. The objective of this survey is to review the latest advancements\nin GRL methods and their applications in the biomedical field. We also\nhighlight key challenges currently faced by GRL and outline potential\ndirections for future research.\n","authors":["Fang Li","Yi Nian","Zenan Sun","Cui Tao"],"pdf_url":"https://arxiv.org/pdf/2306.10456v2.pdf","comment":"Accepted by 2023 IMIA Yearbook of Medical Informatics"},{"id":"http://arxiv.org/abs/2306.12001v1","updated":"2023-06-21T03:35:06Z","published":"2023-06-21T03:35:06Z","title":"An Overview of Catastrophic AI Risks","summary":"  Rapid advancements in artificial intelligence (AI) have sparked growing\nconcerns among experts, policymakers, and world leaders regarding the potential\nfor increasingly advanced AI systems to pose catastrophic risks. Although\nnumerous risks have been detailed separately, there is a pressing need for a\nsystematic discussion and illustration of the potential dangers to better\ninform efforts to mitigate them. This paper provides an overview of the main\nsources of catastrophic AI risks, which we organize into four categories:\nmalicious use, in which individuals or groups intentionally use AIs to cause\nharm; AI race, in which competitive environments compel actors to deploy unsafe\nAIs or cede control to AIs; organizational risks, highlighting how human\nfactors and complex systems can increase the chances of catastrophic accidents;\nand rogue AIs, describing the inherent difficulty in controlling agents far\nmore intelligent than humans. For each category of risk, we describe specific\nhazards, present illustrative stories, envision ideal scenarios, and propose\npractical suggestions for mitigating these dangers. Our goal is to foster a\ncomprehensive understanding of these risks and inspire collective and proactive\nefforts to ensure that AIs are developed and deployed in a safe manner.\nUltimately, we hope this will allow us to realize the benefits of this powerful\ntechnology while minimizing the potential for catastrophic outcomes.\n","authors":["Dan Hendrycks","Mantas Mazeika","Thomas Woodside"],"pdf_url":"https://arxiv.org/pdf/2306.12001v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11987v1","updated":"2023-06-21T02:45:01Z","published":"2023-06-21T02:45:01Z","title":"Training Transformers with 4-bit Integers","summary":"  Quantizing the activation, weight, and gradient to 4-bit is promising to\naccelerate neural network training. However, existing 4-bit training methods\nrequire custom numerical formats which are not supported by contemporary\nhardware. In this work, we propose a training method for transformers with all\nmatrix multiplications implemented with the INT4 arithmetic. Training with an\nultra-low INT4 precision is challenging. To achieve this, we carefully analyze\nthe specific structures of activation and gradients in transformers to propose\ndedicated quantizers for them. For forward propagation, we identify the\nchallenge of outliers and propose a Hadamard quantizer to suppress the\noutliers. For backpropagation, we leverage the structural sparsity of gradients\nby proposing bit splitting and leverage score sampling techniques to quantize\ngradients accurately. Our algorithm achieves competitive accuracy on a wide\nrange of tasks including natural language understanding, machine translation,\nand image classification. Unlike previous 4-bit training methods, our algorithm\ncan be implemented on the current generation of GPUs. Our prototypical linear\noperator implementation is up to 2.2 times faster than the FP16 counterparts\nand speeds up the training by up to 35.1%.\n","authors":["Haocheng Xi","Changhao Li","Jianfei Chen","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2306.11987v1.pdf","comment":"9 pages, 8 figures"},{"id":"http://arxiv.org/abs/2306.11986v1","updated":"2023-06-21T02:42:37Z","published":"2023-06-21T02:42:37Z","title":"Addressing the Rank Degeneration in Sequential Recommendation via\n  Singular Spectrum Smoothing","summary":"  Sequential recommendation (SR) investigates the dynamic user preferences\nmodeling and generates the next-item prediction. The next item preference is\ntypically generated by the affinity between the sequence and item\nrepresentations. However, both sequence and item representations suffer from\nthe rank degeneration issue due to the data sparsity problem. The rank\ndegeneration issue significantly impairs the representations for SR. This\nmotivates us to measure how severe is the rank degeneration issue and alleviate\nthe sequence and item representation rank degeneration issues simultaneously\nfor SR.\n  In this work, we theoretically connect the sequence representation\ndegeneration issue with the item rank degeneration, particularly for short\nsequences and cold items. We also identify the connection between the fast\nsingular value decay phenomenon and the rank collapse issue in transformer\nsequence output and item embeddings. We propose the area under the singular\nvalue curve metric to evaluate the severity of the singular value decay\nphenomenon and use it as an indicator of rank degeneration. We further\nintroduce a novel singular spectrum smoothing regularization to alleviate the\nrank degeneration on both sequence and item sides, which is the Singular\nsPectrum sMoothing for sequential Recommendation (SPMRec). We also establish a\ncorrelation between the ranks of sequence and item embeddings and the rank of\nthe user-item preference prediction matrix, which can affect recommendation\ndiversity. We conduct experiments on four benchmark datasets to demonstrate the\nsuperiority of SPMRec over the state-of-the-art recommendation methods,\nespecially in short sequences. The experiments also demonstrate a strong\nconnection between our proposed singular spectrum smoothing and recommendation\ndiversity.\n","authors":["Ziwei Fan","Zhiwei Liu","Hao Peng","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2306.11986v1.pdf","comment":"18 pages, regularizations on preserving embedding rank are surrogates\n  of intra-list recommendation diversity (controllable diversity). The code is\n  in https://github.com/zfan20/SPMRec"},{"id":"http://arxiv.org/abs/2302.08703v2","updated":"2023-06-21T02:35:39Z","published":"2023-02-17T05:32:24Z","title":"PAC Prediction Sets for Large Language Models of Code","summary":"  Prediction sets have recently been shown to be a promising strategy for\nquantifying the uncertainty of deep neural networks in a way that provides\ntheoretical guarantees. However, existing techniques have largely targeted\nsettings where the space of labels is simple, so prediction sets can be\narbitrary subsets of labels. For structured prediction problems where the space\nof labels is exponential in size, even prediction sets containing a small\nfraction of all labels can be exponentially large. In the context of code\ngeneration, we propose a solution that considers a restricted set of prediction\nsets that can compactly be represented as partial programs, which are programs\nwith portions replaced with holes. Given a trained code generation model, our\nalgorithm leverages a programming language's abstract syntax tree to generate a\nset of programs such that the correct program is in the set with\nhigh-confidence. Valuable applications of our algorithm include a Codex-style\ncode generator with holes in uncertain parts of the generated code, which\nprovides a partial program with theoretical guarantees. We evaluate our\napproach on PICARD (a T5 model for SQL semantic parsing) and Codex (a GPT model\nfor over a dozen programming languages, including Python), demonstrating that\nour approach generates compact PAC prediction sets. This is the first research\ncontribution that generates PAC prediction sets for generative code models.\n","authors":["Adam Khakhar","Stephen Mell","Osbert Bastani"],"pdf_url":"https://arxiv.org/pdf/2302.08703v2.pdf","comment":"Proceedings of the 40th International Conference on Machine Learning"},{"id":"http://arxiv.org/abs/2302.00942v5","updated":"2023-06-21T02:34:32Z","published":"2023-02-02T08:33:36Z","title":"Efficient Graph Field Integrators Meet Point Clouds","summary":"  We present two new classes of algorithms for efficient field integration on\ngraphs encoding point clouds. The first class, SeparatorFactorization(SF),\nleverages the bounded genus of point cloud mesh graphs, while the second class,\nRFDiffusion(RFD), uses popular epsilon-nearest-neighbor graph representations\nfor point clouds. Both can be viewed as providing the functionality of Fast\nMultipole Methods (FMMs), which have had a tremendous impact on efficient\nintegration, but for non-Euclidean spaces. We focus on geometries induced by\ndistributions of walk lengths between points (e.g., shortest-path distance). We\nprovide an extensive theoretical analysis of our algorithms, obtaining new\nresults in structural graph theory as a byproduct. We also perform exhaustive\nempirical evaluation, including on-surface interpolation for rigid and\ndeformable objects (particularly for mesh-dynamics modeling), Wasserstein\ndistance computations for point clouds, and the Gromov-Wasserstein variant.\n","authors":["Krzysztof Choromanski","Arijit Sehanobish","Han Lin","Yunfan Zhao","Eli Berger","Tetiana Parshakova","Alvin Pan","David Watkins","Tianyi Zhang","Valerii Likhosherstov","Somnath Basu Roy Chowdhury","Avinava Dubey","Deepali Jain","Tamas Sarlos","Snigdha Chaturvedi","Adrian Weller"],"pdf_url":"https://arxiv.org/pdf/2302.00942v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11985v1","updated":"2023-06-21T02:29:30Z","published":"2023-06-21T02:29:30Z","title":"Evaluation of Popular XAI Applied to Clinical Prediction Models: Can\n  They be Trusted?","summary":"  The absence of transparency and explainability hinders the clinical adoption\nof Machine learning (ML) algorithms. Although various methods of explainable\nartificial intelligence (XAI) have been suggested, there is a lack of\nliterature that delves into their practicality and assesses them based on\ncriteria that could foster trust in clinical environments. To address this gap\nthis study evaluates two popular XAI methods used for explaining predictive\nmodels in the healthcare context in terms of whether they (i) generate\ndomain-appropriate representation, i.e. coherent with respect to the\napplication task, (ii) impact clinical workflow and (iii) are consistent. To\nthat end, explanations generated at the cohort and patient levels were\nanalysed. The paper reports the first benchmarking of the XAI methods applied\nto risk prediction models obtained by evaluating the concordance between\ngenerated explanations and the trigger of a future clinical deterioration\nepisode recorded by the data collection system. We carried out an analysis\nusing two Electronic Medical Records (EMR) datasets sourced from Australian\nmajor hospitals. The findings underscore the limitations of state-of-the-art\nXAI methods in the clinical context and their potential benefits. We discuss\nthese limitations and contribute to the theoretical development of trustworthy\nXAI solutions where clinical decision support guides the choice of intervention\nby suggesting the pattern or drivers for clinical deterioration in the future.\n","authors":["Aida Brankovic","David Cook","Jessica Rahman","Wenjie Huang","Sankalp Khanna"],"pdf_url":"https://arxiv.org/pdf/2306.11985v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11982v1","updated":"2023-06-21T02:18:27Z","published":"2023-06-21T02:18:27Z","title":"Balanced Mixture of SuperNets for Learning the CNN Pooling Architecture","summary":"  Downsampling layers, including pooling and strided convolutions, are crucial\ncomponents of the convolutional neural network architecture that determine both\nthe granularity/scale of image feature analysis as well as the receptive field\nsize of a given layer. To fully understand this problem, we analyse the\nperformance of models independently trained with each pooling configurations on\nCIFAR10, using a ResNet20 network, and show that the position of the\ndownsampling layers can highly influence the performance of a network and\npredefined downsampling configurations are not optimal. Network Architecture\nSearch (NAS) might be used to optimize downsampling configurations as an\nhyperparameter. However, we find that common one-shot NAS based on a single\nSuperNet does not work for this problem. We argue that this is because a\nSuperNet trained for finding the optimal pooling configuration fully shares its\nparameters among all pooling configurations. This makes its training hard,\nbecause learning some configurations can harm the performance of others.\nTherefore, we propose a balanced mixture of SuperNets that automatically\nassociates pooling configurations to different weight models and helps to\nreduce the weight-sharing and inter-influence of pooling configurations on the\nSuperNet parameters. We evaluate our proposed approach on CIFAR10, CIFAR100, as\nwell as Food101 and show that in all cases, our model outperforms other\napproaches and improves over the default pooling configurations.\n","authors":["Mehraveh Javan","Matthew Toews","Marco Pedersoli"],"pdf_url":"https://arxiv.org/pdf/2306.11982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11307v2","updated":"2023-06-21T02:12:52Z","published":"2023-06-20T06:04:03Z","title":"Transforming Graphs for Enhanced Attribute-Based Clustering: An\n  Innovative Graph Transformer Method","summary":"  Graph Representation Learning (GRL) is an influential methodology, enabling a\nmore profound understanding of graph-structured data and aiding graph\nclustering, a critical task across various domains. The recent incursion of\nattention mechanisms, originally an artifact of Natural Language Processing\n(NLP), into the realm of graph learning has spearheaded a notable shift in\nresearch trends. Consequently, Graph Attention Networks (GATs) and Graph\nAttention Auto-Encoders have emerged as preferred tools for graph clustering\ntasks. Yet, these methods primarily employ a local attention mechanism, thereby\ncurbing their capacity to apprehend the intricate global dependencies between\nnodes within graphs. Addressing these impediments, this study introduces an\ninnovative method known as the Graph Transformer Auto-Encoder for Graph\nClustering (GTAGC). By melding the Graph Auto-Encoder with the Graph\nTransformer, GTAGC is adept at capturing global dependencies between nodes.\nThis integration amplifies the graph representation and surmounts the\nconstraints posed by the local attention mechanism. The architecture of GTAGC\nencompasses graph embedding, integration of the Graph Transformer within the\nautoencoder structure, and a clustering component. It strategically alternates\nbetween graph embedding and clustering, thereby tailoring the Graph Transformer\nfor clustering tasks, whilst preserving the graph's global structural\ninformation. Through extensive experimentation on diverse benchmark datasets,\nGTAGC has exhibited superior performance against existing state-of-the-art\ngraph clustering methodologies. This pioneering approach represents a novel\ncontribution to the field of graph clustering, paving the way for promising\navenues in future research.\n","authors":["Shuo Han","Jiacheng Liu","Jiayun Wu","Yinan Chen","Li Tao"],"pdf_url":"https://arxiv.org/pdf/2306.11307v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11974v1","updated":"2023-06-21T02:02:41Z","published":"2023-06-21T02:02:41Z","title":"Universal adversarial perturbations for multiple classification tasks\n  with quantum classifiers","summary":"  Quantum adversarial machine learning is an emerging field that studies the\nvulnerability of quantum learning systems against adversarial perturbations and\ndevelops possible defense strategies. Quantum universal adversarial\nperturbations are small perturbations, which can make different input samples\ninto adversarial examples that may deceive a given quantum classifier. This is\na field that was rarely looked into but worthwhile investigating because\nuniversal perturbations might simplify malicious attacks to a large extent,\ncausing unexpected devastation to quantum machine learning models. In this\npaper, we take a step forward and explore the quantum universal perturbations\nin the context of heterogeneous classification tasks. In particular, we find\nthat quantum classifiers that achieve almost state-of-the-art accuracy on two\ndifferent classification tasks can be both conclusively deceived by one\ncarefully-crafted universal perturbation. This result is explicitly\ndemonstrated with well-designed quantum continual learning models with elastic\nweight consolidation method to avoid catastrophic forgetting, as well as\nreal-life heterogeneous datasets from hand-written digits and medical MRI\nimages. Our results provide a simple and efficient way to generate universal\nperturbations on heterogeneous classification tasks and thus would provide\nvaluable guidance for future quantum learning technologies.\n","authors":["Yun-Zhong Qiu"],"pdf_url":"https://arxiv.org/pdf/2306.11974v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11971v1","updated":"2023-06-21T01:53:01Z","published":"2023-06-21T01:53:01Z","title":"AdCraft: An Advanced Reinforcement Learning Benchmark Environment for\n  Search Engine Marketing Optimization","summary":"  We introduce \\env{}, a novel benchmark environment for the Reinforcement\nLearning (RL) community distinguished by its stochastic and non-stationary\nproperties. The environment simulates bidding and budgeting dynamics within\nSearch Engine Marketing (SEM), a digital marketing technique utilizing paid\nadvertising to enhance the visibility of websites on search engine results\npages (SERPs). The performance of SEM advertisement campaigns depends on\nseveral factors, including keyword selection, ad design, bid management, budget\nadjustments, and performance monitoring. Deep RL recently emerged as a\npotential strategy to optimize campaign profitability within the complex and\ndynamic landscape of SEM but it requires substantial data, which may be costly\nor infeasible to acquire in practice. Our customizable environment enables\npractitioners to assess and enhance the robustness of RL algorithms pertinent\nto SEM bid and budget management without such costs. Through a series of\nexperiments within the environment, we demonstrate the challenges imposed by\nsparsity and non-stationarity on agent convergence and performance. We hope\nthese challenges further encourage discourse and development around effective\nstrategies for managing real-world uncertainties.\n","authors":["Maziar Gomrokchi","Owen Levin","Jeffrey Roach","Jonah White"],"pdf_url":"https://arxiv.org/pdf/2306.11971v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11967v1","updated":"2023-06-21T01:43:25Z","published":"2023-06-21T01:43:25Z","title":"Complementary Learning Subnetworks for Parameter-Efficient\n  Class-Incremental Learning","summary":"  In the scenario of class-incremental learning (CIL), deep neural networks\nhave to adapt their model parameters to non-stationary data distributions,\ne.g., the emergence of new classes over time. However, CIL models are\nchallenged by the well-known catastrophic forgetting phenomenon. Typical\nmethods such as rehearsal-based ones rely on storing exemplars of old classes\nto mitigate catastrophic forgetting, which limits real-world applications\nconsidering memory resources and privacy issues. In this paper, we propose a\nnovel rehearsal-free CIL approach that learns continually via the synergy\nbetween two Complementary Learning Subnetworks. Our approach involves jointly\noptimizing a plastic CNN feature extractor and an analytical feed-forward\nclassifier. The inaccessibility of historical data is tackled by holistically\ncontrolling the parameters of a well-trained model, ensuring that the decision\nboundary learned fits new classes while retaining recognition of previously\nlearned classes. Specifically, the trainable CNN feature extractor provides\ntask-dependent knowledge separately without interference; and the final\nclassifier integrates task-specific knowledge incrementally for decision-making\nwithout forgetting. In each CIL session, it accommodates new tasks by attaching\na tiny set of declarative parameters to its backbone, in which only one matrix\nper task or one vector per class is kept for knowledge retention. Extensive\nexperiments on a variety of task sequences show that our method achieves\ncompetitive results against state-of-the-art methods, especially in accuracy\ngain, memory cost, training efficiency, and task-order robustness. Furthermore,\nto make the non-growing backbone (i.e., a model with limited network capacity)\nsuffice to train on more incoming tasks, a graceful forgetting implementation\non previously learned trivial tasks is empirically investigated.\n","authors":["Depeng Li","Zhigang Zeng"],"pdf_url":"https://arxiv.org/pdf/2306.11967v1.pdf","comment":"13 pages, 4 figures. Under review"},{"id":"http://arxiv.org/abs/2303.16187v2","updated":"2023-06-21T01:27:37Z","published":"2023-03-28T17:53:06Z","title":"Visual Chain-of-Thought Diffusion Models","summary":"  Recent progress with conditional image diffusion models has been stunning,\nand this holds true whether we are speaking about models conditioned on a text\ndescription, a scene layout, or a sketch. Unconditional image diffusion models\nare also improving but lag behind, as do diffusion models which are conditioned\non lower-dimensional features like class labels. We propose to close the gap\nbetween conditional and unconditional models using a two-stage sampling\nprocedure. In the first stage we sample an embedding describing the semantic\ncontent of the image. In the second stage we sample the image conditioned on\nthis embedding and then discard the embedding. Doing so lets us leverage the\npower of conditional diffusion models on the unconditional generation task,\nwhich we show improves FID by 25-50% compared to standard unconditional\ngeneration.\n","authors":["William Harvey","Frank Wood"],"pdf_url":"https://arxiv.org/pdf/2303.16187v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11964v1","updated":"2023-06-21T01:26:34Z","published":"2023-06-21T01:26:34Z","title":"Sampling Individually-Fair Rankings that are Always Group Fair","summary":"  Rankings on online platforms help their end-users find the relevant\ninformation -- people, news, media, and products -- quickly. Fair ranking\ntasks, which ask to rank a set of items to maximize utility subject to\nsatisfying group-fairness constraints, have gained significant interest in the\nAlgorithmic Fairness, Information Retrieval, and Machine Learning literature.\nRecent works, however, identify uncertainty in the utilities of items as a\nprimary cause of unfairness and propose introducing randomness in the output.\nThis randomness is carefully chosen to guarantee an adequate representation of\neach item (while accounting for the uncertainty). However, due to this\nrandomness, the output rankings may violate group fairness constraints. We give\nan efficient algorithm that samples rankings from an individually-fair\ndistribution while ensuring that every output ranking is group fair. The\nexpected utility of the output ranking is at least $\\alpha$ times the utility\nof the optimal fair solution. Here, $\\alpha$ depends on the utilities,\nposition-discounts, and constraints -- it approaches 1 as the range of\nutilities or the position-discounts shrinks, or when utilities satisfy\ndistributional assumptions. Empirically, we observe that our algorithm achieves\nindividual and group fairness and that Pareto dominates the state-of-the-art\nbaselines.\n","authors":["Sruthi Gorantla","Anay Mehrotra","Amit Deshpande","Anand Louis"],"pdf_url":"https://arxiv.org/pdf/2306.11964v1.pdf","comment":"Full version of a paper accepted for presentation in ACM AIES 2023"},{"id":"http://arxiv.org/abs/2306.10045v2","updated":"2023-06-21T01:14:56Z","published":"2023-06-12T07:19:01Z","title":"Efficient Approximations of Complete Interatomic Potentials for Crystal\n  Property Prediction","summary":"  We study property prediction for crystal materials. A crystal structure\nconsists of a minimal unit cell that is repeated infinitely in 3D space. How to\naccurately represent such repetitive structures in machine learning models\nremains unresolved. Current methods construct graphs by establishing edges only\nbetween nearby nodes, thereby failing to faithfully capture infinite repeating\npatterns and distant interatomic interactions. In this work, we propose several\ninnovations to overcome these limitations. First, we propose to model\nphysics-principled interatomic potentials directly instead of only using\ndistances as in many existing methods. These potentials include the Coulomb\npotential, London dispersion potential, and Pauli repulsion potential. Second,\nwe model the complete set of potentials among all atoms, instead of only\nbetween nearby atoms as in existing methods. This is enabled by our\napproximations of infinite potential summations with provable error bounds. We\nfurther develop efficient algorithms to compute the approximations. Finally, we\npropose to incorporate our computations of complete interatomic potentials into\nmessage passing neural networks for representation learning. We perform\nexperiments on the JARVIS and Materials Project benchmarks for evaluation.\nResults show that the use of interatomic potentials and complete interatomic\npotentials leads to consistent performance improvements with reasonable\ncomputational costs. Our code is publicly available as part of the AIRS library\n(https://github.com/divelab/AIRS).\n","authors":["Yuchao Lin","Keqiang Yan","Youzhi Luo","Yi Liu","Xiaoning Qian","Shuiwang Ji"],"pdf_url":"https://arxiv.org/pdf/2306.10045v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11957v1","updated":"2023-06-21T00:59:06Z","published":"2023-06-21T00:59:06Z","title":"Towards Mitigating Spurious Correlations in the Wild: A Benchmark & a\n  more Realistic Dataset","summary":"  Deep neural networks often exploit non-predictive features that are\nspuriously correlated with class labels, leading to poor performance on groups\nof examples without such features. Despite the growing body of recent works on\nremedying spurious correlations, the lack of a standardized benchmark hinders\nreproducible evaluation and comparison of the proposed solutions. To address\nthis, we present SpuCo, a python package with modular implementations of\nstate-of-the-art solutions enabling easy and reproducible evaluation of current\nmethods. Using SpuCo, we demonstrate the limitations of existing datasets and\nevaluation schemes in validating the learning of predictive features over\nspurious ones. To overcome these limitations, we propose two new vision\ndatasets: (1) SpuCoMNIST, a synthetic dataset that enables simulating the\neffect of real world data properties e.g. difficulty of learning spurious\nfeature, as well as noise in the labels and features; (2) SpuCoAnimals, a\nlarge-scale dataset curated from ImageNet that captures spurious correlations\nin the wild much more closely than existing datasets. These contributions\nhighlight the shortcomings of current methods and provide a direction for\nfuture research in tackling spurious correlations. SpuCo, containing the\nbenchmark and datasets, can be found at https://github.com/BigML-CS-UCLA/SpuCo,\nwith detailed documentation available at\nhttps://spuco.readthedocs.io/en/latest/.\n","authors":["Siddharth Joshi","Yu Yang","Yihao Xue","Wenhan Yang","Baharan Mirzasoleiman"],"pdf_url":"https://arxiv.org/pdf/2306.11957v1.pdf","comment":"Package: https://github.com/BigML-CS-UCLA/SpuCo"},{"id":"http://arxiv.org/abs/2306.11955v1","updated":"2023-06-21T00:55:02Z","published":"2023-06-21T00:55:02Z","title":"TADIL: Task-Agnostic Domain-Incremental Learning through Task-ID\n  Inference using Transformer Nearest-Centroid Embeddings","summary":"  Machine Learning (ML) models struggle with data that changes over time or\nacross domains due to factors such as noise, occlusion, illumination, or\nfrequency, unlike humans who can learn from such non independent and\nidentically distributed data. Consequently, a Continual Learning (CL) approach\nis indispensable, particularly, Domain-Incremental Learning. In this paper, we\npropose a novel pipeline for identifying tasks in domain-incremental learning\nscenarios without supervision. The pipeline comprises four steps. First, we\nobtain base embeddings from the raw data using an existing transformer-based\nmodel. Second, we group the embedding densities based on their similarity to\nobtain the nearest points to each cluster centroid. Third, we train an\nincremental task classifier using only these few points. Finally, we leverage\nthe lightweight computational requirements of the pipeline to devise an\nalgorithm that decides in an online fashion when to learn a new task using the\ntask classifier and a drift detector. We conduct experiments using the SODA10M\nreal-world driving dataset and several CL strategies. We demonstrate that the\nperformance of these CL strategies with our pipeline can match the ground-truth\napproach, both in classical experiments assuming task boundaries, and also in\nmore realistic task-agnostic scenarios that require detecting new tasks\non-the-fly\n","authors":["Gusseppe Bravo-Rocca","Peini Liu","Jordi Guitart","Ajay Dholakia","David Ellison"],"pdf_url":"https://arxiv.org/pdf/2306.11955v1.pdf","comment":"An early version of this work was presented at CVPR 2023, LXAI\n  Workshop"},{"id":"http://arxiv.org/abs/2306.11951v1","updated":"2023-06-21T00:31:23Z","published":"2023-06-21T00:31:23Z","title":"On the Optimal Bounds for Noisy Computing","summary":"  We revisit the problem of computing with noisy information considered in\nFeige et al. 1994, which includes computing the OR function from noisy queries,\nand computing the MAX, SEARCH and SORT functions from noisy pairwise\ncomparisons. For $K$ given elements, the goal is to correctly recover the\ndesired function with probability at least $1-\\delta$ when the outcome of each\nquery is flipped with probability $p$. We consider both the adaptive sampling\nsetting where each query can be adaptively designed based on past outcomes, and\nthe non-adaptive sampling setting where the query cannot depend on past\noutcomes. The prior work provides tight bounds on the worst-case query\ncomplexity in terms of the dependence on $K$. However, the upper and lower\nbounds do not match in terms of the dependence on $\\delta$ and $p$. We improve\nthe lower bounds for all the four functions under both adaptive and\nnon-adaptive query models. Most of our lower bounds match the upper bounds up\nto constant factors when either $p$ or $\\delta$ is bounded away from $0$, while\nthe ratio between the best prior upper and lower bounds goes to infinity when\n$p\\rightarrow 0$ or $p\\rightarrow 1/2$. On the other hand, we also provide\nmatching upper and lower bounds for the number of queries in expectation,\nimproving both the upper and lower bounds for the variable-length query model.\n","authors":["Banghua Zhu","Ziao Wang","Nadim Ghaddar","Jiantao Jiao","Lele Wang"],"pdf_url":"https://arxiv.org/pdf/2306.11951v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11950v1","updated":"2023-06-21T00:28:20Z","published":"2023-06-21T00:28:20Z","title":"Mitigating Communication Costs in Neural Networks: The Role of Dendritic\n  Nonlinearity","summary":"  Our comprehension of biological neuronal networks has profoundly influenced\nthe evolution of artificial neural networks (ANNs). However, the neurons\nemployed in ANNs exhibit remarkable deviations from their biological analogs,\nmainly due to the absence of complex dendritic trees encompassing local\nnonlinearity. Despite such disparities, previous investigations have\ndemonstrated that point neurons can functionally substitute dendritic neurons\nin executing computational tasks. In this study, we scrutinized the importance\nof nonlinear dendrites within neural networks. By employing machine-learning\nmethodologies, we assessed the impact of dendritic structure nonlinearity on\nneural network performance. Our findings reveal that integrating dendritic\nstructures can substantially enhance model capacity and performance while\nkeeping signal communication costs effectively restrained. This investigation\noffers pivotal insights that hold considerable implications for the development\nof future neural network accelerators.\n","authors":["Xundong Wu","Pengfei Zhao","Zilin Yu","Lei Ma","Ka-Wa Yip","Huajin Tang","Gang Pan","Tiejun Huang"],"pdf_url":"https://arxiv.org/pdf/2306.11950v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.08776v5","updated":"2023-06-21T23:34:18Z","published":"2021-09-17T22:37:39Z","title":"Exploring the Training Robustness of Distributional Reinforcement\n  Learning against Noisy State Observations","summary":"  In real scenarios, state observations that an agent observes may contain\nmeasurement errors or adversarial noises, misleading the agent to take\nsuboptimal actions or even collapse while training. In this paper, we study the\ntraining robustness of distributional Reinforcement Learning (RL), a class of\nstate-of-the-art methods that estimate the whole distribution, as opposed to\nonly the expectation, of the total return. Firstly, we validate the contraction\nof distributional Bellman operators in the State-Noisy Markov Decision Process\n(SN-MDP), a typical tabular case that incorporates both random and adversarial\nstate observation noises. In the noisy setting with function approximation, we\nthen analyze the vulnerability of least squared loss in expectation-based RL\nwith either linear or nonlinear function approximation. By contrast, we\ntheoretically characterize the bounded gradient norm of distributional RL loss\nbased on the categorical parameterization equipped with the KL divergence. The\nresulting stable gradients while the optimization in distributional RL accounts\nfor its better training robustness against state observation noises. Finally,\nextensive experiments on the suite of environments verified that distributional\nRL is less vulnerable against both random and adversarial noisy state\nobservations compared with its expectation-based counterpart.\n","authors":["Ke Sun","Yingnan Zhao","Shangling Jui","Linglong Kong"],"pdf_url":"https://arxiv.org/pdf/2109.08776v5.pdf","comment":"Accepted in ECML PKDD 2023. This is the authors version of the work.\n  The definitive Version of Record will be published in the Proceedings of ECML\n  PKDD 2023"},{"id":"http://arxiv.org/abs/2302.13522v2","updated":"2023-06-21T23:30:52Z","published":"2023-02-27T05:21:35Z","title":"IGB: Addressing The Gaps In Labeling, Features, Heterogeneity, and Size\n  of Public Graph Datasets for Deep Learning Research","summary":"  Graph neural networks (GNNs) have shown high potential for a variety of\nreal-world, challenging applications, but one of the major obstacles in GNN\nresearch is the lack of large-scale flexible datasets. Most existing public\ndatasets for GNNs are relatively small, which limits the ability of GNNs to\ngeneralize to unseen data. The few existing large-scale graph datasets provide\nvery limited labeled data. This makes it difficult to determine if the GNN\nmodel's low accuracy for unseen data is inherently due to insufficient training\ndata or if the model failed to generalize. Additionally, datasets used to train\nGNNs need to offer flexibility to enable a thorough study of the impact of\nvarious factors while training GNN models.\n  In this work, we introduce the Illinois Graph Benchmark (IGB), a research\ndataset tool that the developers can use to train, scrutinize and\nsystematically evaluate GNN models with high fidelity. IGB includes both\nhomogeneous and heterogeneous academic graphs of enormous sizes, with more than\n40% of their nodes labeled. Compared to the largest graph datasets publicly\navailable, the IGB provides over 162X more labeled data for deep learning\npractitioners and developers to create and evaluate models with higher\naccuracy. The IGB dataset is a collection of academic graphs designed to be\nflexible, enabling the study of various GNN architectures, embedding generation\ntechniques, and analyzing system performance issues for node classification\ntasks. IGB is open-sourced, supports DGL and PyG frameworks, and comes with\nreleases of the raw text that we believe foster emerging language models and\nGNN research projects. An early public version of IGB is available at\nhttps://github.com/IllinoisGraphBenchmark/IGB-Datasets.\n","authors":["Arpandeep Khatua","Vikram Sharma Mailthody","Bhagyashree Taleka","Tengfei Ma","Xiang Song","Wen-mei Hwu"],"pdf_url":"https://arxiv.org/pdf/2302.13522v2.pdf","comment":"Accepted in KDD'23 conference. This is final preprint version"},{"id":"http://arxiv.org/abs/2306.02957v2","updated":"2023-06-21T23:09:58Z","published":"2023-06-05T15:24:39Z","title":"Complex Preferences for Different Convergent Priors in Discrete Graph\n  Diffusion","summary":"  Diffusion models have achieved state-of-the-art performance in generating\nmany different kinds of data, including images, text, and videos. Despite their\nsuccess, there has been limited research on how the underlying diffusion\nprocess and the final convergent prior can affect generative performance; this\nresearch has also been limited to continuous data types and a score-based\ndiffusion framework. To fill this gap, we explore how different discrete\ndiffusion kernels (which converge to different prior distributions) affect the\nperformance of diffusion models for graphs. To this end, we developed a novel\nformulation of a family of discrete diffusion kernels which are easily\nadjustable to converge to different Bernoulli priors, and we study the effect\nof these different kernels on generative performance. We show that the quality\nof generated graphs is sensitive to the prior used, and that the optimal choice\ncannot be explained by obvious statistics or metrics, which challenges the\nintuitions which previous works have suggested.\n","authors":["Alex M. Tseng","Nathaniel Diamant","Tommaso Biancalani","Gabriele Scalia"],"pdf_url":"https://arxiv.org/pdf/2306.02957v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2007.12674v2","updated":"2023-06-21T22:54:04Z","published":"2020-07-24T17:43:08Z","title":"Controlling Privacy Loss in Sampling Schemes: an Analysis of Stratified\n  and Cluster Sampling","summary":"  Sampling schemes are fundamental tools in statistics, survey design, and\nalgorithm design. A fundamental result in differential privacy is that a\ndifferentially private mechanism run on a simple random sample of a population\nprovides stronger privacy guarantees than the same algorithm run on the entire\npopulation. However, in practice, sampling designs are often more complex than\nthe simple, data-independent sampling schemes that are addressed in prior work.\nIn this work, we extend the study of privacy amplification results to more\ncomplex, data-dependent sampling schemes. We find that not only do these\nsampling schemes often fail to amplify privacy, they can actually result in\nprivacy degradation. We analyze the privacy implications of the pervasive\ncluster sampling and stratified sampling paradigms, as well as provide some\ninsight into the study of more general sampling designs.\n","authors":["Mark Bun","Jörg Drechsler","Marco Gaboardi","Audra McMillan","Jayshree Sarathy"],"pdf_url":"https://arxiv.org/pdf/2007.12674v2.pdf","comment":"Appeared at FORC 2022"},{"id":"http://arxiv.org/abs/2306.12599v1","updated":"2023-06-21T22:41:58Z","published":"2023-06-21T22:41:58Z","title":"Constant Memory Attention Block","summary":"  Modern foundation model architectures rely on attention mechanisms to\neffectively capture context. However, these methods require linear or quadratic\nmemory in terms of the number of inputs/datapoints, limiting their\napplicability in low-compute domains. In this work, we propose Constant Memory\nAttention Block (CMAB), a novel general-purpose attention block that computes\nits output in constant memory and performs updates in constant computation.\nHighlighting CMABs efficacy, we introduce methods for Neural Processes and\nTemporal Point Processes. Empirically, we show our proposed methods achieve\nresults competitive with state-of-the-art while being significantly more memory\nefficient.\n","authors":["Leo Feng","Frederick Tung","Hossein Hajimirsadeghi","Yoshua Bengio","Mohamed Osama Ahmed"],"pdf_url":"https://arxiv.org/pdf/2306.12599v1.pdf","comment":"Workshop version of arXiv:2305.14567"},{"id":"http://arxiv.org/abs/2306.12594v1","updated":"2023-06-21T22:28:17Z","published":"2023-06-21T22:28:17Z","title":"State-wise Constrained Policy Optimization","summary":"  Reinforcement Learning (RL) algorithms have shown tremendous success in\nsimulation environments, but their application to real-world problems faces\nsignificant challenges, with safety being a major concern. In particular,\nenforcing state-wise constraints is essential for many challenging tasks such\nas autonomous driving and robot manipulation. However, existing safe RL\nalgorithms under the framework of Constrained Markov Decision Process (CMDP) do\nnot consider state-wise constraints. To address this gap, we propose State-wise\nConstrained Policy Optimization (SCPO), the first general-purpose policy search\nalgorithm for state-wise constrained reinforcement learning. SCPO provides\nguarantees for state-wise constraint satisfaction in expectation. In\nparticular, we introduce the framework of Maximum Markov Decision Process, and\nprove that the worst-case safety violation is bounded under SCPO. We\ndemonstrate the effectiveness of our approach on training neural network\npolicies for extensive robot locomotion tasks, where the agent must satisfy a\nvariety of state-wise safety constraints. Our results show that SCPO\nsignificantly outperforms existing methods and can handle state-wise\nconstraints in high-dimensional robotics tasks.\n","authors":["Weiye Zhao","Rui Chen","Yifan Sun","Tianhao Wei","Changliu Liu"],"pdf_url":"https://arxiv.org/pdf/2306.12594v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2305.13681"},{"id":"http://arxiv.org/abs/2306.12589v1","updated":"2023-06-21T22:01:12Z","published":"2023-06-21T22:01:12Z","title":"Rapid building damage assessment workflow: An implementation for the\n  2023 Rolling Fork, Mississippi tornado event","summary":"  Rapid and accurate building damage assessments from high-resolution satellite\nimagery following a natural disaster is essential to inform and optimize first\nresponder efforts. However, performing such building damage assessments in an\nautomated manner is non-trivial due to the challenges posed by variations in\ndisaster-specific damage, diversity in satellite imagery, and the dearth of\nextensive, labeled datasets. To circumvent these issues, this paper introduces\na human-in-the-loop workflow for rapidly training building damage assessment\nmodels after a natural disaster. This article details a case study using this\nworkflow, executed in partnership with the American Red Cross during a tornado\nevent in Rolling Fork, Mississippi in March, 2023. The output from our\nhuman-in-the-loop modeling process achieved a precision of 0.86 and recall of\n0.80 for damaged buildings when compared to ground truth data collected\npost-disaster. This workflow was implemented end-to-end in under 2 hours per\nsatellite imagery scene, highlighting its potential for real-time deployment.\n","authors":["Caleb Robinson","Simone Fobi Nsutezo","Anthony Ortiz","Tina Sederholm","Rahul Dodhia","Cameron Birge","Kasie Richards","Kris Pitcher","Paulo Duarte","Juan M. Lavista Ferres"],"pdf_url":"https://arxiv.org/pdf/2306.12589v1.pdf","comment":"In submission to the 2023 ICCV Humanitarian Assistance and Disaster\n  Response Workshop"},{"id":"http://arxiv.org/abs/2306.00684v2","updated":"2023-06-21T21:55:29Z","published":"2023-06-01T13:58:06Z","title":"Balanced Training of Energy-Based Models with Adaptive Flow Sampling","summary":"  Energy-based models (EBMs) are versatile density estimation models that\ndirectly parameterize an unnormalized log density. Although very flexible, EBMs\nlack a specified normalization constant of the model, making the likelihood of\nthe model computationally intractable. Several approximate samplers and\nvariational inference techniques have been proposed to estimate the likelihood\ngradients for training. These techniques have shown promising results in\ngenerating samples, but little attention has been paid to the statistical\naccuracy of the estimated density, such as determining the relative importance\nof different classes in a dataset. In this work, we propose a new maximum\nlikelihood training algorithm for EBMs that uses a different type of generative\nmodel, normalizing flows (NF), which have recently been proposed to facilitate\nsampling. Our method fits an NF to an EBM during training so that an\nNF-assisted sampling scheme provides an accurate gradient for the EBMs at all\ntimes, ultimately leading to a fast sampler for generating new data.\n","authors":["Louis Grenioux","Éric Moulines","Marylou Gabrié"],"pdf_url":"https://arxiv.org/pdf/2306.00684v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12584v1","updated":"2023-06-21T21:50:42Z","published":"2023-06-21T21:50:42Z","title":"Hierarchical Neural Simulation-Based Inference Over Event Ensembles","summary":"  When analyzing real-world data it is common to work with event ensembles,\nwhich comprise sets of observations that collectively constrain the parameters\nof an underlying model of interest. Such models often have a hierarchical\nstructure, where \"local\" parameters impact individual events and \"global\"\nparameters influence the entire dataset. We introduce practical approaches for\noptimal dataset-wide probabilistic inference in cases where the likelihood is\nintractable, but simulations can be realized via forward modeling. We construct\nneural estimators for the likelihood(-ratio) or posterior and show that\nexplicitly accounting for the model's hierarchical structure can lead to\ntighter parameter constraints. We ground our discussion using case studies from\nthe physical sciences, focusing on examples from particle physics (particle\ncollider data) and astrophysics (strong gravitational lensing observations).\n","authors":["Lukas Heinrich","Siddharth Mishra-Sharma","Chris Pollard","Philipp Windischhofer"],"pdf_url":"https://arxiv.org/pdf/2306.12584v1.pdf","comment":"10+4 pages, 5 figures"},{"id":"http://arxiv.org/abs/2306.12582v1","updated":"2023-06-21T21:35:36Z","published":"2023-06-21T21:35:36Z","title":"Adversarial Training with Generated Data in High-Dimensional Regression:\n  An Asymptotic Study","summary":"  In recent years, studies such as\n\\cite{carmon2019unlabeled,gowal2021improving,xing2022artificial} have\ndemonstrated that incorporating additional real or generated data with\npseudo-labels can enhance adversarial training through a two-stage training\napproach. In this paper, we perform a theoretical analysis of the asymptotic\nbehavior of this method in high-dimensional linear regression. While a\ndouble-descent phenomenon can be observed in ridgeless training, with an\nappropriate $\\mathcal{L}_2$ regularization, the two-stage adversarial training\nachieves a better performance. Finally, we derive a shortcut cross-validation\nformula specifically tailored for the two-stage training method.\n","authors":["Yue Xing"],"pdf_url":"https://arxiv.org/pdf/2306.12582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12574v1","updated":"2023-06-21T21:22:38Z","published":"2023-06-21T21:22:38Z","title":"An efficient and straightforward online quantization method for a data\n  stream through remove-birth updating","summary":"  The growth of network-connected devices is creating an explosion of data,\nknown as big data, and posing significant challenges to efficient data\nanalysis. This data is generated continuously, creating a dynamic flow known as\na data stream. The characteristics of a data stream may change dynamically, and\nthis change is known as concept drift. Consequently, a method for handling data\nstreams must efficiently reduce their volume while dynamically adapting to\nthese changing characteristics. This paper proposes a simple online vector\nquantization method for concept drift. The proposed method identifies and\nreplaces units with low win probability through remove-birth updating, thus\nachieving a rapid adaptation to concept drift. Furthermore, the results of this\nstudy show that the proposed method can generate minimal dead units even in the\npresence of concept drift. This study also suggests that some metrics\ncalculated from the proposed method will be helpful for drift detection.\n","authors":["Kazuhisa Fujita"],"pdf_url":"https://arxiv.org/pdf/2306.12574v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03673v3","updated":"2023-06-21T21:15:10Z","published":"2023-02-07T18:47:48Z","title":"Breaking the Curse of Multiagents in a Large State Space: RL in Markov\n  Games with Independent Linear Function Approximation","summary":"  We propose a new model, independent linear Markov game, for multi-agent\nreinforcement learning with a large state space and a large number of agents.\nThis is a class of Markov games with independent linear function approximation,\nwhere each agent has its own function approximation for the state-action value\nfunctions that are marginalized by other players' policies. We design new\nalgorithms for learning the Markov coarse correlated equilibria (CCE) and\nMarkov correlated equilibria (CE) with sample complexity bounds that only scale\npolynomially with each agent's own function class complexity, thus breaking the\ncurse of multiagents. In contrast, existing works for Markov games with\nfunction approximation have sample complexity bounds scale with the size of the\n\\emph{joint action space} when specialized to the canonical tabular Markov game\nsetting, which is exponentially large in the number of agents. Our algorithms\nrely on two key technical innovations: (1) utilizing policy replay to tackle\nnon-stationarity incurred by multiple agents and the use of function\napproximation; (2) separating learning Markov equilibria and exploration in the\nMarkov games, which allows us to use the full-information no-regret learning\noracle instead of the stronger bandit-feedback no-regret learning oracle used\nin the tabular setting. Furthermore, we propose an iterative-best-response type\nalgorithm that can learn pure Markov Nash equilibria in independent linear\nMarkov potential games. In the tabular case, by adapting the policy replay\nmechanism for independent linear Markov games, we propose an algorithm with\n$\\widetilde{O}(\\epsilon^{-2})$ sample complexity to learn Markov CCE, which\nimproves the state-of-the-art result $\\widetilde{O}(\\epsilon^{-3})$ in\nDaskalakis et al. 2022, where $\\epsilon$ is the desired accuracy, and also\nsignificantly improves other problem parameters.\n","authors":["Qiwen Cui","Kaiqing Zhang","Simon S. Du"],"pdf_url":"https://arxiv.org/pdf/2302.03673v3.pdf","comment":"51 pages. Update: Accepted for presentation at the Conference on\n  Learning Theory (COLT) 2023"},{"id":"http://arxiv.org/abs/2208.03264v3","updated":"2023-06-21T20:48:58Z","published":"2022-08-05T16:35:24Z","title":"Towards Antisymmetric Neural Ansatz Separation","summary":"  We study separations between two fundamental models (or \\emph{Ans\\\"atze}) of\nantisymmetric functions, that is, functions $f$ of the form $f(x_{\\sigma(1)},\n\\ldots, x_{\\sigma(N)}) = \\text{sign}(\\sigma)f(x_1, \\ldots, x_N)$, where\n$\\sigma$ is any permutation. These arise in the context of quantum chemistry,\nand are the basic modeling tool for wavefunctions of Fermionic systems.\nSpecifically, we consider two popular antisymmetric Ans\\\"atze: the Slater\nrepresentation, which leverages the alternating structure of determinants, and\nthe Jastrow ansatz, which augments Slater determinants with a product by an\narbitrary symmetric function. We construct an antisymmetric function in $N$\ndimensions that can be efficiently expressed in Jastrow form, yet provably\ncannot be approximated by Slater determinants unless there are exponentially\n(in $N^2$) many terms. This represents the first explicit quantitative\nseparation between these two Ans\\\"atze.\n","authors":["Aaron Zweig","Joan Bruna"],"pdf_url":"https://arxiv.org/pdf/2208.03264v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.09442v2","updated":"2023-06-21T20:48:40Z","published":"2023-06-15T18:49:50Z","title":"Explore, Establish, Exploit: Red Teaming Language Models from Scratch","summary":"  Deploying Large language models (LLMs) can pose hazards from harmful outputs\nsuch as toxic or dishonest speech. Prior work has introduced tools that elicit\nharmful outputs in order to identify and mitigate these risks. While this is a\nvaluable step toward securing language models, these approaches typically rely\non a pre-existing classifier for undesired outputs. This limits their\napplication to situations where the type of harmful behavior is known with\nprecision beforehand. However, this skips a central challenge of red teaming:\ndeveloping a contextual understanding of the behaviors that a model can\nexhibit. Furthermore, when such a classifier already exists, red teaming has\nlimited marginal value because the classifier could simply be used to filter\ntraining data or model outputs. In this work, we consider red teaming under the\nassumption that the adversary is working from a high-level, abstract\nspecification of undesired behavior. The red team is expected to refine/extend\nthis specification and identify methods to elicit this behavior from the model.\nOur red teaming framework consists of three steps: 1) Exploring the model's\nbehavior in the desired context; 2) Establishing a measurement of undesired\nbehavior (e.g., a classifier trained to reflect human evaluations); and 3)\nExploiting the model's flaws using this measure and an established red teaming\nmethodology. We apply this approach to red team GPT-2 and GPT-3 models to\nsystematically discover classes of prompts that elicit toxic and dishonest\nstatements. In doing so, we also construct and release the CommonClaim dataset\nof 20,000 statements that have been labeled by human subjects as\ncommon-knowledge-true, common-knowledge-false, or neither. Code is available at\nhttps://github.com/thestephencasper/explore_establish_exploit_llms. CommonClaim\nis available at https://github.com/Algorithmic-Alignment-Lab/CommonClaim.\n","authors":["Stephen Casper","Jason Lin","Joe Kwon","Gatlen Culp","Dylan Hadfield-Menell"],"pdf_url":"https://arxiv.org/pdf/2306.09442v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12554v1","updated":"2023-06-21T20:47:23Z","published":"2023-06-21T20:47:23Z","title":"Improving Long-Horizon Imitation Through Instruction Prediction","summary":"  Complex, long-horizon planning and its combinatorial nature pose steep\nchallenges for learning-based agents. Difficulties in such settings are\nexacerbated in low data regimes where over-fitting stifles generalization and\ncompounding errors hurt accuracy. In this work, we explore the use of an often\nunused source of auxiliary supervision: language. Inspired by recent advances\nin transformer-based models, we train agents with an instruction prediction\nloss that encourages learning temporally extended representations that operate\nat a high level of abstraction. Concretely, we demonstrate that instruction\nmodeling significantly improves performance in planning environments when\ntraining with a limited number of demonstrations on the BabyAI and Crafter\nbenchmarks. In further analysis we find that instruction modeling is most\nimportant for tasks that require complex reasoning, while understandably\noffering smaller gains in environments that require simple plans. More details\nand code can be found at https://github.com/jhejna/instruction-prediction.\n","authors":["Joey Hejna","Pieter Abbeel","Lerrel Pinto"],"pdf_url":"https://arxiv.org/pdf/2306.12554v1.pdf","comment":"Published at AAAI 2023"},{"id":"http://arxiv.org/abs/2208.12348v2","updated":"2023-06-21T20:35:08Z","published":"2022-08-25T21:20:54Z","title":"SNAP: Efficient Extraction of Private Properties with Poisoning","summary":"  Property inference attacks allow an adversary to extract global properties of\nthe training dataset from a machine learning model. Such attacks have privacy\nimplications for data owners sharing their datasets to train machine learning\nmodels. Several existing approaches for property inference attacks against deep\nneural networks have been proposed, but they all rely on the attacker training\na large number of shadow models, which induces a large computational overhead.\n  In this paper, we consider the setting of property inference attacks in which\nthe attacker can poison a subset of the training dataset and query the trained\ntarget model. Motivated by our theoretical analysis of model confidences under\npoisoning, we design an efficient property inference attack, SNAP, which\nobtains higher attack success and requires lower amounts of poisoning than the\nstate-of-the-art poisoning-based property inference attack by Mahloujifar et\nal. For example, on the Census dataset, SNAP achieves 34% higher success rate\nthan Mahloujifar et al. while being 56.5x faster. We also extend our attack to\ninfer whether a certain property was present at all during training and\nestimate the exact proportion of a property of interest efficiently. We\nevaluate our attack on several properties of varying proportions from four\ndatasets and demonstrate SNAP's generality and effectiveness. An open-source\nimplementation of SNAP can be found at https://github.com/johnmath/snap-sp23.\n","authors":["Harsh Chaudhari","John Abascal","Alina Oprea","Matthew Jagielski","Florian Tramèr","Jonathan Ullman"],"pdf_url":"https://arxiv.org/pdf/2208.12348v2.pdf","comment":"28 pages, 16 figures"},{"id":"http://arxiv.org/abs/2306.12548v1","updated":"2023-06-21T20:21:23Z","published":"2023-06-21T20:21:23Z","title":"Finite-time Lyapunov exponents of deep neural networks","summary":"  We compute how small input perturbations affect the output of deep neural\nnetworks, exploring an analogy between deep networks and dynamical systems,\nwhere the growth or decay of local perturbations is characterised by\nfinite-time Lyapunov exponents. We show that the maximal exponent forms\ngeometrical structures in input space, akin to coherent structures in dynamical\nsystems. Ridges of large positive exponents divide input space into different\nregions that the network associates with different classes. These ridges\nvisualise the geometry that deep networks construct in input space, shedding\nlight on the fundamental mechanisms underlying their learning capabilities.\n","authors":["L. Storm","H. Linander","J. Bec","K. Gustavsson","B. Mehlig"],"pdf_url":"https://arxiv.org/pdf/2306.12548v1.pdf","comment":"6 pages, 4 figures"},{"id":"http://arxiv.org/abs/2306.12545v1","updated":"2023-06-21T20:19:57Z","published":"2023-06-21T20:19:57Z","title":"Neural Multigrid Memory For Computational Fluid Dynamics","summary":"  Turbulent flow simulation plays a crucial role in various applications,\nincluding aircraft and ship design, industrial process optimization, and\nweather prediction. In this paper, we propose an advanced data-driven method\nfor simulating turbulent flow, representing a significant improvement over\nexisting approaches.\n  Our methodology combines the strengths of Video Prediction Transformer (VPTR)\n(Ye & Bilodeau, 2022) and Multigrid Architecture (MgConv, MgResnet) (Ke et al.,\n2017). VPTR excels in capturing complex spatiotemporal dependencies and\nhandling large input data, making it a promising choice for turbulent flow\nprediction. Meanwhile, Multigrid Architecture utilizes multiple grids with\ndifferent resolutions to capture the multiscale nature of turbulent flows,\nresulting in more accurate and efficient simulations.\n  Through our experiments, we demonstrate the effectiveness of our proposed\napproach, named MGxTransformer, in accurately predicting velocity, temperature,\nand turbulence intensity for incompressible turbulent flows across various\ngeometries and flow conditions. Our results exhibit superior accuracy compared\nto other baselines, while maintaining computational efficiency.\n","authors":["Duc Minh Nguyen","Minh Chau Vu","Tuan Anh Nguyen","Tri Huynh","Nguyen Tri Nguyen","Truong Son Hy"],"pdf_url":"https://arxiv.org/pdf/2306.12545v1.pdf","comment":"arXiv admin note: text overlap with arXiv:1911.08655 by other authors"},{"id":"http://arxiv.org/abs/2111.06530v2","updated":"2023-06-21T20:09:59Z","published":"2021-11-12T01:51:50Z","title":"Distributed Sparse Regression via Penalization","summary":"  We study sparse linear regression over a network of agents, modeled as an\nundirected graph (with no centralized node). The estimation problem is\nformulated as the minimization of the sum of the local LASSO loss functions\nplus a quadratic penalty of the consensus constraint -- the latter being\ninstrumental to obtain distributed solution methods. While penalty-based\nconsensus methods have been extensively studied in the optimization literature,\ntheir statistical and computational guarantees in the high dimensional setting\nremain unclear. This work provides an answer to this open problem. Our\ncontribution is two-fold. First, we establish statistical consistency of the\nestimator: under a suitable choice of the penalty parameter, the optimal\nsolution of the penalized problem achieves near optimal minimax rate\n$\\mathcal{O}(s \\log d/N)$ in $\\ell_2$-loss, where $s$ is the sparsity value,\n$d$ is the ambient dimension, and $N$ is the total sample size in the network\n-- this matches centralized sample rates. Second, we show that the\nproximal-gradient algorithm applied to the penalized problem, which naturally\nleads to distributed implementations, converges linearly up to a tolerance of\nthe order of the centralized statistical error -- the rate scales as\n$\\mathcal{O}(d)$, revealing an unavoidable speed-accuracy dilemma.Numerical\nresults demonstrate the tightness of the derived sample rate and convergence\nrate scalings.\n","authors":["Yao Ji","Gesualdo Scutari","Ying Sun","Harsha Honnappa"],"pdf_url":"https://arxiv.org/pdf/2111.06530v2.pdf","comment":"63 pages, journal publication"},{"id":"http://arxiv.org/abs/2303.00028v2","updated":"2023-06-21T20:04:36Z","published":"2023-02-28T19:10:12Z","title":"Efficient Sensor Placement from Regression with Sparse Gaussian\n  Processes in Continuous and Discrete Spaces","summary":"  We present a novel approach based on sparse Gaussian processes (SGPs) to\naddress the sensor placement problem for monitoring spatially (or\nspatiotemporally) correlated phenomena such as temperature and precipitation.\nExisting Gaussian process (GP) based sensor placement approaches use GPs with\nknown kernel function parameters to model a phenomenon and subsequently\noptimize the sensor locations in a discretized representation of the\nenvironment. In our approach, we fit an SGP with known kernel function\nparameters to randomly sampled unlabeled locations in the environment and show\nthat the learned inducing points of the SGP inherently solve the sensor\nplacement problem in continuous spaces. Using SGPs avoids discretizing the\nenvironment and reduces the computation cost from cubic to linear complexity.\nWhen restricted to a candidate set of sensor placement locations, we can use\ngreedy sequential selection algorithms on the SGP's optimization bound to find\ngood solutions. We also present an approach to efficiently map our continuous\nspace solutions to discrete solution spaces using the assignment problem, which\ngives us discrete sensor placements optimized in unison. Moreover, we\ngeneralize our approach to model sensors with non-point field-of-view and\nintegrated observations by leveraging the inherent properties of GPs and SGPs.\nOur experimental results on three real-world datasets show that our approaches\ngenerate solution placements that result in reconstruction quality that is\nconsistently on par or better than the prior state-of-the-art approach while\nbeing significantly faster. Our computationally efficient approaches will\nenable both large-scale sensor placement, and fast sensor placement for\ninformative path planning problems.\n","authors":["Kalvik Jakkala","Srinivas Akella"],"pdf_url":"https://arxiv.org/pdf/2303.00028v2.pdf","comment":"11 pages, 4 figures, preprint, supplementary"},{"id":"http://arxiv.org/abs/2301.11360v2","updated":"2023-06-21T19:56:14Z","published":"2023-01-26T19:17:10Z","title":"The Power of Linear Combinations: Learning with Random Convolutions","summary":"  Following the traditional paradigm of convolutional neural networks (CNNs),\nmodern CNNs manage to keep pace with more recent, for example\ntransformer-based, models by not only increasing model depth and width but also\nthe kernel size. This results in large amounts of learnable model parameters\nthat need to be handled during training. While following the convolutional\nparadigm with the according spatial inductive bias, we question the\nsignificance of \\emph{learned} convolution filters. In fact, our findings\ndemonstrate that many contemporary CNN architectures can achieve high test\naccuracies without ever updating randomly initialized (spatial) convolution\nfilters. Instead, simple linear combinations (implemented through efficient\n$1\\times 1$ convolutions) suffice to effectively recombine even random filters\ninto expressive network operators. Furthermore, these combinations of random\nfilters can implicitly regularize the resulting operations, mitigating\noverfitting and enhancing overall performance and robustness. Conversely,\nretaining the ability to learn filter updates can impair network performance.\nLastly, although we only observe relatively small gains from learning $3\\times\n3$ convolutions, the learning gains increase proportionally with kernel size,\nowing to the non-idealities of the independent and identically distributed\n(\\textit{i.i.d.}) nature of default initialization techniques.\n","authors":["Paul Gavrikov","Janis Keuper"],"pdf_url":"https://arxiv.org/pdf/2301.11360v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12534v1","updated":"2023-06-21T19:48:58Z","published":"2023-06-21T19:48:58Z","title":"Memory-Query Tradeoffs for Randomized Convex Optimization","summary":"  We show that any randomized first-order algorithm which minimizes a\n$d$-dimensional, $1$-Lipschitz convex function over the unit ball must either\nuse $\\Omega(d^{2-\\delta})$ bits of memory or make $\\Omega(d^{1+\\delta/6-o(1)})$\nqueries, for any constant $\\delta\\in (0,1)$ and when the precision $\\epsilon$\nis quasipolynomially small in $d$. Our result implies that cutting plane\nmethods, which use $\\tilde{O}(d^2)$ bits of memory and $\\tilde{O}(d)$ queries,\nare Pareto-optimal among randomized first-order algorithms, and quadratic\nmemory is required to achieve optimal query complexity for convex optimization.\n","authors":["Xi Chen","Binghui Peng"],"pdf_url":"https://arxiv.org/pdf/2306.12534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12517v1","updated":"2023-06-21T19:06:41Z","published":"2023-06-21T19:06:41Z","title":"FFCV: Accelerating Training by Removing Data Bottlenecks","summary":"  We present FFCV, a library for easy and fast machine learning model training.\nFFCV speeds up model training by eliminating (often subtle) data bottlenecks\nfrom the training process. In particular, we combine techniques such as an\nefficient file storage format, caching, data pre-loading, asynchronous data\ntransfer, and just-in-time compilation to (a) make data loading and transfer\nsignificantly more efficient, ensuring that GPUs can reach full utilization;\nand (b) offload as much data processing as possible to the CPU asynchronously,\nfreeing GPU cycles for training. Using FFCV, we train ResNet-18 and ResNet-50\non the ImageNet dataset with competitive tradeoff between accuracy and training\ntime. For example, we are able to train an ImageNet ResNet-50 model to 75\\% in\nonly 20 mins on a single machine. We demonstrate FFCV's performance,\nease-of-use, extensibility, and ability to adapt to resource constraints\nthrough several case studies. Detailed installation instructions,\ndocumentation, and Slack support channel are available at https://ffcv.io/ .\n","authors":["Guillaume Leclerc","Andrew Ilyas","Logan Engstrom","Sung Min Park","Hadi Salman","Aleksander Madry"],"pdf_url":"https://arxiv.org/pdf/2306.12517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12511v1","updated":"2023-06-21T18:49:22Z","published":"2023-06-21T18:49:22Z","title":"Semi-Implicit Denoising Diffusion Models (SIDDMs)","summary":"  Despite the proliferation of generative models, achieving fast sampling\nduring inference without compromising sample diversity and quality remains\nchallenging. Existing models such as Denoising Diffusion Probabilistic Models\n(DDPM) deliver high-quality, diverse samples but are slowed by an inherently\nhigh number of iterative steps. The Denoising Diffusion Generative Adversarial\nNetworks (DDGAN) attempted to circumvent this limitation by integrating a GAN\nmodel for larger jumps in the diffusion process. However, DDGAN encountered\nscalability limitations when applied to large datasets. To address these\nlimitations, we introduce a novel approach that tackles the problem by matching\nimplicit and explicit factors. More specifically, our approach involves\nutilizing an implicit model to match the marginal distributions of noisy data\nand the explicit conditional distribution of the forward diffusion. This\ncombination allows us to effectively match the joint denoising distributions.\nUnlike DDPM but similar to DDGAN, we do not enforce a parametric distribution\nfor the reverse step, enabling us to take large steps during inference. Similar\nto the DDPM but unlike DDGAN, we take advantage of the exact form of the\ndiffusion process. We demonstrate that our proposed method obtains comparable\ngenerative performance to diffusion-based models and vastly superior results to\nmodels with a small number of sampling steps.\n","authors":["Yanwu Xu","Mingming Gong","Shaoan Xie","Wei Wei","Matthias Grundmann","kayhan Batmanghelich","Tingbo Hou"],"pdf_url":"https://arxiv.org/pdf/2306.12511v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12510v1","updated":"2023-06-21T18:49:21Z","published":"2023-06-21T18:49:21Z","title":"Comparative Analysis of Segment Anything Model and U-Net for Breast\n  Tumor Detection in Ultrasound and Mammography Images","summary":"  In this study, the main objective is to develop an algorithm capable of\nidentifying and delineating tumor regions in breast ultrasound (BUS) and\nmammographic images. The technique employs two advanced deep learning\narchitectures, namely U-Net and pretrained SAM, for tumor segmentation. The\nU-Net model is specifically designed for medical image segmentation and\nleverages its deep convolutional neural network framework to extract meaningful\nfeatures from input images. On the other hand, the pretrained SAM architecture\nincorporates a mechanism to capture spatial dependencies and generate\nsegmentation results. Evaluation is conducted on a diverse dataset containing\nannotated tumor regions in BUS and mammographic images, covering both benign\nand malignant tumors. This dataset enables a comprehensive assessment of the\nalgorithm's performance across different tumor types. Results demonstrate that\nthe U-Net model outperforms the pretrained SAM architecture in accurately\nidentifying and segmenting tumor regions in both BUS and mammographic images.\nThe U-Net exhibits superior performance in challenging cases involving\nirregular shapes, indistinct boundaries, and high tumor heterogeneity. In\ncontrast, the pretrained SAM architecture exhibits limitations in accurately\nidentifying tumor areas, particularly for malignant tumors and objects with\nweak boundaries or complex shapes. These findings highlight the importance of\nselecting appropriate deep learning architectures tailored for medical image\nsegmentation. The U-Net model showcases its potential as a robust and accurate\ntool for tumor detection, while the pretrained SAM architecture suggests the\nneed for further improvements to enhance segmentation performance.\n","authors":["Mohsen Ahmadi","Masoumeh Farhadi Nia","Sara Asgarian","Kasra Danesh","Elyas Irankhah","Ahmad Gholizadeh Lonbar","Abbas Sharifi"],"pdf_url":"https://arxiv.org/pdf/2306.12510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12509v1","updated":"2023-06-21T18:45:56Z","published":"2023-06-21T18:45:56Z","title":"Deep Language Networks: Joint Prompt Training of Stacked LLMs using\n  Variational Inference","summary":"  We view large language models (LLMs) as stochastic \\emph{language layers} in\na network, where the learnable parameters are the natural language\n\\emph{prompts} at each layer. We stack two such layers, feeding the output of\none layer to the next. We call the stacked architecture a \\emph{Deep Language\nNetwork} (DLN). We first show how to effectively perform prompt optimization\nfor a 1-Layer language network (DLN-1). We then show how to train 2-layer DLNs\n(DLN-2), where two prompts must be learnt. We consider the output of the first\nlayer as a latent variable to marginalize, and devise a variational inference\nalgorithm for joint prompt training. A DLN-2 reaches higher performance than a\nsingle layer, sometimes comparable to few-shot GPT-4 even when each LLM in the\nnetwork is smaller and less powerful. The DLN code is open source:\nhttps://github.com/microsoft/deep-language-networks .\n","authors":["Alessandro Sordoni","Xingdi Yuan","Marc-Alexandre Côté","Matheus Pereira","Adam Trischler","Ziang Xiao","Arian Hosseini","Friederike Niedtner","Nicolas Le Roux"],"pdf_url":"https://arxiv.org/pdf/2306.12509v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12507v1","updated":"2023-06-21T18:36:15Z","published":"2023-06-21T18:36:15Z","title":"Investigating Poor Performance Regions of Black Boxes: LIME-based\n  Exploration in Sepsis Detection","summary":"  Interpreting machine learning models remains a challenge, hindering their\nadoption in clinical settings. This paper proposes leveraging Local\nInterpretable Model-Agnostic Explanations (LIME) to provide interpretable\ndescriptions of black box classification models in high-stakes sepsis\ndetection. By analyzing misclassified instances, significant features\ncontributing to suboptimal performance are identified. The analysis reveals\nregions where the classifier performs poorly, allowing the calculation of error\nrates within these regions. This knowledge is crucial for cautious\ndecision-making in sepsis detection and other critical applications. The\nproposed approach is demonstrated using the eICU dataset, effectively\nidentifying and visualizing regions where the classifier underperforms. By\nenhancing interpretability, our method promotes the adoption of machine\nlearning models in clinical practice, empowering informed decision-making and\nmitigating risks in critical scenarios.\n","authors":["Mozhgan Salimiparsa","Surajsinh Parmar","San Lee","Choongmin Kim","Yonghwan Kim","Jang Yong Kim"],"pdf_url":"https://arxiv.org/pdf/2306.12507v1.pdf","comment":"Accepted at the 1st World Conference on eXplainable Artificial\n  Intelligence - Late-breaking work, Demos and Doctoral Consortium, 2023"},{"id":"http://arxiv.org/abs/2306.12498v1","updated":"2023-06-21T18:14:44Z","published":"2023-06-21T18:14:44Z","title":"Empirical Risk Minimization with Shuffled SGD: A Primal-Dual Perspective\n  and Improved Bounds","summary":"  Stochastic gradient descent (SGD) is perhaps the most prevalent optimization\nmethod in modern machine learning. Contrary to the empirical practice of\nsampling from the datasets without replacement and with (possible) reshuffling\nat each epoch, the theoretical counterpart of SGD usually relies on the\nassumption of sampling with replacement. It is only very recently that SGD with\nsampling without replacement -- shuffled SGD -- has been analyzed. For convex\nfinite sum problems with $n$ components and under the $L$-smoothness assumption\nfor each component function, there are matching upper and lower bounds, under\nsufficiently small -- $\\mathcal{O}(\\frac{1}{nL})$ -- step sizes. Yet those\nbounds appear too pessimistic -- in fact, the predicted performance is\ngenerally no better than for full gradient descent -- and do not agree with the\nempirical observations. In this work, to narrow the gap between the theory and\npractice of shuffled SGD, we sharpen the focus from general finite sum problems\nto empirical risk minimization with linear predictors. This allows us to take a\nprimal-dual perspective and interpret shuffled SGD as a primal-dual method with\ncyclic coordinate updates on the dual side. Leveraging this perspective, we\nprove a fine-grained complexity bound that depends on the data matrix and is\nnever worse than what is predicted by the existing bounds. Notably, our bound\ncan predict much faster convergence than the existing analyses -- by a factor\nof the order of $\\sqrt{n}$ in some cases. We empirically demonstrate that on\ncommon machine learning datasets our bound is indeed much tighter. We further\nshow how to extend our analysis to convex nonsmooth problems, with similar\nimprovements.\n","authors":["Xufeng Cai","Cheuk Yin Lin","Jelena Diakonikolas"],"pdf_url":"https://arxiv.org/pdf/2306.12498v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12497v1","updated":"2023-06-21T18:12:58Z","published":"2023-06-21T18:12:58Z","title":"Density Uncertainty Layers for Reliable Uncertainty Estimation","summary":"  Assessing the predictive uncertainty of deep neural networks is crucial for\nsafety-related applications of deep learning. Although Bayesian deep learning\noffers a principled framework for estimating model uncertainty, the approaches\nthat are commonly used to approximate the posterior often fail to deliver\nreliable estimates of predictive uncertainty. In this paper we propose a novel\ncriterion for predictive uncertainty, that a model's predictive variance should\nbe grounded in the empirical density of the input. It should produce higher\nuncertainty for inputs that are improbable in the training data and lower\nuncertainty for those inputs that are more probable. To operationalize this\ncriterion, we develop the density uncertainty layer, an architectural element\nfor a stochastic neural network that guarantees that the density uncertain\ncriterion is satisfied. We study neural networks with density uncertainty\nlayers on the CIFAR-10 and CIFAR-100 uncertainty benchmarks. Compared to\nexisting approaches, we find that density uncertainty layers provide reliable\nuncertainty estimates and robust out-of-distribution detection performance.\n","authors":["Yookoon Park","David M. Blei"],"pdf_url":"https://arxiv.org/pdf/2306.12497v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12495v1","updated":"2023-06-21T18:08:55Z","published":"2023-06-21T18:08:55Z","title":"Verifying Global Neural Network Specifications using Hyperproperties","summary":"  Current approaches to neural network verification focus on specifications\nthat target small regions around known input data points, such as local\nrobustness. Thus, using these approaches, we can not obtain guarantees for\ninputs that are not close to known inputs. Yet, it is highly likely that a\nneural network will encounter such truly unseen inputs during its application.\nWe study global specifications that - when satisfied - provide guarantees for\nall potential inputs. We introduce a hyperproperty formalism that allows for\nexpressing global specifications such as monotonicity, Lipschitz continuity,\nglobal robustness, and dependency fairness. Our formalism enables verifying\nglobal specifications using existing neural network verification approaches by\nleveraging capabilities for verifying general computational graphs. Thereby, we\nextend the scope of guarantees that can be provided using existing methods.\nRecent success in verifying specific global specifications shows that attaining\nstrong guarantees for all potential data points is feasible.\n","authors":["David Boetius","Stefan Leue"],"pdf_url":"https://arxiv.org/pdf/2306.12495v1.pdf","comment":"10 pages, 2 figures. Accepted at FoMLAS 2023"}],"Multimedia":[{"id":"http://arxiv.org/abs/2306.12249v1","updated":"2023-06-21T13:12:12Z","published":"2023-06-21T13:12:12Z","title":"Knowledge-based Multimodal Music Similarity","summary":"  Music similarity is an essential aspect of music retrieval, recommendation\nsystems, and music analysis. Moreover, similarity is of vital interest for\nmusic experts, as it allows studying analogies and influences among composers\nand historical periods. Current approaches to musical similarity rely mainly on\nsymbolic content, which can be expensive to produce and is not always readily\navailable. Conversely, approaches using audio signals typically fail to provide\nany insight about the reasons behind the observed similarity. This research\naddresses the limitations of current approaches by focusing on the study of\nmusical similarity using both symbolic and audio content. The aim of this\nresearch is to develop a fully explainable and interpretable system that can\nprovide end-users with more control and understanding of music similarity and\nclassification systems.\n","authors":["Andrea Poltronieri"],"pdf_url":"https://arxiv.org/pdf/2306.12249v1.pdf","comment":"11 pages, 1 figure"},{"id":"http://arxiv.org/abs/2305.15905v2","updated":"2023-06-21T12:34:57Z","published":"2023-05-25T10:12:46Z","title":"Latent Diffusion Model Based Foley Sound Generation System For DCASE\n  Challenge 2023 Task 7","summary":"  Foley sound presents the background sound for multimedia content and the\ngeneration of Foley sound involves computationally modelling sound effects with\nspecialized techniques. In this work, we proposed a system for DCASE 2023\nchallenge task 7: Foley Sound Synthesis. The proposed system is based on\nAudioLDM, which is a diffusion-based text-to-audio generation model. To\nalleviate the data-hungry problem, the system first trained with large-scale\ndatasets and then downstreamed into this DCASE task via transfer learning.\nThrough experiments, we found out that the feature extracted by the encoder can\nsignificantly affect the performance of the generation model. Hence, we improve\nthe results by leveraging the input label with related text embedding features\nobtained by a significant language model, i.e., contrastive language-audio\npertaining (CLAP). In addition, we utilize a filtering strategy to further\nrefine the output, i.e. by selecting the best results from the candidate clips\ngenerated in terms of the similarity score between the sound and target labels.\nThe overall system achieves a Frechet audio distance (FAD) score of 4.765 on\naverage among all seven different classes, substantially outperforming the\nbaseline system which performs a FAD score of 9.7.\n","authors":["Yi Yuan","Haohe Liu","Xubo Liu","Xiyuan Kang","Mark D. Plumbley","Wenwu Wang"],"pdf_url":"https://arxiv.org/pdf/2305.15905v2.pdf","comment":"DCASE 2023 task 7 technical report, ranked 1st in the challenge"},{"id":"http://arxiv.org/abs/2210.02437v2","updated":"2023-06-21T01:00:52Z","published":"2022-10-05T17:57:29Z","title":"ASVspoof 2021: Towards Spoofed and Deepfake Speech Detection in the Wild","summary":"  Benchmarking initiatives support the meaningful comparison of competing\nsolutions to prominent problems in speech and language processing. Successive\nbenchmarking evaluations typically reflect a progressive evolution from ideal\nlab conditions towards to those encountered in the wild. ASVspoof, the spoofing\nand deepfake detection initiative and challenge series, has followed the same\ntrend. This article provides a summary of the ASVspoof 2021 challenge and the\nresults of 54 participating teams that submitted to the evaluation phase. For\nthe logical access (LA) task, results indicate that countermeasures are robust\nto newly introduced encoding and transmission effects. Results for the physical\naccess (PA) task indicate the potential to detect replay attacks in real, as\nopposed to simulated physical spaces, but a lack of robustness to variations\nbetween simulated and real acoustic environments. The Deepfake (DF) task, new\nto the 2021 edition, targets solutions to the detection of manipulated,\ncompressed speech data posted online. While detection solutions offer some\nresilience to compression effects, they lack generalization across different\nsource datasets. In addition to a summary of the top-performing systems for\neach task, new analyses of influential data factors and results for hidden data\nsubsets, the article includes a review of post-challenge results, an outline of\nthe principal challenge limitations and a road-map for the future of ASVspoof.\n","authors":["Xuechen Liu","Xin Wang","Md Sahidullah","Jose Patino","Héctor Delgado","Tomi Kinnunen","Massimiliano Todisco","Junichi Yamagishi","Nicholas Evans","Andreas Nautsch","Kong Aik Lee"],"pdf_url":"https://arxiv.org/pdf/2210.02437v2.pdf","comment":"IEEE/ACM Transactions on Audio, Speech, and Language Processing (doi\n  updated)"}]},"2023-06-22T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2306.09896v3","updated":"2023-06-22T17:55:21Z","published":"2023-06-16T15:13:17Z","title":"Demystifying GPT Self-Repair for Code Generation","summary":"  Large Language Models (LLMs) have shown remarkable aptitude in code\ngeneration but still struggle on challenging programming tasks. Self-repair --\nin which the model debugs and fixes mistakes in its own code -- has recently\nbecome a popular way to boost performance in these settings. However, only very\nlimited studies on how and when self-repair works effectively exist in the\nliterature, and one might wonder to what extent a model is really capable of\nproviding accurate feedback on why the code is wrong when that code was\ngenerated by the same model. In this paper, we analyze GPT-3.5 and GPT-4's\nability to perform self-repair on APPS, a challenging dataset consisting of\ndiverse coding challenges. To do so, we first establish a new evaluation\nstrategy dubbed pass@t that measures the pass rate of the tasks against the\ntotal number of tokens sampled from the model, enabling a fair comparison to\npurely sampling-based approaches. With this evaluation strategy, we find that\nthe effectiveness of self-repair is only seen in GPT-4. We also observe that\nself-repair is bottlenecked by the feedback stage; using GPT-4 to give feedback\non the programs generated by GPT-3.5 and using expert human programmers to give\nfeedback on the programs generated by GPT-4, we unlock significant performance\ngains.\n","authors":["Theo X. Olausson","Jeevana Priya Inala","Chenglong Wang","Jianfeng Gao","Armando Solar-Lezama"],"pdf_url":"https://arxiv.org/pdf/2306.09896v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13075v1","updated":"2023-06-22T17:47:42Z","published":"2023-06-22T17:47:42Z","title":"Semi-automated extraction of research topics and trends from NCI funding\n  in radiological sciences from 2000-2020","summary":"  Investigators, funders, and the public desire knowledge on topics and trends\nin publicly funded research but current efforts in manual categorization are\nlimited in scale and understanding. We developed a semi-automated approach to\nextract and name research topics, and applied this to \\$1.9B of NCI funding\nover 21 years in the radiological sciences to determine micro- and macro-scale\nresearch topics and funding trends. Our method relies on sequential clustering\nof existing biomedical-based word embeddings, naming using subject matter\nexperts, and visualization to discover trends at a macroscopic scale above\nindividual topics. We present results using 15 and 60 cluster topics, where we\nfound that 2D projection of grant embeddings reveals two dominant axes:\nphysics-biology and therapeutic-diagnostic. For our dataset, we found that\nfunding for therapeutics- and physics-based research have outpaced diagnostics-\nand biology-based research, respectively. We hope these results may (1) give\ninsight to funders on the appropriateness of their funding allocation, (2)\nassist investigators in contextualizing their work and explore neighboring\nresearch domains, and (3) allow the public to review where their tax dollars\nare being allocated.\n","authors":["Mark Nguyen","Peter Beidler","Joseph Tsai","August Anderson","Daniel Chen","Paul Kinahan","John Kang"],"pdf_url":"https://arxiv.org/pdf/2306.13075v1.pdf","comment":"Presented at the American Society of Radiation Oncology annual\n  meeting in 2021 ((doi: 10.1016/j.ijrobp.2021.07.263) and the Practical Big\n  Data Workshop 2022"},{"id":"http://arxiv.org/abs/2306.13063v1","updated":"2023-06-22T17:31:44Z","published":"2023-06-22T17:31:44Z","title":"Can LLMs Express Their Uncertainty? An Empirical Evaluation of\n  Confidence Elicitation in LLMs","summary":"  The task of empowering large language models (LLMs) to accurately express\ntheir confidence, referred to as confidence elicitation, is essential in\nensuring reliable and trustworthy decision-making processes. Previous methods,\nwhich primarily rely on model logits, have become less suitable for LLMs and\neven infeasible with the rise of closed-source LLMs (e.g., commercialized LLM\nAPIs). This leads to a growing need to explore the untapped area of\n\\emph{non-logit-based} approaches to estimate the uncertainty of LLMs. Hence,\nin this study, we investigate approaches for confidence elicitation that do not\nrequire model fine-tuning or access to proprietary information. We introduce\nthree categories of methods: verbalize-based, consistency-based, and their\nhybrid methods for benchmarking, and evaluate their performance across five\ntypes of datasets and four widely-used LLMs. Our analysis of these methods\nuncovers several key insights: 1) LLMs often exhibit a high degree of\noverconfidence when verbalizing their confidence; 2) Prompting strategies such\nas CoT, Top-K and Multi-step confidences improve calibration of verbalized\nconfidence; 3) Consistency-based methods outperform the verbalized confidences\nin most cases, with particularly notable improvements on the arithmetic\nreasoning task; 4) Hybrid methods consistently deliver the best performance\nover their baselines, thereby emerging as a promising state-of-the-art\napproach; 5) Despite these advancements, all investigated methods continue to\nstruggle with challenging tasks, such as those requiring professional\nknowledge, leaving significant scope for improvement of confidence elicitation.\n","authors":["Miao Xiong","Zhiyuan Hu","Xinyang Lu","Yifei Li","Jie Fu","Junxian He","Bryan Hooi"],"pdf_url":"https://arxiv.org/pdf/2306.13063v1.pdf","comment":"11 Pages"},{"id":"http://arxiv.org/abs/2306.13062v1","updated":"2023-06-22T17:30:37Z","published":"2023-06-22T17:30:37Z","title":"Named entity recognition in resumes","summary":"  Named entity recognition (NER) is used to extract information from various\ndocuments and texts such as names and dates. It is important to extract\neducation and work experience information from resumes in order to filter them.\nConsidering the fact that all information in a resume has to be entered to the\ncompanys system manually, automatizing this process will save time of the\ncompanies. In this study, a deep learning-based semi-automatic named entity\nrecognition system has been implemented with a focus on resumes in the field of\nIT. Firstly, resumes of employees from five different IT related fields has\nbeen annotated. Six transformer based pre-trained models have been adapted to\nnamed entity recognition problem using the annotated data. These models have\nbeen selected among popular models in the natural language processing field.\nThe obtained system can recognize eight different entity types which are city,\ndate, degree, diploma major, job title, language, country and skill. Models\nused in the experiments are compared using micro, macro and weighted F1 scores\nand the performance of the methods was evaluated. Taking these scores into\naccount for test set the best micro and weighted F1 score is obtained by\nRoBERTa and the best macro F1 score is obtained by Electra model.\n","authors":["Ege Kesim","Aysu Deliahmetoglu"],"pdf_url":"https://arxiv.org/pdf/2306.13062v1.pdf","comment":"in Turkish language"},{"id":"http://arxiv.org/abs/2306.13047v1","updated":"2023-06-22T17:13:08Z","published":"2023-06-22T17:13:08Z","title":"CamChoice: A Corpus of Multiple Choice Questions and Candidate Response\n  Distributions","summary":"  Multiple Choice examinations are a ubiquitous form of assessment that is used\nto measure the ability of candidates across various domains and tasks.\nMaintaining the quality of proposed questions is of great importance to test\ndesigners, and therefore newly proposed questions go through several pre-test\nevaluation stages before they can be deployed into real-world exams. This\nprocess is currently quite manual, which can lead to time lags in the question\ndevelopment cycle. Automating this process would lead to a large improvement in\nefficiency, however, current datasets do not contain sufficient pre-test\nanalysis information. In this paper, we introduce CamChoice; a multiple-choice\ncomprehension dataset with questions at different target levels, where\nquestions have the true candidate selected options distributions. We introduce\nthe task of candidate distribution matching, propose several evaluation metrics\nfor the task, and demonstrate that automatic systems trained on RACE++ can be\nleveraged as baselines for our task. We further demonstrate that these\nautomatic systems can be used for practical pre-test evaluation tasks such as\ndetecting underperforming distractors, where our detection systems can\nautomatically identify poor distractors that few candidates select. We release\nthe data publicly for future research.\n","authors":["Adian Liusie","Vatsal Raina","Andrew Mullooly","Kate Knill","Mark J. F. Gales"],"pdf_url":"https://arxiv.org/pdf/2306.13047v1.pdf","comment":"9 pages, 6 figures, 7 tables"},{"id":"http://arxiv.org/abs/2306.13041v1","updated":"2023-06-22T17:07:57Z","published":"2023-06-22T17:07:57Z","title":"Towards Explainable Evaluation Metrics for Machine Translation","summary":"  Unlike classical lexical overlap metrics such as BLEU, most current\nevaluation metrics for machine translation (for example, COMET or BERTScore)\nare based on black-box large language models. They often achieve strong\ncorrelations with human judgments, but recent research indicates that the\nlower-quality classical metrics remain dominant, one of the potential reasons\nbeing that their decision processes are more transparent. To foster more\nwidespread acceptance of novel high-quality metrics, explainability thus\nbecomes crucial. In this concept paper, we identify key properties as well as\nkey goals of explainable machine translation metrics and provide a\ncomprehensive synthesis of recent techniques, relating them to our established\ngoals and properties. In this context, we also discuss the latest\nstate-of-the-art approaches to explainable metrics based on generative models\nsuch as ChatGPT and GPT4. Finally, we contribute a vision of next-generation\napproaches, including natural language explanations. We hope that our work can\nhelp catalyze and guide future research on explainable evaluation metrics and,\nmediately, also contribute to better and more transparent machine translation\nsystems.\n","authors":["Christoph Leiter","Piyawat Lertvittayakumjorn","Marina Fomicheva","Wei Zhao","Yang Gao","Steffen Eger"],"pdf_url":"https://arxiv.org/pdf/2306.13041v1.pdf","comment":"Preprint. We published an earlier version of this paper\n  (arXiv:2203.11131) under a different title. Both versions consider the\n  conceptualization of explainable metrics and are overall similar. However,\n  the new version puts a stronger emphasis on the survey of approaches for the\n  explanation of MT metrics including the latest LLM based approaches"},{"id":"http://arxiv.org/abs/2207.00221v2","updated":"2023-06-22T16:55:44Z","published":"2022-07-01T06:25:53Z","title":"VL-CheckList: Evaluating Pre-trained Vision-Language Models with\n  Objects, Attributes and Relations","summary":"  Vision-Language Pretraining (VLP) models have recently successfully\nfacilitated many cross-modal downstream tasks. Most existing works evaluated\ntheir systems by comparing the fine-tuned downstream task performance. However,\nonly average downstream task accuracy provides little information about the\npros and cons of each VLP method, let alone provides insights on how the\ncommunity can improve the systems in the future. Inspired by the CheckList for\ntesting natural language processing, we exploit VL-CheckList, a novel framework\nto understand the capabilities of VLP models. The proposed method divides the\nimage-texting ability of a VLP model into three categories: objects,\nattributes, and relations, and uses a novel taxonomy to further break down\nthese three aspects. We conduct comprehensive studies to analyze seven recently\npopular VLP models via the proposed framework. Results confirm the\neffectiveness of the proposed method by revealing fine-grained differences\namong the compared models that were not visible from downstream task-only\nevaluation. Further results show promising research direction in building\nbetter VLP models. Our data and code are available at:\nhttps://github.com/om-ai-lab/VL-CheckList.\n","authors":["Tiancheng Zhao","Tianqi Zhang","Mingwei Zhu","Haozhan Shen","Kyusong Lee","Xiaopeng Lu","Jianwei Yin"],"pdf_url":"https://arxiv.org/pdf/2207.00221v2.pdf","comment":"9 pages, preprint"},{"id":"http://arxiv.org/abs/2306.13000v1","updated":"2023-06-22T15:56:50Z","published":"2023-06-22T15:56:50Z","title":"Apolitical Intelligence? Auditing Delphi's responses on controversial\n  political issues in the US","summary":"  As generative language models are deployed in ever-wider contexts, concerns\nabout their political values have come to the forefront with critique from all\nparts of the political spectrum that the models are biased and lack neutrality.\nHowever, the question of what neutrality is and whether it is desirable remains\nunderexplored. In this paper, I examine neutrality through an audit of Delphi\n[arXiv:2110.07574], a large language model designed for crowdsourced ethics. I\nanalyse how Delphi responds to politically controversial questions compared to\ndifferent US political subgroups. I find that Delphi is poorly calibrated with\nrespect to confidence and exhibits a significant political skew. Based on these\nresults, I examine the question of neutrality from a data-feminist lens, in\nterms of how notions of neutrality shift power and further marginalise unheard\nvoices. These findings can hopefully contribute to a more reflexive debate\nabout the normative questions of alignment and what role we want generative\nmodels to play in society.\n","authors":["Jonathan H. Rystrøm"],"pdf_url":"https://arxiv.org/pdf/2306.13000v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12991v1","updated":"2023-06-22T15:47:36Z","published":"2023-06-22T15:47:36Z","title":"Speech Emotion Diarization: Which Emotion Appears When?","summary":"  Speech Emotion Recognition (SER) typically relies on utterance-level\nsolutions. However, emotions conveyed through speech should be considered as\ndiscrete speech events with definite temporal boundaries, rather than\nattributes of the entire utterance. To reflect the fine-grained nature of\nspeech emotions, we propose a new task: Speech Emotion Diarization (SED). Just\nas Speaker Diarization answers the question of \"Who speaks when?\", Speech\nEmotion Diarization answers the question of \"Which emotion appears when?\". To\nfacilitate the evaluation of the performance and establish a common benchmark\nfor researchers, we introduce the Zaion Emotion Dataset (ZED), an openly\naccessible speech emotion dataset that includes non-acted emotions recorded in\nreal-life conditions, along with manually-annotated boundaries of emotion\nsegments within the utterance. We provide competitive baselines and open-source\nthe code and the pre-trained models.\n","authors":["Yingzhi Wang","Mirco Ravanelli","Alaa Nfissi","Alya Yacoubi"],"pdf_url":"https://arxiv.org/pdf/2306.12991v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12982v1","updated":"2023-06-22T15:40:59Z","published":"2023-06-22T15:40:59Z","title":"Conversation Derailment Forecasting with Graph Convolutional Networks","summary":"  Online conversations are particularly susceptible to derailment, which can\nmanifest itself in the form of toxic communication patterns like disrespectful\ncomments or verbal abuse. Forecasting conversation derailment predicts signs of\nderailment in advance enabling proactive moderation of conversations. Current\nstate-of-the-art approaches to address this problem rely on sequence models\nthat treat dialogues as text streams. We propose a novel model based on a graph\nconvolutional neural network that considers dialogue user dynamics and the\ninfluence of public perception on conversation utterances. Through empirical\nevaluation, we show that our model effectively captures conversation dynamics\nand outperforms the state-of-the-art models on the CGA and CMV benchmark\ndatasets by 1.5\\% and 1.7\\%, respectively.\n","authors":["Enas Altarawneh","Ammeta Agrawal","Michael Jenkin","Manos Papagelis"],"pdf_url":"https://arxiv.org/pdf/2306.12982v1.pdf","comment":"WOAH, ACL"},{"id":"http://arxiv.org/abs/2306.12951v1","updated":"2023-06-22T15:10:18Z","published":"2023-06-22T15:10:18Z","title":"Tracking public attitudes toward ChatGPT on Twitter using sentiment\n  analysis and topic modeling","summary":"  ChatGPT sets a new record with the fastest-growing user base, as a chatbot\npowered by a large language model (LLM). While it demonstrates state-of-the-art\ncapabilities in a variety of language-generating tasks, it also raises\nwidespread public concerns regarding its societal impact. In this paper, we\nutilize natural language processing approaches to investigate the public\nattitudes towards ChatGPT by applying sentiment analysis and topic modeling\ntechniques to Twitter data. Our result shows that the overall sentiment is\nlargely neutral to positive, which also holds true across different occupation\ngroups. Among a wide range of topics mentioned in tweets, the most popular\ntopics are Artificial Intelligence, Search Engines, Education, Writing, and\nQuestion Answering.\n","authors":["Ratanond Koonchanok","Yanling Pan","Hyeju Jang"],"pdf_url":"https://arxiv.org/pdf/2306.12951v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.04118v2","updated":"2023-06-22T15:05:16Z","published":"2023-05-06T19:03:12Z","title":"Exploring Human-Like Translation Strategy with Large Language Models","summary":"  Large language models (LLMs) have demonstrated impressive capabilities in\ngeneral scenarios, exhibiting a level of aptitude that approaches, in some\naspects even surpasses, human-level intelligence. Among their numerous skills,\nthe translation abilities of LLMs have received considerable attention. In\ncontrast to traditional machine translation that focuses solely on\nsource-target mapping, LLM-based translation can potentially mimic the human\ntranslation process that takes many preparatory steps to ensure high-quality\ntranslation. This work aims to explore this possibility by proposing the MAPS\nframework, which stands for Multi-Aspect Prompting and Selection. Specifically,\nwe enable LLMs to first analyze the given source text and extract three aspects\nof translation-related knowledge: keywords, topics and relevant demonstrations\nto guide the translation process. To filter out the noisy and unhelpful\nknowledge, we employ a selection mechanism based on quality estimation.\nExperiments suggest that MAPS brings significant and consistent improvements\nover text-davinci-003 and Alpaca on eight translation directions from the\nlatest WMT22 test sets. Our further analysis shows that the extracted knowledge\nis critical in resolving up to 59% of hallucination mistakes in translation.\nCode is available at https://github.com/zwhe99/MAPS-mt.\n","authors":["Zhiwei He","Tian Liang","Wenxiang Jiao","Zhuosheng Zhang","Yujiu Yang","Rui Wang","Zhaopeng Tu","Shuming Shi","Xing Wang"],"pdf_url":"https://arxiv.org/pdf/2305.04118v2.pdf","comment":"V2: add more experiments and case studies; polish writing"},{"id":"http://arxiv.org/abs/2306.12929v1","updated":"2023-06-22T14:39:04Z","published":"2023-06-22T14:39:04Z","title":"Quantizable Transformers: Removing Outliers by Helping Attention Heads\n  Do Nothing","summary":"  Transformer models have been widely adopted in various domains over the last\nyears, and especially large language models have advanced the field of AI\nsignificantly. Due to their size, the capability of these networks has\nincreased tremendously, but this has come at the cost of a significant increase\nin necessary compute. Quantization is one of the most effective ways to reduce\nthe computational time and memory consumption of neural networks. Many studies\nhave shown, however, that modern transformer models tend to learn strong\noutliers in their activations, making them difficult to quantize. To retain\nacceptable performance, the existence of these outliers requires activations to\nbe in higher bitwidth or the use of different numeric formats, extra\nfine-tuning, or other workarounds. We show that strong outliers are related to\nvery specific behavior of attention heads that try to learn a \"no-op\" or just a\npartial update of the residual. To achieve the exact zeros needed in the\nattention matrix for a no-update, the input to the softmax is pushed to be\nlarger and larger during training, causing outliers in other parts of the\nnetwork. Based on these observations, we propose two simple (independent)\nmodifications to the attention mechanism - clipped softmax and gated attention.\nWe empirically show that models pre-trained using our methods learn\nsignificantly smaller outliers while maintaining and sometimes even improving\nthe floating-point task performance. This enables us to quantize transformers\nto full INT8 quantization of the activations without any additional effort. We\ndemonstrate the effectiveness of our methods on both language models (BERT,\nOPT) and vision transformers.\n","authors":["Yelysei Bondarenko","Markus Nagel","Tijmen Blankevoort"],"pdf_url":"https://arxiv.org/pdf/2306.12929v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12925v1","updated":"2023-06-22T14:37:54Z","published":"2023-06-22T14:37:54Z","title":"AudioPaLM: A Large Language Model That Can Speak and Listen","summary":"  We introduce AudioPaLM, a large language model for speech understanding and\ngeneration. AudioPaLM fuses text-based and speech-based language models, PaLM-2\n[Anil et al., 2023] and AudioLM [Borsos et al., 2022], into a unified\nmultimodal architecture that can process and generate text and speech with\napplications including speech recognition and speech-to-speech translation.\nAudioPaLM inherits the capability to preserve paralinguistic information such\nas speaker identity and intonation from AudioLM and the linguistic knowledge\npresent only in text large language models such as PaLM-2. We demonstrate that\ninitializing AudioPaLM with the weights of a text-only large language model\nimproves speech processing, successfully leveraging the larger quantity of text\ntraining data used in pretraining to assist with the speech tasks. The\nresulting model significantly outperforms existing systems for speech\ntranslation tasks and has the ability to perform zero-shot speech-to-text\ntranslation for many languages for which input/target language combinations\nwere not seen in training. AudioPaLM also demonstrates features of audio\nlanguage models, such as transferring a voice across languages based on a short\nspoken prompt. We release examples of our method at\nhttps://google-research.github.io/seanet/audiopalm/examples\n","authors":["Paul K. Rubenstein","Chulayuth Asawaroengchai","Duc Dung Nguyen","Ankur Bapna","Zalán Borsos","Félix de Chaumont Quitry","Peter Chen","Dalia El Badawy","Wei Han","Eugene Kharitonov","Hannah Muckenhirn","Dirk Padfield","James Qin","Danny Rozenberg","Tara Sainath","Johan Schalkwyk","Matt Sharifi","Michelle Tadmor Ramanovich","Marco Tagliasacchi","Alexandru Tudor","Mihajlo Velimirović","Damien Vincent","Jiahui Yu","Yongqiang Wang","Vicky Zayats","Neil Zeghidour","Yu Zhang","Zhishuai Zhang","Lukas Zilka","Christian Frank"],"pdf_url":"https://arxiv.org/pdf/2306.12925v1.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2306.12916v1","updated":"2023-06-22T14:31:18Z","published":"2023-06-22T14:31:18Z","title":"Cross-lingual Cross-temporal Summarization: Dataset, Models, Evaluation","summary":"  While summarization has been extensively researched in natural language\nprocessing (NLP), cross-lingual cross-temporal summarization (CLCTS) is a\nlargely unexplored area that has the potential to improve cross-cultural\naccessibility, information sharing, and understanding. This paper\ncomprehensively addresses the CLCTS task, including dataset creation, modeling,\nand evaluation. We build the first CLCTS corpus, leveraging historical fictive\ntexts and Wikipedia summaries in English and German, and examine the\neffectiveness of popular transformer end-to-end models with different\nintermediate task finetuning tasks. Additionally, we explore the potential of\nChatGPT for CLCTS as a summarizer and an evaluator. Overall, we report\nevaluations from humans, ChatGPT, and several recent automatic evaluation\nmetrics where we find our intermediate task finetuned end-to-end models\ngenerate bad to moderate quality summaries; ChatGPT as a summarizer (without\nany finetuning) provides moderate to good quality outputs and as an evaluator\ncorrelates moderately with human evaluations though it is prone to giving lower\nscores. ChatGPT also seems to be very adept at normalizing historical text. We\nfinally test ChatGPT in a scenario with adversarially attacked and unseen\nsource documents and find that ChatGPT is better at omission and entity swap\nthan negating against its prior knowledge.\n","authors":["Ran Zhang","Jihed Ouni","Steffen Eger"],"pdf_url":"https://arxiv.org/pdf/2306.12916v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2306.12913v1","updated":"2023-06-22T14:29:53Z","published":"2023-06-22T14:29:53Z","title":"Implicit spoken language diarization","summary":"  Spoken language diarization (LD) and related tasks are mostly explored using\nthe phonotactic approach. Phonotactic approaches mostly use explicit way of\nlanguage modeling, hence requiring intermediate phoneme modeling and\ntranscribed data. Alternatively, the ability of deep learning approaches to\nmodel temporal dynamics may help for the implicit modeling of language\ninformation through deep embedding vectors. Hence this work initially explores\nthe available speaker diarization frameworks that capture speaker information\nimplicitly to perform LD tasks. The performance of the LD system on synthetic\ncode-switch data using the end-to-end x-vector approach is 6.78% and 7.06%, and\nfor practical data is 22.50% and 60.38%, in terms of diarization error rate and\nJaccard error rate (JER), respectively. The performance degradation is due to\nthe data imbalance and resolved to some extent by using pre-trained wave2vec\nembeddings that provide a relative improvement of 30.74% in terms of JER.\n","authors":["Jagabandhu Mishra","Amartya Chowdhury","S. R. Mahadeva Prasanna"],"pdf_url":"https://arxiv.org/pdf/2306.12913v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12907v1","updated":"2023-06-22T14:20:15Z","published":"2023-06-22T14:20:15Z","title":"xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource\n  Languages","summary":"  We introduce a new proxy score for evaluating bitext mining based on\nsimilarity in a multilingual embedding space: xSIM++. In comparison to xSIM,\nthis improved proxy leverages rule-based approaches to extend English sentences\nin any evaluation set with synthetic, hard-to-distinguish examples which more\nclosely mirror the scenarios we encounter during large-scale mining. We\nvalidate this proxy by running a significant number of bitext mining\nexperiments for a set of low-resource languages, and subsequently train NMT\nsystems on the mined data. In comparison to xSIM, we show that xSIM++ is better\ncorrelated with the downstream BLEU scores of translation systems trained on\nmined bitexts, providing a reliable proxy of bitext mining performance without\nneeding to run expensive bitext mining pipelines. xSIM++ also reports\nperformance for different error types, offering more fine-grained feedback for\nmodel development.\n","authors":["Mingda Chen","Kevin Heffernan","Onur Çelebi","Alex Mourachko","Holger Schwenk"],"pdf_url":"https://arxiv.org/pdf/2306.12907v1.pdf","comment":"The first two authors contributed equally; ACL 2023 short; Code and\n  data are available at https://github.com/facebookresearch/LASER"},{"id":"http://arxiv.org/abs/2305.03423v2","updated":"2023-06-22T14:09:56Z","published":"2023-05-05T10:39:32Z","title":"Using ChatGPT for Entity Matching","summary":"  Entity Matching is the task of deciding if two entity descriptions refer to\nthe same real-world entity. State-of-the-art entity matching methods often rely\non fine-tuning Transformer models such as BERT or RoBERTa. Two major drawbacks\nof using these models for entity matching are that (i) the models require\nsignificant amounts of fine-tuning data for reaching a good performance and\n(ii) the fine-tuned models are not robust concerning out-of-distribution\nentities. In this paper, we investigate using ChatGPT for entity matching as a\nmore robust, training data-efficient alternative to traditional Transformer\nmodels. We perform experiments along three dimensions: (i) general prompt\ndesign, (ii) in-context learning, and (iii) provision of higher-level matching\nknowledge. We show that ChatGPT is competitive with a fine-tuned RoBERTa model,\nreaching a zero-shot performance of 82.35% F1 on a challenging matching task on\nwhich RoBERTa requires 2000 training examples for reaching a similar\nperformance. Adding in-context demonstrations to the prompts further improves\nthe F1 by up to 7.85% when using similarity-based example selection. Always\nusing the same set of 10 handpicked demonstrations leads to an improvement of\n4.92% over the zero-shot performance. Finally, we show that ChatGPT can also be\nguided by adding higher-level matching knowledge in the form of rules to the\nprompts. Providing matching rules leads to similar performance gains as\nproviding in-context demonstrations.\n","authors":["Ralph Peeters","Christian Bizer"],"pdf_url":"https://arxiv.org/pdf/2305.03423v2.pdf","comment":"Accepted and to be published in Proceedings of ADBIS 2023 as short\n  paper (https://www.essi.upc.edu/dtim/ADBIS2023/index.html)"},{"id":"http://arxiv.org/abs/2306.12886v1","updated":"2023-06-22T13:52:31Z","published":"2023-06-22T13:52:31Z","title":"Unveiling Global Narratives: A Multilingual Twitter Dataset of News\n  Media on the Russo-Ukrainian Conflict","summary":"  The ongoing Russo-Ukrainian conflict has been a subject of intense media\ncoverage worldwide. Understanding the global narrative surrounding this topic\nis crucial for researchers that aim to gain insights into its multifaceted\ndimensions. In this paper, we present a novel dataset that focuses on this\ntopic by collecting and processing tweets posted by news or media companies on\nsocial media across the globe. We collected tweets from February 2022 to May\n2023 to acquire approximately 1.5 million tweets in 60 different languages.\nEach tweet in the dataset is accompanied by processed tags, allowing for the\nidentification of entities, stances, concepts, and sentiments expressed. The\navailability of the dataset serves as a valuable resource for researchers\naiming to investigate the global narrative surrounding the ongoing conflict\nfrom various aspects such as who are the prominent entities involved, what\nstances are taken, where do these stances originate, and how are the different\nconcepts related to the event portrayed.\n","authors":["Sherzod Hakimov","Gullal S. Cheema"],"pdf_url":"https://arxiv.org/pdf/2306.12886v1.pdf","comment":"Dataset can be found at https://zenodo.org/record/8043459"},{"id":"http://arxiv.org/abs/2205.12593v2","updated":"2023-06-22T13:05:57Z","published":"2022-05-25T09:08:35Z","title":"Less Learn Shortcut: Analyzing and Mitigating Learning of Spurious\n  Feature-Label Correlation","summary":"  Recent research has revealed that deep neural networks often take dataset\nbiases as a shortcut to make decisions rather than understand tasks, leading to\nfailures in real-world applications. In this study, we focus on the spurious\ncorrelation between word features and labels that models learn from the biased\ndata distribution of training data. In particular, we define the word highly\nco-occurring with a specific label as biased word, and the example containing\nbiased word as biased example. Our analysis shows that biased examples are\neasier for models to learn, while at the time of prediction, biased words make\na significantly higher contribution to the models' predictions, and models tend\nto assign predicted labels over-relying on the spurious correlation between\nwords and labels. To mitigate models' over-reliance on the shortcut (i.e.\nspurious correlation), we propose a training strategy Less-Learn-Shortcut\n(LLS): our strategy quantifies the biased degree of the biased examples and\ndown-weights them accordingly. Experimental results on Question Matching,\nNatural Language Inference and Sentiment Analysis tasks show that LLS is a\ntask-agnostic strategy and can improve the model performance on adversarial\ndata while maintaining good performance on in-domain data.\n","authors":["Yanrui Du","Jing Yan","Yan Chen","Jing Liu","Sendong Zhao","Qiaoqiao She","Hua Wu","Haifeng Wang","Bing Qin"],"pdf_url":"https://arxiv.org/pdf/2205.12593v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.13994v3","updated":"2023-06-22T13:02:23Z","published":"2023-04-27T07:32:37Z","title":"SweCTRL-Mini: a data-transparent Transformer-based large language model\n  for controllable text generation in Swedish","summary":"  We present SweCTRL-Mini, a large Swedish language model that can be used for\ninference and fine-tuning on a single consumer-grade GPU. The model is based on\nthe CTRL architecture by Keskar, McCann, Varshney, Xiong, and Socher (2019),\nwhich means that users of the SweCTRL-Mini model can control the genre of the\ngenerated text by inserting special tokens in the generation prompts.\nSweCTRL-Mini is trained on a subset of the Swedish part of the mC4 corpus and a\nset of Swedish novels. In this article, we provide (1) a detailed account of\nthe utilized training data and text pre-processing steps, to the extent that it\nis possible to check whether a specific phrase/source was a part of the\ntraining data, and (2) an evaluation of the model on both discriminative tasks,\nusing automatic evaluation methods, and generative tasks, using human referees.\nWe also compare the generative capabilities of the model with those of GPT-3.\nSweCTRL-Mini is fully open and available for download.\n","authors":["Dmytro Kalpakchi","Johan Boye"],"pdf_url":"https://arxiv.org/pdf/2304.13994v3.pdf","comment":"Added information about training tokenizer"},{"id":"http://arxiv.org/abs/2306.12834v1","updated":"2023-06-22T12:10:41Z","published":"2023-06-22T12:10:41Z","title":"Natural Language Processing in Electronic Health Records in Relation to\n  Healthcare Decision-making: A Systematic Review","summary":"  Background: Natural Language Processing (NLP) is widely used to extract\nclinical insights from Electronic Health Records (EHRs). However, the lack of\nannotated data, automated tools, and other challenges hinder the full\nutilisation of NLP for EHRs. Various Machine Learning (ML), Deep Learning (DL)\nand NLP techniques are studied and compared to understand the limitations and\nopportunities in this space comprehensively.\n  Methodology: After screening 261 articles from 11 databases, we included 127\npapers for full-text review covering seven categories of articles: 1) medical\nnote classification, 2) clinical entity recognition, 3) text summarisation, 4)\ndeep learning (DL) and transfer learning architecture, 5) information\nextraction, 6) Medical language translation and 7) other NLP applications. This\nstudy follows the Preferred Reporting Items for Systematic Reviews and\nMeta-Analyses (PRISMA) guidelines.\n  Result and Discussion: EHR was the most commonly used data type among the\nselected articles, and the datasets were primarily unstructured. Various ML and\nDL methods were used, with prediction or classification being the most common\napplication of ML or DL. The most common use cases were: the International\nClassification of Diseases, Ninth Revision (ICD-9) classification, clinical\nnote analysis, and named entity recognition (NER) for clinical descriptions and\nresearch on psychiatric disorders.\n  Conclusion: We find that the adopted ML models were not adequately assessed.\nIn addition, the data imbalance problem is quite important, yet we must find\ntechniques to address this underlining problem. Future studies should address\nkey limitations in studies, primarily identifying Lupus Nephritis, Suicide\nAttempts, perinatal self-harmed and ICD-9 classification.\n","authors":["Elias Hossain","Rajib Rana","Niall Higgins","Jeffrey Soar","Prabal Datta Barua","Anthony R. Pisani","Ph. D","Kathryn Turner}"],"pdf_url":"https://arxiv.org/pdf/2306.12834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.09525v2","updated":"2023-06-22T11:30:13Z","published":"2023-06-15T21:58:18Z","title":"Explaining Legal Concepts with Augmented Large Language Models (GPT-4)","summary":"  Interpreting the meaning of legal open-textured terms is a key task of legal\nprofessionals. An important source for this interpretation is how the term was\napplied in previous court cases. In this paper, we evaluate the performance of\nGPT-4 in generating factually accurate, clear and relevant explanations of\nterms in legislation. We compare the performance of a baseline setup, where\nGPT-4 is directly asked to explain a legal term, to an augmented approach,\nwhere a legal information retrieval module is used to provide relevant context\nto the model, in the form of sentences from case law. We found that the direct\napplication of GPT-4 yields explanations that appear to be of very high quality\non their surface. However, detailed analysis uncovered limitations in terms of\nthe factual accuracy of the explanations. Further, we found that the\naugmentation leads to improved quality, and appears to eliminate the issue of\nhallucination, where models invent incorrect statements. These findings open\nthe door to the building of systems that can autonomously retrieve relevant\nsentences from case law and condense them into a useful explanation for legal\nscholars, educators or practicing lawyers alike.\n","authors":["Jaromir Savelka","Kevin D. Ashley","Morgan A. Gray","Hannes Westermann","Huihui Xu"],"pdf_url":"https://arxiv.org/pdf/2306.09525v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12794v1","updated":"2023-06-22T10:50:23Z","published":"2023-06-22T10:50:23Z","title":"Overview of Robust and Multilingual Automatic Evaluation Metrics for\n  Open-Domain Dialogue Systems at DSTC 11 Track 4","summary":"  The advent and fast development of neural networks have revolutionized the\nresearch on dialogue systems and subsequently have triggered various challenges\nregarding their automatic evaluation. Automatic evaluation of open-domain\ndialogue systems as an open challenge has been the center of the attention of\nmany researchers. Despite the consistent efforts to improve automatic metrics'\ncorrelations with human evaluation, there have been very few attempts to assess\ntheir robustness over multiple domains and dimensions. Also, their focus is\nmainly on the English language. All of these challenges prompt the development\nof automatic evaluation metrics that are reliable in various domains,\ndimensions, and languages. This track in the 11th Dialogue System Technology\nChallenge (DSTC11) is part of the ongoing effort to promote robust and\nmultilingual automatic evaluation metrics. This article describes the datasets\nand baselines provided to participants and discusses the submission and result\ndetails of the two proposed subtasks.\n","authors":["Mario Rodríguez-Cantelar","Chen Zhang","Chengguang Tang","Ke Shi","Sarik Ghazarian","João Sedoc","Luis Fernando D'Haro","Alexander Rudnicky"],"pdf_url":"https://arxiv.org/pdf/2306.12794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04091v3","updated":"2023-06-22T10:41:41Z","published":"2023-03-07T17:52:46Z","title":"Abstract Visual Reasoning Enabled by Language","summary":"  While artificial intelligence (AI) models have achieved human or even\nsuperhuman performance in many well-defined applications, they still struggle\nto show signs of broad and flexible intelligence. The Abstraction and Reasoning\nCorpus (ARC), a visual intelligence benchmark introduced by Fran\\c{c}ois\nChollet, aims to assess how close AI systems are to human-like cognitive\nabilities. Most current approaches rely on carefully handcrafted\ndomain-specific program searches to brute-force solutions for the tasks present\nin ARC. In this work, we propose a general learning-based framework for solving\nARC. It is centered on transforming tasks from the vision to the language\ndomain. This composition of language and vision allows for pre-trained models\nto be leveraged at each stage, enabling a shift from handcrafted priors towards\nthe learned priors of the models. While not yet beating state-of-the-art models\non ARC, we demonstrate the potential of our approach, for instance, by solving\nsome ARC tasks that have not been solved previously.\n","authors":["Giacomo Camposampiero","Loic Houmard","Benjamin Estermann","Joël Mathys","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2303.04091v3.pdf","comment":"The first two authors have contributed equally to this work. Accepted\n  as regular paper at CVPR 2023 Workshop and Challenges for New Frontiers in\n  Visual Language Reasoning: Compositionality, Prompts and Causality (NFVLR)"},{"id":"http://arxiv.org/abs/2211.11419v3","updated":"2023-06-22T09:46:33Z","published":"2022-11-21T13:04:37Z","title":"Sequentially Sampled Chunk Conformer for Streaming End-to-End ASR","summary":"  This paper presents an in-depth study on a Sequentially Sampled Chunk\nConformer, SSC-Conformer, for streaming End-to-End (E2E) ASR. The SSC-Conformer\nfirst demonstrates the significant performance gains from using the\nsequentially sampled chunk-wise multi-head self-attention (SSC-MHSA) in the\nConformer encoder by allowing efficient cross-chunk interactions while keeping\nlinear complexities. Furthermore, it explores taking advantage of chunked\nconvolution to make use of the chunk-wise future context and integrates with\ncasual convolution in the convolution layers to further reduce CER. We verify\nthe proposed SSC-Conformer on the AISHELL-1 benchmark and experimental results\nshow that a state-of-the-art performance for streaming E2E ASR is achieved with\nCER 5.33% without LM rescoring. And, owing to its linear complexity, the\nSSC-Conformer can train with large batch sizes and infer more efficiently.\n","authors":["Fangyuan Wang","Bo Xu"],"pdf_url":"https://arxiv.org/pdf/2211.11419v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12766v1","updated":"2023-06-22T09:42:54Z","published":"2023-06-22T09:42:54Z","title":"Mapping and Cleaning Open Commonsense Knowledge Bases with Generative\n  Translation","summary":"  Structured knowledge bases (KBs) are the backbone of many\nknow\\-ledge-intensive applications, and their automated construction has\nreceived considerable attention. In particular, open information extraction\n(OpenIE) is often used to induce structure from a text. However, although it\nallows high recall, the extracted knowledge tends to inherit noise from the\nsources and the OpenIE algorithm. Besides, OpenIE tuples contain an open-ended,\nnon-canonicalized set of relations, making the extracted knowledge's downstream\nexploitation harder. In this paper, we study the problem of mapping an open KB\ninto the fixed schema of an existing KB, specifically for the case of\ncommonsense knowledge. We propose approaching the problem by generative\ntranslation, i.e., by training a language model to generate fixed-schema\nassertions from open ones. Experiments show that this approach occupies a sweet\nspot between traditional manual, rule-based, or classification-based\ncanonicalization and purely generative KB construction like COMET. Moreover, it\nproduces higher mapping accuracy than the former while avoiding the\nassociation-based noise of the latter.\n","authors":["Julien Romero","Simon Razniewski"],"pdf_url":"https://arxiv.org/pdf/2306.12766v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12756v1","updated":"2023-06-22T09:18:52Z","published":"2023-06-22T09:18:52Z","title":"On the Robustness of Generative Retrieval Models: An Out-of-Distribution\n  Perspective","summary":"  Recently, we have witnessed generative retrieval increasingly gaining\nattention in the information retrieval (IR) field, which retrieves documents by\ndirectly generating their identifiers. So far, much effort has been devoted to\ndeveloping effective generative retrieval models. There has been less attention\npaid to the robustness perspective. When a new retrieval paradigm enters into\nthe real-world application, it is also critical to measure the\nout-of-distribution (OOD) generalization, i.e., how would generative retrieval\nmodels generalize to new distributions. To answer this question, firstly, we\ndefine OOD robustness from three perspectives in retrieval problems: 1) The\nquery variations; 2) The unforeseen query types; and 3) The unforeseen tasks.\nBased on this taxonomy, we conduct empirical studies to analyze the OOD\nrobustness of several representative generative retrieval models against dense\nretrieval models. The empirical results indicate that the OOD robustness of\ngenerative retrieval models requires enhancement. We hope studying the OOD\nrobustness of generative retrieval models would be advantageous to the IR\ncommunity.\n","authors":["Yu-An Liu","Ruqing Zhang","Jiafeng Guo","Wei Chen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2306.12756v1.pdf","comment":"4 pages, submit to GenIR23"},{"id":"http://arxiv.org/abs/2211.15359v2","updated":"2023-06-22T08:55:12Z","published":"2022-11-25T14:29:26Z","title":"Improving Proactive Dialog Agents Using Socially-Aware Reinforcement\n  Learning","summary":"  The next step for intelligent dialog agents is to escape their role as silent\nbystanders and become proactive. Well-defined proactive behavior may improve\nhuman-machine cooperation, as the agent takes a more active role during\ninteraction and takes off responsibility from the user. However, proactivity is\na double-edged sword because poorly executed pre-emptive actions may have a\ndevastating effect not only on the task outcome but also on the relationship\nwith the user. For designing adequate proactive dialog strategies, we propose a\nnovel approach including both social as well as task-relevant features in the\ndialog. Here, the primary goal is to optimize proactive behavior so that it is\ntask-oriented - this implies high task success and efficiency - while also\nbeing socially effective by fostering user trust. Including both aspects in the\nreward function for training a proactive dialog agent using reinforcement\nlearning showed the benefit of our approach for more successful human-machine\ncooperation.\n","authors":["Matthias Kraus","Nicolas Wagner","Ron Riekenbrauck","Wolfgang Minker"],"pdf_url":"https://arxiv.org/pdf/2211.15359v2.pdf","comment":"Preprint of paper publication in UMAP`23"},{"id":"http://arxiv.org/abs/2305.11554v2","updated":"2023-06-22T07:58:56Z","published":"2023-05-19T09:54:21Z","title":"ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via\n  Tool Embeddings","summary":"  Augmenting large language models (LLMs) with external tools has emerged as a\npromising approach to solving complex problems. However, traditional methods,\nwhich finetune LLMs with tool demonstration data, can be both costly and\nrestricted to a predefined set of tools. Recent in-context learning paradigm\nalleviates these issues, but the limited context length only allows for a few\nshots of demonstrations, leading to suboptimal understandings of the tools.\nMoreover, when there are numerous tools to choose from, in-context learning\ncould completely fail to work. In this paper, we propose an alternative\napproach, $\\textbf{ToolkenGPT}$, which combines the benefits of both sides. Our\napproach represents each $\\underline{tool}$ as a to$\\underline{ken}$\n($\\textit{toolken}$) and learns an embedding for it, enabling tool calls in the\nsame way as generating a regular word token. Once a toolken is triggered, the\nLLM is prompted to complete arguments for the tool to execute. ToolkenGPT\noffers the flexibility to plug in an arbitrary number of tools by expanding the\nset of toolkens on the fly. In addition, it improves tool use by allowing\nextensive demonstration data for learning the toolken embeddings. In diverse\ndomains, including numerical reasoning, knowledge-based question answering, and\nembodied plan generation, our approach effectively augments LLMs with tools and\nsubstantially outperforms various latest baselines. ToolkenGPT demonstrates the\npromising ability to use relevant tools from a large tool set in complex\nscenarios.\n","authors":["Shibo Hao","Tianyang Liu","Zhen Wang","Zhiting Hu"],"pdf_url":"https://arxiv.org/pdf/2305.11554v2.pdf","comment":"Add code link and appendix. Code:\n  https://github.com/Ber666/ToolkenGPT"},{"id":"http://arxiv.org/abs/2306.12725v1","updated":"2023-06-22T07:57:19Z","published":"2023-06-22T07:57:19Z","title":"Generative Multimodal Entity Linking","summary":"  Multimodal Entity Linking (MEL) is the task of mapping mentions with\nmultimodal contexts to the referent entities from a knowledge base (e.g.,\nWikipedia). Prior MEL methods mainly focus on designing complex multimodal\ninteraction mechanisms and require fine-tuning all model parameters, which can\nbe prohibitively costly and difficult to scale in the era of Large Language\nModels (LLMs). In this work, we propose GEMEL, a simple yet effective\nGenerative Multimodal Entity Linking method, which leverages the capabilities\nof LLMs from large-scale pre-training to directly generate target entity names.\nWe keep the vision and language model frozen and only train a linear layer to\nenable cross-modality interactions. To adapt LLMs to the MEL task, we take\nadvantage of the emerging in-context learning (ICL) capability of LLMs by\nretrieving multimodal instances as demonstrations. Extensive experiments show\nthat with only ~0.3% of the model parameters fine-tuned, GEMEL achieves\nstate-of-the-art results on two well-established MEL datasets (4.1% accuracy\ngains on WikiDiverse and 15.4% accuracy gains on WikiMEL). Our approach is\ncompatible with any off-the-shelf language model, paving the way towards an\nefficient and general solution for utilizing LLMs in the MEL task.\n","authors":["Senbao Shi","Zhenran Xu","Baotian Hu","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.12725v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12719v1","updated":"2023-06-22T07:52:34Z","published":"2023-06-22T07:52:34Z","title":"Natural Language Generation for Advertising: A Survey","summary":"  Natural language generation methods have emerged as effective tools to help\nadvertisers increase the number of online advertisements they produce. This\nsurvey entails a review of the research trends on this topic over the past\ndecade, from template-based to extractive and abstractive approaches using\nneural networks. Additionally, key challenges and directions revealed through\nthe survey, including metric optimization, faithfulness, diversity,\nmultimodality, and the development of benchmark datasets, are discussed.\n","authors":["Soichiro Murakami","Sho Hoshino","Peinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.12719v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.04493v2","updated":"2023-06-22T07:42:08Z","published":"2023-05-08T06:40:24Z","title":"Token-Level Fitting Issues of Seq2seq Models","summary":"  Sequence-to-sequence (seq2seq) models have been widely used for natural\nlanguage processing, computer vision, and other deep learning tasks. We find\nthat seq2seq models trained with early-stopping suffer from issues at the token\nlevel. In particular, while some tokens in the vocabulary demonstrate\noverfitting, others underfit when training is stopped. Experiments show that\nthe phenomena are pervasive in different models, even in fine-tuned large\npretrained-models. We identify three major factors that influence token-level\nfitting, which include token frequency, parts-of-speech, and prediction\ndiscrepancy. Further, we find that external factors such as language, model\nsize, domain, data scale, and pretraining can also influence the fitting of\ntokens.\n","authors":["Guangsheng Bao","Zhiyang Teng","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.04493v2.pdf","comment":"Accepted by ACL 2023 Workshop on RepL4NLP, 9 pages"},{"id":"http://arxiv.org/abs/2305.05480v2","updated":"2023-06-22T07:12:15Z","published":"2023-05-09T14:30:29Z","title":"Investigating the effect of sub-word segmentation on the performance of\n  transformer language models","summary":"  We would like to explore how morphemes can affect the performance of a\nlanguage model. We trained GPT-2 and Bert model with StateMorph for both\nFinnish and Russian, which is a morpheme segmenting algorithm. As a comparison,\nwe also trained a model with BPE and Morfessor. Our preliminary result shows\nthat StateMorph can help the model to converge more efficiently and achieve a\nbetter validation score.\n","authors":["Jue Hou","Anisia Katinskaia","Anh-Duc Vu","Roman Yangarber"],"pdf_url":"https://arxiv.org/pdf/2305.05480v2.pdf","comment":"This submission is undergoing a major revision, and will be back\n  online as soon as possible -- once we have completed the experiments and have\n  new results"},{"id":"http://arxiv.org/abs/2301.11309v2","updated":"2023-06-22T06:56:24Z","published":"2023-01-26T18:49:02Z","title":"SemSup-XC: Semantic Supervision for Zero and Few-shot Extreme\n  Classification","summary":"  Extreme classification (XC) involves predicting over large numbers of classes\n(thousands to millions), with real-world applications like news article\nclassification and e-commerce product tagging. The zero-shot version of this\ntask requires generalization to novel classes without additional supervision.\nIn this paper, we develop SemSup-XC, a model that achieves state-of-the-art\nzero-shot and few-shot performance on three XC datasets derived from legal,\ne-commerce, and Wikipedia data. To develop SemSup-XC, we use automatically\ncollected semantic class descriptions to represent classes and facilitate\ngeneralization through a novel hybrid matching module that matches input\ninstances to class descriptions using a combination of semantic and lexical\nsimilarity. Trained with contrastive learning, SemSup-XC significantly\noutperforms baselines and establishes state-of-the-art performance on all three\ndatasets considered, gaining up to 12 precision points on zero-shot and more\nthan 10 precision points on one-shot tests, with similar gains for recall@10.\nOur ablation studies highlight the relative importance of our hybrid matching\nmodule and automatically collected class descriptions.\n","authors":["Pranjal Aggarwal","Ameet Deshpande","Karthik Narasimhan"],"pdf_url":"https://arxiv.org/pdf/2301.11309v2.pdf","comment":"Published at ICML 2023. V2: camera ready version at ICML 2023"},{"id":"http://arxiv.org/abs/2306.12693v1","updated":"2023-06-22T06:44:09Z","published":"2023-06-22T06:44:09Z","title":"Multilingual Neural Machine Translation System for Indic to Indic\n  Languages","summary":"  This paper gives an Indic-to-Indic (IL-IL) MNMT baseline model for 11 ILs\nimplemented on the Samanantar corpus and analyzed on the Flores-200 corpus. All\nthe models are evaluated using the BLEU score. In addition, the languages are\nclassified under three groups namely East Indo- Aryan (EI), Dravidian (DR), and\nWest Indo-Aryan (WI). The effect of language relatedness on MNMT model\nefficiency is studied. Owing to the presence of large corpora from English (EN)\nto ILs, MNMT IL-IL models using EN as a pivot are also built and examined. To\nachieve this, English- Indic (EN-IL) models are also developed, with and\nwithout the usage of related languages. Results reveal that using related\nlanguages is beneficial for the WI group only, while it is detrimental for the\nEI group and shows an inconclusive effect on the DR group, but it is useful for\nEN-IL models. Thus, related language groups are used to develop pivot MNMT\nmodels. Furthermore, the IL corpora are transliterated from the corresponding\nscripts to a modified ITRANS script, and the best MNMT models from the previous\napproaches are built on the transliterated corpus. It is observed that the\nusage of pivot models greatly improves MNMT baselines with AS-TA achieving the\nminimum BLEU score and PA-HI achieving the maximum score. Among languages, AS,\nML, and TA achieve the lowest BLEU score, whereas HI, PA, and GU perform the\nbest. Transliteration also helps the models with few exceptions. The best\nincrement of scores is observed in ML, TA, and BN and the worst average\nincrement is observed in KN, HI, and PA, across all languages. The best model\nobtained is the PA-HI language pair trained on PAWI transliterated corpus which\ngives 24.29 BLEU.\n","authors":["Sudhansu Bala Das","Divyajyoti Panda","Tapas Kumar Mishra","Bidyut Kr. Patra","Asif Ekbal"],"pdf_url":"https://arxiv.org/pdf/2306.12693v1.pdf","comment":"38 pages, 2 figures"},{"id":"http://arxiv.org/abs/2306.12689v1","updated":"2023-06-22T06:23:31Z","published":"2023-06-22T06:23:31Z","title":"Vec2Vec: A Compact Neural Network Approach for Transforming Text\n  Embeddings with High Fidelity","summary":"  Vector embeddings have become ubiquitous tools for many language-related\ntasks. A leading embedding model is OpenAI's text-ada-002 which can embed\napproximately 6,000 words into a 1,536-dimensional vector. While powerful,\ntext-ada-002 is not open source and is only available via API. We trained a\nsimple neural network to convert open-source 768-dimensional MPNet embeddings\ninto text-ada-002 embeddings. We compiled a subset of 50,000 online food\nreviews. We calculated MPNet and text-ada-002 embeddings for each review and\ntrained a simple neural network to for 75 epochs. The neural network was\ndesigned to predict the corresponding text-ada-002 embedding for a given MPNET\nembedding. Our model achieved an average cosine similarity of 0.932 on 10,000\nunseen reviews in our held-out test dataset. We manually assessed the quality\nof our predicted embeddings for vector search over text-ada-002-embedded\nreviews. While not as good as real text-ada-002 embeddings, predicted\nembeddings were able to retrieve highly relevant reviews. Our final model,\nVec2Vec, is lightweight (<80 MB) and fast. Future steps include training a\nneural network with a more sophisticated architecture and a larger dataset of\npaired embeddings to achieve greater performance. The ability to convert\nbetween and align embedding spaces may be helpful for interoperability,\nlimiting dependence on proprietary models, protecting data privacy, reducing\ncosts, and offline operations.\n","authors":["Andrew Kean Gao"],"pdf_url":"https://arxiv.org/pdf/2306.12689v1.pdf","comment":"14 pages, 6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2306.12679v1","updated":"2023-06-22T05:51:22Z","published":"2023-06-22T05:51:22Z","title":"Constructing Colloquial Dataset for Persian Sentiment Analysis of Social\n  Microblogs","summary":"  Introduction: Microblogging websites have massed rich data sources for\nsentiment analysis and opinion mining. In this regard, sentiment classification\nhas frequently proven inefficient because microblog posts typically lack\nsyntactically consistent terms and representatives since users on these social\nnetworks do not like to write lengthy statements. Also, there are some\nlimitations to low-resource languages. The Persian language has exceptional\ncharacteristics and demands unique annotated data and models for the sentiment\nanalysis task, which are distinctive from text features within the English\ndialect. Method: This paper first constructs a user opinion dataset called\nITRC-Opinion by collaborative environment and insource way. Our dataset\ncontains 60,000 informal and colloquial Persian texts from social microblogs\nsuch as Twitter and Instagram. Second, this study proposes a new deep\nconvolutional neural network (CNN) model for more effective sentiment analysis\nof colloquial text in social microblog posts. The constructed datasets are used\nto evaluate the presented model. Furthermore, some models, such as LSTM,\nCNN-RNN, BiLSTM, and BiGRU with different word embeddings, including Fasttext,\nGlove, and Word2vec, investigated our dataset and evaluated the results.\nResults: The results demonstrate the benefit of our dataset and the proposed\nmodel (72% accuracy), displaying meaningful improvement in sentiment\nclassification performance.\n","authors":["Mojtaba Mazoochi","Leyla Rabiei","Farzaneh Rahmani","Zeinab Rajabi"],"pdf_url":"https://arxiv.org/pdf/2306.12679v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12672v1","updated":"2023-06-22T05:14:00Z","published":"2023-06-22T05:14:00Z","title":"From Word Models to World Models: Translating from Natural Language to\n  the Probabilistic Language of Thought","summary":"  How does language inform our downstream thinking? In particular, how do\nhumans make meaning from language -- and how can we leverage a theory of\nlinguistic meaning to build machines that think in more human-like ways? In\nthis paper, we propose \\textit{rational meaning construction}, a computational\nframework for language-informed thinking that combines neural models of\nlanguage with probabilistic models for rational inference. We frame linguistic\nmeaning as a context-sensitive mapping from natural language into a\n\\textit{probabilistic language of thought} (PLoT) -- a general-purpose symbolic\nsubstrate for probabilistic, generative world modeling. Our architecture\nintegrates two powerful computational tools that have not previously come\ntogether: we model thinking with \\textit{probabilistic programs}, an expressive\nrepresentation for flexible commonsense reasoning; and we model meaning\nconstruction with \\textit{large language models} (LLMs), which support\nbroad-coverage translation from natural language utterances to code expressions\nin a probabilistic programming language. We illustrate our framework in action\nthrough examples covering four core domains from cognitive science:\nprobabilistic reasoning, logical and relational reasoning, visual and physical\nreasoning, and social reasoning about agents and their plans. In each, we show\nthat LLMs can generate context-sensitive translations that capture\npragmatically-appropriate linguistic meanings, while Bayesian inference with\nthe generated programs supports coherent and robust commonsense reasoning. We\nextend our framework to integrate cognitively-motivated symbolic modules to\nprovide a unified commonsense thinking interface from language. Finally, we\nexplore how language can drive the construction of world models themselves.\n","authors":["Lionel Wong","Gabriel Grand","Alexander K. Lew","Noah D. Goodman","Vikash K. Mansinghka","Jacob Andreas","Joshua B. Tenenbaum"],"pdf_url":"https://arxiv.org/pdf/2306.12672v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11207v2","updated":"2023-06-22T05:01:16Z","published":"2023-06-20T00:14:47Z","title":"Quilt-1M: One Million Image-Text Pairs for Histopathology","summary":"  Recent accelerations in multi-modal applications have been made possible with\nthe plethora of image and text data available online. However, the scarcity of\nanalogous data in the medical field, specifically in histopathology, has halted\ncomparable progress. To enable similar representation learning for\nhistopathology, we turn to YouTube, an untapped resource of videos, offering\n$1,087$ hours of valuable educational histopathology videos from expert\nclinicians. From YouTube, we curate Quilt: a large-scale vision-language\ndataset consisting of $768,826$ image and text pairs. Quilt was automatically\ncurated using a mixture of models, including large language models, handcrafted\nalgorithms, human knowledge databases, and automatic speech recognition. In\ncomparison, the most comprehensive datasets curated for histopathology amass\nonly around $200$K samples. We combine Quilt with datasets from other sources,\nincluding Twitter, research papers, and the internet in general, to create an\neven larger dataset: Quilt-1M, with $1$M paired image-text samples, marking it\nas the largest vision-language histopathology dataset to date. We demonstrate\nthe value of Quilt-1M by fine-tuning a pre-trained CLIP model. Our model\noutperforms state-of-the-art models on both zero-shot and linear probing tasks\nfor classifying new histopathology images across $13$ diverse patch-level\ndatasets of $8$ different sub-pathologies and cross-modal retrieval tasks.\n","authors":["Wisdom Oluchi Ikezogwo","Mehmet Saygin Seyfioglu","Fatemeh Ghezloo","Dylan Stefan Chan Geva","Fatwir Sheikh Mohammed","Pavan Kumar Anand","Ranjay Krishna","Linda Shapiro"],"pdf_url":"https://arxiv.org/pdf/2306.11207v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.09770v4","updated":"2023-06-22T04:04:17Z","published":"2023-05-16T19:48:49Z","title":"ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to\n  Support Human-AI Scientific Writing","summary":"  Despite a surge collection of XAI methods, users still struggle to obtain\nrequired AI explanations. Previous research suggests chatbots as dynamic\nsolutions, but the effective design of conversational XAI agents for practical\nhuman needs remains under-explored. This paper focuses on Conversational XAI\nfor AI-assisted scientific writing tasks. Drawing from human linguistic\ntheories and formative studies, we identify four design rationales:\n\"multifaceted\", \"controllability\", \"mix-initiative\", \"context-aware\ndrill-down\". We incorporate them into an interactive prototype, ConvXAI, which\nfacilitates heterogeneous AI explanations for scientific writing through\ndialogue. In two studies with 21 users, ConvXAI outperforms a GUI-based\nbaseline on improving human-perceived understanding and writing improvement.\nThe paper further discusses the practical human usage patterns in interacting\nwith ConvXAI for scientific co-writing.\n","authors":["Hua Shen","Chieh-Yang Huang","Tongshuang Wu","Ting-Hao 'Kenneth' Huang"],"pdf_url":"https://arxiv.org/pdf/2305.09770v4.pdf","comment":"To appear in CSCW 2023 Demo. 20-page Full Paper. ConvXAI system code:\n  https://github.com/huashen218/convxai.git"},{"id":"http://arxiv.org/abs/2306.12659v1","updated":"2023-06-22T03:56:38Z","published":"2023-06-22T03:56:38Z","title":"Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of\n  General-Purpose Large Language Models","summary":"  Sentiment analysis is a vital tool for uncovering insights from financial\narticles, news, and social media, shaping our understanding of market\nmovements. Despite the impressive capabilities of large language models (LLMs)\nin financial natural language processing (NLP), they still struggle with\naccurately interpreting numerical values and grasping financial context,\nlimiting their effectiveness in predicting financial sentiment. In this paper,\nwe introduce a simple yet effective instruction tuning approach to address\nthese issues. By transforming a small portion of supervised financial sentiment\nanalysis data into instruction data and fine-tuning a general-purpose LLM with\nthis method, we achieve remarkable advancements in financial sentiment\nanalysis. In the experiment, our approach outperforms state-of-the-art\nsupervised sentiment analysis models, as well as widely used LLMs like ChatGPT\nand LLaMAs, particularly in scenarios where numerical understanding and\ncontextual comprehension are vital.\n","authors":["Boyu Zhang","Hongyang Yang","Xiao-Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2306.12659v1.pdf","comment":"FinLLM Symposium at IJCAI 2023"},{"id":"http://arxiv.org/abs/2306.12656v1","updated":"2023-06-22T03:52:12Z","published":"2023-06-22T03:52:12Z","title":"Identifying and Extracting Rare Disease Phenotypes with Large Language\n  Models","summary":"  Rare diseases (RDs) are collectively common and affect 300 million people\nworldwide. Accurate phenotyping is critical for informing diagnosis and\ntreatment, but RD phenotypes are often embedded in unstructured text and\ntime-consuming to extract manually. While natural language processing (NLP)\nmodels can perform named entity recognition (NER) to automate extraction, a\nmajor bottleneck is the development of a large, annotated corpus for model\ntraining. Recently, prompt learning emerged as an NLP paradigm that can lead to\nmore generalizable results without any (zero-shot) or few labeled samples\n(few-shot). Despite growing interest in ChatGPT, a revolutionary large language\nmodel capable of following complex human prompts and generating high-quality\nresponses, none have studied its NER performance for RDs in the zero- and\nfew-shot settings. To this end, we engineered novel prompts aimed at extracting\nRD phenotypes and, to the best of our knowledge, are the first the establish a\nbenchmark for evaluating ChatGPT's performance in these settings. We compared\nits performance to the traditional fine-tuning approach and conducted an\nin-depth error analysis. Overall, fine-tuning BioClinicalBERT resulted in\nhigher performance (F1 of 0.689) than ChatGPT (F1 of 0.472 and 0.591 in the\nzero- and few-shot settings, respectively). Despite this, ChatGPT achieved\nsimilar or higher accuracy for certain entities (i.e., rare diseases and signs)\nin the one-shot setting (F1 of 0.776 and 0.725). This suggests that with\nappropriate prompt engineering, ChatGPT has the potential to match or\noutperform fine-tuned language models for certain entity types with just one\nlabeled sample. While the proliferation of large language models may provide\nopportunities for supporting RD diagnosis and treatment, researchers and\nclinicians should critically evaluate model outputs and be well-informed of\ntheir limitations.\n","authors":["Cathy Shyr","Yan Hu","Paul A. Harris","Hua Xu"],"pdf_url":"https://arxiv.org/pdf/2306.12656v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10535v2","updated":"2023-06-22T01:37:02Z","published":"2022-12-20T18:46:16Z","title":"A Survey of Deep Learning for Mathematical Reasoning","summary":"  Mathematical reasoning is a fundamental aspect of human intelligence and is\napplicable in various fields, including science, engineering, finance, and\neveryday life. The development of artificial intelligence (AI) systems capable\nof solving math problems and proving theorems has garnered significant interest\nin the fields of machine learning and natural language processing. For example,\nmathematics serves as a testbed for aspects of reasoning that are challenging\nfor powerful deep learning models, driving new algorithmic and modeling\nadvances. On the other hand, recent advances in large-scale neural language\nmodels have opened up new benchmarks and opportunities to use deep learning for\nmathematical reasoning. In this survey paper, we review the key tasks,\ndatasets, and methods at the intersection of mathematical reasoning and deep\nlearning over the past decade. We also evaluate existing benchmarks and\nmethods, and discuss future research directions in this domain.\n","authors":["Pan Lu","Liang Qiu","Wenhao Yu","Sean Welleck","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2212.10535v2.pdf","comment":"Accepted to ACL 2023. The repository is available at\n  https://github.com/lupantech/dl4math"},{"id":"http://arxiv.org/abs/2306.12619v1","updated":"2023-06-22T01:14:47Z","published":"2023-06-22T01:14:47Z","title":"Class-Incremental Learning based on Label Generation","summary":"  Despite the great success of pre-trained language models, it is still a\nchallenge to use these models for continual learning, especially for the\nclass-incremental learning (CIL) setting due to catastrophic forgetting (CF).\nThis paper reports our finding that if we formulate CIL as a continual label\ngeneration problem, CF is drastically reduced and the generalizable\nrepresentations of pre-trained models can be better retained. We thus propose a\nnew CIL method (VAG) that also leverages the sparsity of vocabulary to focus\nthe generation and creates pseudo-replay samples by using label semantics.\nExperimental results show that VAG outperforms baselines by a large margin.\n","authors":["Yijia Shao","Yiduo Guo","Dongyan Zhao","Bing Liu"],"pdf_url":"https://arxiv.org/pdf/2306.12619v1.pdf","comment":"12 pages, ACL 2023 Main Conference"},{"id":"http://arxiv.org/abs/2207.00746v2","updated":"2023-06-22T22:46:37Z","published":"2022-07-02T06:18:12Z","title":"INSCIT: Information-Seeking Conversations with Mixed-Initiative\n  Interactions","summary":"  In an information-seeking conversation, a user may ask questions that are\nunder-specified or unanswerable. An ideal agent would interact by initiating\ndifferent response types according to the available knowledge sources. However,\nmost current studies either fail to or artificially incorporate such agent-side\ninitiative. This work presents InSCIt, a dataset for Information-Seeking\nConversations with mixed-initiative Interactions. It contains 4.7K user-agent\nturns from 805 human-human conversations where the agent searches over\nWikipedia and either directly answers, asks for clarification, or provides\nrelevant information to address user queries. The data supports two subtasks,\nevidence passage identification and response generation, as well as a human\nevaluation protocol to assess model performance. We report results of two\nsystems based on state-of-the-art models of conversational knowledge\nidentification and open-domain question answering. Both systems significantly\nunderperform humans, suggesting ample room for improvement in future studies.\n","authors":["Zeqiu Wu","Ryu Parish","Hao Cheng","Sewon Min","Prithviraj Ammanabrolu","Mari Ostendorf","Hannaneh Hajishirzi"],"pdf_url":"https://arxiv.org/pdf/2207.00746v2.pdf","comment":"TACL 2023"},{"id":"http://arxiv.org/abs/2306.13230v1","updated":"2023-06-22T22:29:40Z","published":"2023-06-22T22:29:40Z","title":"DiversiGATE: A Comprehensive Framework for Reliable Large Language\n  Models","summary":"  In this paper, we introduce DiversiGATE, a unified framework that\nconsolidates diverse methodologies for LLM verification. The proposed framework\ncomprises two main components: Diversification and Aggregation which provide a\nholistic perspective on existing verification approaches, such as\nSelf-Consistency, Math Prompter and WebGPT. Furthermore, we propose a novel\n`SelfLearner' model that conforms to the DiversiGATE framework which can learn\nfrom its own outputs and refine its performance over time, leading to improved\naccuracy. To evaluate the effectiveness of SelfLearner, we conducted a rigorous\nseries of experiments, including tests on synthetic data as well as on popular\narithmetic reasoning benchmarks such as GSM8K. Our results demonstrate that our\napproach outperforms traditional LLMs, achieving a considerable 54.8% -> 61.8%\nimprovement on the GSM8K benchmark.\n","authors":["Shima Imani","Ali Beyram","Harsh Shrivastava"],"pdf_url":"https://arxiv.org/pdf/2306.13230v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13213v1","updated":"2023-06-22T22:13:03Z","published":"2023-06-22T22:13:03Z","title":"Visual Adversarial Examples Jailbreak Large Language Models","summary":"  Recently, there has been a surge of interest in introducing vision into Large\nLanguage Models (LLMs). The proliferation of large Visual Language Models\n(VLMs), such as Flamingo, BLIP-2, and GPT-4, signifies an exciting convergence\nof advancements in both visual and language foundation models. Yet, the risks\nassociated with this integrative approach are largely unexamined. In this\npaper, we shed light on the security and safety implications of this trend.\nFirst, we underscore that the continuous and high-dimensional nature of the\nadditional visual input space intrinsically makes it a fertile ground for\nadversarial attacks. This unavoidably expands the attack surfaces of LLMs.\nSecond, we highlight that the broad functionality of LLMs also presents visual\nattackers with a wider array of achievable adversarial objectives, extending\nthe implications of security failures beyond mere misclassification. To\nelucidate these risks, we study adversarial examples in the visual input space\nof a VLM. Specifically, against MiniGPT-4, which incorporates safety mechanisms\nthat can refuse harmful instructions, we present visual adversarial examples\nthat can circumvent the safety mechanisms and provoke harmful behaviors of the\nmodel. Remarkably, we discover that adversarial examples, even if optimized on\na narrow, manually curated derogatory corpus against specific social groups,\ncan universally jailbreak the model's safety mechanisms. A single such\nadversarial example can generally undermine MiniGPT-4's safety, enabling it to\nheed a wide range of harmful instructions and produce harmful content far\nbeyond simply imitating the derogatory corpus used in optimization. Unveiling\nthese risks, we accentuate the urgent need for comprehensive risk assessments,\nrobust defense strategies, and the implementation of responsible practices for\nthe secure and safe utilization of VLMs.\n","authors":["Xiangyu Qi","Kaixuan Huang","Ashwinee Panda","Mengdi Wang","Prateek Mittal"],"pdf_url":"https://arxiv.org/pdf/2306.13213v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13195v1","updated":"2023-06-22T20:38:52Z","published":"2023-06-22T20:38:52Z","title":"Prompt to GPT-3: Step-by-Step Thinking Instructions for Humor Generation","summary":"  Artificial intelligence has made significant progress in natural language\nprocessing, with models like GPT-3 demonstrating impressive capabilities.\nHowever, these models still have limitations when it comes to complex tasks\nthat require an understanding of the user, such as mastering human comedy\nwriting strategies. This paper explores humor generation using GPT-3 by\nmodeling human comedy writing theory and leveraging step-by-step thinking\ninstructions. In addition, we explore the role of cognitive distance in\ncreating humor.\n","authors":["Yuetian Chen","Bowen Shi","Mei Si"],"pdf_url":"https://arxiv.org/pdf/2306.13195v1.pdf","comment":"5 pages, 1 figure; ICCC '23 preprint"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2306.13092v1","updated":"2023-06-22T17:59:58Z","published":"2023-06-22T17:59:58Z","title":"Squeeze, Recover and Relabel: Dataset Condensation at ImageNet Scale\n  From A New Perspective","summary":"  We present a new dataset condensation framework termed Squeeze, Recover and\nRelabel (SRe$^2$L) that decouples the bilevel optimization of model and\nsynthetic data during training, to handle varying scales of datasets, model\narchitectures and image resolutions for effective dataset condensation. The\nproposed method demonstrates flexibility across diverse dataset scales and\nexhibits multiple advantages in terms of arbitrary resolutions of synthesized\nimages, low training cost and memory consumption with high-resolution training,\nand the ability to scale up to arbitrary evaluation network architectures.\nExtensive experiments are conducted on Tiny-ImageNet and full ImageNet-1K\ndatasets. Under 50 IPC, our approach achieves the highest 42.5% and 60.8%\nvalidation accuracy on Tiny-ImageNet and ImageNet-1K, outperforming all\nprevious state-of-the-art methods by margins of 14.5% and 32.9%, respectively.\nOur approach also outperforms MTT by approximately 52$\\times$ (ConvNet-4) and\n16$\\times$ (ResNet-18) faster in speed with less memory consumption of\n11.6$\\times$ and 6.4$\\times$ during data synthesis. Our code and condensed\ndatasets of 50, 200 IPC with 4K recovery budget are available at\nhttps://zeyuanyin.github.io/projects/SRe2L/.\n","authors":["Zeyuan Yin","Eric Xing","Zhiqiang Shen"],"pdf_url":"https://arxiv.org/pdf/2306.13092v1.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2306.13091v1","updated":"2023-06-22T17:59:55Z","published":"2023-06-22T17:59:55Z","title":"Evading Forensic Classifiers with Attribute-Conditioned Adversarial\n  Faces","summary":"  The ability of generative models to produce highly realistic synthetic face\nimages has raised security and ethical concerns. As a first line of defense\nagainst such fake faces, deep learning based forensic classifiers have been\ndeveloped. While these forensic models can detect whether a face image is\nsynthetic or real with high accuracy, they are also vulnerable to adversarial\nattacks. Although such attacks can be highly successful in evading detection by\nforensic classifiers, they introduce visible noise patterns that are detectable\nthrough careful human scrutiny. Additionally, these attacks assume access to\nthe target model(s) which may not always be true. Attempts have been made to\ndirectly perturb the latent space of GANs to produce adversarial fake faces\nthat can circumvent forensic classifiers. In this work, we go one step further\nand show that it is possible to successfully generate adversarial fake faces\nwith a specified set of attributes (e.g., hair color, eye size, race, gender,\netc.). To achieve this goal, we leverage the state-of-the-art generative model\nStyleGAN with disentangled representations, which enables a range of\nmodifications without leaving the manifold of natural images. We propose a\nframework to search for adversarial latent codes within the feature space of\nStyleGAN, where the search can be guided either by a text prompt or a reference\nimage. We also propose a meta-learning based optimization strategy to achieve\ntransferable performance on unknown target models. Extensive experiments\ndemonstrate that the proposed approach can produce semantically manipulated\nadversarial fake faces, which are true to the specified attribute set and can\nsuccessfully fool forensic face classifiers, while remaining undetectable by\nhumans. Code: https://github.com/koushiksrivats/face_attribute_attack.\n","authors":["Fahad Shamshad","Koushik Srivatsan","Karthik Nandakumar"],"pdf_url":"https://arxiv.org/pdf/2306.13091v1.pdf","comment":"Accepted in CVPR 2023. Project page:\n  https://koushiksrivats.github.io/face_attribute_attack/"},{"id":"http://arxiv.org/abs/2306.13090v1","updated":"2023-06-22T17:59:52Z","published":"2023-06-22T17:59:52Z","title":"PromptIR: Prompting for All-in-One Blind Image Restoration","summary":"  Image restoration involves recovering a high-quality clean image from its\ndegraded version. Deep learning-based methods have significantly improved image\nrestoration performance, however, they have limited generalization ability to\ndifferent degradation types and levels. This restricts their real-world\napplication since it requires training individual models for each specific\ndegradation and knowing the input degradation type to apply the relevant model.\nWe present a prompt-based learning approach, PromptIR, for All-In-One image\nrestoration that can effectively restore images from various types and levels\nof degradation. In particular, our method uses prompts to encode\ndegradation-specific information, which is then used to dynamically guide the\nrestoration network. This allows our method to generalize to different\ndegradation types and levels, while still achieving state-of-the-art results on\nimage denoising, deraining, and dehazing. Overall, PromptIR offers a generic\nand efficient plugin module with few lightweight prompts that can be used to\nrestore images of various types and levels of degradation with no prior\ninformation on the corruptions present in the image. Our code and pretrained\nmodels are available here: https://github.com/va1shn9v/PromptIR\n","authors":["Vaishnav Potlapalli","Syed Waqas Zamir","Salman Khan","Fahad Shahbaz Khan"],"pdf_url":"https://arxiv.org/pdf/2306.13090v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13078v1","updated":"2023-06-22T17:51:05Z","published":"2023-06-22T17:51:05Z","title":"Continuous Layout Editing of Single Images with Diffusion Models","summary":"  Recent advancements in large-scale text-to-image diffusion models have\nenabled many applications in image editing. However, none of these methods have\nbeen able to edit the layout of single existing images. To address this gap, we\npropose the first framework for layout editing of a single image while\npreserving its visual properties, thus allowing for continuous editing on a\nsingle image. Our approach is achieved through two key modules. First, to\npreserve the characteristics of multiple objects within an image, we\ndisentangle the concepts of different objects and embed them into separate\ntextual tokens using a novel method called masked textual inversion. Next, we\npropose a training-free optimization method to perform layout control for a\npre-trained diffusion model, which allows us to regenerate images with learned\nconcepts and align them with user-specified layouts. As the first framework to\nedit the layout of existing images, we demonstrate that our method is effective\nand outperforms other baselines that were modified to support this task. Our\ncode will be freely available for public use upon acceptance.\n","authors":["Zhiyuan Zhang","Zhitong Huang","Jing Liao"],"pdf_url":"https://arxiv.org/pdf/2306.13078v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13075v1","updated":"2023-06-22T17:47:42Z","published":"2023-06-22T17:47:42Z","title":"Semi-automated extraction of research topics and trends from NCI funding\n  in radiological sciences from 2000-2020","summary":"  Investigators, funders, and the public desire knowledge on topics and trends\nin publicly funded research but current efforts in manual categorization are\nlimited in scale and understanding. We developed a semi-automated approach to\nextract and name research topics, and applied this to \\$1.9B of NCI funding\nover 21 years in the radiological sciences to determine micro- and macro-scale\nresearch topics and funding trends. Our method relies on sequential clustering\nof existing biomedical-based word embeddings, naming using subject matter\nexperts, and visualization to discover trends at a macroscopic scale above\nindividual topics. We present results using 15 and 60 cluster topics, where we\nfound that 2D projection of grant embeddings reveals two dominant axes:\nphysics-biology and therapeutic-diagnostic. For our dataset, we found that\nfunding for therapeutics- and physics-based research have outpaced diagnostics-\nand biology-based research, respectively. We hope these results may (1) give\ninsight to funders on the appropriateness of their funding allocation, (2)\nassist investigators in contextualizing their work and explore neighboring\nresearch domains, and (3) allow the public to review where their tax dollars\nare being allocated.\n","authors":["Mark Nguyen","Peter Beidler","Joseph Tsai","August Anderson","Daniel Chen","Paul Kinahan","John Kang"],"pdf_url":"https://arxiv.org/pdf/2306.13075v1.pdf","comment":"Presented at the American Society of Radiation Oncology annual\n  meeting in 2021 ((doi: 10.1016/j.ijrobp.2021.07.263) and the Practical Big\n  Data Workshop 2022"},{"id":"http://arxiv.org/abs/2306.13074v1","updated":"2023-06-22T17:47:08Z","published":"2023-06-22T17:47:08Z","title":"Iterative Scale-Up ExpansionIoU and Deep Features Association for\n  Multi-Object Tracking in Sports","summary":"  Multi-object tracking algorithms have made significant advancements due to\nthe recent developments in object detection. However, most existing methods\nprimarily focus on tracking pedestrians or vehicles, which exhibit relatively\nsimple and regular motion patterns. Consequently, there is a scarcity of\nalgorithms that address the tracking of targets with irregular or non-linear\nmotion, such as multi-athlete tracking. Furthermore, popular tracking\nalgorithms often rely on the Kalman filter for object motion modeling, which\nfails to track objects when their motion contradicts the linear motion\nassumption of the Kalman filter. Due to this reason, we proposed a novel online\nand robust multi-object tracking approach, named Iterative Scale-Up\nExpansionIoU and Deep Features for multi-object tracking. Unlike conventional\nmethods, we abandon the use of the Kalman filter and propose utilizing the\niterative scale-up expansion IoU. This approach achieves superior tracking\nperformance without requiring additional training data or adopting a more\nrobust detector, all while maintaining a lower computational cost compared to\nother appearance-based methods. Our proposed method demonstrates remarkable\neffectiveness in tracking irregular motion objects, achieving a score of 75.3%\nin HOTA. It outperforms all state-of-the-art online tracking algorithms on the\nSportsMOT dataset, covering various kinds of sport scenarios.\n","authors":["Hsiang-Wei Huang","Cheng-Yen Yang","Jenq-Neng Hwang","Chung-I Huang"],"pdf_url":"https://arxiv.org/pdf/2306.13074v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.03894v2","updated":"2023-06-22T17:43:11Z","published":"2022-11-07T22:56:23Z","title":"visClust: A visual clustering algorithm based on orthogonal projections","summary":"  We present a novel clustering algorithm, visClust, that is based on lower\ndimensional data representations and visual interpretation. Thereto, we design\na transformation that allows the data to be represented by a binary integer\narray enabling the further use of image processing methods to select a\npartition. Qualitative and quantitative analyses show that the algorithm\nobtains high accuracy (measured with an adjusted one-sided Rand-Index) and\nrequires low runtime and RAM. We compare the results to 6 state-of-the-art\nalgorithms, confirming the quality of visClust by outperforming in most\nexperiments. Moreover, the algorithm asks for just one obligatory input\nparameter while allowing optimization via optional parameters. The code is made\navailable on GitHub.\n","authors":["Anna Breger","Clemens Karner","Martin Ehler"],"pdf_url":"https://arxiv.org/pdf/2211.03894v2.pdf","comment":"27 pages"},{"id":"http://arxiv.org/abs/2306.13055v1","updated":"2023-06-22T17:22:15Z","published":"2023-06-22T17:22:15Z","title":"Deep Metric Learning with Soft Orthogonal Proxies","summary":"  Deep Metric Learning (DML) models rely on strong representations and\nsimilarity-based measures with specific loss functions. Proxy-based losses have\nshown great performance compared to pair-based losses in terms of convergence\nspeed. However, proxies that are assigned to different classes may end up being\nclosely located in the embedding space and hence having a hard time to\ndistinguish between positive and negative items. Alternatively, they may become\nhighly correlated and hence provide redundant information with the model. To\naddress these issues, we propose a novel approach that introduces Soft\nOrthogonality (SO) constraint on proxies. The constraint ensures the proxies to\nbe as orthogonal as possible and hence control their positions in the embedding\nspace. Our approach leverages Data-Efficient Image Transformer (DeiT) as an\nencoder to extract contextual features from images along with a DML objective.\nThe objective is made of the Proxy Anchor loss along with the SO\nregularization. We evaluate our method on four public benchmarks for\ncategory-level image retrieval and demonstrate its effectiveness with\ncomprehensive experimental results and ablation studies. Our evaluations\ndemonstrate the superiority of our proposed approach over state-of-the-art\nmethods by a significant margin.\n","authors":["Farshad Saberi-Movahed","Mohammad K. Ebrahimpour","Farid Saberi-Movahed","Monireh Moshavash","Dorsa Rahmatian","Mahvash Mohazzebi","Mahdi Shariatzadeh","Mahdi Eftekhari"],"pdf_url":"https://arxiv.org/pdf/2306.13055v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.00221v2","updated":"2023-06-22T16:55:44Z","published":"2022-07-01T06:25:53Z","title":"VL-CheckList: Evaluating Pre-trained Vision-Language Models with\n  Objects, Attributes and Relations","summary":"  Vision-Language Pretraining (VLP) models have recently successfully\nfacilitated many cross-modal downstream tasks. Most existing works evaluated\ntheir systems by comparing the fine-tuned downstream task performance. However,\nonly average downstream task accuracy provides little information about the\npros and cons of each VLP method, let alone provides insights on how the\ncommunity can improve the systems in the future. Inspired by the CheckList for\ntesting natural language processing, we exploit VL-CheckList, a novel framework\nto understand the capabilities of VLP models. The proposed method divides the\nimage-texting ability of a VLP model into three categories: objects,\nattributes, and relations, and uses a novel taxonomy to further break down\nthese three aspects. We conduct comprehensive studies to analyze seven recently\npopular VLP models via the proposed framework. Results confirm the\neffectiveness of the proposed method by revealing fine-grained differences\namong the compared models that were not visible from downstream task-only\nevaluation. Further results show promising research direction in building\nbetter VLP models. Our data and code are available at:\nhttps://github.com/om-ai-lab/VL-CheckList.\n","authors":["Tiancheng Zhao","Tianqi Zhang","Mingwei Zhu","Haozhan Shen","Kyusong Lee","Xiaopeng Lu","Jianwei Yin"],"pdf_url":"https://arxiv.org/pdf/2207.00221v2.pdf","comment":"9 pages, preprint"},{"id":"http://arxiv.org/abs/2306.13023v1","updated":"2023-06-22T16:31:46Z","published":"2023-06-22T16:31:46Z","title":"AugDMC: Data Augmentation Guided Deep Multiple Clustering","summary":"  Clustering aims to group similar objects together while separating dissimilar\nones apart. Thereafter, structures hidden in data can be identified to help\nunderstand data in an unsupervised manner. Traditional clustering methods such\nas k-means provide only a single clustering for one data set. Deep clustering\nmethods such as auto-encoder based clustering methods have shown a better\nperformance, but still provide a single clustering. However, a given dataset\nmight have multiple clustering structures and each represents a unique\nperspective of the data. Therefore, some multiple clustering methods have been\ndeveloped to discover multiple independent structures hidden in data. Although\ndeep multiple clustering methods provide better performance, how to efficiently\ncapture the alternative perspectives in data is still a problem. In this paper,\nwe propose AugDMC, a novel data Augmentation guided Deep Multiple Clustering\nmethod, to tackle the challenge. Specifically, AugDMC leverages data\naugmentations to automatically extract features related to a certain aspect of\nthe data using a self-supervised prototype-based representation learning, where\ndifferent aspects of the data can be preserved under different data\naugmentations. Moreover, a stable optimization strategy is proposed to\nalleviate the unstable problem from different augmentations. Thereafter,\nmultiple clusterings based on different aspects of the data can be obtained.\nExperimental results on three real-world datasets compared with\nstate-of-the-art methods validate the effectiveness of the proposed method.\n","authors":["Jiawei Yao","Enbei Liu","Maham Rashid","Juhua Hu"],"pdf_url":"https://arxiv.org/pdf/2306.13023v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13020v1","updated":"2023-06-22T16:29:46Z","published":"2023-06-22T16:29:46Z","title":"Toward Automated Detection of Microbleeds with Anatomical Scale\n  Localization: A Complete Clinical Diagnosis Support Using Deep Learning","summary":"  Cerebral Microbleeds (CMBs) are chronic deposits of small blood products in\nthe brain tissues, which have explicit relation to various cerebrovascular\ndiseases depending on their anatomical location, including cognitive decline,\nintracerebral hemorrhage, and cerebral infarction. However, manual detection of\nCMBs is a time-consuming and error-prone process because of their sparse and\ntiny structural properties. The detection of CMBs is commonly affected by the\npresence of many CMB mimics that cause a high false-positive rate (FPR), such\nas calcification and pial vessels. This paper proposes a novel 3D deep learning\nframework that does not only detect CMBs but also inform their anatomical\nlocation in the brain (i.e., lobar, deep, and infratentorial regions). For the\nCMB detection task, we propose a single end-to-end model by leveraging the\nU-Net as a backbone with Region Proposal Network (RPN). To significantly reduce\nthe FPs within the same single model, we develop a new scheme, containing\nFeature Fusion Module (FFM) that detects small candidates utilizing contextual\ninformation and Hard Sample Prototype Learning (HSPL) that mines CMB mimics and\ngenerates additional loss term called concentration loss using Convolutional\nPrototype Learning (CPL). The anatomical localization task does not only tell\nto which region the CMBs belong but also eliminate some FPs from the detection\ntask by utilizing anatomical information. The results show that the proposed\nRPN that utilizes the FFM and HSPL outperforms the vanilla RPN and achieves a\nsensitivity of 94.66% vs. 93.33% and an average number of false positives per\nsubject (FPavg) of 0.86 vs. 14.73. Also, the anatomical localization task\nfurther improves the detection performance by reducing the FPavg to 0.56 while\nmaintaining the sensitivity of 94.66%.\n","authors":["Jun-Ho Kim","Young Noh","Haejoon Lee","Seul Lee","Woo-Ram Kim","Koung Mi Kang","Eung Yeop Kim","Mohammed A. Al-masni","Dong-Hyun Kim"],"pdf_url":"https://arxiv.org/pdf/2306.13020v1.pdf","comment":"16 pages, 10 figures,3 tables"},{"id":"http://arxiv.org/abs/2306.12996v1","updated":"2023-06-22T15:52:48Z","published":"2023-06-22T15:52:48Z","title":"Affine Correspondences between Multi-Camera Systems for Relative Pose\n  Estimation","summary":"  We present a novel method to compute the relative pose of multi-camera\nsystems using two affine correspondences (ACs). Existing solutions to the\nmulti-camera relative pose estimation are either restricted to special cases of\nmotion, have too high computational complexity, or require too many point\ncorrespondences (PCs). Thus, these solvers impede an efficient or accurate\nrelative pose estimation when applying RANSAC as a robust estimator. This paper\nshows that the 6DOF relative pose estimation problem using ACs permits a\nfeasible minimal solution, when exploiting the geometric constraints between\nACs and multi-camera systems using a special parameterization. We present a\nproblem formulation based on two ACs that encompass two common types of ACs\nacross two views, i.e., inter-camera and intra-camera. Moreover, the framework\nfor generating the minimal solvers can be extended to solve various relative\npose estimation problems, e.g., 5DOF relative pose estimation with known\nrotation angle prior. Experiments on both virtual and real multi-camera systems\nprove that the proposed solvers are more efficient than the state-of-the-art\nalgorithms, while resulting in a better relative pose accuracy. Source code is\navailable at https://github.com/jizhaox/relpose-mcs-depth.\n","authors":["Banglei Guan","Ji Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.12996v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09360v2","updated":"2023-06-22T15:51:34Z","published":"2022-12-19T10:54:51Z","title":"AI Security for Geoscience and Remote Sensing: Challenges and Future\n  Trends","summary":"  Recent advances in artificial intelligence (AI) have significantly\nintensified research in the geoscience and remote sensing (RS) field. AI\nalgorithms, especially deep learning-based ones, have been developed and\napplied widely to RS data analysis. The successful application of AI covers\nalmost all aspects of Earth observation (EO) missions, from low-level vision\ntasks like super-resolution, denoising and inpainting, to high-level vision\ntasks like scene classification, object detection and semantic segmentation.\nWhile AI techniques enable researchers to observe and understand the Earth more\naccurately, the vulnerability and uncertainty of AI models deserve further\nattention, considering that many geoscience and RS tasks are highly\nsafety-critical. This paper reviews the current development of AI security in\nthe geoscience and RS field, covering the following five important aspects:\nadversarial attack, backdoor attack, federated learning, uncertainty and\nexplainability. Moreover, the potential opportunities and trends are discussed\nto provide insights for future research. To the best of the authors' knowledge,\nthis paper is the first attempt to provide a systematic review of AI\nsecurity-related research in the geoscience and RS community. Available code\nand datasets are also listed in the paper to move this vibrant field of\nresearch forward.\n","authors":["Yonghao Xu","Tao Bai","Weikang Yu","Shizhen Chang","Peter M. Atkinson","Pedram Ghamisi"],"pdf_url":"https://arxiv.org/pdf/2212.09360v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12992v1","updated":"2023-06-22T15:47:58Z","published":"2023-06-22T15:47:58Z","title":"Minimalist and High-Quality Panoramic Imaging with PSF-aware\n  Transformers","summary":"  High-quality panoramic images with a Field of View (FoV) of 360-degree are\nessential for contemporary panoramic computer vision tasks. However,\nconventional imaging systems come with sophisticated lens designs and heavy\noptical components. This disqualifies their usage in many mobile and wearable\napplications where thin and portable, minimalist imaging systems are desired.\nIn this paper, we propose a Panoramic Computational Imaging Engine (PCIE) to\naddress minimalist and high-quality panoramic imaging. With less than three\nspherical lenses, a Minimalist Panoramic Imaging Prototype (MPIP) is\nconstructed based on the design of the Panoramic Annular Lens (PAL), but with\nlow-quality imaging results due to aberrations and small image plane size. We\npropose two pipelines, i.e. Aberration Correction (AC) and Super-Resolution and\nAberration Correction (SR&AC), to solve the image quality problems of MPIP,\nwith imaging sensors of small and large pixel size, respectively. To provide a\nuniversal network for the two pipelines, we leverage the information from the\nPoint Spread Function (PSF) of the optical system and design a PSF-aware\nAberration-image Recovery Transformer (PART), in which the self-attention\ncalculation and feature extraction are guided via PSF-aware mechanisms. We\ntrain PART on synthetic image pairs from simulation and put forward the PALHQ\ndataset to fill the gap of real-world high-quality PAL images for low-level\nvision. A comprehensive variety of experiments on synthetic and real-world\nbenchmarks demonstrates the impressive imaging results of PCIE and the\neffectiveness of plug-and-play PSF-aware mechanisms. We further deliver\nheuristic experimental findings for minimalist and high-quality panoramic\nimaging. Our dataset and code will be available at\nhttps://github.com/zju-jiangqi/PCIE-PART.\n","authors":["Qi Jiang","Shaohua Gao","Yao Gao","Kailun Yang","Zhonghua Yi","Hao Shi","Lei Sun","Kaiwei Wang"],"pdf_url":"https://arxiv.org/pdf/2306.12992v1.pdf","comment":"The dataset and code will be available at\n  https://github.com/zju-jiangqi/PCIE-PART"},{"id":"http://arxiv.org/abs/2306.12988v1","updated":"2023-06-22T15:44:39Z","published":"2023-06-22T15:44:39Z","title":"Can a single image processing algorithm work equally well across all\n  phases of DCE-MRI?","summary":"  Image segmentation and registration are said to be challenging when applied\nto dynamic contrast enhanced MRI sequences (DCE-MRI). The contrast agent causes\nrapid changes in intensity in the region of interest and elsewhere, which can\nlead to false positive predictions for segmentation tasks and confound the\nimage registration similarity metric. While it is widely assumed that contrast\nchanges increase the difficulty of these tasks, to our knowledge no work has\nquantified these effects. In this paper we examine the effect of training with\ndifferent ratios of contrast enhanced (CE) data on two popular tasks:\nsegmentation with nnU-Net and Mask R-CNN and registration using VoxelMorph and\nVTN. We experimented further by strategically using the available datasets\nthrough pretraining and fine tuning with different splits of data. We found\nthat to create a generalisable model, pretraining with CE data and fine tuning\nwith non-CE data gave the best result. This interesting find could be expanded\nto other deep learning based image processing tasks with DCE-MRI and provide\nsignificant improvements to the models performance.\n","authors":["Adam G. Tattersall","Keith A. Goatman","Lucy E. Kershaw","Scott I. K. Semple","Sonia Dahdouh"],"pdf_url":"https://arxiv.org/pdf/2306.12988v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08044v2","updated":"2023-06-22T15:43:40Z","published":"2022-11-15T10:49:49Z","title":"Backdoor Attacks for Remote Sensing Data with Wavelet Transform","summary":"  Recent years have witnessed the great success of deep learning algorithms in\nthe geoscience and remote sensing realm. Nevertheless, the security and\nrobustness of deep learning models deserve special attention when addressing\nsafety-critical remote sensing tasks. In this paper, we provide a systematic\nanalysis of backdoor attacks for remote sensing data, where both scene\nclassification and semantic segmentation tasks are considered. While most of\nthe existing backdoor attack algorithms rely on visible triggers like squared\npatches with well-designed patterns, we propose a novel wavelet transform-based\nattack (WABA) method, which can achieve invisible attacks by injecting the\ntrigger image into the poisoned image in the low-frequency domain. In this way,\nthe high-frequency information in the trigger image can be filtered out in the\nattack, resulting in stealthy data poisoning. Despite its simplicity, the\nproposed method can significantly cheat the current state-of-the-art deep\nlearning models with a high attack success rate. We further analyze how\ndifferent trigger images and the hyper-parameters in the wavelet transform\nwould influence the performance of the proposed method. Extensive experiments\non four benchmark remote sensing datasets demonstrate the effectiveness of the\nproposed method for both scene classification and semantic segmentation tasks\nand thus highlight the importance of designing advanced backdoor defense\nalgorithms to address this threat in remote sensing scenarios. The code will be\navailable online at \\url{https://github.com/ndraeger/waba}.\n","authors":["Nikolaus Dräger","Yonghao Xu","Pedram Ghamisi"],"pdf_url":"https://arxiv.org/pdf/2211.08044v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12983v1","updated":"2023-06-22T15:41:15Z","published":"2023-06-22T15:41:15Z","title":"Towards More Realistic Membership Inference Attacks on Large Diffusion\n  Models","summary":"  Generative diffusion models, including Stable Diffusion and Midjourney, can\ngenerate visually appealing, diverse, and high-resolution images for various\napplications. These models are trained on billions of internet-sourced images,\nraising significant concerns about the potential unauthorized use of\ncopyright-protected images. In this paper, we examine whether it is possible to\ndetermine if a specific image was used in the training set, a problem known in\nthe cybersecurity community and referred to as a membership inference attack.\nOur focus is on Stable Diffusion, and we address the challenge of designing a\nfair evaluation framework to answer this membership question. We propose a\nmethodology to establish a fair evaluation setup and apply it to Stable\nDiffusion, enabling potential extensions to other generative models. Utilizing\nthis evaluation setup, we execute membership attacks (both known and newly\nintroduced). Our research reveals that previously proposed evaluation setups do\nnot provide a full understanding of the effectiveness of membership inference\nattacks. We conclude that the membership inference attack remains a significant\nchallenge for large diffusion models (often deployed as black-box systems),\nindicating that related privacy and copyright issues will persist in the\nforeseeable future.\n","authors":["Jan Dubiński","Antoni Kowalczuk","Stanisław Pawlak","Przemysław Rokita","Tomasz Trzciński","Paweł Morawiecki"],"pdf_url":"https://arxiv.org/pdf/2306.12983v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12941v1","updated":"2023-06-22T14:56:06Z","published":"2023-06-22T14:56:06Z","title":"Robust Semantic Segmentation: Strong Adversarial Attacks and Fast\n  Training of Robust Models","summary":"  While a large amount of work has focused on designing adversarial attacks\nagainst image classifiers, only a few methods exist to attack semantic\nsegmentation models. We show that attacking segmentation models presents\ntask-specific challenges, for which we propose novel solutions. Our final\nevaluation protocol outperforms existing methods, and shows that those can\noverestimate the robustness of the models. Additionally, so far adversarial\ntraining, the most successful way for obtaining robust image classifiers, could\nnot be successfully applied to semantic segmentation. We argue that this is\nbecause the task to be learned is more challenging, and requires significantly\nhigher computational effort than for image classification. As a remedy, we show\nthat by taking advantage of recent advances in robust ImageNet classifiers, one\ncan train adversarially robust segmentation models at limited computational\ncost by fine-tuning robust backbones.\n","authors":["Francesco Croce","Naman D Singh","Matthias Hein"],"pdf_url":"https://arxiv.org/pdf/2306.12941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12939v1","updated":"2023-06-22T14:55:01Z","published":"2023-06-22T14:55:01Z","title":"Feature Mixing for Writer Retrieval and Identification on Papyri\n  Fragments","summary":"  This paper proposes a deep-learning-based approach to writer retrieval and\nidentification for papyri, with a focus on identifying fragments associated\nwith a specific writer and those corresponding to the same image. We present a\nnovel neural network architecture that combines a residual backbone with a\nfeature mixing stage to improve retrieval performance, and the final descriptor\nis derived from a projection layer. The methodology is evaluated on two\nbenchmarks: PapyRow, where we achieve a mAP of 26.6 % and 24.9 % on writer and\npage retrieval, and HisFragIR20, showing state-of-the-art performance (44.0 %\nand 29.3 % mAP). Furthermore, our network has an accuracy of 28.7 % for writer\nidentification. Additionally, we conduct experiments on the influence of two\nbinarization techniques on fragments and show that binarizing does not enhance\nperformance. Our code and models are available to the community.\n","authors":["Marco Peer","Robert Sablatnig"],"pdf_url":"https://arxiv.org/pdf/2306.12939v1.pdf","comment":"accepted for HIP@ICDAR2023"},{"id":"http://arxiv.org/abs/2301.11823v3","updated":"2023-06-22T14:49:03Z","published":"2023-01-27T16:25:28Z","title":"HDPV-SLAM: Hybrid Depth-augmented Panoramic Visual SLAM for Mobile\n  Mapping System with Tilted LiDAR and Panoramic Visual Camera","summary":"  This paper proposes a novel visual simultaneous localization and mapping\n(SLAM) system called Hybrid Depth-augmented Panoramic Visual SLAM (HDPV-SLAM),\nthat employs a panoramic camera and a tilted multi-beam LiDAR scanner to\ngenerate accurate and metrically-scaled trajectories. RGB-D SLAM was the design\nbasis for HDPV-SLAM, which added depth information to visual features. It aims\nto solve the two major issues hindering the performance of similar SLAM\nsystems. The first obstacle is the sparseness of LiDAR depth, which makes it\ndifficult to correlate it with the extracted visual features of the RGB image.\nA deep learning-based depth estimation module for iteratively densifying sparse\nLiDAR depth was suggested to address this issue. The second issue pertains to\nthe difficulties in depth association caused by a lack of horizontal overlap\nbetween the panoramic camera and the tilted LiDAR sensor. To surmount this\ndifficulty, we present a hybrid depth association module that optimally\ncombines depth information estimated by two independent procedures,\nfeature-based triangulation and depth estimation. During a phase of feature\ntracking, this hybrid depth association module aims to maximize the use of more\naccurate depth information between the triangulated depth with visual features\ntracked and the deep learning-based corrected depth. We evaluated the efficacy\nof HDPV-SLAM using the 18.95 km-long York University and Teledyne Optech (YUTO)\nMMS dataset. The experimental results demonstrate that the two proposed modules\ncontribute substantially to the performance of HDPV-SLAM, which surpasses that\nof the state-of-the-art (SOTA) SLAM systems.\n","authors":["Mostafa Ahmadi","Amin Alizadeh Naeini","Mohammad Moein Sheikholeslami","Zahra Arjmandi","Yujia Zhang","Gunho Sohn"],"pdf_url":"https://arxiv.org/pdf/2301.11823v3.pdf","comment":"8 pages, 3 figures, To be published in IEEE International Conference\n  on Automation Science and Engineering (CASE) 2023"},{"id":"http://arxiv.org/abs/2302.06733v2","updated":"2023-06-22T14:44:26Z","published":"2023-02-13T22:45:54Z","title":"Robust Unsupervised StyleGAN Image Restoration","summary":"  GAN-based image restoration inverts the generative process to repair images\ncorrupted by known degradations. Existing unsupervised methods must be\ncarefully tuned for each task and degradation level. In this work, we make\nStyleGAN image restoration robust: a single set of hyperparameters works across\na wide range of degradation levels. This makes it possible to handle\ncombinations of several degradations, without the need to retune. Our proposed\napproach relies on a 3-phase progressive latent space extension and a\nconservative optimizer, which avoids the need for any additional regularization\nterms. Extensive experiments demonstrate robustness on inpainting, upsampling,\ndenoising, and deartifacting at varying degradations levels, outperforming\nother StyleGAN-based inversion techniques. Our approach also favorably compares\nto diffusion-based restoration by yielding much more realistic inversion\nresults. Code is available at https://lvsn.github.io/RobustUnsupervised/.\n","authors":["Yohan Poirier-Ginter","Jean-François Lalonde"],"pdf_url":"https://arxiv.org/pdf/2302.06733v2.pdf","comment":"8 pages, accepted at CVPR 2023"},{"id":"http://arxiv.org/abs/2306.12929v1","updated":"2023-06-22T14:39:04Z","published":"2023-06-22T14:39:04Z","title":"Quantizable Transformers: Removing Outliers by Helping Attention Heads\n  Do Nothing","summary":"  Transformer models have been widely adopted in various domains over the last\nyears, and especially large language models have advanced the field of AI\nsignificantly. Due to their size, the capability of these networks has\nincreased tremendously, but this has come at the cost of a significant increase\nin necessary compute. Quantization is one of the most effective ways to reduce\nthe computational time and memory consumption of neural networks. Many studies\nhave shown, however, that modern transformer models tend to learn strong\noutliers in their activations, making them difficult to quantize. To retain\nacceptable performance, the existence of these outliers requires activations to\nbe in higher bitwidth or the use of different numeric formats, extra\nfine-tuning, or other workarounds. We show that strong outliers are related to\nvery specific behavior of attention heads that try to learn a \"no-op\" or just a\npartial update of the residual. To achieve the exact zeros needed in the\nattention matrix for a no-update, the input to the softmax is pushed to be\nlarger and larger during training, causing outliers in other parts of the\nnetwork. Based on these observations, we propose two simple (independent)\nmodifications to the attention mechanism - clipped softmax and gated attention.\nWe empirically show that models pre-trained using our methods learn\nsignificantly smaller outliers while maintaining and sometimes even improving\nthe floating-point task performance. This enables us to quantize transformers\nto full INT8 quantization of the activations without any additional effort. We\ndemonstrate the effectiveness of our methods on both language models (BERT,\nOPT) and vision transformers.\n","authors":["Yelysei Bondarenko","Markus Nagel","Tijmen Blankevoort"],"pdf_url":"https://arxiv.org/pdf/2306.12929v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12915v1","updated":"2023-06-22T14:30:41Z","published":"2023-06-22T14:30:41Z","title":"Multi-Objective Hull Form Optimization with CAD Engine-based Deep\n  Learning Physics for 3D Flow Prediction","summary":"  In this work, we propose a built-in Deep Learning Physics Optimization (DLPO)\nframework to set up a shape optimization study of the Duisburg Test Case (DTC)\ncontainer vessel. We present two different applications: (1) sensitivity\nanalysis to detect the most promising generic basis hull shapes, and (2)\nmulti-objective optimization to quantify the trade-off between optimal hull\nforms. DLPO framework allows for the evaluation of design iterations\nautomatically in an end-to-end manner. We achieved these results by coupling\nExtrality's Deep Learning Physics (DLP) model to a CAD engine and an optimizer.\nOur proposed DLP model is trained on full 3D volume data coming from RANS\nsimulations, and it can provide accurate and high-quality 3D flow predictions\nin real-time, which makes it a good evaluator to perform optimization of new\ncontainer vessel designs w.r.t the hydrodynamic efficiency. In particular, it\nis able to recover the forces acting on the vessel by integration on the hull\nsurface with a mean relative error of 3.84\\% \\pm 2.179\\% on the total\nresistance. Each iteration takes only 20 seconds, thus leading to a drastic\nsaving of time and engineering efforts, while delivering valuable insight into\nthe performance of the vessel, including RANS-like detailed flow information.\nWe conclude that DLPO framework is a promising tool to accelerate the ship\ndesign process and lead to more efficient ships with better hydrodynamic\nperformance.\n","authors":["Jocelyn Ahmed Mazari","Antoine Reverberi","Pierre Yser","Sebastian Sigmund"],"pdf_url":"https://arxiv.org/pdf/2306.12915v1.pdf","comment":"X International Conference on Computational Methods in Marine\n  Engineering, MARINE 2023, Madrid, Spain"},{"id":"http://arxiv.org/abs/2205.04812v5","updated":"2023-06-22T14:21:56Z","published":"2022-05-10T11:21:18Z","title":"The Impact of Partial Occlusion on Pedestrian Detectability","summary":"  Robust detection of vulnerable road users is a safety critical requirement\nfor the deployment of autonomous vehicles in heterogeneous traffic. One of the\nmost complex outstanding challenges is that of partial occlusion where a target\nobject is only partially available to the sensor due to obstruction by another\nforeground object. A number of leading pedestrian detection benchmarks provide\nannotation for partial occlusion, however each benchmark varies greatly in\ntheir definition of the occurrence and severity of occlusion. Recent research\ndemonstrates that a high degree of subjectivity is used to classify occlusion\nlevel in these cases and occlusion is typically categorized into 2 to 3 broad\ncategories such as partially and heavily occluded. This can lead to inaccurate\nor inconsistent reporting of pedestrian detection model performance depending\non which benchmark is used. This research introduces a novel, objective\nbenchmark for partially occluded pedestrian detection to facilitate the\nobjective characterization of pedestrian detection models. Characterization is\ncarried out on seven popular pedestrian detection models for a range of\nocclusion levels from 0-99%, in order to demonstrate the efficacy and increased\nanalysis capabilities of the proposed characterization method. Results\ndemonstrate that pedestrian detection performance degrades, and the number of\nfalse negative detections increase as pedestrian occlusion level increases. Of\nthe seven popular pedestrian detection routines characterized, CenterNet has\nthe greatest overall performance, followed by SSDlite. RetinaNet has the lowest\noverall detection performance across the range of occlusion levels.\n","authors":["Shane Gilroy","Darragh Mullins","Edward Jones","Ashkan Parsi","Martin Glavin"],"pdf_url":"https://arxiv.org/pdf/2205.04812v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12881v1","updated":"2023-06-22T13:44:40Z","published":"2023-06-22T13:44:40Z","title":"Data-Free Backbone Fine-Tuning for Pruned Neural Networks","summary":"  Model compression techniques reduce the computational load and memory\nconsumption of deep neural networks. After the compression operation, e.g.\nparameter pruning, the model is normally fine-tuned on the original training\ndataset to recover from the performance drop caused by compression. However,\nthe training data is not always available due to privacy issues or other\nfactors. In this work, we present a data-free fine-tuning approach for pruning\nthe backbone of deep neural networks. In particular, the pruned network\nbackbone is trained with synthetically generated images, and our proposed\nintermediate supervision to mimic the unpruned backbone's output feature map.\nAfterwards, the pruned backbone can be combined with the original network head\nto make predictions. We generate synthetic images by back-propagating gradients\nto noise images while relying on L1-pruning for the backbone pruning. In our\nexperiments, we show that our approach is task-independent due to pruning only\nthe backbone. By evaluating our approach on 2D human pose estimation, object\ndetection, and image classification, we demonstrate promising performance\ncompared to the unpruned model. Our code is available at\nhttps://github.com/holzbock/dfbf.\n","authors":["Adrian Holzbock","Achyut Hegde","Klaus Dietmayer","Vasileios Belagiannis"],"pdf_url":"https://arxiv.org/pdf/2306.12881v1.pdf","comment":"Accpeted for presentation at the 31st European Signal Processing\n  Conference (EUSIPCO) 2023, September 4-8, 2023, Helsinki, Finland"},{"id":"http://arxiv.org/abs/2306.12860v1","updated":"2023-06-22T13:14:59Z","published":"2023-06-22T13:14:59Z","title":"Learning from Visual Observation via Offline Pretrained State-to-Go\n  Transformer","summary":"  Learning from visual observation (LfVO), aiming at recovering policies from\nonly visual observation data, is promising yet a challenging problem. Existing\nLfVO approaches either only adopt inefficient online learning schemes or\nrequire additional task-specific information like goal states, making them not\nsuited for open-ended tasks. To address these issues, we propose a two-stage\nframework for learning from visual observation. In the first stage, we\nintroduce and pretrain State-to-Go (STG) Transformer offline to predict and\ndifferentiate latent transitions of demonstrations. Subsequently, in the second\nstage, the STG Transformer provides intrinsic rewards for downstream\nreinforcement learning tasks where an agent learns merely from intrinsic\nrewards. Empirical results on Atari and Minecraft show that our proposed method\noutperforms baselines and in some tasks even achieves performance comparable to\nthe policy learned from environmental rewards. These results shed light on the\npotential of utilizing video-only data to solve difficult visual reinforcement\nlearning tasks rather than relying on complete offline datasets containing\nstates, actions, and rewards. The project's website and code can be found at\nhttps://sites.google.com/view/stgtransformer.\n","authors":["Bohan Zhou","Ke Li","Jiechuan Jiang","Zongqing Lu"],"pdf_url":"https://arxiv.org/pdf/2306.12860v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2202.07731v2","updated":"2023-06-22T12:58:40Z","published":"2022-02-15T21:20:18Z","title":"Enhancing Deformable Convolution based Video Frame Interpolation with\n  Coarse-to-fine 3D CNN","summary":"  This paper presents a new deformable convolution-based video frame\ninterpolation (VFI) method, using a coarse to fine 3D CNN to enhance the\nmulti-flow prediction. This model first extracts spatio-temporal features at\nmultiple scales using a 3D CNN, and estimates multi-flows using these features\nin a coarse-to-fine manner. The estimated multi-flows are then used to warp the\noriginal input frames as well as context maps, and the warped results are fused\nby a synthesis network to produce the final output. This VFI approach has been\nfully evaluated against 12 state-of-the-art VFI methods on three commonly used\ntest databases. The results evidently show the effectiveness of the proposed\nmethod, which offers superior interpolation performance over other state of the\nart algorithms, with PSNR gains up to 0.19dB.\n","authors":["Duolikun Danier","Fan Zhang","David Bull"],"pdf_url":"https://arxiv.org/pdf/2202.07731v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.07727v2","updated":"2023-06-22T12:56:35Z","published":"2022-02-15T21:13:23Z","title":"A Subjective Quality Study for Video Frame Interpolation","summary":"  Video frame interpolation (VFI) is one of the fundamental research areas in\nvideo processing and there has been extensive research on novel and enhanced\ninterpolation algorithms. The same is not true for quality assessment of the\ninterpolated content. In this paper, we describe a subjective quality study for\nVFI based on a newly developed video database, BVI-VFI. BVI-VFI contains 36\nreference sequences at three different frame rates and 180 distorted videos\ngenerated using five conventional and learning based VFI algorithms. Subjective\nopinion scores have been collected from 60 human participants, and then\nemployed to evaluate eight popular quality metrics, including PSNR, SSIM and\nLPIPS which are all commonly used for assessing VFI methods. The results\nindicate that none of these metrics provide acceptable correlation with the\nperceived quality on interpolated content, with the best-performing metric,\nLPIPS, offering a SROCC value below 0.6. Our findings show that there is an\nurgent need to develop a bespoke perceptual quality metric for VFI. The BVI-VFI\ndataset is publicly available and can be accessed at\nhttps://danier97.github.io/BVI-VFI/.\n","authors":["Duolikun Danier","Fan Zhang","David Bull"],"pdf_url":"https://arxiv.org/pdf/2202.07727v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.08119v2","updated":"2023-06-22T12:51:58Z","published":"2022-07-17T09:07:33Z","title":"FloLPIPS: A Bespoke Video Quality Metric for Frame Interpoation","summary":"  Video frame interpolation (VFI) serves as a useful tool for many video\nprocessing applications. Recently, it has also been applied in the video\ncompression domain for enhancing both conventional video codecs and\nlearning-based compression architectures. While there has been an increased\nfocus on the development of enhanced frame interpolation algorithms in recent\nyears, the perceptual quality assessment of interpolated content remains an\nopen field of research. In this paper, we present a bespoke full reference\nvideo quality metric for VFI, FloLPIPS, that builds on the popular perceptual\nimage quality metric, LPIPS, which captures the perceptual degradation in\nextracted image feature space. In order to enhance the performance of LPIPS for\nevaluating interpolated content, we re-designed its spatial feature aggregation\nstep by using the temporal distortion (through comparing optical flows) to\nweight the feature difference maps. Evaluated on the BVI-VFI database, which\ncontains 180 test sequences with various frame interpolation artefacts,\nFloLPIPS shows superior correlation performance (with statistical significance)\nwith subjective ground truth over 12 popular quality assessors. To facilitate\nfurther research in VFI quality assessment, our code is publicly available at\nhttps://danier97.github.io/FloLPIPS.\n","authors":["Duolikun Danier","Fan Zhang","David Bull"],"pdf_url":"https://arxiv.org/pdf/2207.08119v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.06854v2","updated":"2023-06-22T12:33:20Z","published":"2022-06-14T13:49:08Z","title":"On the explainable properties of 1-Lipschitz Neural Networks: An Optimal\n  Transport Perspective","summary":"  Input gradients have a pivotal role in a variety of applications, including\nadversarial attack algorithms for evaluating model robustness, explainable AI\ntechniques for generating Saliency Maps, and counterfactual explanations.\nHowever, Saliency Maps generated by traditional neural networks are often noisy\nand provide limited insights. In this paper, we demonstrate that, on the\ncontrary, the Saliency Maps of 1-Lipschitz neural networks, learnt with the\ndual loss of an optimal transportation problem, exhibit desirable XAI\nproperties: They are highly concentrated on the essential parts of the image\nwith low noise, significantly outperforming state-of-the-art explanation\napproaches across various models and metrics. We also prove that these maps\nalign unprecedentedly well with human explanations on ImageNet. To explain the\nparticularly beneficial properties of the Saliency Map for such models, we\nprove this gradient encodes both the direction of the transportation plan and\nthe direction towards the nearest adversarial attack. Following the gradient\ndown to the decision boundary is no longer considered an adversarial attack,\nbut rather a counterfactual explanation that explicitly transports the input\nfrom one class to another. Thus, Learning with such a loss jointly optimizes\nthe classification objective and the alignment of the gradient , i.e. the\nSaliency Map, to the transportation plan direction. These networks were\npreviously known to be certifiably robust by design, and we demonstrate that\nthey scale well for large problems and models, and are tailored for\nexplainability using a fast and straightforward method.\n","authors":["Mathieu Serrurier","Franck Mamalet","Thomas Fel","Louis Béthune","Thibaut Boissin"],"pdf_url":"https://arxiv.org/pdf/2206.06854v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12217v2","updated":"2023-06-22T12:00:27Z","published":"2023-06-21T12:19:17Z","title":"Lumbar spine segmentation in MR images: a dataset and a public benchmark","summary":"  This paper presents a large publicly available multi-center lumbar spine\nmagnetic resonance imaging (MRI) dataset with reference segmentations of\nvertebrae, intervertebral discs (IVDs), and spinal canal. The dataset includes\n447 sagittal T1 and T2 MRI series from 218 patients with a history of low back\npain. It was collected from four different hospitals and was divided into a\ntraining (179 patients) and validation (39 patients) set. An iterative data\nannotation approach was used by training a segmentation algorithm on a small\npart of the dataset, enabling semi-automatic segmentation of the remaining\nimages. The algorithm provided an initial segmentation, which was subsequently\nreviewed, manually corrected, and added to the training data. We provide\nreference performance values for this baseline algorithm and nnU-Net, which\nperformed comparably. We set up a continuous segmentation challenge to allow\nfor a fair comparison of different segmentation algorithms. This study may\nencourage wider collaboration in the field of spine segmentation, and improve\nthe diagnostic value of lumbar spine MRI.\n","authors":["Jasper W. van der Graaf","Miranda L. van Hooff","Constantinus F. M. Buckens","Matthieu Rutten","Job L. C. van Susante","Robert Jan Kroeze","Marinus de Kleuver","Bram van Ginneken","Nikolas Lessmann"],"pdf_url":"https://arxiv.org/pdf/2306.12217v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2003.07289v5","updated":"2023-06-22T11:55:07Z","published":"2020-03-12T14:52:10Z","title":"VMLoc: Variational Fusion For Learning-Based Multimodal Camera\n  Localization","summary":"  Recent learning-based approaches have achieved impressive results in the\nfield of single-shot camera localization. However, how best to fuse multiple\nmodalities (e.g., image and depth) and to deal with degraded or missing input\nare less well studied. In particular, we note that previous approaches towards\ndeep fusion do not perform significantly better than models employing a single\nmodality. We conjecture that this is because of the naive approaches to feature\nspace fusion through summation or concatenation which do not take into account\nthe different strengths of each modality. To address this, we propose an\nend-to-end framework, termed VMLoc, to fuse different sensor inputs into a\ncommon latent space through a variational Product-of-Experts (PoE) followed by\nattention-based fusion. Unlike previous multimodal variational works directly\nadapting the objective function of vanilla variational auto-encoder, we show\nhow camera localization can be accurately estimated through an unbiased\nobjective function based on importance weighting. Our model is extensively\nevaluated on RGB-D datasets and the results prove the efficacy of our model.\nThe source code is available at https://github.com/kaichen-z/VMLoc.\n","authors":["Kaichen Zhou","Changhao Chen","Bing Wang","Muhamad Risqi U. Saputra","Niki Trigoni","Andrew Markham"],"pdf_url":"https://arxiv.org/pdf/2003.07289v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12816v1","updated":"2023-06-22T11:31:11Z","published":"2023-06-22T11:31:11Z","title":"XAI-TRIS: Non-linear benchmarks to quantify ML explanation performance","summary":"  The field of 'explainable' artificial intelligence (XAI) has produced highly\ncited methods that seek to make the decisions of complex machine learning (ML)\nmethods 'understandable' to humans, for example by attributing 'importance'\nscores to input features. Yet, a lack of formal underpinning leaves it unclear\nas to what conclusions can safely be drawn from the results of a given XAI\nmethod and has also so far hindered the theoretical verification and empirical\nvalidation of XAI methods. This means that challenging non-linear problems,\ntypically solved by deep neural networks, presently lack appropriate remedies.\nHere, we craft benchmark datasets for three different non-linear classification\nscenarios, in which the important class-conditional features are known by\ndesign, serving as ground truth explanations. Using novel quantitative metrics,\nwe benchmark the explanation performance of a wide set of XAI methods across\nthree deep learning model architectures. We show that popular XAI methods are\noften unable to significantly outperform random performance baselines and edge\ndetection methods. Moreover, we demonstrate that explanations derived from\ndifferent model architectures can be vastly different; thus, prone to\nmisinterpretation even under controlled conditions.\n","authors":["Benedict Clark","Rick Wilming","Stefan Haufe"],"pdf_url":"https://arxiv.org/pdf/2306.12816v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2302.07570v3","updated":"2023-06-22T11:13:34Z","published":"2023-02-15T10:21:38Z","title":"Super-Resolution of BVOC Maps by Adapting Deep Learning Methods","summary":"  Biogenic Volatile Organic Compounds (BVOCs) play a critical role in\nbiosphere-atmosphere interactions, being a key factor in the physical and\nchemical properties of the atmosphere and climate. Acquiring large and\nfine-grained BVOC emission maps is expensive and time-consuming, so most\navailable BVOC data are obtained on a loose and sparse sampling grid or on\nsmall regions. However, high-resolution BVOC data are desirable in many\napplications, such as air quality, atmospheric chemistry, and climate\nmonitoring. In this work, we investigate the possibility of enhancing BVOC\nacquisitions, further explaining the relationships between the environment and\nthese compounds. We do so by comparing the performances of several\nstate-of-the-art neural networks proposed for image Super-Resolution (SR),\nadapting them to overcome the challenges posed by the large dynamic range of\nthe emission and reduce the impact of outliers in the prediction. Moreover, we\nalso consider realistic scenarios, considering both temporal and geographical\nconstraints. Finally, we present possible future developments regarding SR\ngeneralization, considering the scale-invariance property and super-resolving\nemissions from unseen compounds.\n","authors":["Antonio Giganti","Sara Mandelli","Paolo Bestagini","Marco Marcon","Stefano Tubaro"],"pdf_url":"https://arxiv.org/pdf/2302.07570v3.pdf","comment":"5 pages, 4 figures, 3 tables, accepted at IEEE-ICIP 2023"},{"id":"http://arxiv.org/abs/2305.14180v3","updated":"2023-06-22T11:03:30Z","published":"2023-05-23T15:58:53Z","title":"Multi-BVOC Super-Resolution Exploiting Compounds Inter-Connection","summary":"  Biogenic Volatile Organic Compounds (BVOCs) emitted from the terrestrial\necosystem into the Earth's atmosphere are an important component of atmospheric\nchemistry. Due to the scarcity of measurement, a reliable enhancement of BVOCs\nemission maps can aid in providing denser data for atmospheric chemical,\nclimate, and air quality models. In this work, we propose a strategy to\nsuper-resolve coarse BVOC emission maps by simultaneously exploiting the\ncontributions of different compounds. To this purpose, we first accurately\ninvestigate the spatial inter-connections between several BVOC species. Then,\nwe exploit the found similarities to build a Multi-Image Super-Resolution\n(MISR) system, in which a number of emission maps associated with diverse\ncompounds are aggregated to boost Super-Resolution (SR) performance. We compare\ndifferent configurations regarding the species and the number of joined BVOCs.\nOur experimental results show that incorporating BVOCs' relationship into the\nprocess can substantially improve the accuracy of the super-resolved maps.\nInterestingly, the best results are achieved when we aggregate the emission\nmaps of strongly uncorrelated compounds. This peculiarity seems to confirm what\nwas already guessed for other data-domains, i.e., joined uncorrelated\ninformation are more helpful than correlated ones to boost MISR performance.\nNonetheless, the proposed work represents the first attempt in SR of BVOC\nemissions through the fusion of multiple different compounds.\n","authors":["Antonio Giganti","Sara Mandelli","Paolo Bestagini","Marco Marcon","Stefano Tubaro"],"pdf_url":"https://arxiv.org/pdf/2305.14180v3.pdf","comment":"5 pages, 4 figures, 1 table, accepted at EURASIP-EUSIPCO 2023"},{"id":"http://arxiv.org/abs/2306.12796v1","updated":"2023-06-22T10:59:15Z","published":"2023-06-22T10:59:15Z","title":"Super-Resolution of BVOC Emission Maps Via Domain Adaptation","summary":"  Enhancing the resolution of Biogenic Volatile Organic Compound (BVOC)\nemission maps is a critical task in remote sensing. Recently, some\nSuper-Resolution (SR) methods based on Deep Learning (DL) have been proposed,\nleveraging data from numerical simulations for their training process. However,\nwhen dealing with data derived from satellite observations, the reconstruction\nis particularly challenging due to the scarcity of measurements to train SR\nalgorithms with. In our work, we aim at super-resolving low resolution emission\nmaps derived from satellite observations by leveraging the information of\nemission maps obtained through numerical simulations. To do this, we combine a\nSR method based on DL with Domain Adaptation (DA) techniques, harmonizing the\ndifferent aggregation strategies and spatial information used in simulated and\nobserved domains to ensure compatibility. We investigate the effectiveness of\nDA strategies at different stages by systematically varying the number of\nsimulated and observed emissions used, exploring the implications of data\nscarcity on the adaptation strategies. To the best of our knowledge, there are\nno prior investigations of DA in satellite-derived BVOC maps enhancement. Our\nwork represents a first step toward the development of robust strategies for\nthe reconstruction of observed BVOC emissions.\n","authors":["Antonio Giganti","Sara Mandelli","Paolo Bestagini","Marco Marcon","Stefano Tubaro"],"pdf_url":"https://arxiv.org/pdf/2306.12796v1.pdf","comment":"4 pages, 4 figures, 1 table, accepted at IEEE-IGARSS 2023"},{"id":"http://arxiv.org/abs/2306.12795v1","updated":"2023-06-22T10:53:10Z","published":"2023-06-22T10:53:10Z","title":"Learning Unseen Modality Interaction","summary":"  Multimodal learning assumes all modality combinations of interest are\navailable during training to learn cross-modal correspondences. In this paper,\nwe challenge this modality-complete assumption for multimodal learning and\ninstead strive for generalization to unseen modality combinations during\ninference. We pose the problem of unseen modality interaction and introduce a\nfirst solution. It exploits a feature projection module to project the\nmultidimensional features of different modalities into a common space with rich\ninformation reserved. This allows the information to be accumulated with a\nsimple summation operation across available modalities. To reduce overfitting\nto unreliable modality combinations during training, we further improve the\nmodel learning with pseudo-supervision indicating the reliability of a\nmodality's prediction. We demonstrate that our approach is effective for\ndiverse tasks and modalities by evaluating it for multimodal video\nclassification, robot state regression, and multimedia retrieval.\n","authors":["Yunhua Zhang","Hazel Doughty","Cees G. M. Snoek"],"pdf_url":"https://arxiv.org/pdf/2306.12795v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2306.12790v1","updated":"2023-06-22T10:45:49Z","published":"2023-06-22T10:45:49Z","title":"DiffWA: Diffusion Models for Watermark Attack","summary":"  With the rapid development of deep neural networks(DNNs), many robust blind\nwatermarking algorithms and frameworks have been proposed and achieved good\nresults. At present, the watermark attack algorithm can not compete with the\nwatermark addition algorithm. And many watermark attack algorithms only care\nabout interfering with the normal extraction of the watermark, and the\nwatermark attack will cause great visual loss to the image. To this end, we\npropose DiffWA, a conditional diffusion model with distance guidance for\nwatermark attack, which can restore the image while removing the embedded\nwatermark. The core of our method is training an image-to-image conditional\ndiffusion model on unwatermarked images and guiding the conditional model using\na distance guidance when sampling so that the model will generate unwatermarked\nimages which is similar to original images. We conducted experiments on\nCIFAR-10 using our proposed models. The results shows that the model can remove\nthe watermark with good effect and make the bit error rate of watermark\nextraction higher than 0.4. At the same time, the attacked image will maintain\ngood visual effect with PSNR more than 31 and SSIM more than 0.97 compared with\nthe original image.\n","authors":["Xinyu Li"],"pdf_url":"https://arxiv.org/pdf/2306.12790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01721v2","updated":"2023-06-22T10:23:36Z","published":"2023-06-02T17:47:01Z","title":"Denoising Diffusion Semantic Segmentation with Mask Prior Modeling","summary":"  The evolution of semantic segmentation has long been dominated by learning\nmore discriminative image representations for classifying each pixel. Despite\nthe prominent advancements, the priors of segmentation masks themselves, e.g.,\ngeometric and semantic constraints, are still under-explored. In this paper, we\npropose to ameliorate the semantic segmentation quality of existing\ndiscriminative approaches with a mask prior modeled by a recently-developed\ndenoising diffusion generative model. Beginning with a unified architecture\nthat adapts diffusion models for mask prior modeling, we focus this work on a\nspecific instantiation with discrete diffusion and identify a variety of key\ndesign choices for its successful application. Our exploratory analysis\nrevealed several important findings, including: (1) a simple integration of\ndiffusion models into semantic segmentation is not sufficient, and a\npoorly-designed diffusion process might lead to degradation in segmentation\nperformance; (2) during the training, the object to which noise is added is\nmore important than the type of noise; (3) during the inference, the strict\ndiffusion denoising scheme may not be essential and can be relaxed to a simpler\nscheme that even works better. We evaluate the proposed prior modeling with\nseveral off-the-shelf segmentors, and our experimental results on ADE20K and\nCityscapes demonstrate that our approach could achieve competitively\nquantitative performance and more appealing visual quality.\n","authors":["Zeqiang Lai","Yuchen Duan","Jifeng Dai","Ziheng Li","Ying Fu","Hongsheng Li","Yu Qiao","Wenhai Wang"],"pdf_url":"https://arxiv.org/pdf/2306.01721v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11710v2","updated":"2023-06-22T10:15:48Z","published":"2023-06-20T17:39:24Z","title":"Data-Driven but Privacy-Conscious: Pedestrian Dataset De-identification\n  via Full-Body Person Synthesis","summary":"  The advent of data-driven technology solutions is accompanied by an\nincreasing concern with data privacy. This is of particular importance for\nhuman-centered image recognition tasks, such as pedestrian detection,\nre-identification, and tracking. To highlight the importance of privacy issues\nand motivate future research, we motivate and introduce the Pedestrian Dataset\nDe-Identification (PDI) task. PDI evaluates the degree of de-identification and\ndownstream task training performance for a given de-identification method. As a\nfirst baseline, we propose IncogniMOT, a two-stage full-body de-identification\npipeline based on image synthesis via generative adversarial networks. The\nfirst stage replaces target pedestrians with synthetic identities. To improve\ndownstream task performance, we then apply stage two, which blends and adapts\nthe synthetic image parts into the data. To demonstrate the effectiveness of\nIncogniMOT, we generate a fully de-identified version of the MOT17 pedestrian\ntracking dataset and analyze its application as training data for pedestrian\nre-identification, detection, and tracking models. Furthermore, we show how our\ndata is able to narrow the synthetic-to-real performance gap in a\nprivacy-conscious manner.\n","authors":["Maxim Maximov","Tim Meinhardt","Ismail Elezi","Zoe Papakipos","Caner Hazirbas","Cristian Canton Ferrer","Laura Leal-Taixé"],"pdf_url":"https://arxiv.org/pdf/2306.11710v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12770v1","updated":"2023-06-22T09:49:28Z","published":"2023-06-22T09:49:28Z","title":"3D Reconstruction of Spherical Images based on Incremental Structure\n  from Motion","summary":"  3D reconstruction plays an increasingly important role in modern\nphotogrammetric systems. Conventional satellite or aerial-based remote sensing\n(RS) platforms can provide the necessary data sources for the 3D reconstruction\nof large-scale landforms and cities. Even with low-altitude UAVs (Unmanned\nAerial Vehicles), 3D reconstruction in complicated situations, such as urban\ncanyons and indoor scenes, is challenging due to the frequent tracking failures\nbetween camera frames and high data collection costs. Recently, spherical\nimages have been extensively exploited due to the capability of recording\nsurrounding environments from one camera exposure. Classical 3D reconstruction\npipelines, however, cannot be used for spherical images. Besides, there exist\nfew software packages for 3D reconstruction of spherical images. Based on the\nimaging geometry of spherical cameras, this study investigates the algorithms\nfor the relative orientation using spherical correspondences, absolute\norientation using 3D correspondences between scene and spherical points, and\nthe cost functions for BA (bundle adjustment) optimization. In addition, an\nincremental SfM (Structure from Motion) workflow has been proposed for\nspherical images using the above-mentioned algorithms. The proposed solution is\nfinally verified by using three spherical datasets captured by both\nconsumer-grade and professional spherical cameras. The results demonstrate that\nthe proposed SfM workflow can achieve the successful 3D reconstruction of\ncomplex scenes and provide useful clues for the implementation in open-source\nsoftware packages. The source code of the designed SfM workflow would be made\npublicly available.\n","authors":["San Jiang","Kan You","Yaxin Li","Duojie Weng","Wu Chen"],"pdf_url":"https://arxiv.org/pdf/2306.12770v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12760v1","updated":"2023-06-22T09:34:55Z","published":"2023-06-22T09:34:55Z","title":"Blended-NeRF: Zero-Shot Object Generation and Blending in Existing\n  Neural Radiance Fields","summary":"  Editing a local region or a specific object in a 3D scene represented by a\nNeRF is challenging, mainly due to the implicit nature of the scene\nrepresentation. Consistently blending a new realistic object into the scene\nadds an additional level of difficulty. We present Blended-NeRF, a robust and\nflexible framework for editing a specific region of interest in an existing\nNeRF scene, based on text prompts or image patches, along with a 3D ROI box.\nOur method leverages a pretrained language-image model to steer the synthesis\ntowards a user-provided text prompt or image patch, along with a 3D MLP model\ninitialized on an existing NeRF scene to generate the object and blend it into\na specified region in the original scene. We allow local editing by localizing\na 3D ROI box in the input scene, and seamlessly blend the content synthesized\ninside the ROI with the existing scene using a novel volumetric blending\ntechnique. To obtain natural looking and view-consistent results, we leverage\nexisting and new geometric priors and 3D augmentations for improving the visual\nfidelity of the final result.\n  We test our framework both qualitatively and quantitatively on a variety of\nreal 3D scenes and text prompts, demonstrating realistic multi-view consistent\nresults with much flexibility and diversity compared to the baselines. Finally,\nwe show the applicability of our framework for several 3D editing applications,\nincluding adding new objects to a scene, removing/replacing/altering existing\nobjects, and texture conversion.\n","authors":["Ori Gordon","Omri Avrahami","Dani Lischinski"],"pdf_url":"https://arxiv.org/pdf/2306.12760v1.pdf","comment":"14 pages, 12 figures. Project page:\n  https://www.vision.huji.ac.il/blended-nerf/"},{"id":"http://arxiv.org/abs/2306.12757v1","updated":"2023-06-22T09:21:48Z","published":"2023-06-22T09:21:48Z","title":"Restoration of the JPEG Maximum Lossy Compressed Face Images with\n  Hourglass Block based on Early Stopping Discriminator","summary":"  When a JPEG image is compressed using the loss compression method with a high\ncompression rate, a blocking phenomenon can occur in the image, making it\nnecessary to restore the image to its original quality. In particular,\nrestoring compressed images that are unrecognizable presents an innovative\nchallenge. Therefore, this paper aims to address the restoration of JPEG images\nthat have suffered significant loss due to maximum compression using a\nGAN-based net-work method. The generator in this network is based on the U-Net\narchitecture and features a newly presented hourglass structure that can\npreserve the charac-teristics of deep layers. Additionally, the network\nincorporates two loss functions, LF Loss and HF Loss, to generate natural and\nhigh-performance images. HF Loss uses a pretrained VGG-16 network and is\nconfigured using a specific layer that best represents features, which can\nenhance performance for the high-frequency region. LF Loss, on the other hand,\nis used to handle the low-frequency region. These two loss functions facilitate\nthe generation of images by the generator that can deceive the discriminator\nwhile accurately generating both high and low-frequency regions. The results\nshow that the blocking phe-nomenon in lost compressed images was removed, and\nrecognizable identities were generated. This study represents a significant\nimprovement over previous research in terms of image restoration performance.\n","authors":["Jongwook Si","Sungyoung Kim"],"pdf_url":"https://arxiv.org/pdf/2306.12757v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12737v1","updated":"2023-06-22T08:36:17Z","published":"2023-06-22T08:36:17Z","title":"Ladder Fine-tuning approach for SAM integrating complementary network","summary":"  Recently, foundation models have been introduced demonstrating various tasks\nin the field of computer vision. These models such as Segment Anything Model\n(SAM) are generalized models trained using huge datasets. Currently, ongoing\nresearch focuses on exploring the effective utilization of these generalized\nmodels for specific domains, such as medical imaging. However, in medical\nimaging, the lack of training samples due to privacy concerns and other factors\npresents a major challenge for applying these generalized models to medical\nimage segmentation task. To address this issue, the effective fine tuning of\nthese models is crucial to ensure their optimal utilization. In this study, we\npropose to combine a complementary Convolutional Neural Network (CNN) along\nwith the standard SAM network for medical image segmentation. To reduce the\nburden of fine tuning large foundation model and implement cost-efficient\ntrainnig scheme, we focus only on fine-tuning the additional CNN network and\nSAM decoder part. This strategy significantly reduces trainnig time and\nachieves competitive results on publicly available dataset. The code is\navailable at https://github.com/11yxk/SAM-LST.\n","authors":["Shurong Chai","Rahul Kumar Jain","Shiyu Teng","Jiaqing Liu","Yinhao Li","Tomoko Tateyama","Yen-wei Chen"],"pdf_url":"https://arxiv.org/pdf/2306.12737v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.04474v3","updated":"2023-06-22T06:44:57Z","published":"2023-05-08T05:53:30Z","title":"Vision Language Pre-training by Contrastive Learning with Cross-Modal\n  Similarity Regulation","summary":"  Cross-modal contrastive learning in vision language pretraining (VLP) faces\nthe challenge of (partial) false negatives. In this paper, we study this\nproblem from the perspective of Mutual Information (MI) optimization. It is\ncommon sense that InfoNCE loss used in contrastive learning will maximize the\nlower bound of MI between anchors and their positives, while we theoretically\nprove that MI involving negatives also matters when noises commonly exist.\nGuided by a more general lower bound form for optimization, we propose a\ncontrastive learning strategy regulated by progressively refined cross-modal\nsimilarity, to more accurately optimize MI between an image/text anchor and its\nnegative texts/images instead of improperly minimizing it. Our method performs\ncompetitively on four downstream cross-modal tasks and systematically balances\nthe beneficial and harmful effects of (partial) false negative samples under\ntheoretical guidance.\n","authors":["Chaoya Jiang","Wei Ye","Haiyang Xu","Miang yan","Shikun Zhang","Jie Zhang","Fei Huang"],"pdf_url":"https://arxiv.org/pdf/2305.04474v3.pdf","comment":"Accepted by ACL2023"},{"id":"http://arxiv.org/abs/2211.16193v2","updated":"2023-06-22T06:29:25Z","published":"2022-11-28T12:20:49Z","title":"In-Hand 3D Object Scanning from an RGB Sequence","summary":"  We propose a method for in-hand 3D scanning of an unknown object with a\nmonocular camera. Our method relies on a neural implicit surface representation\nthat captures both the geometry and the appearance of the object, however, by\ncontrast with most NeRF-based methods, we do not assume that the camera-object\nrelative poses are known. Instead, we simultaneously optimize both the object\nshape and the pose trajectory. As direct optimization over all shape and pose\nparameters is prone to fail without coarse-level initialization, we propose an\nincremental approach that starts by splitting the sequence into carefully\nselected overlapping segments within which the optimization is likely to\nsucceed. We reconstruct the object shape and track its poses independently\nwithin each segment, then merge all the segments before performing a global\noptimization. We show that our method is able to reconstruct the shape and\ncolor of both textured and challenging texture-less objects, outperforms\nclassical methods that rely only on appearance features, and that its\nperformance is close to recent methods that assume known camera poses.\n","authors":["Shreyas Hampali","Tomas Hodan","Luan Tran","Lingni Ma","Cem Keskin","Vincent Lepetit"],"pdf_url":"https://arxiv.org/pdf/2211.16193v2.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2306.12686v1","updated":"2023-06-22T06:18:29Z","published":"2023-06-22T06:18:29Z","title":"FlowFace++: Explicit Semantic Flow-supervised End-to-End Face Swapping","summary":"  This work proposes a novel face-swapping framework FlowFace++, utilizing\nexplicit semantic flow supervision and end-to-end architecture to facilitate\nshape-aware face-swapping. Specifically, our work pretrains a facial shape\ndiscriminator to supervise the face swapping network. The discriminator is\nshape-aware and relies on a semantic flow-guided operation to explicitly\ncalculate the shape discrepancies between the target and source faces, thus\noptimizing the face swapping network to generate highly realistic results. The\nface swapping network is a stack of a pre-trained face-masked autoencoder\n(MAE), a cross-attention fusion module, and a convolutional decoder. The MAE\nprovides a fine-grained facial image representation space, which is unified for\nthe target and source faces and thus facilitates final realistic results. The\ncross-attention fusion module carries out the source-to-target face swapping in\na fine-grained latent space while preserving other attributes of the target\nimage (e.g. expression, head pose, hair, background, illumination, etc).\nLastly, the convolutional decoder further synthesizes the swapping results\naccording to the face-swapping latent embedding from the cross-attention fusion\nmodule. Extensive quantitative and qualitative experiments on in-the-wild faces\ndemonstrate that our FlowFace++ outperforms the state-of-the-art significantly,\nparticularly while the source face is obstructed by uneven lighting or angle\noffset.\n","authors":["Yu Zhang","Hao Zeng","Bowen Ma","Wei Zhang","Zhimeng Zhang","Yu Ding","Tangjie Lv","Changjie Fan"],"pdf_url":"https://arxiv.org/pdf/2306.12686v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12685v1","updated":"2023-06-22T06:12:23Z","published":"2023-06-22T06:12:23Z","title":"Rethinking the Backward Propagation for Adversarial Transferability","summary":"  Transfer-based attacks generate adversarial examples on the surrogate model,\nwhich can mislead other black-box models without any access, making it\npromising to attack real-world applications. Recently, several works have been\nproposed to boost adversarial transferability, in which the surrogate model is\nusually overlooked. In this work, we identify that non-linear layers (e.g.,\nReLU, max-pooling, etc.) truncate the gradient during backward propagation,\nmaking the gradient w.r.t.input image imprecise to the loss function. We\nhypothesize and empirically validate that such truncation undermines the\ntransferability of adversarial examples. Based on these findings, we propose a\nnovel method called Backward Propagation Attack (BPA) to increase the relevance\nbetween the gradient w.r.t. input image and loss function so as to generate\nadversarial examples with higher transferability. Specifically, BPA adopts a\nnon-monotonic function as the derivative of ReLU and incorporates softmax with\ntemperature to smooth the derivative of max-pooling, thereby mitigating the\ninformation loss during the backward propagation of gradients. Empirical\nresults on the ImageNet dataset demonstrate that not only does our method\nsubstantially boost the adversarial transferability, but it also is general to\nexisting transfer-based attacks.\n","authors":["Xiaosen Wang","Kangheng Tong","Kun He"],"pdf_url":"https://arxiv.org/pdf/2306.12685v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2306.12681v1","updated":"2023-06-22T05:55:53Z","published":"2023-06-22T05:55:53Z","title":"One at A Time: Multi-step Volumetric Probability Distribution Diffusion\n  for Depth Estimation","summary":"  Recent works have explored the fundamental role of depth estimation in\nmulti-view stereo (MVS) and semantic scene completion (SSC). They generally\nconstruct 3D cost volumes to explore geometric correspondence in depth, and\nestimate such volumes in a single step relying directly on the ground truth\napproximation. However, such problem cannot be thoroughly handled in one step\ndue to complex empirical distributions, especially in challenging regions like\nocclusions, reflections, etc. In this paper, we formulate the depth estimation\ntask as a multi-step distribution approximation process, and introduce a new\nparadigm of modeling the Volumetric Probability Distribution progressively\n(step-by-step) following a Markov chain with Diffusion models (VPDD).\nSpecifically, to constrain the multi-step generation of volume in VPDD, we\nconstruct a meta volume guidance and a confidence-aware contextual guidance as\nconditional geometry priors to facilitate the distribution approximation. For\nthe sampling process, we further investigate an online filtering strategy to\nmaintain consistency in volume representations for stable training. Experiments\ndemonstrate that our plug-and-play VPDD outperforms the state-of-the-arts for\ntasks of MVS and SSC, and can also be easily extended to different baselines to\nget improvement. It is worth mentioning that we are the first camera-based work\nthat surpasses LiDAR-based methods on the SemanticKITTI dataset.\n","authors":["Bohan Li","Jingxin Dong","Yunnan Wang","Jinming Liu","Lianying Yin","Wei Zhao","Zheng Zhu","Xin Jin","Wenjun Zeng"],"pdf_url":"https://arxiv.org/pdf/2306.12681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07778v5","updated":"2023-06-22T05:44:39Z","published":"2022-09-16T08:10:17Z","title":"Spatial-then-Temporal Self-Supervised Learning for Video Correspondence","summary":"  In low-level video analyses, effective representations are important to\nderive the correspondences between video frames. These representations have\nbeen learned in a self-supervised fashion from unlabeled images or videos,\nusing carefully designed pretext tasks in some recent studies. However, the\nprevious work concentrates on either spatial-discriminative features or\ntemporal-repetitive features, with little attention to the synergy between\nspatial and temporal cues. To address this issue, we propose a\nspatial-then-temporal self-supervised learning method. Specifically, we firstly\nextract spatial features from unlabeled images via contrastive learning, and\nsecondly enhance the features by exploiting the temporal cues in unlabeled\nvideos via reconstructive learning. In the second step, we design a global\ncorrelation distillation loss to ensure the learning not to forget the spatial\ncues, and a local correlation distillation loss to combat the temporal\ndiscontinuity that harms the reconstruction. The proposed method outperforms\nthe state-of-the-art self-supervised methods, as established by the\nexperimental results on a series of correspondence-based video analysis tasks.\nAlso, we performed ablation studies to verify the effectiveness of the two-step\ndesign as well as the distillation losses.\n","authors":["Rui Li","Dong Liu"],"pdf_url":"https://arxiv.org/pdf/2209.07778v5.pdf","comment":"CVPR 2023. Code and models are available at\n  https://github.com/qianduoduolr/Spa-then-Temp"},{"id":"http://arxiv.org/abs/2306.10756v2","updated":"2023-06-22T05:19:53Z","published":"2023-06-19T08:00:28Z","title":"A HRNet-based Rehabilitation Monitoring System","summary":"  The rehabilitation treatment helps to heal minor sports and occupational\ninjuries. In a traditional rehabilitation process, a therapist will assign\ncertain actions to a patient to perform in between hospital visits, and it will\nrely on the patient to remember actions correctly and the schedule to perform\nthem. Unfortunately, many patients forget to perform actions or fail to recall\nactions in detail. As a consequence, the rehabilitation treatment is hampered\nor, in the worst case, the patient may suffer from additional injury caused by\nperforming incorrect actions. To resolve these issues, we propose a HRNet-based\nrehabilitation monitoring system, which can remind a patient when to perform\nthe actions and display the actions for the patient to follow via the patient's\nsmartphone. In addition, it helps the therapist to monitor the progress of the\nrehabilitation for the patient. Our system consists of an iOS app and several\ncomponents at the server side. The app is in charge of displaying and\ncollecting action videos. The server computes the similarity score between the\ntherapist's actions and the patient's in the videos to keep track of the number\nof repetitions of each action. Theses stats will be shown to both of the\npatient and therapist. The extensive experiments show that the F1-Score of the\nsimilarity calculation is as high as 0.9 and the soft accuracy of the number of\nrepetitions is higher than 90%.\n","authors":["Yi-Ching Hung","Yu-Qing Jiang","Fong-Syuan Liou","Yu-Hsuan Tsao","Zi-Cing Chiang","MIn-Te Sun"],"pdf_url":"https://arxiv.org/pdf/2306.10756v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02936v4","updated":"2023-06-22T05:17:53Z","published":"2023-03-06T07:10:07Z","title":"UniHCP: A Unified Model for Human-Centric Perceptions","summary":"  Human-centric perceptions (e.g., pose estimation, human parsing, pedestrian\ndetection, person re-identification, etc.) play a key role in industrial\napplications of visual models. While specific human-centric tasks have their\nown relevant semantic aspect to focus on, they also share the same underlying\nsemantic structure of the human body. However, few works have attempted to\nexploit such homogeneity and design a general-propose model for human-centric\ntasks. In this work, we revisit a broad range of human-centric tasks and unify\nthem in a minimalist manner. We propose UniHCP, a Unified Model for\nHuman-Centric Perceptions, which unifies a wide range of human-centric tasks in\na simplified end-to-end manner with the plain vision transformer architecture.\nWith large-scale joint training on 33 human-centric datasets, UniHCP can\noutperform strong baselines on several in-domain and downstream tasks by direct\nevaluation. When adapted to a specific task, UniHCP achieves new SOTAs on a\nwide range of human-centric tasks, e.g., 69.8 mIoU on CIHP for human parsing,\n86.18 mA on PA-100K for attribute prediction, 90.3 mAP on Market1501 for ReID,\nand 85.8 JI on CrowdHuman for pedestrian detection, performing better than\nspecialized models tailored for each task.\n","authors":["Yuanzheng Ci","Yizhou Wang","Meilin Chen","Shixiang Tang","Lei Bai","Feng Zhu","Rui Zhao","Fengwei Yu","Donglian Qi","Wanli Ouyang"],"pdf_url":"https://arxiv.org/pdf/2303.02936v4.pdf","comment":"Accepted for publication at the IEEE/CVF Conference on Computer\n  Vision and Pattern Recognition 2023 (CVPR 2023)"},{"id":"http://arxiv.org/abs/2306.12673v1","updated":"2023-06-22T05:16:58Z","published":"2023-06-22T05:16:58Z","title":"Identifying and Disentangling Spurious Features in Pretrained Image\n  Representations","summary":"  Neural networks employ spurious correlations in their predictions, resulting\nin decreased performance when these correlations do not hold. Recent works\nsuggest fixing pretrained representations and training a classification head\nthat does not use spurious features. We investigate how spurious features are\nrepresented in pretrained representations and explore strategies for removing\ninformation about spurious features. Considering the Waterbirds dataset and a\nfew pretrained representations, we find that even with full knowledge of\nspurious features, their removal is not straightforward due to entangled\nrepresentation. To address this, we propose a linear autoencoder training\nmethod to separate the representation into core, spurious, and other features.\nWe propose two effective spurious feature removal approaches that are applied\nto the encoding and significantly improve classification performance measured\nby worst group accuracy.\n","authors":["Rafayel Darbinyan","Hrayr Harutyunyan","Aram H. Markosyan","Hrant Khachatrian"],"pdf_url":"https://arxiv.org/pdf/2306.12673v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11207v2","updated":"2023-06-22T05:01:16Z","published":"2023-06-20T00:14:47Z","title":"Quilt-1M: One Million Image-Text Pairs for Histopathology","summary":"  Recent accelerations in multi-modal applications have been made possible with\nthe plethora of image and text data available online. However, the scarcity of\nanalogous data in the medical field, specifically in histopathology, has halted\ncomparable progress. To enable similar representation learning for\nhistopathology, we turn to YouTube, an untapped resource of videos, offering\n$1,087$ hours of valuable educational histopathology videos from expert\nclinicians. From YouTube, we curate Quilt: a large-scale vision-language\ndataset consisting of $768,826$ image and text pairs. Quilt was automatically\ncurated using a mixture of models, including large language models, handcrafted\nalgorithms, human knowledge databases, and automatic speech recognition. In\ncomparison, the most comprehensive datasets curated for histopathology amass\nonly around $200$K samples. We combine Quilt with datasets from other sources,\nincluding Twitter, research papers, and the internet in general, to create an\neven larger dataset: Quilt-1M, with $1$M paired image-text samples, marking it\nas the largest vision-language histopathology dataset to date. We demonstrate\nthe value of Quilt-1M by fine-tuning a pre-trained CLIP model. Our model\noutperforms state-of-the-art models on both zero-shot and linear probing tasks\nfor classifying new histopathology images across $13$ diverse patch-level\ndatasets of $8$ different sub-pathologies and cross-modal retrieval tasks.\n","authors":["Wisdom Oluchi Ikezogwo","Mehmet Saygin Seyfioglu","Fatemeh Ghezloo","Dylan Stefan Chan Geva","Fatwir Sheikh Mohammed","Pavan Kumar Anand","Ranjay Krishna","Linda Shapiro"],"pdf_url":"https://arxiv.org/pdf/2306.11207v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12652v1","updated":"2023-06-22T03:41:47Z","published":"2023-06-22T03:41:47Z","title":"Hand Pose Estimation with Mems-Ultrasonic Sensors","summary":"  Hand tracking is an important aspect of human-computer interaction and has a\nwide range of applications in extended reality devices. However, current hand\nmotion capture methods suffer from various limitations. For instance,\nvisual-based hand pose estimation is susceptible to self-occlusion and changes\nin lighting conditions, while IMU-based tracking gloves experience significant\ndrift and are not resistant to external magnetic field interference. To address\nthese issues, we propose a novel and low-cost hand-tracking glove that utilizes\nseveral MEMS-ultrasonic sensors attached to the fingers, to measure the\ndistance matrix among the sensors. Our lightweight deep network then\nreconstructs the hand pose from the distance matrix. Our experimental results\ndemonstrate that this approach is both accurate, size-agnostic, and robust to\nexternal interference. We also show the design logic for the sensor selection,\nsensor configurations, circuit diagram, as well as model architecture.\n","authors":["Qiang Zhang","Yuanqiao Lin","Yubin Lin","Szymon Rusinkiewicz"],"pdf_url":"https://arxiv.org/pdf/2306.12652v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12651v1","updated":"2023-06-22T03:35:09Z","published":"2023-06-22T03:35:09Z","title":"Curriculum Knowledge Switching for Pancreas Segmentation","summary":"  Pancreas segmentation is challenging due to the small proportion and highly\nchangeable anatomical structure. It motivates us to propose a novel\nsegmentation framework, namely Curriculum Knowledge Switching (CKS) framework,\nwhich decomposes detecting pancreas into three phases with different difficulty\nextent: straightforward, difficult, and challenging. The framework switches\nfrom straightforward to challenging phases and thereby gradually learns to\ndetect pancreas. In addition, we adopt the momentum update parameter updating\nmechanism during switching, ensuring the loss converges gradually when the\ninput dataset changes. Experimental results show that different neural network\nbackbones with the CKS framework achieved state-of-the-art performance on the\nNIH dataset as measured by the DSC metric.\n","authors":["Yumou Tang","Kun Zhan","Zhibo Tian","Mingxuan Zhang","Saisai Wang","Xueming Wen"],"pdf_url":"https://arxiv.org/pdf/2306.12651v1.pdf","comment":"ICIP 2023"},{"id":"http://arxiv.org/abs/2306.10286v3","updated":"2023-06-22T03:20:02Z","published":"2023-06-17T07:58:44Z","title":"Enlighten Anything: When Segment Anything Model Meets Low-Light Image\n  Enhancement","summary":"  Image restoration is a low-level visual task, and most CNN methods are\ndesigned as black boxes, lacking transparency and intrinsic aesthetics. Many\nunsupervised approaches ignore the degradation of visible information in\nlow-light scenes, which will seriously affect the aggregation of complementary\ninformation and also make the fusion algorithm unable to produce satisfactory\nfusion results under extreme conditions. In this paper, we propose\nEnlighten-anything, which is able to enhance and fuse the semantic intent of\nSAM segmentation with low-light images to obtain fused images with good visual\nperception. The generalization ability of unsupervised learning is greatly\nimproved, and experiments on LOL dataset are conducted to show that our method\nimproves 3db in PSNR over baseline and 8 in SSIM. Zero-shot learning of SAM\nintroduces a powerful aid for unsupervised low-light enhancement. The source\ncode of Enlighten Anything can be obtained from\nhttps://github.com/zhangbaijin/enlighten-anything\n","authors":["Qihan Zhao","Xiaofeng Zhang","Hao Tang","Chaochen Gu","Shanying Zhu"],"pdf_url":"https://arxiv.org/pdf/2306.10286v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12646v1","updated":"2023-06-22T03:08:42Z","published":"2023-06-22T03:08:42Z","title":"Learnability and Algorithm for Continual Learning","summary":"  This paper studies the challenging continual learning (CL) setting of Class\nIncremental Learning (CIL). CIL learns a sequence of tasks consisting of\ndisjoint sets of concepts or classes. At any time, a single model is built that\ncan be applied to predict/classify test instances of any classes learned thus\nfar without providing any task related information for each test instance.\nAlthough many techniques have been proposed for CIL, they are mostly empirical.\nIt has been shown recently that a strong CIL system needs a strong within-task\nprediction (WP) and a strong out-of-distribution (OOD) detection for each task.\nHowever, it is still not known whether CIL is actually learnable. This paper\nshows that CIL is learnable. Based on the theory, a new CIL algorithm is also\nproposed. Experimental results demonstrate its effectiveness.\n","authors":["Gyuhak Kim","Changnan Xiao","Tatsuya Konishi","Bing Liu"],"pdf_url":"https://arxiv.org/pdf/2306.12646v1.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2306.12642v1","updated":"2023-06-22T03:00:24Z","published":"2023-06-22T03:00:24Z","title":"TaCA: Upgrading Your Visual Foundation Model with Task-agnostic\n  Compatible Adapter","summary":"  Visual foundation models like CLIP excel in learning feature representations\nfrom extensive datasets through self-supervised methods, demonstrating\nremarkable transfer learning and generalization capabilities. A growing number\nof applications based on visual foundation models are emerging, including\ninnovative solutions such as BLIP-2. These applications employ pre-trained CLIP\nmodels as upstream feature extractors and train various downstream modules to\naccomplish diverse tasks. In situations involving system upgrades that require\nupdating the upstream foundation model, it becomes essential to re-train all\ndownstream modules to adapt to the new foundation model, which is inflexible\nand inefficient. In this paper, we introduce a parameter-efficient and\ntask-agnostic adapter, dubbed TaCA, that facilitates compatibility across\ndistinct foundation models while ensuring enhanced performance for the new\nmodels. TaCA allows downstream applications to seamlessly integrate\nbetter-performing foundation models without necessitating retraining. We\nconduct extensive experimental validation of TaCA using different scales of\nmodels with up to one billion parameters on various tasks such as video-text\nretrieval, video recognition, and visual question answering. The results\nconsistently demonstrate the emergent ability of TaCA on hot-plugging upgrades\nfor visual foundation models. Codes and models will be available at\nhttps://github.com/TencentARC/TaCA.\n","authors":["Binjie Zhang","Yixiao Ge","Xuyuan Xu","Ying Shan","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2306.12642v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.14720v2","updated":"2023-06-22T02:36:06Z","published":"2023-05-24T04:51:04Z","title":"BLIP-Diffusion: Pre-trained Subject Representation for Controllable\n  Text-to-Image Generation and Editing","summary":"  Subject-driven text-to-image generation models create novel renditions of an\ninput subject based on text prompts. Existing models suffer from lengthy\nfine-tuning and difficulties preserving the subject fidelity. To overcome these\nlimitations, we introduce BLIP-Diffusion, a new subject-driven image generation\nmodel that supports multimodal control which consumes inputs of subject images\nand text prompts. Unlike other subject-driven generation models, BLIP-Diffusion\nintroduces a new multimodal encoder which is pre-trained to provide subject\nrepresentation. We first pre-train the multimodal encoder following BLIP-2 to\nproduce visual representation aligned with the text. Then we design a subject\nrepresentation learning task which enables a diffusion model to leverage such\nvisual representation and generates new subject renditions. Compared with\nprevious methods such as DreamBooth, our model enables zero-shot subject-driven\ngeneration, and efficient fine-tuning for customized subject with up to 20x\nspeedup. We also demonstrate that BLIP-Diffusion can be flexibly combined with\nexisting techniques such as ControlNet and prompt-to-prompt to enable novel\nsubject-driven generation and editing applications. Code and models will be\nreleased at\nhttps://github.com/salesforce/LAVIS/tree/main/projects/blip-diffusion. Project\npage at https://dxli94.github.io/BLIP-Diffusion-website/.\n","authors":["Dongxu Li","Junnan Li","Steven C. H. Hoi"],"pdf_url":"https://arxiv.org/pdf/2305.14720v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12634v1","updated":"2023-06-22T02:18:56Z","published":"2023-06-22T02:18:56Z","title":"Efficient quantum image representation and compression circuit using\n  zero-discarded state preparation approach","summary":"  Quantum image computing draws a lot of attention due to storing and\nprocessing image data faster than classical. With increasing the image size,\nthe number of connections also increases, leading to the circuit complex.\nTherefore, efficient quantum image representation and compression issues are\nstill challenging. The encoding of images for representation and compression in\nquantum systems is different from classical ones. In quantum, encoding of\nposition is more concerned which is the major difference from the classical. In\nthis paper, a novel zero-discarded state connection novel enhance quantum\nrepresentation (ZSCNEQR) approach is introduced to reduce complexity further by\ndiscarding '0' in the location representation information. In the control\noperational gate, only input '1' contribute to its output thus, discarding zero\nmakes the proposed ZSCNEQR circuit more efficient. The proposed ZSCNEQR\napproach significantly reduced the required bit for both representation and\ncompression. The proposed method requires 11.76\\% less qubits compared to the\nrecent existing method. The results show that the proposed approach is highly\neffective for representing and compressing images compared to the two relevant\nexisting methods in terms of rate-distortion performance.\n","authors":["Md Ershadul Haque","Manoranjan Paul","Anwaar Ulhaq","Tanmoy Debnath"],"pdf_url":"https://arxiv.org/pdf/2306.12634v1.pdf","comment":"7 figures"},{"id":"http://arxiv.org/abs/2212.10535v2","updated":"2023-06-22T01:37:02Z","published":"2022-12-20T18:46:16Z","title":"A Survey of Deep Learning for Mathematical Reasoning","summary":"  Mathematical reasoning is a fundamental aspect of human intelligence and is\napplicable in various fields, including science, engineering, finance, and\neveryday life. The development of artificial intelligence (AI) systems capable\nof solving math problems and proving theorems has garnered significant interest\nin the fields of machine learning and natural language processing. For example,\nmathematics serves as a testbed for aspects of reasoning that are challenging\nfor powerful deep learning models, driving new algorithmic and modeling\nadvances. On the other hand, recent advances in large-scale neural language\nmodels have opened up new benchmarks and opportunities to use deep learning for\nmathematical reasoning. In this survey paper, we review the key tasks,\ndatasets, and methods at the intersection of mathematical reasoning and deep\nlearning over the past decade. We also evaluate existing benchmarks and\nmethods, and discuss future research directions in this domain.\n","authors":["Pan Lu","Liang Qiu","Wenhao Yu","Sean Welleck","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2212.10535v2.pdf","comment":"Accepted to ACL 2023. The repository is available at\n  https://github.com/lupantech/dl4math"},{"id":"http://arxiv.org/abs/2306.12627v1","updated":"2023-06-22T01:33:47Z","published":"2023-06-22T01:33:47Z","title":"Targeted collapse regularized autoencoder for anomaly detection: black\n  hole at the center","summary":"  Autoencoders have been extensively used in the development of recent anomaly\ndetection techniques. The premise of their application is based on the notion\nthat after training the autoencoder on normal training data, anomalous inputs\nwill exhibit a significant reconstruction error. Consequently, this enables a\nclear differentiation between normal and anomalous samples. In practice,\nhowever, it is observed that autoencoders can generalize beyond the normal\nclass and achieve a small reconstruction error on some of the anomalous\nsamples. To improve the performance, various techniques propose additional\ncomponents and more sophisticated training procedures. In this work, we propose\na remarkably straightforward alternative: instead of adding neural network\ncomponents, involved computations, and cumbersome training, we complement the\nreconstruction loss with a computationally light term that regulates the norm\nof representations in the latent space. The simplicity of our approach\nminimizes the requirement for hyperparameter tuning and customization for new\napplications which, paired with its permissive data modality constraint,\nenhances the potential for successful adoption across a broad range of\napplications. We test the method on various visual and tabular benchmarks and\ndemonstrate that the technique matches and frequently outperforms alternatives.\nWe also provide a theoretical analysis and numerical simulations that help\ndemonstrate the underlying process that unfolds during training and how it can\nhelp with anomaly detection. This mitigates the black-box nature of\nautoencoder-based anomaly detection algorithms and offers an avenue for further\ninvestigation of advantages, fail cases, and potential new directions.\n","authors":["Amin Ghafourian","Huanyi Shui","Devesh Upadhyay","Rajesh Gupta","Dimitar Filev","Iman Soltani Bozchalooi"],"pdf_url":"https://arxiv.org/pdf/2306.12627v1.pdf","comment":"16 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2306.12626v1","updated":"2023-06-22T01:32:30Z","published":"2023-06-22T01:32:30Z","title":"1st Place Solution to MultiEarth 2023 Challenge on Multimodal SAR-to-EO\n  Image Translation","summary":"  The Multimodal Learning for Earth and Environment Workshop (MultiEarth 2023)\naims to harness the substantial amount of remote sensing data gathered over\nextensive periods for the monitoring and analysis of Earth's ecosystems'health.\nThe subtask, Multimodal SAR-to-EO Image Translation, involves the use of robust\nSAR data, even under adverse weather and lighting conditions, transforming it\ninto high-quality, clear, and visually appealing EO data. In the context of the\nSAR2EO task, the presence of clouds or obstructions in EO data can potentially\npose a challenge. To address this issue, we propose the Clean Collector\nAlgorithm (CCA), designed to take full advantage of this cloudless SAR data and\neliminate factors that may hinder the data learning process. Subsequently, we\napplied pix2pixHD for the SAR-to-EO translation and Restormer for image\nenhancement. In the final evaluation, the team 'CDRL' achieved an MAE of\n0.07313, securing the top rank on the leaderboard.\n","authors":["Jingi Ju","Hyeoncheol Noh","Minwoo Kim","Dong-Geol Choi"],"pdf_url":"https://arxiv.org/pdf/2306.12626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12174v2","updated":"2023-06-22T01:31:10Z","published":"2023-06-21T11:09:48Z","title":"OphGLM: Training an Ophthalmology Large Language-and-Vision Assistant\n  based on Instructions and Dialogue","summary":"  Large multimodal language models (LMMs) have achieved significant success in\ngeneral domains. However, due to the significant differences between medical\nimages and text and general web content, the performance of LMMs in medical\nscenarios is limited. In ophthalmology, clinical diagnosis relies on multiple\nmodalities of medical images, but unfortunately, multimodal ophthalmic large\nlanguage models have not been explored to date. In this paper, we study and\nconstruct an ophthalmic large multimodal model. Firstly, we use fundus images\nas an entry point to build a disease assessment and diagnosis pipeline to\nachieve common ophthalmic disease diagnosis and lesion segmentation. Then, we\nestablish a new ophthalmic multimodal instruction-following and dialogue\nfine-tuning dataset based on disease-related knowledge data and publicly\navailable real-world medical dialogue. We introduce visual ability into the\nlarge language model to complete the ophthalmic large language and vision\nassistant (OphGLM). Our experimental results demonstrate that the OphGLM model\nperforms exceptionally well, and it has the potential to revolutionize clinical\napplications in ophthalmology. The dataset, code, and models will be made\npublicly available at https://github.com/ML-AILab/OphGLM.\n","authors":["Weihao Gao","Zhuo Deng","Zhiyuan Niu","Fuju Rong","Chucheng Chen","Zheng Gong","Wenze Zhang","Daimin Xiao","Fang Li","Zhenjie Cao","Zhaoyi Ma","Wenbin Wei","Lan Ma"],"pdf_url":"https://arxiv.org/pdf/2306.12174v2.pdf","comment":"OphGLM:The first ophthalmology large language-and-vision assistant\n  based on instructions and dialogue"},{"id":"http://arxiv.org/abs/2306.12624v1","updated":"2023-06-22T01:29:06Z","published":"2023-06-22T01:29:06Z","title":"DreamEdit: Subject-driven Image Editing","summary":"  Subject-driven image generation aims at generating images containing\ncustomized subjects, which has recently drawn enormous attention from the\nresearch community. However, the previous works cannot precisely control the\nbackground and position of the target subject. In this work, we aspire to fill\nthe void and propose two novel subject-driven sub-tasks, i.e., Subject\nReplacement and Subject Addition. The new tasks are challenging in multiple\naspects: replacing a subject with a customized one can change its shape,\ntexture, and color, while adding a target subject to a designated position in a\nprovided scene necessitates a context-aware posture. To conquer these two novel\ntasks, we first manually curate a new dataset DreamEditBench containing 22\ndifferent types of subjects, and 440 source images with different difficulty\nlevels. We plan to host DreamEditBench as a platform and hire trained\nevaluators for standard human evaluation. We also devise an innovative method\nDreamEditor to resolve these tasks by performing iterative generation, which\nenables a smooth adaptation to the customized subject. In this project, we\nconduct automatic and human evaluations to understand the performance of\nDreamEditor and baselines on DreamEditBench. For Subject Replacement, we found\nthat the existing models are sensitive to the shape and color of the original\nsubject. The model failure rate will dramatically increase when the source and\ntarget subjects are highly different. For Subject Addition, we found that the\nexisting models cannot easily blend the customized subjects into the background\nsmoothly, leading to noticeable artifacts in the generated image. We hope\nDreamEditBench can become a standard platform to enable future investigations\ntoward building more controllable subject-driven image editing. Our project\nhomepage is https://dreameditbenchteam.github.io/.\n","authors":["Tianle Li","Max Ku","Cong Wei","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2306.12624v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12621v1","updated":"2023-06-22T01:27:00Z","published":"2023-06-22T01:27:00Z","title":"RXFOOD: Plug-in RGB-X Fusion for Object of Interest Detection","summary":"  The emergence of different sensors (Near-Infrared, Depth, etc.) is a remedy\nfor the limited application scenarios of traditional RGB camera. The RGB-X\ntasks, which rely on RGB input and another type of data input to resolve\nspecific problems, have become a popular research topic in multimedia. A\ncrucial part in two-branch RGB-X deep neural networks is how to fuse\ninformation across modalities. Given the tremendous information inside RGB-X\nnetworks, previous works typically apply naive fusion (e.g., average or max\nfusion) or only focus on the feature fusion at the same scale(s). While in this\npaper, we propose a novel method called RXFOOD for the fusion of features\nacross different scales within the same modality branch and from different\nmodality branches simultaneously in a unified attention mechanism. An Energy\nExchange Module is designed for the interaction of each feature map's energy\nmatrix, who reflects the inter-relationship of different positions and\ndifferent channels inside a feature map. The RXFOOD method can be easily\nincorporated to any dual-branch encoder-decoder network as a plug-in module,\nand help the original backbone network better focus on important positions and\nchannels for object of interest detection. Experimental results on RGB-NIR\nsalient object detection, RGB-D salient object detection, and RGBFrequency\nimage manipulation detection demonstrate the clear effectiveness of the\nproposed RXFOOD.\n","authors":["Jin Ma","Jinlong Li","Qing Guo","Tianyun Zhang","Yuewei Lin","Hongkai Yu"],"pdf_url":"https://arxiv.org/pdf/2306.12621v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2306.10311v2","updated":"2023-06-22T01:24:03Z","published":"2023-06-17T10:10:15Z","title":"Efficient HDR Reconstruction from Real-World Raw Images","summary":"  High dynamic range (HDR) imaging is still a significant yet challenging\nproblem due to the limited dynamic range of generic image sensors. Most\nexisting learning-based HDR reconstruction methods take a set of\nbracketed-exposure sRGB images to extend the dynamic range, and thus are\ncomputational- and memory-inefficient by requiring the Image Signal Processor\n(ISP) to produce multiple sRGB images from the raw ones. In this paper, we\npropose to broaden the dynamic range from the raw inputs and perform only one\nISP processing for the reconstructed HDR raw image. Our key insights are\nthreefold: (1) we design a new computational raw HDR data formation pipeline\nand construct the first real-world raw HDR dataset, RealRaw-HDR; (2) we develop\na lightweight-efficient HDR model, RepUNet, using the structural\nre-parameterization technique; (3) we propose a plug-and-play motion alignment\nloss to mitigate motion misalignment between short- and long-exposure images.\nExtensive experiments demonstrate that our approach achieves state-of-the-art\nperformance in both visual quality and quantitative metrics.\n","authors":["Qirui Yang","Yihao Liu","Jingyu Yang"],"pdf_url":"https://arxiv.org/pdf/2306.10311v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12610v1","updated":"2023-06-22T00:13:44Z","published":"2023-06-22T00:13:44Z","title":"Revisiting Image Classifier Training for Improved Certified Robust\n  Defense against Adversarial Patches","summary":"  Certifiably robust defenses against adversarial patches for image classifiers\nensure correct prediction against any changes to a constrained neighborhood of\npixels. PatchCleanser arXiv:2108.09135 [cs.CV], the state-of-the-art certified\ndefense, uses a double-masking strategy for robust classification. The success\nof this strategy relies heavily on the model's invariance to image pixel\nmasking. In this paper, we take a closer look at model training schemes to\nimprove this invariance. Instead of using Random Cutout arXiv:1708.04552v2\n[cs.CV] augmentations like PatchCleanser, we introduce the notion of worst-case\nmasking, i.e., selecting masked images which maximize classification loss.\nHowever, finding worst-case masks requires an exhaustive search, which might be\nprohibitively expensive to do on-the-fly during training. To solve this\nproblem, we propose a two-round greedy masking strategy (Greedy Cutout) which\nfinds an approximate worst-case mask location with much less compute. We show\nthat the models trained with our Greedy Cutout improves certified robust\naccuracy over Random Cutout in PatchCleanser across a range of datasets and\narchitectures. Certified robust accuracy on ImageNet with a ViT-B16-224 model\nincreases from 58.1\\% to 62.3\\% against a 3\\% square patch applied anywhere on\nthe image.\n","authors":["Aniruddha Saha","Shuhua Yu","Arash Norouzzadeh","Wan-Yi Lin","Chaithanya Kumar Mummadi"],"pdf_url":"https://arxiv.org/pdf/2306.12610v1.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.06876v2","updated":"2023-06-22T00:00:40Z","published":"2023-03-13T05:51:35Z","title":"Revisiting model self-interpretability in a decision-theoretic way for\n  binary medical image classification","summary":"  Interpretability is highly desired for deep neural network-based classifiers,\nespecially when addressing high-stake decisions in medical imaging. Commonly\nused post-hoc interpretability methods have the limitation that they can\nproduce plausible but different interpretations of a given model, leading to\nambiguity about which one to choose. To address this problem, a novel\ndecision-theory-motivated approach is investigated to establish a\nself-interpretable model, given a pretrained deep binary black-box medical\nimage classifier. This approach involves utilizing a self-interpretable\nencoder-decoder model in conjunction with a single-layer fully connected\nnetwork with unity weights. The model is trained to estimate the test statistic\nof the given trained black-box deep binary classifier to maintain a similar\naccuracy. The decoder output image, referred to as an equivalency map, is an\nimage that represents a transformed version of the to-be-classified image that,\nwhen processed by the fixed fully connected layer, produces the same test\nstatistic value as the original classifier. The equivalency map provides a\nvisualization of the transformed image features that directly contribute to the\ntest statistic value and, moreover, permits quantification of their relative\ncontributions. Unlike the traditional post-hoc interpretability methods, the\nproposed method is self-interpretable, quantitative, and fundamentally based on\ndecision theory. Detailed quantitative and qualitative analysis have been\nperformed with three different medical image binary classification tasks.\n","authors":["Sourya Sengupta","Mark A. Anastasio"],"pdf_url":"https://arxiv.org/pdf/2303.06876v2.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2306.13050v1","updated":"2023-06-22T17:17:45Z","published":"2023-06-22T17:17:45Z","title":"Data augmentation for recommender system: A semi-supervised approach\n  using maximum margin matrix factorization","summary":"  Collaborative filtering (CF) has become a popular method for developing\nrecommender systems (RS) where ratings of a user for new items is predicted\nbased on her past preferences and available preference information of other\nusers. Despite the popularity of CF-based methods, their performance is often\ngreatly limited by the sparsity of observed entries. In this study, we explore\nthe data augmentation and refinement aspects of Maximum Margin Matrix\nFactorization (MMMF), a widely accepted CF technique for the rating\npredictions, which have not been investigated before. We exploit the inherent\ncharacteristics of CF algorithms to assess the confidence level of individual\nratings and propose a semi-supervised approach for rating augmentation based on\nself-training. We hypothesize that any CF algorithm's predictions with low\nconfidence are due to some deficiency in the training data and hence, the\nperformance of the algorithm can be improved by adopting a systematic data\naugmentation strategy. We iteratively use some of the ratings predicted with\nhigh confidence to augment the training data and remove low-confidence entries\nthrough a refinement process. By repeating this process, the system learns to\nimprove prediction accuracy. Our method is experimentally evaluated on several\nstate-of-the-art CF algorithms and leads to informative rating augmentation,\nimproving the performance of the baseline approaches.\n","authors":["Shamal Shaikh","Venkateswara Rao Kagita","Vikas Kumar","Arun K Pujari"],"pdf_url":"https://arxiv.org/pdf/2306.13050v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2306.12857v1","updated":"2023-06-22T13:08:42Z","published":"2023-06-22T13:08:42Z","title":"Efficient Partitioning Method of Large-Scale Public Safety\n  Spatio-Temporal Data based on Information Loss Constraints","summary":"  The storage, management, and application of massive spatio-temporal data are\nwidely applied in various practical scenarios, including public safety.\nHowever, due to the unique spatio-temporal distribution characteristics of\nre-al-world data, most existing methods have limitations in terms of the\nspatio-temporal proximity of data and load balancing in distributed storage.\nThere-fore, this paper proposes an efficient partitioning method of large-scale\npublic safety spatio-temporal data based on information loss constraints\n(IFL-LSTP). The IFL-LSTP model specifically targets large-scale spatio-temporal\npoint da-ta by combining the spatio-temporal partitioning module (STPM) with\nthe graph partitioning module (GPM). This approach can significantly reduce the\nscale of data while maintaining the model's accuracy, in order to improve the\npartitioning efficiency. It can also ensure the load balancing of distributed\nstorage while maintaining spatio-temporal proximity of the data partitioning\nresults. This method provides a new solution for distributed storage of\nmas-sive spatio-temporal data. The experimental results on multiple real-world\nda-tasets demonstrate the effectiveness and superiority of IFL-LSTP.\n","authors":["Jie Gao","Yawen Li","Zhe Xue","Zeli Guan"],"pdf_url":"https://arxiv.org/pdf/2306.12857v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12800v1","updated":"2023-06-22T10:59:58Z","published":"2023-06-22T10:59:58Z","title":"HypeRS: Building a Hypergraph-driven ensemble Recommender System","summary":"  Recommender systems are designed to predict user preferences over collections\nof items. These systems process users' previous interactions to decide which\nitems should be ranked higher to satisfy their desires. An ensemble recommender\nsystem can achieve great recommendation performance by effectively combining\nthe decisions generated by individual models. In this paper, we propose a novel\nensemble recommender system that combines predictions made by different models\ninto a unified hypergraph ranking framework. This is the first time that\nhypergraph ranking has been employed to model an ensemble of recommender\nsystems. Hypergraphs are generalizations of graphs where multiple vertices can\nbe connected via hyperedges, efficiently modeling high-order relations. We\ndifferentiate real and predicted connections between users and items by\nassigning different hyperedge weights to individual recommender systems. We\nperform experiments using four datasets from the fields of movie, music and\nnews media recommendation. The obtained results show that the ensemble\nhypergraph ranking method generates more accurate recommendations compared to\nthe individual models and a weighted hybrid approach. The assignment of\ndifferent hyperedge weights to the ensemble hypergraph further improves the\nperformance compared to a setting with identical hyperedge weights.\n","authors":["Alireza Gharahighehi","Celine Vens","Konstantinos Pliakos"],"pdf_url":"https://arxiv.org/pdf/2306.12800v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.04541v2","updated":"2023-06-22T10:50:37Z","published":"2023-04-10T12:25:10Z","title":"Sequential Recommendation with Diffusion Models","summary":"  Generative models, such as Variational Auto-Encoder (VAE) and Generative\nAdversarial Network (GAN), have been successfully applied in sequential\nrecommendation. These methods require sampling from probability distributions\nand adopt auxiliary loss functions to optimize the model, which can capture the\nuncertainty of user behaviors and alleviate exposure bias. However, existing\ngenerative models still suffer from the posterior collapse problem or the model\ncollapse problem, thus limiting their applications in sequential\nrecommendation. To tackle the challenges mentioned above, we leverage a new\nparadigm of the generative models, i.e., diffusion models, and present\nsequential recommendation with diffusion models (DiffRec), which can avoid the\nissues of VAE- and GAN-based models and show better performance. While\ndiffusion models are originally proposed to process continuous image data, we\ndesign an additional transition in the forward process together with a\ntransition in the reverse process to enable the processing of the discrete\nrecommendation data. We also design a different noising strategy that only\nnoises the target item instead of the whole sequence, which is more suitable\nfor sequential recommendation. Based on the modified diffusion process, we\nderive the objective function of our framework using a simplification technique\nand design a denoise sequential recommender to fulfill the objective function.\nAs the lengthened diffusion steps substantially increase the time complexity,\nwe propose an efficient training strategy and an efficient inference strategy\nto reduce training and inference cost and improve recommendation diversity.\nExtensive experiment results on three public benchmark datasets verify the\neffectiveness of our approach and show that DiffRec outperforms the\nstate-of-the-art sequential recommendation models.\n","authors":["Hanwen Du","Huanhuan Yuan","Zhen Huang","Pengpeng Zhao","Xiaofang Zhou"],"pdf_url":"https://arxiv.org/pdf/2304.04541v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.04101v4","updated":"2023-06-22T09:49:18Z","published":"2023-05-06T17:15:27Z","title":"SRTK: A Toolkit for Semantic-relevant Subgraph Retrieval","summary":"  Information retrieval based knowledge base question answering (KBQA) first\nretrieves a subgraph to reduce search space, then reasons on the subgraph to\nselect answer entities. Existing approaches have three issues that impede the\nretrieval of such subgraphs. Firstly, there is no off-the-shelf toolkit for\nsemantic-relevant subgraph retrieval. Secondly, existing methods are\nknowledge-graph-dependent, resulting in outdated knowledge graphs used even in\nrecent studies. Thirdly, previous solutions fail to incorporate the best\navailable techniques for entity linking or path expansion. In this paper, we\npresent SRTK, a user-friendly toolkit for semantic-relevant subgraph retrieval\nfrom large-scale knowledge graphs. SRTK is the first toolkit that streamlines\nthe entire lifecycle of subgraph retrieval across multiple knowledge graphs.\nAdditionally, it comes with state-of-the-art subgraph retrieval algorithms,\nguaranteeing an up-to-date solution set out of the box.\n","authors":["Yuanchun Shen"],"pdf_url":"https://arxiv.org/pdf/2305.04101v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12756v1","updated":"2023-06-22T09:18:52Z","published":"2023-06-22T09:18:52Z","title":"On the Robustness of Generative Retrieval Models: An Out-of-Distribution\n  Perspective","summary":"  Recently, we have witnessed generative retrieval increasingly gaining\nattention in the information retrieval (IR) field, which retrieves documents by\ndirectly generating their identifiers. So far, much effort has been devoted to\ndeveloping effective generative retrieval models. There has been less attention\npaid to the robustness perspective. When a new retrieval paradigm enters into\nthe real-world application, it is also critical to measure the\nout-of-distribution (OOD) generalization, i.e., how would generative retrieval\nmodels generalize to new distributions. To answer this question, firstly, we\ndefine OOD robustness from three perspectives in retrieval problems: 1) The\nquery variations; 2) The unforeseen query types; and 3) The unforeseen tasks.\nBased on this taxonomy, we conduct empirical studies to analyze the OOD\nrobustness of several representative generative retrieval models against dense\nretrieval models. The empirical results indicate that the OOD robustness of\ngenerative retrieval models requires enhancement. We hope studying the OOD\nrobustness of generative retrieval models would be advantageous to the IR\ncommunity.\n","authors":["Yu-An Liu","Ruqing Zhang","Jiafeng Guo","Wei Chen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2306.12756v1.pdf","comment":"4 pages, submit to GenIR23"},{"id":"http://arxiv.org/abs/2306.12689v1","updated":"2023-06-22T06:23:31Z","published":"2023-06-22T06:23:31Z","title":"Vec2Vec: A Compact Neural Network Approach for Transforming Text\n  Embeddings with High Fidelity","summary":"  Vector embeddings have become ubiquitous tools for many language-related\ntasks. A leading embedding model is OpenAI's text-ada-002 which can embed\napproximately 6,000 words into a 1,536-dimensional vector. While powerful,\ntext-ada-002 is not open source and is only available via API. We trained a\nsimple neural network to convert open-source 768-dimensional MPNet embeddings\ninto text-ada-002 embeddings. We compiled a subset of 50,000 online food\nreviews. We calculated MPNet and text-ada-002 embeddings for each review and\ntrained a simple neural network to for 75 epochs. The neural network was\ndesigned to predict the corresponding text-ada-002 embedding for a given MPNET\nembedding. Our model achieved an average cosine similarity of 0.932 on 10,000\nunseen reviews in our held-out test dataset. We manually assessed the quality\nof our predicted embeddings for vector search over text-ada-002-embedded\nreviews. While not as good as real text-ada-002 embeddings, predicted\nembeddings were able to retrieve highly relevant reviews. Our final model,\nVec2Vec, is lightweight (<80 MB) and fast. Future steps include training a\nneural network with a more sophisticated architecture and a larger dataset of\npaired embeddings to achieve greater performance. The ability to convert\nbetween and align embedding spaces may be helpful for interoperability,\nlimiting dependence on proprietary models, protecting data privacy, reducing\ncosts, and offline operations.\n","authors":["Andrew Kean Gao"],"pdf_url":"https://arxiv.org/pdf/2306.12689v1.pdf","comment":"14 pages, 6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2306.12680v1","updated":"2023-06-22T05:51:49Z","published":"2023-06-22T05:51:49Z","title":"Recent Developments in Recommender Systems: A Survey","summary":"  In this technical survey, we comprehensively summarize the latest\nadvancements in the field of recommender systems. The objective of this study\nis to provide an overview of the current state-of-the-art in the field and\nhighlight the latest trends in the development of recommender systems. The\nstudy starts with a comprehensive summary of the main taxonomy of recommender\nsystems, including personalized and group recommender systems, and then delves\ninto the category of knowledge-based recommender systems. In addition, the\nsurvey analyzes the robustness, data bias, and fairness issues in recommender\nsystems, summarizing the evaluation metrics used to assess the performance of\nthese systems. Finally, the study provides insights into the latest trends in\nthe development of recommender systems and highlights the new directions for\nfuture research in the field.\n","authors":["Yang Li","Kangbo Liu","Ranjan Satapathy","Suhang Wang","Erik Cambria"],"pdf_url":"https://arxiv.org/pdf/2306.12680v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.02572v2","updated":"2023-06-22T03:41:43Z","published":"2023-04-05T16:44:36Z","title":"Evaluating Online Bandit Exploration In Large-Scale Recommender System","summary":"  Bandit learning has been an increasingly popular design choice for\nrecommender system. Despite the strong interest in bandit learning from the\ncommunity, there remains multiple bottlenecks that prevent many bandit learning\napproaches from productionalization. One major bottleneck is how to test the\neffectiveness of bandit algorithm with fairness and without data leakage.\nDifferent from supervised learning algorithms, bandit learning algorithms\nemphasize greatly on the data collection process through their explorative\nnature. Such explorative behavior may induce unfair evaluation in a classic A/B\ntest setting. In this work, we apply upper confidence bound (UCB) to our large\nscale short video recommender system and present a test framework for the\nproduction bandit learning life-cycle with a new set of metrics. Extensive\nexperiment results show that our experiment design is able to fairly evaluate\nthe performance of bandit learning in the recommender system.\n","authors":["Hongbo Guo","Ruben Naeff","Alex Nikulkov","Zheqing Zhu"],"pdf_url":"https://arxiv.org/pdf/2304.02572v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.08808v2","updated":"2023-06-22T02:16:24Z","published":"2023-06-15T01:51:06Z","title":"ReLoop2: Building Self-Adaptive Recommendation Models via Responsive\n  Error Compensation Loop","summary":"  Industrial recommender systems face the challenge of operating in\nnon-stationary environments, where data distribution shifts arise from evolving\nuser behaviors over time. To tackle this challenge, a common approach is to\nperiodically re-train or incrementally update deployed deep models with newly\nobserved data, resulting in a continual training process. However, the\nconventional learning paradigm of neural networks relies on iterative\ngradient-based updates with a small learning rate, making it slow for large\nrecommendation models to adapt. In this paper, we introduce ReLoop2, a\nself-correcting learning loop that facilitates fast model adaptation in online\nrecommender systems through responsive error compensation. Inspired by the\nslow-fast complementary learning system observed in human brains, we propose an\nerror memory module that directly stores error samples from incoming data\nstreams. These stored samples are subsequently leveraged to compensate for\nmodel prediction errors during testing, particularly under distribution shifts.\nThe error memory module is designed with fast access capabilities and undergoes\ncontinual refreshing with newly observed data samples during the model serving\nphase to support fast model adaptation. We evaluate the effectiveness of\nReLoop2 on three open benchmark datasets as well as a real-world production\ndataset. The results demonstrate the potential of ReLoop2 in enhancing the\nresponsiveness and adaptiveness of recommender systems operating in\nnon-stationary environments.\n","authors":["Jieming Zhu","Guohao Cai","Junjie Huang","Zhenhua Dong","Ruiming Tang","Weinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.08808v2.pdf","comment":"Accepted by KDD 2023. See the project page at\n  https://xpai.github.io/ReLoop"},{"id":"http://arxiv.org/abs/2306.13186v1","updated":"2023-06-22T20:03:09Z","published":"2023-06-22T20:03:09Z","title":"A Decade of Scholarly Research on Open Knowledge Graphs","summary":"  The proliferation of open knowledge graphs has led to a surge in scholarly\nresearch on the topic over the past decade. This paper presents a bibliometric\nanalysis of the scholarly literature on open knowledge graphs published between\n2013 and 2023. The study aims to identify the trends, patterns, and impact of\nresearch in this field, as well as the key topics and research questions that\nhave emerged. The work uses bibliometric techniques to analyze a sample of 4445\nscholarly articles retrieved from Scopus. The findings reveal an\never-increasing number of publications on open knowledge graphs published every\nyear, particularly in developed countries (+50 per year). These outputs are\npublished in highly-referred scholarly journals and conferences. The study\nidentifies three main research themes: (1) knowledge graph construction and\nenrichment, (2) evaluation and reuse, and (3) fusion of knowledge graphs into\nNLP systems. Within these themes, the study identifies specific tasks that have\nreceived considerable attention, including entity linking, knowledge graph\nembedding, and graph neural networks.\n","authors":["Houcemeddine Turki","Abraham Toluwase Owodunni","Mohamed Ali Hadj Taieb","René Fabrice Bile","Mohamed Ben Aouicha","Vilém Zouhar"],"pdf_url":"https://arxiv.org/pdf/2306.13186v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13118v1","updated":"2023-06-22T15:15:13Z","published":"2023-06-22T15:15:13Z","title":"An overview on the evaluated video retrieval tasks at TRECVID 2022","summary":"  The TREC Video Retrieval Evaluation (TRECVID) is a TREC-style video analysis\nand retrieval evaluation with the goal of promoting progress in research and\ndevelopment of content-based exploitation and retrieval of information from\ndigital video via open, tasks-based evaluation supported by metrology. Over the\nlast twenty-one years this effort has yielded a better understanding of how\nsystems can effectively accomplish such processing and how one can reliably\nbenchmark their performance. TRECVID has been funded by NIST (National\nInstitute of Standards and Technology) and other US government agencies. In\naddition, many organizations and individuals worldwide contribute significant\ntime and effort. TRECVID 2022 planned for the following six tasks: Ad-hoc video\nsearch, Video to text captioning, Disaster scene description and indexing,\nActivity in extended videos, deep video understanding, and movie summarization.\nIn total, 35 teams from various research organizations worldwide signed up to\njoin the evaluation campaign this year. This paper introduces the tasks,\ndatasets used, evaluation frameworks and metrics, as well as a high-level\nresults overview.\n","authors":["George Awad","Keith Curtis","Asad Butt","Jonathan Fiscus","Afzal Godil","Yooyoung Lee","Andrew Delgado","Eliot Godard","Lukas Diduch","Jeffrey Liu","Yvette Graham","Georges Quenot"],"pdf_url":"https://arxiv.org/pdf/2306.13118v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2104.13473,\n  arXiv:2009.09984"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2306.13092v1","updated":"2023-06-22T17:59:58Z","published":"2023-06-22T17:59:58Z","title":"Squeeze, Recover and Relabel: Dataset Condensation at ImageNet Scale\n  From A New Perspective","summary":"  We present a new dataset condensation framework termed Squeeze, Recover and\nRelabel (SRe$^2$L) that decouples the bilevel optimization of model and\nsynthetic data during training, to handle varying scales of datasets, model\narchitectures and image resolutions for effective dataset condensation. The\nproposed method demonstrates flexibility across diverse dataset scales and\nexhibits multiple advantages in terms of arbitrary resolutions of synthesized\nimages, low training cost and memory consumption with high-resolution training,\nand the ability to scale up to arbitrary evaluation network architectures.\nExtensive experiments are conducted on Tiny-ImageNet and full ImageNet-1K\ndatasets. Under 50 IPC, our approach achieves the highest 42.5% and 60.8%\nvalidation accuracy on Tiny-ImageNet and ImageNet-1K, outperforming all\nprevious state-of-the-art methods by margins of 14.5% and 32.9%, respectively.\nOur approach also outperforms MTT by approximately 52$\\times$ (ConvNet-4) and\n16$\\times$ (ResNet-18) faster in speed with less memory consumption of\n11.6$\\times$ and 6.4$\\times$ during data synthesis. Our code and condensed\ndatasets of 50, 200 IPC with 4K recovery budget are available at\nhttps://zeyuanyin.github.io/projects/SRe2L/.\n","authors":["Zeyuan Yin","Eric Xing","Zhiqiang Shen"],"pdf_url":"https://arxiv.org/pdf/2306.13092v1.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2306.13091v1","updated":"2023-06-22T17:59:55Z","published":"2023-06-22T17:59:55Z","title":"Evading Forensic Classifiers with Attribute-Conditioned Adversarial\n  Faces","summary":"  The ability of generative models to produce highly realistic synthetic face\nimages has raised security and ethical concerns. As a first line of defense\nagainst such fake faces, deep learning based forensic classifiers have been\ndeveloped. While these forensic models can detect whether a face image is\nsynthetic or real with high accuracy, they are also vulnerable to adversarial\nattacks. Although such attacks can be highly successful in evading detection by\nforensic classifiers, they introduce visible noise patterns that are detectable\nthrough careful human scrutiny. Additionally, these attacks assume access to\nthe target model(s) which may not always be true. Attempts have been made to\ndirectly perturb the latent space of GANs to produce adversarial fake faces\nthat can circumvent forensic classifiers. In this work, we go one step further\nand show that it is possible to successfully generate adversarial fake faces\nwith a specified set of attributes (e.g., hair color, eye size, race, gender,\netc.). To achieve this goal, we leverage the state-of-the-art generative model\nStyleGAN with disentangled representations, which enables a range of\nmodifications without leaving the manifold of natural images. We propose a\nframework to search for adversarial latent codes within the feature space of\nStyleGAN, where the search can be guided either by a text prompt or a reference\nimage. We also propose a meta-learning based optimization strategy to achieve\ntransferable performance on unknown target models. Extensive experiments\ndemonstrate that the proposed approach can produce semantically manipulated\nadversarial fake faces, which are true to the specified attribute set and can\nsuccessfully fool forensic face classifiers, while remaining undetectable by\nhumans. Code: https://github.com/koushiksrivats/face_attribute_attack.\n","authors":["Fahad Shamshad","Koushik Srivatsan","Karthik Nandakumar"],"pdf_url":"https://arxiv.org/pdf/2306.13091v1.pdf","comment":"Accepted in CVPR 2023. Project page:\n  https://koushiksrivats.github.io/face_attribute_attack/"},{"id":"http://arxiv.org/abs/2306.13085v1","updated":"2023-06-22T17:58:02Z","published":"2023-06-22T17:58:02Z","title":"Harnessing Mixed Offline Reinforcement Learning Datasets via Trajectory\n  Weighting","summary":"  Most offline reinforcement learning (RL) algorithms return a target policy\nmaximizing a trade-off between (1) the expected performance gain over the\nbehavior policy that collected the dataset, and (2) the risk stemming from the\nout-of-distribution-ness of the induced state-action occupancy. It follows that\nthe performance of the target policy is strongly related to the performance of\nthe behavior policy and, thus, the trajectory return distribution of the\ndataset. We show that in mixed datasets consisting of mostly low-return\ntrajectories and minor high-return trajectories, state-of-the-art offline RL\nalgorithms are overly restrained by low-return trajectories and fail to exploit\nhigh-performing trajectories to the fullest. To overcome this issue, we show\nthat, in deterministic MDPs with stochastic initial states, the dataset\nsampling can be re-weighted to induce an artificial dataset whose behavior\npolicy has a higher return. This re-weighted sampling strategy may be combined\nwith any offline RL algorithm. We further analyze that the opportunity for\nperformance improvement over the behavior policy correlates with the\npositive-sided variance of the returns of the trajectories in the dataset. We\nempirically show that while CQL, IQL, and TD3+BC achieve only a part of this\npotential policy improvement, these same algorithms combined with our\nreweighted sampling strategy fully exploit the dataset. Furthermore, we\nempirically demonstrate that, despite its theoretical limitation, the approach\nmay still be efficient in stochastic environments. The code is available at\nhttps://github.com/Improbable-AI/harness-offline-rl.\n","authors":["Zhang-Wei Hong","Pulkit Agrawal","Rémi Tachet des Combes","Romain Laroche"],"pdf_url":"https://arxiv.org/pdf/2306.13085v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13076v1","updated":"2023-06-22T17:48:18Z","published":"2023-06-22T17:48:18Z","title":"A Comparison of Time-based Models for Multimodal Emotion Recognition","summary":"  Emotion recognition has become an important research topic in the field of\nhuman-computer interaction. Studies on sound and videos to understand emotions\nfocused mainly on analyzing facial expressions and classified 6 basic emotions.\nIn this study, the performance of different sequence models in multi-modal\nemotion recognition was compared. The sound and images were first processed by\nmulti-layered CNN models, and the outputs of these models were fed into various\nsequence models. The sequence model is GRU, Transformer, LSTM and Max Pooling.\nAccuracy, precision, and F1 Score values of all models were calculated. The\nmulti-modal CREMA-D dataset was used in the experiments. As a result of the\ncomparison of the CREMA-D dataset, GRU-based architecture with 0.640 showed the\nbest result in F1 score, LSTM-based architecture with 0.699 in precision\nmetric, while sensitivity showed the best results over time with Max\nPooling-based architecture with 0.620. As a result, it has been observed that\nthe sequence models compare performances close to each other.\n","authors":["Ege Kesim","Selahattin Serdar Helli","Sena Nur Cavsak"],"pdf_url":"https://arxiv.org/pdf/2306.13076v1.pdf","comment":"in Turkish language"},{"id":"http://arxiv.org/abs/2306.13064v1","updated":"2023-06-22T17:32:12Z","published":"2023-06-22T17:32:12Z","title":"Auditing Predictive Models for Intersectional Biases","summary":"  Predictive models that satisfy group fairness criteria in aggregate for\nmembers of a protected class, but do not guarantee subgroup fairness, could\nproduce biased predictions for individuals at the intersection of two or more\nprotected classes. To address this risk, we propose Conditional Bias Scan\n(CBS), a flexible auditing framework for detecting intersectional biases in\nclassification models. CBS identifies the subgroup for which there is the most\nsignificant bias against the protected class, as compared to the equivalent\nsubgroup in the non-protected class, and can incorporate multiple commonly used\nfairness definitions for both probabilistic and binarized predictions. We show\nthat this methodology can detect previously unidentified intersectional and\ncontextual biases in the COMPAS pre-trial risk assessment tool and has higher\nbias detection power compared to similar methods that audit for subgroup\nfairness.\n","authors":["Kate S. Boxer","Edward McFowland III","Daniel B. Neill"],"pdf_url":"https://arxiv.org/pdf/2306.13064v1.pdf","comment":"29 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.12383v2","updated":"2023-06-22T17:30:36Z","published":"2023-06-21T17:03:22Z","title":"Sample Complexity for Quadratic Bandits: Hessian Dependent Bounds and\n  Optimal Algorithms","summary":"  In stochastic zeroth-order optimization, a problem of practical relevance is\nunderstanding how to fully exploit the local geometry of the underlying\nobjective function. We consider a fundamental setting in which the objective\nfunction is quadratic, and provide the first tight characterization of the\noptimal Hessian-dependent sample complexity. Our contribution is twofold.\nFirst, from an information-theoretic point of view, we prove tight lower bounds\non Hessian-dependent complexities by introducing a concept called energy\nallocation, which captures the interaction between the searching algorithm and\nthe geometry of objective functions. A matching upper bound is obtained by\nsolving the optimal energy spectrum. Then, algorithmically, we show the\nexistence of a Hessian-independent algorithm that universally achieves the\nasymptotic optimal sample complexities for all Hessian instances. The optimal\nsample complexities achieved by our algorithm remain valid for heavy-tailed\nnoise distributions, which are enabled by a truncation method.\n","authors":["Qian Yu","Yining Wang","Baihe Huang","Qi Lei","Jason D. Lee"],"pdf_url":"https://arxiv.org/pdf/2306.12383v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13057v1","updated":"2023-06-22T17:23:36Z","published":"2023-06-22T17:23:36Z","title":"SQ Lower Bounds for Learning Bounded Covariance GMMs","summary":"  We study the complexity of learning mixtures of separated Gaussians with\ncommon unknown bounded covariance matrix. Specifically, we focus on learning\nGaussian mixture models (GMMs) on $\\mathbb{R}^d$ of the form $P= \\sum_{i=1}^k\nw_i \\mathcal{N}(\\boldsymbol \\mu_i,\\mathbf \\Sigma_i)$, where $\\mathbf \\Sigma_i =\n\\mathbf \\Sigma \\preceq \\mathbf I$ and $\\min_{i \\neq j} \\| \\boldsymbol \\mu_i -\n\\boldsymbol \\mu_j\\|_2 \\geq k^\\epsilon$ for some $\\epsilon>0$. Known learning\nalgorithms for this family of GMMs have complexity $(dk)^{O(1/\\epsilon)}$. In\nthis work, we prove that any Statistical Query (SQ) algorithm for this problem\nrequires complexity at least $d^{\\Omega(1/\\epsilon)}$. In the special case\nwhere the separation is on the order of $k^{1/2}$, we additionally obtain\nfine-grained SQ lower bounds with the correct exponent. Our SQ lower bounds\nimply similar lower bounds for low-degree polynomial tests. Conceptually, our\nresults provide evidence that known algorithms for this problem are nearly best\npossible.\n","authors":["Ilias Diakonikolas","Daniel M. Kane","Thanasis Pittas","Nikos Zarifis"],"pdf_url":"https://arxiv.org/pdf/2306.13057v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13054v1","updated":"2023-06-22T17:21:17Z","published":"2023-06-22T17:21:17Z","title":"Quantum Pufferfish Privacy: A Flexible Privacy Framework for Quantum\n  Systems","summary":"  We propose a versatile privacy framework for quantum systems, termed quantum\npufferfish privacy (QPP). Inspired by classical pufferfish privacy, our\nformulation generalizes and addresses limitations of quantum differential\nprivacy by offering flexibility in specifying private information, feasible\nmeasurements, and domain knowledge. We show that QPP can be equivalently\nformulated in terms of the Datta-Leditzky information spectrum divergence, thus\nproviding the first operational interpretation thereof. We reformulate this\ndivergence as a semi-definite program and derive several properties of it,\nwhich are then used to prove convexity, composability, and post-processing of\nQPP mechanisms. Parameters that guarantee QPP of the depolarization mechanism\nare also derived. We analyze the privacy-utility tradeoff of general QPP\nmechanisms and, again, study the depolarization mechanism as an explicit\ninstance. The QPP framework is then applied to privacy auditing for identifying\nprivacy violations via a hypothesis testing pipeline that leverages quantum\nalgorithms. Connections to quantum fairness and other quantum divergences are\nalso explored and several variants of QPP are examined.\n","authors":["Theshani Nuradha","Ziv Goldfeld","Mark M. Wilde"],"pdf_url":"https://arxiv.org/pdf/2306.13054v1.pdf","comment":"31 pages, 10 figures"},{"id":"http://arxiv.org/abs/2306.13053v1","updated":"2023-06-22T17:20:30Z","published":"2023-06-22T17:20:30Z","title":"Context-lumpable stochastic bandits","summary":"  We consider a contextual bandit problem with $S $ contexts and $A $ actions.\nIn each round $t=1,2,\\dots$ the learner observes a random context and chooses\nan action based on its past experience. The learner then observes a random\nreward whose mean is a function of the context and the action for the round.\nUnder the assumption that the contexts can be lumped into $r\\le \\min\\{S ,A \\}$\ngroups such that the mean reward for the various actions is the same for any\ntwo contexts that are in the same group, we give an algorithm that outputs an\n$\\epsilon$-optimal policy after using at most $\\widetilde O(r (S +A\n)/\\epsilon^2)$ samples with high probability and provide a matching\n$\\widetilde\\Omega(r (S +A )/\\epsilon^2)$ lower bound. In the regret\nminimization setting, we give an algorithm whose cumulative regret up to time\n$T$ is bounded by $\\widetilde O(\\sqrt{r^3(S +A )T})$. To the best of our\nknowledge, we are the first to show the near-optimal sample complexity in the\nPAC setting and $\\widetilde O(\\sqrt{{poly}(r)(S+K)T})$ minimax regret in the\nonline setting for this problem. We also show our algorithms can be applied to\nmore general low-rank bandits and get improved regret bounds in some scenarios.\n","authors":["Chung-Wei Lee","Qinghua Liu","Yasin Abbasi-Yadkori","Chi Jin","Tor Lattimore","Csaba Szepesvári"],"pdf_url":"https://arxiv.org/pdf/2306.13053v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13050v1","updated":"2023-06-22T17:17:45Z","published":"2023-06-22T17:17:45Z","title":"Data augmentation for recommender system: A semi-supervised approach\n  using maximum margin matrix factorization","summary":"  Collaborative filtering (CF) has become a popular method for developing\nrecommender systems (RS) where ratings of a user for new items is predicted\nbased on her past preferences and available preference information of other\nusers. Despite the popularity of CF-based methods, their performance is often\ngreatly limited by the sparsity of observed entries. In this study, we explore\nthe data augmentation and refinement aspects of Maximum Margin Matrix\nFactorization (MMMF), a widely accepted CF technique for the rating\npredictions, which have not been investigated before. We exploit the inherent\ncharacteristics of CF algorithms to assess the confidence level of individual\nratings and propose a semi-supervised approach for rating augmentation based on\nself-training. We hypothesize that any CF algorithm's predictions with low\nconfidence are due to some deficiency in the training data and hence, the\nperformance of the algorithm can be improved by adopting a systematic data\naugmentation strategy. We iteratively use some of the ratings predicted with\nhigh confidence to augment the training data and remove low-confidence entries\nthrough a refinement process. By repeating this process, the system learns to\nimprove prediction accuracy. Our method is experimentally evaluated on several\nstate-of-the-art CF algorithms and leads to informative rating augmentation,\nimproving the performance of the baseline approaches.\n","authors":["Shamal Shaikh","Venkateswara Rao Kagita","Vikas Kumar","Arun K Pujari"],"pdf_url":"https://arxiv.org/pdf/2306.13050v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2302.09766v2","updated":"2023-06-22T17:12:44Z","published":"2023-02-20T05:16:18Z","title":"A One-Sample Decentralized Proximal Algorithm for Non-Convex Stochastic\n  Composite Optimization","summary":"  We focus on decentralized stochastic non-convex optimization, where $n$\nagents work together to optimize a composite objective function which is a sum\nof a smooth term and a non-smooth convex term. To solve this problem, we\npropose two single-time scale algorithms: Prox-DASA and Prox-DASA-GT. These\nalgorithms can find $\\epsilon$-stationary points in\n$\\mathcal{O}(n^{-1}\\epsilon^{-2})$ iterations using constant batch sizes (i.e.,\n$\\mathcal{O}(1)$). Unlike prior work, our algorithms achieve comparable\ncomplexity without requiring large batch sizes, more complex per-iteration\noperations (such as double loops), or stronger assumptions. Our theoretical\nfindings are supported by extensive numerical experiments, which demonstrate\nthe superiority of our algorithms over previous approaches. Our code is\navailable at https://github.com/xuxingc/ProxDASA.\n","authors":["Tesi Xiao","Xuxing Chen","Krishnakumar Balasubramanian","Saeed Ghadimi"],"pdf_url":"https://arxiv.org/pdf/2302.09766v2.pdf","comment":"UAI 2023"},{"id":"http://arxiv.org/abs/2306.13045v1","updated":"2023-06-22T17:11:18Z","published":"2023-06-22T17:11:18Z","title":"Multi-Task Learning with Loop Specific Attention for CDR Structure\n  Prediction","summary":"  The Complementarity Determining Region (CDR) structure prediction of loops in\nantibody engineering has gained a lot of attraction by researchers. When\ndesigning antibodies, a main challenge is to predict the CDR structure of the\nH3 loop. Compared with the other CDR loops, that is the H1 and H2 loops, the\nCDR structure of the H3 loop is more challenging due to its varying length and\nflexible structure. In this paper, we propose a Multi-task learning model with\nLoop Specific Attention, namely MLSA. In particular, to the best of our\nknowledge we are the first to jointly learn the three CDR loops, via a novel\nmulti-task learning strategy. In addition, to account for the structural and\nfunctional similarities and differences of the three CDR loops, we propose a\nloop specific attention mechanism to control the influence of each CDR loop on\nthe training of MLSA. Our experimental evaluation on widely used benchmark data\nshows that the proposed MLSA method significantly reduces the prediction error\nof the CDR structure of the H3 loop, by at least 19%, when compared with other\nbaseline strategies. Finally, for reproduction purposes we make the\nimplementation of MLSA publicly available at\nhttps://anonymous.4open.science/r/MLSA-2442/.\n","authors":["Eleni Giovanoudi","Dimitrios Rafailidis"],"pdf_url":"https://arxiv.org/pdf/2306.13045v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2306.13041v1","updated":"2023-06-22T17:07:57Z","published":"2023-06-22T17:07:57Z","title":"Towards Explainable Evaluation Metrics for Machine Translation","summary":"  Unlike classical lexical overlap metrics such as BLEU, most current\nevaluation metrics for machine translation (for example, COMET or BERTScore)\nare based on black-box large language models. They often achieve strong\ncorrelations with human judgments, but recent research indicates that the\nlower-quality classical metrics remain dominant, one of the potential reasons\nbeing that their decision processes are more transparent. To foster more\nwidespread acceptance of novel high-quality metrics, explainability thus\nbecomes crucial. In this concept paper, we identify key properties as well as\nkey goals of explainable machine translation metrics and provide a\ncomprehensive synthesis of recent techniques, relating them to our established\ngoals and properties. In this context, we also discuss the latest\nstate-of-the-art approaches to explainable metrics based on generative models\nsuch as ChatGPT and GPT4. Finally, we contribute a vision of next-generation\napproaches, including natural language explanations. We hope that our work can\nhelp catalyze and guide future research on explainable evaluation metrics and,\nmediately, also contribute to better and more transparent machine translation\nsystems.\n","authors":["Christoph Leiter","Piyawat Lertvittayakumjorn","Marina Fomicheva","Wei Zhao","Yang Gao","Steffen Eger"],"pdf_url":"https://arxiv.org/pdf/2306.13041v1.pdf","comment":"Preprint. We published an earlier version of this paper\n  (arXiv:2203.11131) under a different title. Both versions consider the\n  conceptualization of explainable metrics and are overall similar. However,\n  the new version puts a stronger emphasis on the survey of approaches for the\n  explanation of MT metrics including the latest LLM based approaches"},{"id":"http://arxiv.org/abs/2207.00221v2","updated":"2023-06-22T16:55:44Z","published":"2022-07-01T06:25:53Z","title":"VL-CheckList: Evaluating Pre-trained Vision-Language Models with\n  Objects, Attributes and Relations","summary":"  Vision-Language Pretraining (VLP) models have recently successfully\nfacilitated many cross-modal downstream tasks. Most existing works evaluated\ntheir systems by comparing the fine-tuned downstream task performance. However,\nonly average downstream task accuracy provides little information about the\npros and cons of each VLP method, let alone provides insights on how the\ncommunity can improve the systems in the future. Inspired by the CheckList for\ntesting natural language processing, we exploit VL-CheckList, a novel framework\nto understand the capabilities of VLP models. The proposed method divides the\nimage-texting ability of a VLP model into three categories: objects,\nattributes, and relations, and uses a novel taxonomy to further break down\nthese three aspects. We conduct comprehensive studies to analyze seven recently\npopular VLP models via the proposed framework. Results confirm the\neffectiveness of the proposed method by revealing fine-grained differences\namong the compared models that were not visible from downstream task-only\nevaluation. Further results show promising research direction in building\nbetter VLP models. Our data and code are available at:\nhttps://github.com/om-ai-lab/VL-CheckList.\n","authors":["Tiancheng Zhao","Tianqi Zhang","Mingwei Zhu","Haozhan Shen","Kyusong Lee","Xiaopeng Lu","Jianwei Yin"],"pdf_url":"https://arxiv.org/pdf/2207.00221v2.pdf","comment":"9 pages, preprint"},{"id":"http://arxiv.org/abs/2306.12962v1","updated":"2023-06-22T16:55:01Z","published":"2023-06-22T16:55:01Z","title":"PyKoopman: A Python Package for Data-Driven Approximation of the Koopman\n  Operator","summary":"  PyKoopman is a Python package for the data-driven approximation of the\nKoopman operator associated with a dynamical system. The Koopman operator is a\nprincipled linear embedding of nonlinear dynamics and facilitates the\nprediction, estimation, and control of strongly nonlinear dynamics using linear\nsystems theory. In particular, PyKoopman provides tools for data-driven system\nidentification for unforced and actuated systems that build on the\nequation-free dynamic mode decomposition (DMD) and its variants. In this work,\nwe provide a brief description of the mathematical underpinnings of the Koopman\noperator, an overview and demonstration of the features implemented in\nPyKoopman (with code examples), practical advice for users, and a list of\npotential extensions to PyKoopman. Software is available at\nhttp://github.com/dynamicslab/pykoopman\n","authors":["Shaowu Pan","Eurika Kaiser","Brian M. de Silva","J. Nathan Kutz","Steven L. Brunton"],"pdf_url":"https://arxiv.org/pdf/2306.12962v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2306.13030v1","updated":"2023-06-22T16:46:35Z","published":"2023-06-22T16:46:35Z","title":"Online Self-Supervised Learning in Machine Learning Intrusion Detection\n  for the Internet of Things","summary":"  This paper proposes a novel Self-Supervised Intrusion Detection (SSID)\nframework, which enables a fully online Machine Learning (ML) based Intrusion\nDetection System (IDS) that requires no human intervention or prior off-line\nlearning. The proposed framework analyzes and labels incoming traffic packets\nbased only on the decisions of the IDS itself using an Auto-Associative Deep\nRandom Neural Network, and on an online estimate of its statistically measured\ntrustworthiness. The SSID framework enables IDS to adapt rapidly to\ntime-varying characteristics of the network traffic, and eliminates the need\nfor offline data collection. This approach avoids human errors in data\nlabeling, and human labor and computational costs of model training and data\ncollection. The approach is experimentally evaluated on public datasets and\ncompared with well-known ML models, showing that this SSID framework is very\nuseful and advantageous as an accurate and online learning ML-based IDS for IoT\nsystems.\n","authors":["Mert Nakıp","Erol Gelenbe"],"pdf_url":"https://arxiv.org/pdf/2306.13030v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13029v1","updated":"2023-06-22T16:46:00Z","published":"2023-06-22T16:46:00Z","title":"Decentralized Online Federated G-Network Learning for Lightweight\n  Intrusion Detection","summary":"  Cyberattacks are increasingly threatening networked systems, often with the\nemergence of new types of unknown (zero-day) attacks and the rise of vulnerable\ndevices. While Machine Learning (ML)-based Intrusion Detection Systems (IDSs)\nhave been shown to be extremely promising in detecting these attacks, the need\nto learn large amounts of labelled data often limits the applicability of\nML-based IDSs to cybersystems that only have access to private local data. To\naddress this issue, this paper proposes a novel Decentralized and Online\nFederated Learning Intrusion Detection (DOF-ID) architecture. DOF-ID is a\ncollaborative learning system that allows each IDS used for a cybersystem to\nlearn from experience gained in other cybersystems in addition to its own local\ndata without violating the data privacy of other systems. As the performance\nevaluation results using public Kitsune and Bot-IoT datasets show, DOF-ID\nsignificantly improves the intrusion detection performance in all collaborating\nnodes simultaneously with acceptable computation time for online learning.\n","authors":["Mert Nakıp","Baran Can Gül","Erol Gelenbe"],"pdf_url":"https://arxiv.org/pdf/2306.13029v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13028v1","updated":"2023-06-22T16:45:45Z","published":"2023-06-22T16:45:45Z","title":"Transferable Curricula through Difficulty Conditioned Generators","summary":"  Advancements in reinforcement learning (RL) have demonstrated superhuman\nperformance in complex tasks such as Starcraft, Go, Chess etc. However,\nknowledge transfer from Artificial \"Experts\" to humans remain a significant\nchallenge. A promising avenue for such transfer would be the use of curricula.\nRecent methods in curricula generation focuses on training RL agents\nefficiently, yet such methods rely on surrogate measures to track student\nprogress, and are not suited for training robots in the real world (or more\nambitiously humans). In this paper, we introduce a method named Parameterized\nEnvironment Response Model (PERM) that shows promising results in training RL\nagents in parameterized environments. Inspired by Item Response Theory, PERM\nseeks to model difficulty of environments and ability of RL agents directly.\nGiven that RL agents and humans are trained more efficiently under the \"zone of\nproximal development\", our method generates a curriculum by matching the\ndifficulty of an environment to the current ability of the student. In\naddition, PERM can be trained offline and does not employ non-stationary\nmeasures of student ability, making it suitable for transfer between students.\nWe demonstrate PERM's ability to represent the environment parameter space, and\ntraining with RL agents with PERM produces a strong performance in\ndeterministic environments. Lastly, we show that our method is transferable\nbetween students, without any sacrifice in training quality.\n","authors":["Sidney Tio","Pradeep Varakantham"],"pdf_url":"https://arxiv.org/pdf/2306.13028v1.pdf","comment":"IJCAI'23"},{"id":"http://arxiv.org/abs/2210.04819v2","updated":"2023-06-22T16:33:47Z","published":"2022-10-10T16:31:11Z","title":"Efficient Learning of Locomotion Skills through the Discovery of Diverse\n  Environmental Trajectory Generator Priors","summary":"  Data-driven learning based methods have recently been particularly successful\nat learning robust locomotion controllers for a variety of unstructured\nterrains. Prior work has shown that incorporating good locomotion priors in the\nform of trajectory generators (TGs) is effective at efficiently learning\ncomplex locomotion skills. However, defining a good, single TG as\ntasks/environments become increasingly more complex remains a challenging\nproblem as it requires extensive tuning and risks reducing the effectiveness of\nthe prior. In this paper, we present Evolved Environmental Trajectory\nGenerators (EETG), a method that learns a diverse set of specialised locomotion\npriors using Quality-Diversity algorithms while maintaining a single policy\nwithin the Policies Modulating TG (PMTG) architecture. The results demonstrate\nthat EETG enables a quadruped robot to successfully traverse a wide range of\nenvironments, such as slopes, stairs, rough terrain, and balance beams. Our\nexperiments show that learning a diverse set of specialized TG priors is\nsignificantly (5 times) more efficient than using a single, fixed prior when\ndealing with a wide range of environments.\n","authors":["Shikha Surana","Bryan Lim","Antoine Cully"],"pdf_url":"https://arxiv.org/pdf/2210.04819v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10066v2","updated":"2023-06-22T16:22:47Z","published":"2023-02-20T16:13:19Z","title":"Sharp analysis of EM for learning mixtures of pairwise differences","summary":"  We consider a symmetric mixture of linear regressions with random samples\nfrom the pairwise comparison design, which can be seen as a noisy version of a\ntype of Euclidean distance geometry problem. We analyze the\nexpectation-maximization (EM) algorithm locally around the ground truth and\nestablish that the sequence converges linearly, providing an $\\ell_\\infty$-norm\nguarantee on the estimation error of the iterates. Furthermore, we show that\nthe limit of the EM sequence achieves the sharp rate of estimation in the\n$\\ell_2$-norm, matching the information-theoretically optimal constant. We also\nargue through simulation that convergence from a random initialization is much\nmore delicate in this setting, and does not appear to occur in general. Our\nresults show that the EM algorithm can exhibit several unique behaviors when\nthe covariate distribution is suitably structured.\n","authors":["Abhishek Dhawan","Cheng Mao","Ashwin Pananjady"],"pdf_url":"https://arxiv.org/pdf/2302.10066v2.pdf","comment":"45 pages, 2 figures"},{"id":"http://arxiv.org/abs/2210.06518v3","updated":"2023-06-22T16:12:20Z","published":"2022-10-12T18:22:23Z","title":"Semi-Supervised Offline Reinforcement Learning with Action-Free\n  Trajectories","summary":"  Natural agents can effectively learn from multiple data sources that differ\nin size, quality, and types of measurements. We study this heterogeneity in the\ncontext of offline reinforcement learning (RL) by introducing a new,\npractically motivated semi-supervised setting. Here, an agent has access to two\nsets of trajectories: labelled trajectories containing state, action and reward\ntriplets at every timestep, along with unlabelled trajectories that contain\nonly state and reward information. For this setting, we develop and study a\nsimple meta-algorithmic pipeline that learns an inverse dynamics model on the\nlabelled data to obtain proxy-labels for the unlabelled data, followed by the\nuse of any offline RL algorithm on the true and proxy-labelled trajectories.\nEmpirically, we find this simple pipeline to be highly successful -- on several\nD4RL benchmarks~\\cite{fu2020d4rl}, certain offline RL algorithms can match the\nperformance of variants trained on a fully labelled dataset even when we label\nonly 10\\% of trajectories which are highly suboptimal. To strengthen our\nunderstanding, we perform a large-scale controlled empirical study\ninvestigating the interplay of data-centric properties of the labelled and\nunlabelled datasets, with algorithmic design choices (e.g., choice of inverse\ndynamics, offline RL algorithm) to identify general trends and best practices\nfor training RL agents on semi-supervised offline datasets.\n","authors":["Qinqing Zheng","Mikael Henaff","Brandon Amos","Aditya Grover"],"pdf_url":"https://arxiv.org/pdf/2210.06518v3.pdf","comment":"ICML 2023. Code: https://github.com/facebookresearch/ssorl/"},{"id":"http://arxiv.org/abs/2306.13004v1","updated":"2023-06-22T16:04:16Z","published":"2023-06-22T16:04:16Z","title":"Can Differentiable Decision Trees Learn Interpretable Reward Functions?","summary":"  There is an increasing interest in learning reward functions that model human\nintent and human preferences. However, many frameworks use blackbox learning\nmethods that, while expressive, are difficult to interpret. We propose and\nevaluate a novel approach for learning expressive and interpretable reward\nfunctions from preferences using Differentiable Decision Trees (DDTs) for both\nlow- and high-dimensional state inputs. We explore and discuss the viability of\nlearning interpretable reward functions using DDTs by evaluating our algorithm\non Cartpole, Visual Gridworld environments, and Atari games. We provide\nevidence that that the tree structure of our learned reward function is useful\nin determining the extent to which a reward function is aligned with human\npreferences. We visualize the learned reward DDTs and find that they are\ncapable of learning interpretable reward functions but that the discrete nature\nof the trees hurts the performance of reinforcement learning at test time.\nHowever, we also show evidence that using soft outputs (averaged over all leaf\nnodes) results in competitive performance when compared with larger capacity\ndeep neural network reward functions.\n","authors":["Akansha Kalra","Daniel S. Brown"],"pdf_url":"https://arxiv.org/pdf/2306.13004v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06034v2","updated":"2023-06-22T16:03:04Z","published":"2023-06-09T16:55:49Z","title":"RANS-PINN based Simulation Surrogates for Predicting Turbulent Flows","summary":"  Physics-informed neural networks (PINNs) provide a framework to build\nsurrogate models for dynamical systems governed by differential equations.\nDuring the learning process, PINNs incorporate a physics-based regularization\nterm within the loss function to enhance generalization performance. Since\nsimulating dynamics controlled by partial differential equations (PDEs) can be\ncomputationally expensive, PINNs have gained popularity in learning parametric\nsurrogates for fluid flow problems governed by Navier-Stokes equations. In this\nwork, we introduce RANS-PINN, a modified PINN framework, to predict flow fields\n(i.e., velocity and pressure) in high Reynolds number turbulent flow regime. To\naccount for the additional complexity introduced by turbulence, RANS-PINN\nemploys a 2-equation eddy viscosity model based on a Reynolds-averaged\nNavier-Stokes (RANS) formulation. Furthermore, we adopt a novel training\napproach that ensures effective initialization and balance among the various\ncomponents of the loss function. The effectiveness of RANS-PINN framework is\nthen demonstrated using a parametric PINN.\n","authors":["Shinjan Ghosh","Amit Chakraborty","Georgia Olympia Brikis","Biswadip Dey"],"pdf_url":"https://arxiv.org/pdf/2306.06034v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12988v1","updated":"2023-06-22T15:44:39Z","published":"2023-06-22T15:44:39Z","title":"Can a single image processing algorithm work equally well across all\n  phases of DCE-MRI?","summary":"  Image segmentation and registration are said to be challenging when applied\nto dynamic contrast enhanced MRI sequences (DCE-MRI). The contrast agent causes\nrapid changes in intensity in the region of interest and elsewhere, which can\nlead to false positive predictions for segmentation tasks and confound the\nimage registration similarity metric. While it is widely assumed that contrast\nchanges increase the difficulty of these tasks, to our knowledge no work has\nquantified these effects. In this paper we examine the effect of training with\ndifferent ratios of contrast enhanced (CE) data on two popular tasks:\nsegmentation with nnU-Net and Mask R-CNN and registration using VoxelMorph and\nVTN. We experimented further by strategically using the available datasets\nthrough pretraining and fine tuning with different splits of data. We found\nthat to create a generalisable model, pretraining with CE data and fine tuning\nwith non-CE data gave the best result. This interesting find could be expanded\nto other deep learning based image processing tasks with DCE-MRI and provide\nsignificant improvements to the models performance.\n","authors":["Adam G. Tattersall","Keith A. Goatman","Lucy E. Kershaw","Scott I. K. Semple","Sonia Dahdouh"],"pdf_url":"https://arxiv.org/pdf/2306.12988v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05021v2","updated":"2023-06-22T15:44:01Z","published":"2023-06-08T08:16:38Z","title":"Mixed-TD: Efficient Neural Network Accelerator with Layer-Specific\n  Tensor Decomposition","summary":"  Neural Network designs are quite diverse, from VGG-style to ResNet-style, and\nfrom Convolutional Neural Networks to Transformers. Towards the design of\nefficient accelerators, many works have adopted a dataflow-based, inter-layer\npipelined architecture, with a customised hardware towards each layer,\nachieving ultra high throughput and low latency. The deployment of neural\nnetworks to such dataflow architecture accelerators is usually hindered by the\navailable on-chip memory as it is desirable to preload the weights of neural\nnetworks on-chip to maximise the system performance. To address this, networks\nare usually compressed before the deployment through methods such as pruning,\nquantization and tensor decomposition. In this paper, a framework for mapping\nCNNs onto FPGAs based on a novel tensor decomposition method called Mixed-TD is\nproposed. The proposed method applies layer-specific Singular Value\nDecomposition (SVD) and Canonical Polyadic Decomposition (CPD) in a mixed\nmanner, achieving 1.73x to 10.29x throughput per DSP to state-of-the-art CNNs.\nOur work is open-sourced: https://github.com/Yu-Zhewen/Mixed-TD\n","authors":["Zhewen Yu","Christos-Savvas Bouganis"],"pdf_url":"https://arxiv.org/pdf/2306.05021v2.pdf","comment":"accepted by FPL2023"},{"id":"http://arxiv.org/abs/2306.12984v1","updated":"2023-06-22T15:41:46Z","published":"2023-06-22T15:41:46Z","title":"Inferring the finest pattern of mutual independence from data","summary":"  For a random variable $X$, we are interested in the blind extraction of its\nfinest mutual independence pattern $\\mu ( X )$. We introduce a specific kind of\nindependence that we call dichotomic. If $\\Delta ( X )$ stands for the set of\nall patterns of dichotomic independence that hold for $X$, we show that $\\mu (\nX )$ can be obtained as the intersection of all elements of $\\Delta ( X )$. We\nthen propose a method to estimate $\\Delta ( X )$ when the data are independent\nand identically (i.i.d.) realizations of a multivariate normal distribution. If\n$\\hat{\\Delta} ( X )$ is the estimated set of valid patterns of dichotomic\nindependence, we estimate $\\mu ( X )$ as the intersection of all patterns of\n$\\hat{\\Delta} ( X )$. The method is tested on simulated data, showing its\nadvantages and limits. We also consider an application to a toy example as well\nas to experimental data.\n","authors":["G. Marrelec","A. Giron"],"pdf_url":"https://arxiv.org/pdf/2306.12984v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12983v1","updated":"2023-06-22T15:41:15Z","published":"2023-06-22T15:41:15Z","title":"Towards More Realistic Membership Inference Attacks on Large Diffusion\n  Models","summary":"  Generative diffusion models, including Stable Diffusion and Midjourney, can\ngenerate visually appealing, diverse, and high-resolution images for various\napplications. These models are trained on billions of internet-sourced images,\nraising significant concerns about the potential unauthorized use of\ncopyright-protected images. In this paper, we examine whether it is possible to\ndetermine if a specific image was used in the training set, a problem known in\nthe cybersecurity community and referred to as a membership inference attack.\nOur focus is on Stable Diffusion, and we address the challenge of designing a\nfair evaluation framework to answer this membership question. We propose a\nmethodology to establish a fair evaluation setup and apply it to Stable\nDiffusion, enabling potential extensions to other generative models. Utilizing\nthis evaluation setup, we execute membership attacks (both known and newly\nintroduced). Our research reveals that previously proposed evaluation setups do\nnot provide a full understanding of the effectiveness of membership inference\nattacks. We conclude that the membership inference attack remains a significant\nchallenge for large diffusion models (often deployed as black-box systems),\nindicating that related privacy and copyright issues will persist in the\nforeseeable future.\n","authors":["Jan Dubiński","Antoni Kowalczuk","Stanisław Pawlak","Przemysław Rokita","Tomasz Trzciński","Paweł Morawiecki"],"pdf_url":"https://arxiv.org/pdf/2306.12983v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12981v1","updated":"2023-06-22T15:40:10Z","published":"2023-06-22T15:40:10Z","title":"Achieving Sample and Computational Efficient Reinforcement Learning by\n  Action Space Reduction via Grouping","summary":"  Reinforcement learning often needs to deal with the exponential growth of\nstates and actions when exploring optimal control in high-dimensional spaces\n(often known as the curse of dimensionality). In this work, we address this\nissue by learning the inherent structure of action-wise similar MDP to\nappropriately balance the performance degradation versus sample/computational\ncomplexity. In particular, we partition the action spaces into multiple groups\nbased on the similarity in transition distribution and reward function, and\nbuild a linear decomposition model to capture the difference between the\nintra-group transition kernel and the intra-group rewards. Both our theoretical\nanalysis and experiments reveal a \\emph{surprising and counter-intuitive\nresult}: while a more refined grouping strategy can reduce the approximation\nerror caused by treating actions in the same group as identical, it also leads\nto increased estimation error when the size of samples or the computation\nresources is limited. This finding highlights the grouping strategy as a new\ndegree of freedom that can be optimized to minimize the overall performance\nloss. To address this issue, we formulate a general optimization problem for\ndetermining the optimal grouping strategy, which strikes a balance between\nperformance loss and sample/computational complexity. We further propose a\ncomputationally efficient method for selecting a nearly-optimal grouping\nstrategy, which maintains its computational complexity independent of the size\nof the action space.\n","authors":["Yining Li","Peizhong Ju","Ness Shroff"],"pdf_url":"https://arxiv.org/pdf/2306.12981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12977v1","updated":"2023-06-22T15:38:22Z","published":"2023-06-22T15:38:22Z","title":"Sum-Rate Maximization of RSMA-based Aerial Communications with Energy\n  Harvesting: A Reinforcement Learning Approach","summary":"  In this letter, we investigate a joint power and beamforming design problem\nfor rate-splitting multiple access (RSMA)-based aerial communications with\nenergy harvesting, where a self-sustainable aerial base station serves multiple\nusers by utilizing the harvested energy. Considering maximizing the sum-rate\nfrom the long-term perspective, we utilize a deep reinforcement learning (DRL)\napproach, namely the soft actor-critic algorithm, to restrict the maximum\ntransmission power at each time based on the stochastic property of the channel\nenvironment, harvested energy, and battery power information. Moreover, for\ndesigning precoders and power allocation among all the private/common streams\nof the RSMA, we employ sequential least squares programming (SLSQP) using the\nHan-Powell quasi-Newton method to maximize the sum-rate for the given\ntransmission power via DRL. Numerical results show the superiority of the\nproposed scheme over several baseline methods in terms of the average sum-rate\nperformance.\n","authors":["Jaehyup Seong","Mesut Toka","Wonjae Shin"],"pdf_url":"https://arxiv.org/pdf/2306.12977v1.pdf","comment":"13 pages, 4 figures, submitted to IEEE Wireless Communications\n  Letters"},{"id":"http://arxiv.org/abs/2306.12974v1","updated":"2023-06-22T15:35:38Z","published":"2023-06-22T15:35:38Z","title":"Adaptive Bernstein Change Detector for High-Dimensional Data Streams","summary":"  Change detection is of fundamental importance when analyzing data streams.\nDetecting changes both quickly and accurately enables monitoring and prediction\nsystems to react, e.g., by issuing an alarm or by updating a learning\nalgorithm. However, detecting changes is challenging when observations are\nhigh-dimensional. In high-dimensional data, change detectors should not only be\nable to identify when changes happen, but also in which subspace they occur.\nIdeally, one should also quantify how severe they are. Our approach, ABCD, has\nthese properties. ABCD learns an encoder-decoder model and monitors its\naccuracy over a window of adaptive size. ABCD derives a change score based on\nBernstein's inequality to detect deviations in terms of accuracy, which\nindicate changes. Our experiments demonstrate that ABCD outperforms its best\ncompetitor by at least 8% and up to 23% in F1-score on average. It can also\naccurately estimate changes' subspace, together with a severity measure that\ncorrelates with the ground truth.\n","authors":["Marco Heyden","Edouard Fouché","Vadim Arzamasov","Tanja Fenn","Florian Kalinke","Klemens Böhm"],"pdf_url":"https://arxiv.org/pdf/2306.12974v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12957v1","updated":"2023-06-22T15:16:06Z","published":"2023-06-22T15:16:06Z","title":"Siamese SIREN: Audio Compression with Implicit Neural Representations","summary":"  Implicit Neural Representations (INRs) have emerged as a promising method for\nrepresenting diverse data modalities, including 3D shapes, images, and audio.\nWhile recent research has demonstrated successful applications of INRs in image\nand 3D shape compression, their potential for audio compression remains largely\nunexplored. Motivated by this, we present a preliminary investigation into the\nuse of INRs for audio compression. Our study introduces Siamese SIREN, a novel\napproach based on the popular SIREN architecture. Our experimental results\nindicate that Siamese SIREN achieves superior audio reconstruction fidelity\nwhile utilizing fewer network parameters compared to previous INR\narchitectures.\n","authors":["Luca A. Lanzendörfer","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2306.12957v1.pdf","comment":"Published as a workshop paper at ICML 2023 neural compression\n  workshop"},{"id":"http://arxiv.org/abs/2306.12955v1","updated":"2023-06-22T15:13:18Z","published":"2023-06-22T15:13:18Z","title":"Triggering Dark Showers with Conditional Dual Auto-Encoders","summary":"  Auto-encoders (AEs) have the potential to be effective and generic tools for\nnew physics searches at colliders, requiring little to no model-dependent\nassumptions. New hypothetical physics signals can be considered anomalies that\ndeviate from the well-known background processes generally expected to describe\nthe whole dataset. We present a search formulated as an anomaly detection (AD)\nproblem, using an AE to define a criterion to decide about the physics nature\nof an event. In this work, we perform an AD search for manifestations of a dark\nversion of strong force using raw detector images, which are large and very\nsparse, without leveraging any physics-based pre-processing or assumption on\nthe signals. We propose a dual-encoder design which can learn a compact latent\nspace through conditioning. In the context of multiple AD metrics, we present a\nclear improvement over competitive baselines and prior approaches. It is the\nfirst time that an AE is shown to exhibit excellent discrimination against\nmultiple dark shower models, illustrating the suitability of this method as a\nperformant, model-independent algorithm to deploy, e.g., in the trigger stage\nof LHC experiments such as ATLAS and CMS.\n","authors":["Luca Anzalone","Simranjit Singh Chhibra","Benedikt Maier","Nadezda Chernyavskaya","Maurizio Pierini"],"pdf_url":"https://arxiv.org/pdf/2306.12955v1.pdf","comment":"25 pages, 7 figures, and 11 tables"},{"id":"http://arxiv.org/abs/2204.07321v2","updated":"2023-06-22T15:00:07Z","published":"2022-04-15T04:02:06Z","title":"Graph Pooling for Graph Neural Networks: Progress, Challenges, and\n  Opportunities","summary":"  Graph neural networks have emerged as a leading architecture for many\ngraph-level tasks, such as graph classification and graph generation. As an\nessential component of the architecture, graph pooling is indispensable for\nobtaining a holistic graph-level representation of the whole graph. Although a\ngreat variety of methods have been proposed in this promising and\nfast-developing research field, to the best of our knowledge, little effort has\nbeen made to systematically summarize these works. To set the stage for the\ndevelopment of future works, in this paper, we attempt to fill this gap by\nproviding a broad review of recent methods for graph pooling. Specifically, 1)\nwe first propose a taxonomy of existing graph pooling methods with a\nmathematical summary for each category; 2) then, we provide an overview of the\nlibraries related to graph pooling, including the commonly used datasets, model\narchitectures for downstream tasks, and open-source implementations; 3) next,\nwe further outline the applications that incorporate the idea of graph pooling\nin a variety of domains; 4) finally, we discuss certain critical challenges\nfacing current studies and share our insights on future potential directions\nfor research on the improvement of graph pooling.\n","authors":["Chuang Liu","Yibing Zhan","Jia Wu","Chang Li","Bo Du","Wenbin Hu","Tongliang Liu","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2204.07321v2.pdf","comment":"11 pages, 2 figures. Accepted by IJCAI Survey Track 2023"},{"id":"http://arxiv.org/abs/2111.07473v2","updated":"2023-06-22T14:58:57Z","published":"2021-11-14T23:02:02Z","title":"Scrutinizing XAI using linear ground-truth data with suppressor\n  variables","summary":"  Machine learning (ML) is increasingly often used to inform high-stakes\ndecisions. As complex ML models (e.g., deep neural networks) are often\nconsidered black boxes, a wealth of procedures has been developed to shed light\non their inner workings and the ways in which their predictions come about,\ndefining the field of 'explainable AI' (XAI). Saliency methods rank input\nfeatures according to some measure of 'importance'. Such methods are difficult\nto validate since a formal definition of feature importance is, thus far,\nlacking. It has been demonstrated that some saliency methods can highlight\nfeatures that have no statistical association with the prediction target\n(suppressor variables). To avoid misinterpretations due to such behavior, we\npropose the actual presence of such an association as a necessary condition and\nobjective preliminary definition for feature importance. We carefully crafted a\nground-truth dataset in which all statistical dependencies are well-defined and\nlinear, serving as a benchmark to study the problem of suppressor variables. We\nevaluate common explanation methods including LRP, DTD, PatternNet,\nPatternAttribution, LIME, Anchors, SHAP, and permutation-based methods with\nrespect to our objective definition. We show that most of these methods are\nunable to distinguish important features from suppressors in this setting.\n","authors":["Rick Wilming","Céline Budding","Klaus-Robert Müller","Stefan Haufe"],"pdf_url":"https://arxiv.org/pdf/2111.07473v2.pdf","comment":"Corrected typos"},{"id":"http://arxiv.org/abs/2306.12943v1","updated":"2023-06-22T14:58:18Z","published":"2023-06-22T14:58:18Z","title":"Evolving Computation Graphs","summary":"  Graph neural networks (GNNs) have demonstrated success in modeling relational\ndata, especially for data that exhibits homophily: when a connection between\nnodes tends to imply that they belong to the same class. However, while this\nassumption is true in many relevant situations, there are important real-world\nscenarios that violate this assumption, and this has spurred research into\nimproving GNNs for these cases. In this work, we propose Evolving Computation\nGraphs (ECGs), a novel method for enhancing GNNs on heterophilic datasets. Our\napproach builds on prior theoretical insights linking node degree, high\nhomophily, and inter vs intra-class embedding similarity by rewiring the GNNs'\ncomputation graph towards adding edges that connect nodes that are likely to be\nin the same class. We utilise weaker classifiers to identify these edges,\nultimately improving GNN performance on non-homophilic data as a result. We\nevaluate ECGs on a diverse set of recently-proposed heterophilous datasets and\ndemonstrate improvements over the relevant baselines. ECG presents a simple,\nintuitive and elegant approach for improving GNN performance on heterophilic\ndatasets without requiring prior domain knowledge.\n","authors":["Andreea Deac","Jian Tang"],"pdf_url":"https://arxiv.org/pdf/2306.12943v1.pdf","comment":"To appear at ICML TAGML 2023; 18 pages, 2 figures"},{"id":"http://arxiv.org/abs/2303.06053v3","updated":"2023-06-22T14:56:28Z","published":"2023-03-10T16:41:24Z","title":"TSMixer: An all-MLP Architecture for Time Series Forecasting","summary":"  Real-world time-series datasets are often multivariate with complex dynamics.\nTo capture this complexity, high capacity architectures like recurrent- or\nattention-based sequential deep learning models have become popular. However,\nrecent work demonstrates that simple univariate linear models can outperform\nsuch deep learning models on several commonly used academic benchmarks.\nExtending them, in this paper, we investigate the capabilities of linear models\nfor time-series forecasting and present Time-Series Mixer (TSMixer), a novel\narchitecture designed by stacking multi-layer perceptrons (MLPs). TSMixer is\nbased on mixing operations along both the time and feature dimensions to\nextract information efficiently. On popular academic benchmarks, the\nsimple-to-implement TSMixer is comparable to specialized state-of-the-art\nmodels that leverage the inductive biases of specific benchmarks. On the\nchallenging and large scale M5 benchmark, a real-world retail dataset, TSMixer\ndemonstrates superior performance compared to the state-of-the-art\nalternatives. Our results underline the importance of efficiently utilizing\ncross-variate and auxiliary information for improving the performance of time\nseries forecasting. We present various analyses to shed light into the\ncapabilities of TSMixer. The design paradigms utilized in TSMixer are expected\nto open new horizons for deep learning-based time series forecasting. The\nimplementation is available at\nhttps://github.com/google-research/google-research/tree/master/tsmixer\n","authors":["Si-An Chen","Chun-Liang Li","Nate Yoder","Sercan O. Arik","Tomas Pfister"],"pdf_url":"https://arxiv.org/pdf/2303.06053v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12941v1","updated":"2023-06-22T14:56:06Z","published":"2023-06-22T14:56:06Z","title":"Robust Semantic Segmentation: Strong Adversarial Attacks and Fast\n  Training of Robust Models","summary":"  While a large amount of work has focused on designing adversarial attacks\nagainst image classifiers, only a few methods exist to attack semantic\nsegmentation models. We show that attacking segmentation models presents\ntask-specific challenges, for which we propose novel solutions. Our final\nevaluation protocol outperforms existing methods, and shows that those can\noverestimate the robustness of the models. Additionally, so far adversarial\ntraining, the most successful way for obtaining robust image classifiers, could\nnot be successfully applied to semantic segmentation. We argue that this is\nbecause the task to be learned is more challenging, and requires significantly\nhigher computational effort than for image classification. As a remedy, we show\nthat by taking advantage of recent advances in robust ImageNet classifiers, one\ncan train adversarially robust segmentation models at limited computational\ncost by fine-tuning robust backbones.\n","authors":["Francesco Croce","Naman D Singh","Matthias Hein"],"pdf_url":"https://arxiv.org/pdf/2306.12941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01726v2","updated":"2023-06-22T14:46:17Z","published":"2023-06-02T17:52:59Z","title":"Streaming algorithms for evaluating noisy judges on unlabeled data --\n  binary classification","summary":"  The evaluation of noisy binary classifiers on unlabeled data is treated as a\nstreaming task: given a data sketch of the decisions by an ensemble, estimate\nthe true prevalence of the labels as well as each classifier's accuracy on\nthem. Two fully algebraic evaluators are constructed to do this. Both are based\non the assumption that the classifiers make independent errors. The first is\nbased on majority voting. The second, the main contribution of the paper, is\nguaranteed to be correct. But how do we know the classifiers are independent on\nany given test? This principal/agent monitoring paradox is ameliorated by\nexploiting the failures of the independent evaluator to return sensible\nestimates. A search for nearly error independent trios is empirically carried\nout on the \\texttt{adult}, \\texttt{mushroom}, and \\texttt{two-norm} datasets by\nusing the algebraic failure modes to reject evaluation ensembles as too\ncorrelated. The searches are refined by constructing a surface in evaluation\nspace that contains the true value point. The algebra of arbitrarily correlated\nclassifiers permits the selection of a polynomial subset free of any\ncorrelation variables. Candidate evaluation ensembles are rejected if their\ndata sketches produce independent estimates too far from the constructed\nsurface. The results produced by the surviving ensembles can sometimes be as\ngood as 1\\%. But handling even small amounts of correlation remains a\nchallenge. A Taylor expansion of the estimates produced when independence is\nassumed but the classifiers are, in fact, slightly correlated helps clarify how\nthe independent evaluator has algebraic `blind spots'.\n","authors":["Andrés Corrada-Emmanuel"],"pdf_url":"https://arxiv.org/pdf/2306.01726v2.pdf","comment":"23 pages, 5 figures. Minor fixes removing the Frankenstein spelling\n  of Groebner with both a umlaut o and an \"e\""},{"id":"http://arxiv.org/abs/2302.02522v2","updated":"2023-06-22T14:44:23Z","published":"2023-02-06T01:29:15Z","title":"Prior Density Learning in Variational Bayesian Phylogenetic Parameters\n  Inference","summary":"  The advances in variational inference are providing promising paths in\nBayesian estimation problems. These advances make variational phylogenetic\ninference an alternative approach to Markov Chain Monte Carlo methods for\napproximating the phylogenetic posterior. However, one of the main drawbacks of\nsuch approaches is the modelling of the prior through fixed distributions,\nwhich could bias the posterior approximation if they are distant from the\ncurrent data distribution. In this paper, we propose an approach and an\nimplementation framework to relax the rigidity of the prior densities by\nlearning their parameters using a gradient-based method and a neural\nnetwork-based parameterization. We applied this approach for branch lengths and\nevolutionary parameters estimation under several Markov chain substitution\nmodels. The results of performed simulations show that the approach is powerful\nin estimating branch lengths and evolutionary model parameters. They also show\nthat a flexible prior model could provide better results than a predefined\nprior model. Finally, the results highlight that using neural networks improves\nthe initialization of the optimization of the prior density parameters.\n","authors":["Amine M. Remita","Golrokh Kiani Vitae","Abdoulaye Baniré Diallo"],"pdf_url":"https://arxiv.org/pdf/2302.02522v2.pdf","comment":"Accepted as a full paper for publication at RECOMB-CG 2023\n  (Camera-ready version). 15 pages (excluding references), 6 tables and 1\n  figure"},{"id":"http://arxiv.org/abs/2306.12929v1","updated":"2023-06-22T14:39:04Z","published":"2023-06-22T14:39:04Z","title":"Quantizable Transformers: Removing Outliers by Helping Attention Heads\n  Do Nothing","summary":"  Transformer models have been widely adopted in various domains over the last\nyears, and especially large language models have advanced the field of AI\nsignificantly. Due to their size, the capability of these networks has\nincreased tremendously, but this has come at the cost of a significant increase\nin necessary compute. Quantization is one of the most effective ways to reduce\nthe computational time and memory consumption of neural networks. Many studies\nhave shown, however, that modern transformer models tend to learn strong\noutliers in their activations, making them difficult to quantize. To retain\nacceptable performance, the existence of these outliers requires activations to\nbe in higher bitwidth or the use of different numeric formats, extra\nfine-tuning, or other workarounds. We show that strong outliers are related to\nvery specific behavior of attention heads that try to learn a \"no-op\" or just a\npartial update of the residual. To achieve the exact zeros needed in the\nattention matrix for a no-update, the input to the softmax is pushed to be\nlarger and larger during training, causing outliers in other parts of the\nnetwork. Based on these observations, we propose two simple (independent)\nmodifications to the attention mechanism - clipped softmax and gated attention.\nWe empirically show that models pre-trained using our methods learn\nsignificantly smaller outliers while maintaining and sometimes even improving\nthe floating-point task performance. This enables us to quantize transformers\nto full INT8 quantization of the activations without any additional effort. We\ndemonstrate the effectiveness of our methods on both language models (BERT,\nOPT) and vision transformers.\n","authors":["Yelysei Bondarenko","Markus Nagel","Tijmen Blankevoort"],"pdf_url":"https://arxiv.org/pdf/2306.12929v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12926v1","updated":"2023-06-22T14:38:12Z","published":"2023-06-22T14:38:12Z","title":"Decentralized Multi-Agent Reinforcement Learning with Global State\n  Prediction","summary":"  Deep reinforcement learning (DRL) has seen remarkable success in the control\nof single robots. However, applying DRL to robot swarms presents significant\nchallenges. A critical challenge is non-stationarity, which occurs when two or\nmore robots update individual or shared policies concurrently, thereby engaging\nin an interdependent training process with no guarantees of convergence.\nCircumventing non-stationarity typically involves training the robots with\nglobal information about other agents' states and/or actions. In contrast, in\nthis paper we explore how to remove the need for global information. We pose\nour problem as a Partially Observable Markov Decision Process, due to the\nabsence of global knowledge on other agents. Using collective transport as a\ntestbed scenario, we study two approaches to multi-agent training. In the\nfirst, the robots exchange no messages, and are trained to rely on implicit\ncommunication through push-and-pull on the object to transport. In the second\napproach, we introduce Global State Prediction (GSP), a network trained to\nforma a belief over the swarm as a whole and predict its future states. We\nprovide a comprehensive study over four well-known deep reinforcement learning\nalgorithms in environments with obstacles, measuring performance as the\nsuccessful transport of the object to the goal within a desired time-frame.\nThrough an ablation study, we show that including GSP boosts performance and\nincreases robustness when compared with methods that use global knowledge.\n","authors":["Joshua Bloom","Pranjal Paliwal","Apratim Mukherjee","Carlo Pinciroli"],"pdf_url":"https://arxiv.org/pdf/2306.12926v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12919v1","updated":"2023-06-22T14:32:53Z","published":"2023-06-22T14:32:53Z","title":"An Interactive Interface for Novel Class Discovery in Tabular Data","summary":"  Novel Class Discovery (NCD) is the problem of trying to discover novel\nclasses in an unlabeled set, given a labeled set of different but related\nclasses. The majority of NCD methods proposed so far only deal with image data,\ndespite tabular data being among the most widely used type of data in practical\napplications. To interpret the results of clustering or NCD algorithms, data\nscientists need to understand the domain- and application-specific attributes\nof tabular data. This task is difficult and can often only be performed by a\ndomain expert. Therefore, this interface allows a domain expert to easily run\nstate-of-the-art algorithms for NCD in tabular data. With minimal knowledge in\ndata science, interpretable results can be generated.\n","authors":["Colin Troisemaine","Joachim Flocon-Cholet","Stéphane Gosselin","Alexandre Reiffers-Masson","Sandrine Vaton","Vincent Lemaire"],"pdf_url":"https://arxiv.org/pdf/2306.12919v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2306.12915v1","updated":"2023-06-22T14:30:41Z","published":"2023-06-22T14:30:41Z","title":"Multi-Objective Hull Form Optimization with CAD Engine-based Deep\n  Learning Physics for 3D Flow Prediction","summary":"  In this work, we propose a built-in Deep Learning Physics Optimization (DLPO)\nframework to set up a shape optimization study of the Duisburg Test Case (DTC)\ncontainer vessel. We present two different applications: (1) sensitivity\nanalysis to detect the most promising generic basis hull shapes, and (2)\nmulti-objective optimization to quantify the trade-off between optimal hull\nforms. DLPO framework allows for the evaluation of design iterations\nautomatically in an end-to-end manner. We achieved these results by coupling\nExtrality's Deep Learning Physics (DLP) model to a CAD engine and an optimizer.\nOur proposed DLP model is trained on full 3D volume data coming from RANS\nsimulations, and it can provide accurate and high-quality 3D flow predictions\nin real-time, which makes it a good evaluator to perform optimization of new\ncontainer vessel designs w.r.t the hydrodynamic efficiency. In particular, it\nis able to recover the forces acting on the vessel by integration on the hull\nsurface with a mean relative error of 3.84\\% \\pm 2.179\\% on the total\nresistance. Each iteration takes only 20 seconds, thus leading to a drastic\nsaving of time and engineering efforts, while delivering valuable insight into\nthe performance of the vessel, including RANS-like detailed flow information.\nWe conclude that DLPO framework is a promising tool to accelerate the ship\ndesign process and lead to more efficient ships with better hydrodynamic\nperformance.\n","authors":["Jocelyn Ahmed Mazari","Antoine Reverberi","Pierre Yser","Sebastian Sigmund"],"pdf_url":"https://arxiv.org/pdf/2306.12915v1.pdf","comment":"X International Conference on Computational Methods in Marine\n  Engineering, MARINE 2023, Madrid, Spain"},{"id":"http://arxiv.org/abs/2305.06347v2","updated":"2023-06-22T14:29:11Z","published":"2023-05-10T17:54:10Z","title":"CosmoPower-JAX: high-dimensional Bayesian inference with differentiable\n  cosmological emulators","summary":"  We present CosmoPower-JAX, a JAX-based implementation of the CosmoPower\nframework, which accelerates cosmological inference by building neural\nemulators of cosmological power spectra. We show how, using the automatic\ndifferentiation, batch evaluation and just-in-time compilation features of JAX,\nand running the inference pipeline on graphics processing units (GPUs),\nparameter estimation can be accelerated by orders of magnitude with advanced\ngradient-based sampling techniques. These can be used to efficiently explore\nhigh-dimensional parameter spaces, such as those needed for the analysis of\nnext-generation cosmological surveys. We showcase the accuracy and\ncomputational efficiency of CosmoPower-JAX on two simulated Stage IV\nconfigurations. We first consider a single survey performing a cosmic shear\nanalysis totalling 37 model parameters. We validate the contours derived with\nCosmoPower-JAX and a Hamiltonian Monte Carlo sampler against those derived with\na nested sampler and without emulators, obtaining a speed-up factor of\n$\\mathcal{O}(10^3)$. We then consider a combination of three Stage IV surveys,\neach performing a joint cosmic shear and galaxy clustering (3x2pt) analysis,\nfor a total of 157 model parameters. Even with such a high-dimensional\nparameter space, CosmoPower-JAX provides converged posterior contours in 3\ndays, as opposed to the estimated 6 years required by standard methods.\nCosmoPower-JAX is fully written in Python, and we make it publicly available to\nhelp the cosmological community meet the accuracy requirements set by\nnext-generation surveys.\n","authors":["D. Piras","A. Spurio Mancini"],"pdf_url":"https://arxiv.org/pdf/2305.06347v2.pdf","comment":"12 pages, 5 figures. Accepted for publication in The Open Journal of\n  Astrophysics. CosmoPower-JAX is available at\n  https://github.com/dpiras/cosmopower-jax"},{"id":"http://arxiv.org/abs/2306.12912v1","updated":"2023-06-22T14:27:17Z","published":"2023-06-22T14:27:17Z","title":"Mitigating Discrimination in Insurance with Wasserstein Barycenters","summary":"  The insurance industry is heavily reliant on predictions of risks based on\ncharacteristics of potential customers. Although the use of said models is\ncommon, researchers have long pointed out that such practices perpetuate\ndiscrimination based on sensitive features such as gender or race. Given that\nsuch discrimination can often be attributed to historical data biases, an\nelimination or at least mitigation is desirable. With the shift from more\ntraditional models to machine-learning based predictions, calls for greater\nmitigation have grown anew, as simply excluding sensitive variables in the\npricing process can be shown to be ineffective. In this article, we first\ninvestigate why predictions are a necessity within the industry and why\ncorrecting biases is not as straightforward as simply identifying a sensitive\nvariable. We then propose to ease the biases through the use of Wasserstein\nbarycenters instead of simple scaling. To demonstrate the effects and\neffectiveness of the approach we employ it on real data and discuss its\nimplications.\n","authors":["Arthur Charpentier","François Hu","Philipp Ratz"],"pdf_url":"https://arxiv.org/pdf/2306.12912v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.01054v2","updated":"2023-06-22T14:19:41Z","published":"2022-09-02T13:44:00Z","title":"Taming Multi-Agent Reinforcement Learning with Estimator Variance\n  Reduction","summary":"  Centralised training with decentralised execution (CT-DE) serves as the\nfoundation of many leading multi-agent reinforcement learning (MARL)\nalgorithms. Despite its popularity, it suffers from a critical drawback due to\nits reliance on learning from a single sample of the joint-action at a given\nstate. As agents explore and update their policies during training, these\nsingle samples may poorly represent the actual joint-policy of the system of\nagents leading to high variance gradient estimates that hinder learning. To\naddress this problem, we propose an enhancement tool that accommodates any\nactor-critic MARL method. Our framework, Performance Enhancing Reinforcement\nLearning Apparatus (PERLA), introduces a sampling technique of the agents'\njoint-policy into the critics while the agents train. This leads to TD updates\nthat closely approximate the true expected value under the current joint-policy\nrather than estimates from a single sample of the joint-action at a given\nstate. This produces low variance and precise estimates of expected returns,\nminimising the variance in the critic estimators which typically hinders\nlearning. Moreover, as we demonstrate, by eliminating much of the critic\nvariance from the single sampling of the joint policy, PERLA enables CT-DE\nmethods to scale more efficiently with the number of agents. Theoretically, we\nprove that PERLA reduces variance in value estimates similar to that of\ndecentralised training while maintaining the benefits of centralised training.\nEmpirically, we demonstrate PERLA's superior performance and ability to reduce\nestimator variance in a range of benchmarks including Multi-agent Mujoco, and\nStarCraft II Multi-agent Challenge.\n","authors":["Taher Jafferjee","Juliusz Ziomek","Tianpei Yang","Zipeng Dai","Jianhong Wang","Matthew Taylor","Kun Shao","Jun Wang","David Mguni"],"pdf_url":"https://arxiv.org/pdf/2209.01054v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12900v1","updated":"2023-06-22T14:07:54Z","published":"2023-06-22T14:07:54Z","title":"In Situ Framework for Coupling Simulation and Machine Learning with\n  Application to CFD","summary":"  Recent years have seen many successful applications of machine learning (ML)\nto facilitate fluid dynamic computations. As simulations grow, generating new\ntraining datasets for traditional offline learning creates I/O and storage\nbottlenecks. Additionally, performing inference at runtime requires non-trivial\ncoupling of ML framework libraries with simulation codes. This work offers a\nsolution to both limitations by simplifying this coupling and enabling in situ\ntraining and inference workflows on heterogeneous clusters. Leveraging\nSmartSim, the presented framework deploys a database to store data and ML\nmodels in memory, thus circumventing the file system. On the Polaris\nsupercomputer, we demonstrate perfect scaling efficiency to the full machine\nsize of the data transfer and inference costs thanks to a novel co-located\ndeployment of the database. Moreover, we train an autoencoder in situ from a\nturbulent flow simulation, showing that the framework overhead is negligible\nrelative to a solver time step and training epoch.\n","authors":["Riccardo Balin","Filippo Simini","Cooper Simpson","Andrew Shao","Alessandro Rigazzi","Matthew Ellis","Stephen Becker","Alireza Doostan","John A. Evans","Kenneth E. Jansen"],"pdf_url":"https://arxiv.org/pdf/2306.12900v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12898v1","updated":"2023-06-22T14:07:23Z","published":"2023-06-22T14:07:23Z","title":"Machine-Learning-Assisted and Real-Time-Feedback-Controlled Growth of\n  InAs/GaAs Quantum Dots","summary":"  Self-assembled InAs/GaAs quantum dots (QDs) have properties highly valuable\nfor developing various optoelectronic devices such as QD lasers and single\nphoton sources. The applications strongly rely on the density and quality of\nthese dots, which has motivated studies of the growth process control to\nrealize high-quality epi-wafers and devices. Establishing the process\nparameters in molecular beam epitaxy (MBE) for a specific density of QDs is a\nmultidimensional optimization challenge, usually addressed through\ntime-consuming and iterative trial-and-error. Meanwhile, reflective high-energy\nelectron diffraction (RHEED) has been widely used to capture a wealth of growth\ninformation in situ. However, it still faces the challenges of extracting\ninformation from noisy and overlapping images. Here, based on 3D ResNet, we\ndeveloped a machine learning (ML) model specially designed for training RHEED\nvideos instead of static images and providing real-time feedback on surface\nmorphologies for process control. We demonstrated that ML from previous growth\ncould predict the post-growth density of QDs, by successfully tuning the QD\ndensities in near-real time from 1.5E10 cm-2 down to 3.8E8 cm-2 or up to 1.4\nE11 cm-2. Compared to traditional methods, our approach, with in-situ tuning\ncapabilities and excellent reliability, can dramatically expedite the material\noptimization process and improve the reproducibility of MBE growth,\nconstituting significant progress for thin film growth techniques. The concepts\nand methodologies proved feasible in this work are promising to be applied to a\nvariety of material growth processes, which will revolutionize semiconductor\nmanufacturing for microelectronic and optoelectronic industries.\n","authors":["Chao Shen","Wenkang Zhan","Kaiyao Xin","Manyang Li","Zhenyu Sun","Jian Tang","Zhaofeng Wu","Bo Xu","Zhongming Wei","Chao Zhao","Zhanguo Wang"],"pdf_url":"https://arxiv.org/pdf/2306.12898v1.pdf","comment":"5 figures"},{"id":"http://arxiv.org/abs/2306.12873v1","updated":"2023-06-22T13:34:26Z","published":"2023-06-22T13:34:26Z","title":"FuXi: A cascade machine learning forecasting system for 15-day global\n  weather forecast","summary":"  Over the past few years, due to the rapid development of machine learning\n(ML) models for weather forecasting, state-of-the-art ML models have shown\nsuperior performance compared to the European Centre for Medium-Range Weather\nForecasts (ECMWF)'s high-resolution forecast (HRES) in 10-day forecasts at a\nspatial resolution of 0.25 degree. However, the challenge remains to perform\ncomparably to the ECMWF ensemble mean (EM) in 15-day forecasts. Previous\nstudies have demonstrated the importance of mitigating the accumulation of\nforecast errors for effective long-term forecasts. Despite numerous efforts to\nreduce accumulation errors, including autoregressive multi-time step loss,\nusing a single model is found to be insufficient to achieve optimal performance\nin both short and long lead times. Therefore, we present FuXi, a cascaded ML\nweather forecasting system that provides 15-day global forecasts with a\ntemporal resolution of 6 hours and a spatial resolution of 0.25 degree. FuXi is\ndeveloped using 39 years of the ECMWF ERA5 reanalysis dataset. The performance\nevaluation, based on latitude-weighted root mean square error (RMSE) and\nanomaly correlation coefficient (ACC), demonstrates that FuXi has comparable\nforecast performance to ECMWF EM in 15-day forecasts, making FuXi the first\nML-based weather forecasting system to accomplish this achievement.\n","authors":["Lei Chen","Xiaohui Zhong","Feng Zhang","Yuan Cheng","Yinghui Xu","Yuan Qi","Hao Li"],"pdf_url":"https://arxiv.org/pdf/2306.12873v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12867v1","updated":"2023-06-22T13:25:57Z","published":"2023-06-22T13:25:57Z","title":"Wind Noise Reduction with a Diffusion-based Stochastic Regeneration\n  Model","summary":"  In this paper we present a method for single-channel wind noise reduction\nusing our previously proposed diffusion-based stochastic regeneration model\ncombining predictive and generative modelling. We introduce a non-additive\nspeech in noise model to account for the non-linear deformation of the membrane\ncaused by the wind flow and possible clipping. We show that our stochastic\nregeneration model outperforms other neural-network-based wind noise reduction\nmethods as well as purely predictive and generative models, on a dataset using\nsimulated and real-recorded wind noise. We further show that the proposed\nmethod generalizes well by testing on an unseen dataset with real-recorded wind\nnoise. Audio samples, data generation scripts and code for the proposed methods\ncan be found online (https://uhh.de/inf-sp-storm-wind).\n","authors":["Jean-Marie Lemercier","Joachim Thiemann","Raphael Koning","Timo Gerkmann"],"pdf_url":"https://arxiv.org/pdf/2306.12867v1.pdf","comment":"Submitted to VDE 15th ITG conference on Speech Communication"},{"id":"http://arxiv.org/abs/2306.12860v1","updated":"2023-06-22T13:14:59Z","published":"2023-06-22T13:14:59Z","title":"Learning from Visual Observation via Offline Pretrained State-to-Go\n  Transformer","summary":"  Learning from visual observation (LfVO), aiming at recovering policies from\nonly visual observation data, is promising yet a challenging problem. Existing\nLfVO approaches either only adopt inefficient online learning schemes or\nrequire additional task-specific information like goal states, making them not\nsuited for open-ended tasks. To address these issues, we propose a two-stage\nframework for learning from visual observation. In the first stage, we\nintroduce and pretrain State-to-Go (STG) Transformer offline to predict and\ndifferentiate latent transitions of demonstrations. Subsequently, in the second\nstage, the STG Transformer provides intrinsic rewards for downstream\nreinforcement learning tasks where an agent learns merely from intrinsic\nrewards. Empirical results on Atari and Minecraft show that our proposed method\noutperforms baselines and in some tasks even achieves performance comparable to\nthe policy learned from environmental rewards. These results shed light on the\npotential of utilizing video-only data to solve difficult visual reinforcement\nlearning tasks rather than relying on complete offline datasets containing\nstates, actions, and rewards. The project's website and code can be found at\nhttps://sites.google.com/view/stgtransformer.\n","authors":["Bohan Zhou","Ke Li","Jiechuan Jiang","Zongqing Lu"],"pdf_url":"https://arxiv.org/pdf/2306.12860v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2306.12859v1","updated":"2023-06-22T13:11:19Z","published":"2023-06-22T13:11:19Z","title":"Reinforcement Federated Learning Method Based on Adaptive OPTICS\n  Clustering","summary":"  Federated learning is a distributed machine learning technology, which\nrealizes the balance between data privacy protection and data sharing\ncomputing. To protect data privacy, feder-ated learning learns shared models by\nlocally executing distributed training on participating devices and aggregating\nlocal models into global models. There is a problem in federated learning, that\nis, the negative impact caused by the non-independent and identical\ndistribu-tion of data across different user terminals. In order to alleviate\nthis problem, this paper pro-poses a strengthened federation aggregation method\nbased on adaptive OPTICS clustering. Specifically, this method perceives the\nclustering environment as a Markov decision process, and models the adjustment\nprocess of parameter search direction, so as to find the best clus-tering\nparameters to achieve the best federated aggregation method. The core\ncontribution of this paper is to propose an adaptive OPTICS clustering\nalgorithm for federated learning. The algorithm combines OPTICS clustering and\nadaptive learning technology, and can effective-ly deal with the problem of\nnon-independent and identically distributed data across different user\nterminals. By perceiving the clustering environment as a Markov decision\nprocess, the goal is to find the best parameters of the OPTICS cluster without\nartificial assistance, so as to obtain the best federated aggregation method\nand achieve better performance. The reliability and practicability of this\nmethod have been verified on the experimental data, and its effec-tiveness and\nsuperiority have been proved.\n","authors":["Tianyu Zhao","Junping Du","Yingxia Shao","Zeli Guan"],"pdf_url":"https://arxiv.org/pdf/2306.12859v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12857v1","updated":"2023-06-22T13:08:42Z","published":"2023-06-22T13:08:42Z","title":"Efficient Partitioning Method of Large-Scale Public Safety\n  Spatio-Temporal Data based on Information Loss Constraints","summary":"  The storage, management, and application of massive spatio-temporal data are\nwidely applied in various practical scenarios, including public safety.\nHowever, due to the unique spatio-temporal distribution characteristics of\nre-al-world data, most existing methods have limitations in terms of the\nspatio-temporal proximity of data and load balancing in distributed storage.\nThere-fore, this paper proposes an efficient partitioning method of large-scale\npublic safety spatio-temporal data based on information loss constraints\n(IFL-LSTP). The IFL-LSTP model specifically targets large-scale spatio-temporal\npoint da-ta by combining the spatio-temporal partitioning module (STPM) with\nthe graph partitioning module (GPM). This approach can significantly reduce the\nscale of data while maintaining the model's accuracy, in order to improve the\npartitioning efficiency. It can also ensure the load balancing of distributed\nstorage while maintaining spatio-temporal proximity of the data partitioning\nresults. This method provides a new solution for distributed storage of\nmas-sive spatio-temporal data. The experimental results on multiple real-world\nda-tasets demonstrate the effectiveness and superiority of IFL-LSTP.\n","authors":["Jie Gao","Yawen Li","Zhe Xue","Zeli Guan"],"pdf_url":"https://arxiv.org/pdf/2306.12857v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.16266v2","updated":"2023-06-22T12:53:24Z","published":"2023-03-28T19:27:02Z","title":"On-line reinforcement learning for optimization of real-life energy\n  trading strategy","summary":"  An increasing share of energy is produced from renewable sources by many\nsmall producers. The efficiency of those sources is volatile and, to some\nextent, random, exacerbating the problem of energy market balancing. In many\ncountries, this balancing is done on the day-ahead (DA) energy markets. This\npaper considers automated trading on the DA energy market by a medium size\nprosumer. We model this activity as a Markov Decision Process and formalize a\nframework in which an applicable in real-life strategy can be optimized with\noff-line data. We design a trading strategy that is fed with the available\nenvironmental information that can impact future prices, including weather\nforecasts. We use state-of-the-art reinforcement learning (RL) algorithms to\noptimize this strategy. For comparison, we also synthesize a simple parametric\ntrading strategy and optimize it with an evolutionary algorithm. Results show\nthat our RL-based strategy generates the highest market profits.\n","authors":["Łukasz Lepak","Paweł Wawrzyński"],"pdf_url":"https://arxiv.org/pdf/2303.16266v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.06854v2","updated":"2023-06-22T12:33:20Z","published":"2022-06-14T13:49:08Z","title":"On the explainable properties of 1-Lipschitz Neural Networks: An Optimal\n  Transport Perspective","summary":"  Input gradients have a pivotal role in a variety of applications, including\nadversarial attack algorithms for evaluating model robustness, explainable AI\ntechniques for generating Saliency Maps, and counterfactual explanations.\nHowever, Saliency Maps generated by traditional neural networks are often noisy\nand provide limited insights. In this paper, we demonstrate that, on the\ncontrary, the Saliency Maps of 1-Lipschitz neural networks, learnt with the\ndual loss of an optimal transportation problem, exhibit desirable XAI\nproperties: They are highly concentrated on the essential parts of the image\nwith low noise, significantly outperforming state-of-the-art explanation\napproaches across various models and metrics. We also prove that these maps\nalign unprecedentedly well with human explanations on ImageNet. To explain the\nparticularly beneficial properties of the Saliency Map for such models, we\nprove this gradient encodes both the direction of the transportation plan and\nthe direction towards the nearest adversarial attack. Following the gradient\ndown to the decision boundary is no longer considered an adversarial attack,\nbut rather a counterfactual explanation that explicitly transports the input\nfrom one class to another. Thus, Learning with such a loss jointly optimizes\nthe classification objective and the alignment of the gradient , i.e. the\nSaliency Map, to the transportation plan direction. These networks were\npreviously known to be certifiably robust by design, and we demonstrate that\nthey scale well for large problems and models, and are tailored for\nexplainability using a fast and straightforward method.\n","authors":["Mathieu Serrurier","Franck Mamalet","Thomas Fel","Louis Béthune","Thibaut Boissin"],"pdf_url":"https://arxiv.org/pdf/2206.06854v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.10359v2","updated":"2023-06-22T12:19:56Z","published":"2023-06-17T14:16:24Z","title":"Text-Driven Foley Sound Generation With Latent Diffusion Model","summary":"  Foley sound generation aims to synthesise the background sound for multimedia\ncontent. Previous models usually employ a large development set with labels as\ninput (e.g., single numbers or one-hot vector). In this work, we propose a\ndiffusion model based system for Foley sound generation with text conditions.\nTo alleviate the data scarcity issue, our model is initially pre-trained with\nlarge-scale datasets and fine-tuned to this task via transfer learning using\nthe contrastive language-audio pertaining (CLAP) technique. We have observed\nthat the feature embedding extracted by the text encoder can significantly\naffect the performance of the generation model. Hence, we introduce a trainable\nlayer after the encoder to improve the text embedding produced by the encoder.\nIn addition, we further refine the generated waveform by generating multiple\ncandidate audio clips simultaneously and selecting the best one, which is\ndetermined in terms of the similarity score between the embedding of the\ncandidate clips and the embedding of the target text label. Using the proposed\nmethod, our system ranks ${1}^{st}$ among the systems submitted to DCASE\nChallenge 2023 Task 7. The results of the ablation studies illustrate that the\nproposed techniques significantly improve sound generation performance. The\ncodes for implementing the proposed system are available online.\n","authors":["Yi Yuan","Haohe Liu","Xubo Liu","Xiyuan Kang","Peipei Wu","Mark D. Plumbley","Wenwu Wang"],"pdf_url":"https://arxiv.org/pdf/2306.10359v2.pdf","comment":"Submit to DCASE-workshop 2023. arXiv admin note: text overlap with\n  arXiv:2305.15905"},{"id":"http://arxiv.org/abs/2306.12830v1","updated":"2023-06-22T12:04:49Z","published":"2023-06-22T12:04:49Z","title":"MultiTASC: A Multi-Tenancy-Aware Scheduler for Cascaded DNN Inference at\n  the Consumer Edge","summary":"  Cascade systems comprise a two-model sequence, with a lightweight model\nprocessing all samples and a heavier, higher-accuracy model conditionally\nrefining harder samples to improve accuracy. By placing the light model on the\ndevice side and the heavy model on a server, model cascades constitute a widely\nused distributed inference approach. With the rapid expansion of intelligent\nindoor environments, such as smart homes, the new setting of Multi-Device\nCascade is emerging where multiple and diverse devices are to simultaneously\nuse a shared heavy model on the same server, typically located within or close\nto the consumer environment. This work presents MultiTASC, a\nmulti-tenancy-aware scheduler that adaptively controls the forwarding decision\nfunctions of the devices in order to maximize the system throughput, while\nsustaining high accuracy and low latency. By explicitly considering device\nheterogeneity, our scheduler improves the latency service-level objective (SLO)\nsatisfaction rate by 20-25 percentage points (pp) over state-of-the-art cascade\nmethods in highly heterogeneous setups, while serving over 40 devices,\nshowcasing its scalability.\n","authors":["Sokratis Nikolaidis","Stylianos I. Venieris","Iakovos S. Venieris"],"pdf_url":"https://arxiv.org/pdf/2306.12830v1.pdf","comment":"Accepted at 28th IEEE Symposium on Computers and Communications\n  (ISCC), 2023"},{"id":"http://arxiv.org/abs/2301.08563v2","updated":"2023-06-22T12:00:52Z","published":"2023-01-17T08:37:20Z","title":"A Semi-supervised Sensing Rate Learning based CMAB Scheme to Combat\n  COVID-19 by Trustful Data Collection in the Crowd","summary":"  The recruitment of trustworthy and high-quality workers is an important\nresearch issue for MCS. Previous studies either assume that the qualities of\nworkers are known in advance, or assume that the platform knows the qualities\nof workers once it receives their collected data. In reality, to reduce costs\nand thus maximize revenue, many strategic workers do not perform their sensing\ntasks honestly and report fake data to the platform, which is called False data\nattacks. And it is very hard for the platform to evaluate the authenticity of\nthe received data. In this paper, an incentive mechanism named Semi-supervision\nbased Combinatorial Multi-Armed Bandit reverse Auction (SCMABA) is proposed to\nsolve the recruitment problem of multiple unknown and strategic workers in MCS.\nFirst, we model the worker recruitment as a multi-armed bandit reverse auction\nproblem and design an UCB-based algorithm to separate the exploration and\nexploitation, regarding the Sensing Rates (SRs) of recruited workers as the\ngain of the bandit. Next, a Semi-supervised Sensing Rate Learning (SSRL)\napproach is proposed to quickly and accurately obtain the workers' SRs, which\nconsists of two phases, supervision and self-supervision. Last, SCMABA is\ndesigned organically combining the SRs acquisition mechanism with multi-armed\nbandit reverse auction, where supervised SR learning is used in the\nexploration, and the self-supervised one is used in the exploitation. We\ntheoretically prove that our SCMABA achieves truthfulness and individual\nrationality and exhibits outstanding performances of the SCMABA mechanism\nthrough in-depth simulations of real-world data traces.\n","authors":["Jianheng Tang","Kejia Fan","Wenxuan Xie","Luomin Zeng","Feijiang Han","Guosheng Huang","Tian Wang","Anfeng Liu","Shaobo Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.08563v2.pdf","comment":"18 pages, 14 figures"},{"id":"http://arxiv.org/abs/2209.07912v3","updated":"2023-06-22T11:55:39Z","published":"2022-09-16T13:24:25Z","title":"Algorithmic decision making methods for fair credit scoring","summary":"  The effectiveness of machine learning in evaluating the creditworthiness of\nloan applicants has been demonstrated for a long time. However, there is\nconcern that the use of automated decision-making processes may result in\nunequal treatment of groups or individuals, potentially leading to\ndiscriminatory outcomes. This paper seeks to address this issue by evaluating\nthe effectiveness of 12 leading bias mitigation methods across 5 different\nfairness metrics, as well as assessing their accuracy and potential\nprofitability for financial institutions. Through our analysis, we have\nidentified the challenges associated with achieving fairness while maintaining\naccuracy and profitabiliy, and have highlighted both the most successful and\nleast successful mitigation methods. Ultimately, our research serves to bridge\nthe gap between experimental machine learning and its practical applications in\nthe finance industry.\n","authors":["Darie Moldovan"],"pdf_url":"https://arxiv.org/pdf/2209.07912v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12818v1","updated":"2023-06-22T11:34:08Z","published":"2023-06-22T11:34:08Z","title":"StrainNet: Predicting crystal structure elastic properties using\n  SE(3)-equivariant graph neural networks","summary":"  Accurately predicting the elastic properties of crystalline solids is vital\nfor computational materials science. However, traditional atomistic scale ab\ninitio approaches are computationally intensive, especially for studying\ncomplex materials with a large number of atoms in a unit cell. We introduce a\nnovel data-driven approach to efficiently predict the elastic properties of\ncrystal structures using SE(3)-equivariant graph neural networks (GNNs). This\napproach yields important scalar elastic moduli with the accuracy comparable to\nrecent data-driven studies. Importantly, our symmetry-aware GNNs model also\nenables the prediction of the strain energy density (SED) and the associated\nelastic constants, the fundamental tensorial quantities that are significantly\ninfluenced by a material's crystallographic group. The model consistently\ndistinguishes independent elements of SED tensors, in accordance with the\nsymmetry of the crystal structures. Finally, our deep learning model possesses\nmeaningful latent features, offering an interpretable prediction of the elastic\nproperties.\n","authors":["Teerachote Pakornchote","Annop Ektarawong","Thiparat Chotibut"],"pdf_url":"https://arxiv.org/pdf/2306.12818v1.pdf","comment":"25 pages, 15 figures"},{"id":"http://arxiv.org/abs/2306.12816v1","updated":"2023-06-22T11:31:11Z","published":"2023-06-22T11:31:11Z","title":"XAI-TRIS: Non-linear benchmarks to quantify ML explanation performance","summary":"  The field of 'explainable' artificial intelligence (XAI) has produced highly\ncited methods that seek to make the decisions of complex machine learning (ML)\nmethods 'understandable' to humans, for example by attributing 'importance'\nscores to input features. Yet, a lack of formal underpinning leaves it unclear\nas to what conclusions can safely be drawn from the results of a given XAI\nmethod and has also so far hindered the theoretical verification and empirical\nvalidation of XAI methods. This means that challenging non-linear problems,\ntypically solved by deep neural networks, presently lack appropriate remedies.\nHere, we craft benchmark datasets for three different non-linear classification\nscenarios, in which the important class-conditional features are known by\ndesign, serving as ground truth explanations. Using novel quantitative metrics,\nwe benchmark the explanation performance of a wide set of XAI methods across\nthree deep learning model architectures. We show that popular XAI methods are\noften unable to significantly outperform random performance baselines and edge\ndetection methods. Moreover, we demonstrate that explanations derived from\ndifferent model architectures can be vastly different; thus, prone to\nmisinterpretation even under controlled conditions.\n","authors":["Benedict Clark","Rick Wilming","Stefan Haufe"],"pdf_url":"https://arxiv.org/pdf/2306.12816v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2306.11086v2","updated":"2023-06-22T11:24:27Z","published":"2023-06-19T17:59:04Z","title":"Enhancing variational quantum state diagonalization using reinforcement\n  learning techniques","summary":"  The development of variational quantum algorithms is crucial for the\napplication of NISQ computers. Such algorithms require short quantum circuits,\nwhich are more amenable to implementation on near-term hardware, and many such\nmethods have been developed. One of particular interest is the so-called the\nvariational diagonalization method, which constitutes an important algorithmic\nsubroutine, and it can be used directly for working with data encoded in\nquantum states. In particular, it can be applied to discern the features of\nquantum states, such as entanglement properties of a system, or in quantum\nmachine learning algorithms. In this work, we tackle the problem of designing a\nvery shallow quantum circuit, required in the quantum state diagonalization\ntask, by utilizing reinforcement learning. To achieve this, we utilize a novel\nencoding method that can be used to tackle the problem of circuit depth\noptimization using a reinforcement learning approach. We demonstrate that our\napproach provides a solid approximation to the diagonalization task while using\na small number of gates. The circuits proposed by the reinforcement learning\nmethods are shallower than the standard variational quantum state\ndiagonalization algorithm, and thus can be used in situations where the depth\nof quantum circuits is limited by the hardware capabilities.\n","authors":["Akash Kundu","Przemysław Bedełek","Mateusz Ostaszewski","Onur Danaci","Yash J. Patel","Vedran Dunjko","Jarosław A. Miszczak"],"pdf_url":"https://arxiv.org/pdf/2306.11086v2.pdf","comment":"17 pages with 13 figures, some minor, important improvements, code\n  available at https://github.com/iitis/RL_for_VQSD_ansatz_optimization"},{"id":"http://arxiv.org/abs/2301.06883v2","updated":"2023-06-22T11:11:18Z","published":"2023-01-17T13:39:26Z","title":"The quantum cost function concentration dependency on the\n  parametrization expressivity","summary":"  Although we are currently in the era of noisy intermediate scale quantum\ndevices, several studies are being conducted with the aim of bringing machine\nlearning to the quantum domain. Currently, quantum variational circuits are one\nof the main strategies used to build such models. However, despite its\nwidespread use, we still do not know what are the minimum resources needed to\ncreate a quantum machine learning model. In this article, we analyze how the\nexpressiveness of the parametrization affects the cost function. We\nanalytically show that the more expressive the parametrization is, the more the\ncost function will tend to concentrate around a value that depends both on the\nchosen observable and on the number of qubits used. For this, we initially\nobtain a relationship between the expressiveness of the parametrization and the\nmean value of the cost function. Afterwards, we relate the expressivity of the\nparametrization with the variance of the cost function. Finally, we show some\nnumerical simulation results that confirm our theoretical-analytical\npredictions. To the best of our knowledge, this is the first time that these\ntwo important aspects of quantum neural networks are explicitly connected.\n","authors":["Lucas Friedrich","Jonas Maziero"],"pdf_url":"https://arxiv.org/pdf/2301.06883v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12806v1","updated":"2023-06-22T11:06:04Z","published":"2023-06-22T11:06:04Z","title":"Conditional Generators for Limit Order Book Environments:\n  Explainability, Challenges, and Robustness","summary":"  Limit order books are a fundamental and widespread market mechanism. This\npaper investigates the use of conditional generative models for order book\nsimulation. For developing a trading agent, this approach has drawn recent\nattention as an alternative to traditional backtesting due to its ability to\nreact to the presence of the trading agent. Using a state-of-the-art CGAN (from\nColetta et al. (2022)), we explore its dependence upon input features, which\nhighlights both strengths and weaknesses. To do this, we use \"adversarial\nattacks\" on the model's features and its mechanism. We then show how these\ninsights can be used to improve the CGAN, both in terms of its realism and\nrobustness. We finish by laying out a roadmap for future work.\n","authors":["Andrea Coletta","Joseph Jerome","Rahul Savani","Svitlana Vyetrenko"],"pdf_url":"https://arxiv.org/pdf/2306.12806v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.14180v3","updated":"2023-06-22T11:03:30Z","published":"2023-05-23T15:58:53Z","title":"Multi-BVOC Super-Resolution Exploiting Compounds Inter-Connection","summary":"  Biogenic Volatile Organic Compounds (BVOCs) emitted from the terrestrial\necosystem into the Earth's atmosphere are an important component of atmospheric\nchemistry. Due to the scarcity of measurement, a reliable enhancement of BVOCs\nemission maps can aid in providing denser data for atmospheric chemical,\nclimate, and air quality models. In this work, we propose a strategy to\nsuper-resolve coarse BVOC emission maps by simultaneously exploiting the\ncontributions of different compounds. To this purpose, we first accurately\ninvestigate the spatial inter-connections between several BVOC species. Then,\nwe exploit the found similarities to build a Multi-Image Super-Resolution\n(MISR) system, in which a number of emission maps associated with diverse\ncompounds are aggregated to boost Super-Resolution (SR) performance. We compare\ndifferent configurations regarding the species and the number of joined BVOCs.\nOur experimental results show that incorporating BVOCs' relationship into the\nprocess can substantially improve the accuracy of the super-resolved maps.\nInterestingly, the best results are achieved when we aggregate the emission\nmaps of strongly uncorrelated compounds. This peculiarity seems to confirm what\nwas already guessed for other data-domains, i.e., joined uncorrelated\ninformation are more helpful than correlated ones to boost MISR performance.\nNonetheless, the proposed work represents the first attempt in SR of BVOC\nemissions through the fusion of multiple different compounds.\n","authors":["Antonio Giganti","Sara Mandelli","Paolo Bestagini","Marco Marcon","Stefano Tubaro"],"pdf_url":"https://arxiv.org/pdf/2305.14180v3.pdf","comment":"5 pages, 4 figures, 1 table, accepted at EURASIP-EUSIPCO 2023"},{"id":"http://arxiv.org/abs/2306.12803v1","updated":"2023-06-22T11:02:18Z","published":"2023-06-22T11:02:18Z","title":"Robust Statistical Comparison of Random Variables with Locally Varying\n  Scale of Measurement","summary":"  Spaces with locally varying scale of measurement, like multidimensional\nstructures with differently scaled dimensions, are pretty common in statistics\nand machine learning. Nevertheless, it is still understood as an open question\nhow to exploit the entire information encoded in them properly. We address this\nproblem by considering an order based on (sets of) expectations of random\nvariables mapping into such non-standard spaces. This order contains stochastic\ndominance and expectation order as extreme cases when no, or respectively\nperfect, cardinal structure is given. We derive a (regularized) statistical\ntest for our proposed generalized stochastic dominance (GSD) order,\noperationalize it by linear optimization, and robustify it by imprecise\nprobability models. Our findings are illustrated with data from\nmultidimensional poverty measurement, finance, and medicine.\n","authors":["Christoph Jansen","Georg Schollmeyer","Hannah Blocher","Julian Rodemann","Thomas Augustin"],"pdf_url":"https://arxiv.org/pdf/2306.12803v1.pdf","comment":"Accepted for the 39th Conference on Uncertainty in Artificial\n  Intelligence (UAI 2023)"},{"id":"http://arxiv.org/abs/2306.12802v1","updated":"2023-06-22T11:01:41Z","published":"2023-06-22T11:01:41Z","title":"Otter-Knowledge: benchmarks of multimodal knowledge graph representation\n  learning from different sources for drug discovery","summary":"  Recent research in representation learning utilizes large databases of\nproteins or molecules to acquire knowledge of drug and protein structures\nthrough unsupervised learning techniques. These pre-trained representations\nhave proven to significantly enhance the accuracy of subsequent tasks, such as\npredicting the affinity between drugs and target proteins. In this study, we\ndemonstrate that by incorporating knowledge graphs from diverse sources and\nmodalities into the sequences or SMILES representation, we can further enrich\nthe representation and achieve state-of-the-art results on established\nbenchmark datasets. We provide preprocessed and integrated data obtained from 7\npublic sources, which encompass over 30M triples. Additionally, we make\navailable the pre-trained models based on this data, along with the reported\noutcomes of their performance on three widely-used benchmark datasets for\ndrug-target binding affinity prediction found in the Therapeutic Data Commons\n(TDC) benchmarks. Additionally, we make the source code for training models on\nbenchmark datasets publicly available. Our objective in releasing these\npre-trained models, accompanied by clean data for model pretraining and\nbenchmark results, is to encourage research in knowledge-enhanced\nrepresentation learning.\n","authors":["Hoang Thanh Lam","Marco Luca Sbodio","Marcos Martínez Gallindo","Mykhaylo Zayats","Raúl Fernández-Díaz","Víctor Valls","Gabriele Picco","Cesar Berrospi Ramis","Vanessa López"],"pdf_url":"https://arxiv.org/pdf/2306.12802v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12800v1","updated":"2023-06-22T10:59:58Z","published":"2023-06-22T10:59:58Z","title":"HypeRS: Building a Hypergraph-driven ensemble Recommender System","summary":"  Recommender systems are designed to predict user preferences over collections\nof items. These systems process users' previous interactions to decide which\nitems should be ranked higher to satisfy their desires. An ensemble recommender\nsystem can achieve great recommendation performance by effectively combining\nthe decisions generated by individual models. In this paper, we propose a novel\nensemble recommender system that combines predictions made by different models\ninto a unified hypergraph ranking framework. This is the first time that\nhypergraph ranking has been employed to model an ensemble of recommender\nsystems. Hypergraphs are generalizations of graphs where multiple vertices can\nbe connected via hyperedges, efficiently modeling high-order relations. We\ndifferentiate real and predicted connections between users and items by\nassigning different hyperedge weights to individual recommender systems. We\nperform experiments using four datasets from the fields of movie, music and\nnews media recommendation. The obtained results show that the ensemble\nhypergraph ranking method generates more accurate recommendations compared to\nthe individual models and a weighted hybrid approach. The assignment of\ndifferent hyperedge weights to the ensemble hypergraph further improves the\nperformance compared to a setting with identical hyperedge weights.\n","authors":["Alireza Gharahighehi","Celine Vens","Konstantinos Pliakos"],"pdf_url":"https://arxiv.org/pdf/2306.12800v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.06868v2","updated":"2023-06-22T10:50:56Z","published":"2022-08-14T15:25:41Z","title":"Frouros: A Python library for drift detection in machine learning\n  systems","summary":"  Frouros is an open-source Python library capable of detecting drift in\nmachine learning systems. It provides a combination of classical and more\nrecent algorithms for drift detection: both concept and data drift. We have\ndesigned it with the objective of making it compatible with any machine\nlearning framework and easily adaptable to real-world use cases. The library is\ndeveloped following a set of best development and continuous integration\npractices to ensure ease of maintenance and extensibility. The source code is\navailable at https://github.com/IFCA/frouros.\n","authors":["Jaime Céspedes-Sisniega","Álvaro López-García"],"pdf_url":"https://arxiv.org/pdf/2208.06868v2.pdf","comment":"11 pages, 1 table"},{"id":"http://arxiv.org/abs/2303.04091v3","updated":"2023-06-22T10:41:41Z","published":"2023-03-07T17:52:46Z","title":"Abstract Visual Reasoning Enabled by Language","summary":"  While artificial intelligence (AI) models have achieved human or even\nsuperhuman performance in many well-defined applications, they still struggle\nto show signs of broad and flexible intelligence. The Abstraction and Reasoning\nCorpus (ARC), a visual intelligence benchmark introduced by Fran\\c{c}ois\nChollet, aims to assess how close AI systems are to human-like cognitive\nabilities. Most current approaches rely on carefully handcrafted\ndomain-specific program searches to brute-force solutions for the tasks present\nin ARC. In this work, we propose a general learning-based framework for solving\nARC. It is centered on transforming tasks from the vision to the language\ndomain. This composition of language and vision allows for pre-trained models\nto be leveraged at each stage, enabling a shift from handcrafted priors towards\nthe learned priors of the models. While not yet beating state-of-the-art models\non ARC, we demonstrate the potential of our approach, for instance, by solving\nsome ARC tasks that have not been solved previously.\n","authors":["Giacomo Camposampiero","Loic Houmard","Benjamin Estermann","Joël Mathys","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2303.04091v3.pdf","comment":"The first two authors have contributed equally to this work. Accepted\n  as regular paper at CVPR 2023 Workshop and Challenges for New Frontiers in\n  Visual Language Reasoning: Compositionality, Prompts and Causality (NFVLR)"},{"id":"http://arxiv.org/abs/2211.12020v3","updated":"2023-06-22T10:34:42Z","published":"2022-11-22T05:24:30Z","title":"PhAST: Physics-Aware, Scalable, and Task-specific GNNs for Accelerated\n  Catalyst Design","summary":"  Mitigating the climate crisis requires a rapid transition towards\nlower-carbon energy. Catalyst materials play a crucial role in the\nelectrochemical reactions involved in numerous industrial processes key to this\ntransition, such as renewable energy storage and electrofuel synthesis. To\nreduce the energy spent on such activities, we must quickly discover more\nefficient catalysts to drive electrochemical reactions. Machine learning (ML)\nholds the potential to efficiently model materials properties from large\namounts of data, accelerating electrocatalyst design. The Open Catalyst Project\nOC20 dataset was constructed to that end. However, ML models trained on OC20\nare still neither scalable nor accurate enough for practical applications. In\nthis paper, we propose task-specific innovations applicable to most\narchitectures, enhancing both computational efficiency and accuracy. This\nincludes improvements in (1) the graph creation step, (2) atom representations,\n(3) the energy prediction head, and (4) the force prediction head. We describe\nthese contributions and evaluate them thoroughly on multiple architectures.\nOverall, our proposed PhAST improvements increase energy MAE by 4 to 42$\\%$\nwhile dividing compute time by 3 to 8$\\times$ depending on the targeted\ntask/model. PhAST also enables CPU training, leading to 40$\\times$ speedups in\nhighly parallelized settings. Python package:\n\\url{https://phast.readthedocs.io}.\n","authors":["Alexandre Duval","Victor Schmidt","Santiago Miret","Yoshua Bengio","Alex Hernández-García","David Rolnick"],"pdf_url":"https://arxiv.org/pdf/2211.12020v3.pdf","comment":"Accepted at the NeurIPS 2022 AI for Accelerated Materials Design\n  Workshop. Under submission at JMLR"},{"id":"http://arxiv.org/abs/2306.12306v2","updated":"2023-06-22T10:26:21Z","published":"2023-06-21T14:36:03Z","title":"Beyond Deep Ensembles: A Large-Scale Evaluation of Bayesian Deep\n  Learning under Distribution Shift","summary":"  Bayesian deep learning (BDL) is a promising approach to achieve\nwell-calibrated predictions on distribution-shifted data. Nevertheless, there\nexists no large-scale survey that evaluates recent SOTA methods on diverse,\nrealistic, and challenging benchmark tasks in a systematic manner. To provide a\nclear picture of the current state of BDL research, we evaluate modern BDL\nalgorithms on real-world datasets from the WILDS collection containing\nchallenging classification and regression tasks, with a focus on generalization\ncapability and calibration under distribution shift. We compare the algorithms\non a wide range of large, convolutional and transformer-based neural network\narchitectures. In particular, we investigate a signed version of the expected\ncalibration error that reveals whether the methods are over- or\nunder-confident, providing further insight into the behavior of the methods.\nFurther, we provide the first systematic evaluation of BDL for fine-tuning\nlarge pre-trained models, where training from scratch is prohibitively\nexpensive. Finally, given the recent success of Deep Ensembles, we extend\npopular single-mode posterior approximations to multiple modes by the use of\nensembles. While we find that ensembling single-mode approximations generally\nimproves the generalization capability and calibration of the models by a\nsignificant margin, we also identify a failure mode of ensembles when\nfinetuning large transformer-based language models. In this setting,\nvariational inference based approaches such as last-layer Bayes By Backprop\noutperform other methods in terms of accuracy by a large margin, while modern\napproximate inference algorithms such as SWAG achieve the best calibration.\n","authors":["Florian Seligmann","Philipp Becker","Michael Volpp","Gerhard Neumann"],"pdf_url":"https://arxiv.org/pdf/2306.12306v2.pdf","comment":"Code at https://github.com/Feuermagier/Beyond_Deep_Ensembles"},{"id":"http://arxiv.org/abs/2306.12776v1","updated":"2023-06-22T10:10:34Z","published":"2023-06-22T10:10:34Z","title":"A prior regularized full waveform inversion using generative diffusion\n  models","summary":"  Full waveform inversion (FWI) has the potential to provide high-resolution\nsubsurface model estimations. However, due to limitations in observation, e.g.,\nregional noise, limited shots or receivers, and band-limited data, it is hard\nto obtain the desired high-resolution model with FWI. To address this\nchallenge, we propose a new paradigm for FWI regularized by generative\ndiffusion models. Specifically, we pre-train a diffusion model in a fully\nunsupervised manner on a prior velocity model distribution that represents our\nexpectations of the subsurface and then adapt it to the seismic observations by\nincorporating the FWI into the sampling process of the generative diffusion\nmodels. What makes diffusion models uniquely appropriate for such an\nimplementation is that the generative process retains the form and dimensions\nof the velocity model. Numerical examples demonstrate that our method can\noutperform the conventional FWI with only negligible additional computational\ncost. Even in cases of very sparse observations or observations with strong\nnoise, the proposed method could still reconstruct a high-quality subsurface\nmodel. Thus, we can incorporate our prior expectations of the solutions in an\nefficient manner. We further test this approach on field data, which\ndemonstrates the effectiveness of the proposed method.\n","authors":["Fu Wang","Xinquan Huang","Tariq Alkhalifah"],"pdf_url":"https://arxiv.org/pdf/2306.12776v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12774v1","updated":"2023-06-22T10:00:33Z","published":"2023-06-22T10:00:33Z","title":"Pure Exploration in Bandits with Linear Constraints","summary":"  We address the problem of identifying the optimal policy with a fixed\nconfidence level in a multi-armed bandit setup, when \\emph{the arms are subject\nto linear constraints}. Unlike the standard best-arm identification problem\nwhich is well studied, the optimal policy in this case may not be deterministic\nand could mix between several arms. This changes the geometry of the problem\nwhich we characterize via an information-theoretic lower bound. We introduce\ntwo asymptotically optimal algorithms for this setting, one based on the\nTrack-and-Stop method and the other based on a game-theoretic approach. Both\nthese algorithms try to track an optimal allocation based on the lower bound\nand computed by a weighted projection onto the boundary of a normal cone.\nFinally, we provide empirical results that validate our bounds and visualize\nhow constraints change the hardness of the problem.\n","authors":["Emil Carlsson","Debabrota Basu","Fredrik D. Johansson","Devdatt Dubhashi"],"pdf_url":"https://arxiv.org/pdf/2306.12774v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12768v1","updated":"2023-06-22T09:45:40Z","published":"2023-06-22T09:45:40Z","title":"Concept-aware clustering for decentralized deep learning under temporal\n  shift","summary":"  Decentralized deep learning requires dealing with non-iid data across\nclients, which may also change over time due to temporal shifts. While non-iid\ndata has been extensively studied in distributed settings, temporal shifts have\nreceived no attention. To the best of our knowledge, we are first with tackling\nthe novel and challenging problem of decentralized learning with non-iid and\ndynamic data. We propose a novel algorithm that can automatically discover and\nadapt to the evolving concepts in the network, without any prior knowledge or\nestimation of the number of concepts. We evaluate our algorithm on standard\nbenchmark datasets and demonstrate that it outperforms previous methods for\ndecentralized learning.\n","authors":["Marcus Toftås","Emilie Klefbom","Edvin Listo Zec","Martin Willbo","Olof Mogren"],"pdf_url":"https://arxiv.org/pdf/2306.12768v1.pdf","comment":"4 pages, 2 figures"},{"id":"http://arxiv.org/abs/2306.12760v1","updated":"2023-06-22T09:34:55Z","published":"2023-06-22T09:34:55Z","title":"Blended-NeRF: Zero-Shot Object Generation and Blending in Existing\n  Neural Radiance Fields","summary":"  Editing a local region or a specific object in a 3D scene represented by a\nNeRF is challenging, mainly due to the implicit nature of the scene\nrepresentation. Consistently blending a new realistic object into the scene\nadds an additional level of difficulty. We present Blended-NeRF, a robust and\nflexible framework for editing a specific region of interest in an existing\nNeRF scene, based on text prompts or image patches, along with a 3D ROI box.\nOur method leverages a pretrained language-image model to steer the synthesis\ntowards a user-provided text prompt or image patch, along with a 3D MLP model\ninitialized on an existing NeRF scene to generate the object and blend it into\na specified region in the original scene. We allow local editing by localizing\na 3D ROI box in the input scene, and seamlessly blend the content synthesized\ninside the ROI with the existing scene using a novel volumetric blending\ntechnique. To obtain natural looking and view-consistent results, we leverage\nexisting and new geometric priors and 3D augmentations for improving the visual\nfidelity of the final result.\n  We test our framework both qualitatively and quantitatively on a variety of\nreal 3D scenes and text prompts, demonstrating realistic multi-view consistent\nresults with much flexibility and diversity compared to the baselines. Finally,\nwe show the applicability of our framework for several 3D editing applications,\nincluding adding new objects to a scene, removing/replacing/altering existing\nobjects, and texture conversion.\n","authors":["Ori Gordon","Omri Avrahami","Dani Lischinski"],"pdf_url":"https://arxiv.org/pdf/2306.12760v1.pdf","comment":"14 pages, 12 figures. Project page:\n  https://www.vision.huji.ac.il/blended-nerf/"},{"id":"http://arxiv.org/abs/2306.12756v1","updated":"2023-06-22T09:18:52Z","published":"2023-06-22T09:18:52Z","title":"On the Robustness of Generative Retrieval Models: An Out-of-Distribution\n  Perspective","summary":"  Recently, we have witnessed generative retrieval increasingly gaining\nattention in the information retrieval (IR) field, which retrieves documents by\ndirectly generating their identifiers. So far, much effort has been devoted to\ndeveloping effective generative retrieval models. There has been less attention\npaid to the robustness perspective. When a new retrieval paradigm enters into\nthe real-world application, it is also critical to measure the\nout-of-distribution (OOD) generalization, i.e., how would generative retrieval\nmodels generalize to new distributions. To answer this question, firstly, we\ndefine OOD robustness from three perspectives in retrieval problems: 1) The\nquery variations; 2) The unforeseen query types; and 3) The unforeseen tasks.\nBased on this taxonomy, we conduct empirical studies to analyze the OOD\nrobustness of several representative generative retrieval models against dense\nretrieval models. The empirical results indicate that the OOD robustness of\ngenerative retrieval models requires enhancement. We hope studying the OOD\nrobustness of generative retrieval models would be advantageous to the IR\ncommunity.\n","authors":["Yu-An Liu","Ruqing Zhang","Jiafeng Guo","Wei Chen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2306.12756v1.pdf","comment":"4 pages, submit to GenIR23"},{"id":"http://arxiv.org/abs/2109.07557v3","updated":"2023-06-22T09:17:44Z","published":"2021-09-15T20:09:13Z","title":"CounterNet: End-to-End Training of Prediction Aware Counterfactual\n  Explanations","summary":"  This work presents CounterNet, a novel end-to-end learning framework which\nintegrates Machine Learning (ML) model training and the generation of\ncorresponding counterfactual (CF) explanations into a single end-to-end\npipeline. Counterfactual explanations offer a contrastive case, i.e., they\nattempt to find the smallest modification to the feature values of an instance\nthat changes the prediction of the ML model on that instance to a predefined\noutput. Prior techniques for generating CF explanations suffer from two major\nlimitations: (i) all of them are post-hoc methods designed for use with\nproprietary ML models -- as a result, their procedure for generating CF\nexplanations is uninformed by the training of the ML model, which leads to\nmisalignment between model predictions and explanations; and (ii) most of them\nrely on solving separate time-intensive optimization problems to find CF\nexplanations for each input data point (which negatively impacts their\nruntime). This work makes a novel departure from the prevalent post-hoc\nparadigm (of generating CF explanations) by presenting CounterNet, an\nend-to-end learning framework which integrates predictive model training and\nthe generation of counterfactual (CF) explanations into a single pipeline.\nUnlike post-hoc methods, CounterNet enables the optimization of the CF\nexplanation generation only once together with the predictive model. We adopt a\nblock-wise coordinate descent procedure which helps in effectively training\nCounterNet's network. Our extensive experiments on multiple real-world datasets\nshow that CounterNet generates high-quality predictions, and consistently\nachieves 100% CF validity and low proximity scores (thereby achieving a\nwell-balanced cost-invalidity trade-off) for any new input instance, and runs\n3X faster than existing state-of-the-art baselines.\n","authors":["Hangzhi Guo","Thanh Hong Nguyen","Amulya Yadav"],"pdf_url":"https://arxiv.org/pdf/2109.07557v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12755v1","updated":"2023-06-22T09:17:23Z","published":"2023-06-22T09:17:23Z","title":"Beyond OOD State Actions: Supported Cross-Domain Offline Reinforcement\n  Learning","summary":"  Offline reinforcement learning (RL) aims to learn a policy using only\npre-collected and fixed data. Although avoiding the time-consuming online\ninteractions in RL, it poses challenges for out-of-distribution (OOD) state\nactions and often suffers from data inefficiency for training. Despite many\nefforts being devoted to addressing OOD state actions, the latter (data\ninefficiency) receives little attention in offline RL. To address this, this\npaper proposes the cross-domain offline RL, which assumes offline data\nincorporate additional source-domain data from varying transition dynamics\n(environments), and expects it to contribute to the offline data efficiency. To\ndo so, we identify a new challenge of OOD transition dynamics, beyond the\ncommon OOD state actions issue, when utilizing cross-domain offline data. Then,\nwe propose our method BOSA, which employs two support-constrained objectives to\naddress the above OOD issues. Through extensive experiments in the cross-domain\noffline RL setting, we demonstrate BOSA can greatly improve offline data\nefficiency: using only 10\\% of the target data, BOSA could achieve {74.4\\%} of\nthe SOTA offline RL performance that uses 100\\% of the target data.\nAdditionally, we also show BOSA can be effortlessly plugged into model-based\noffline RL and noising data augmentation techniques (used for generating\nsource-domain data), which naturally avoids the potential dynamics mismatch\nbetween target-domain data and newly generated source-domain data.\n","authors":["Jinxin Liu","Ziqi Zhang","Zhenyu Wei","Zifeng Zhuang","Yachen Kang","Sibo Gai","Donglin Wang"],"pdf_url":"https://arxiv.org/pdf/2306.12755v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12747v1","updated":"2023-06-22T09:01:58Z","published":"2023-06-22T09:01:58Z","title":"Don't be so Monotone: Relaxing Stochastic Line Search in\n  Over-Parameterized Models","summary":"  Recent works have shown that line search methods can speed up Stochastic\nGradient Descent (SGD) and Adam in modern over-parameterized settings. However,\nexisting line searches may take steps that are smaller than necessary since\nthey require a monotone decrease of the (mini-)batch objective function. We\nexplore nonmonotone line search methods to relax this condition and possibly\naccept larger step sizes. Despite the lack of a monotonic decrease, we prove\nthe same fast rates of convergence as in the monotone case. Our experiments\nshow that nonmonotone methods improve the speed of convergence and\ngeneralization properties of SGD/Adam even beyond the previous monotone line\nsearches. We propose a POlyak NOnmonotone Stochastic (PoNoS) method, obtained\nby combining a nonmonotone line search with a Polyak initial step size.\nFurthermore, we develop a new resetting technique that in the majority of the\niterations reduces the amount of backtracks to zero while still maintaining a\nlarge initial step size. To the best of our knowledge, a first runtime\ncomparison shows that the epoch-wise advantage of line-search-based methods\ngets reflected in the overall computational time.\n","authors":["Leonardo Galli","Holger Rauhut","Mark Schmidt"],"pdf_url":"https://arxiv.org/pdf/2306.12747v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.15359v2","updated":"2023-06-22T08:55:12Z","published":"2022-11-25T14:29:26Z","title":"Improving Proactive Dialog Agents Using Socially-Aware Reinforcement\n  Learning","summary":"  The next step for intelligent dialog agents is to escape their role as silent\nbystanders and become proactive. Well-defined proactive behavior may improve\nhuman-machine cooperation, as the agent takes a more active role during\ninteraction and takes off responsibility from the user. However, proactivity is\na double-edged sword because poorly executed pre-emptive actions may have a\ndevastating effect not only on the task outcome but also on the relationship\nwith the user. For designing adequate proactive dialog strategies, we propose a\nnovel approach including both social as well as task-relevant features in the\ndialog. Here, the primary goal is to optimize proactive behavior so that it is\ntask-oriented - this implies high task success and efficiency - while also\nbeing socially effective by fostering user trust. Including both aspects in the\nreward function for training a proactive dialog agent using reinforcement\nlearning showed the benefit of our approach for more successful human-machine\ncooperation.\n","authors":["Matthias Kraus","Nicolas Wagner","Ron Riekenbrauck","Wolfgang Minker"],"pdf_url":"https://arxiv.org/pdf/2211.15359v2.pdf","comment":"Preprint of paper publication in UMAP`23"},{"id":"http://arxiv.org/abs/2306.11342v2","updated":"2023-06-22T08:12:57Z","published":"2023-06-20T07:21:31Z","title":"Exploring Antitrust and Platform Power in Generative AI","summary":"  The concentration of power in a few digital technology companies has become a\nsubject of increasing interest in both academic and non-academic discussions.\nOne of the most noteworthy contributions to the debate is Lina Khan's Amazon's\nAntitrust Paradox. In this work, Khan contends that Amazon has systematically\nexerted its dominance in online retail to eliminate competitors and\nsubsequently charge above-market prices. This work contributed to Khan's\nappointment as the chair of the US Federal Trade Commission (FTC), one of the\nmost influential antitrust organizations. Today, several ongoing antitrust\nlawsuits in the US and Europe involve major technology companies like Apple,\nGoogle/Alphabet, and Facebook/Meta. In the realm of generative AI, we are once\nagain witnessing the same companies taking the lead in technological\nadvancements, leaving little room for others to compete. This article examines\nthe market dominance of these corporations in the technology stack behind\ngenerative AI from an antitrust law perspective.\n","authors":["Konrad Kollnig","Qian Li"],"pdf_url":"https://arxiv.org/pdf/2306.11342v2.pdf","comment":"Accepted by the Workshop on Generative AI and Law (GenLaw '23) of\n  ICML '23"},{"id":"http://arxiv.org/abs/2306.12729v1","updated":"2023-06-22T08:11:32Z","published":"2023-06-22T08:11:32Z","title":"MP3: Movement Primitive-Based (Re-)Planning Policy","summary":"  We introduce a novel deep reinforcement learning (RL) approach called\nMovement Prmitive-based Planning Policy (MP3). By integrating movement\nprimitives (MPs) into the deep RL framework, MP3 enables the generation of\nsmooth trajectories throughout the whole learning process while effectively\nlearning from sparse and non-Markovian rewards. Additionally, MP3 maintains the\ncapability to adapt to changes in the environment during execution. Although\nmany early successes in robot RL have been achieved by combining RL with MPs,\nthese approaches are often limited to learning single stroke-based motions,\nlacking the ability to adapt to task variations or adjust motions during\nexecution. Building upon our previous work, which introduced an episode-based\nRL method for the non-linear adaptation of MP parameters to different task\nvariations, this paper extends the approach to incorporating replanning\nstrategies. This allows adaptation of the MP parameters throughout motion\nexecution, addressing the lack of online motion adaptation in stochastic\ndomains requiring feedback. We compared our approach against state-of-the-art\ndeep RL and RL with MPs methods. The results demonstrated improved performance\nin sophisticated, sparse reward settings and in domains requiring replanning.\n","authors":["Fabian Otto","Hongyi Zhou","Onur Celik","Ge Li","Rudolf Lioutikov","Gerhard Neumann"],"pdf_url":"https://arxiv.org/pdf/2306.12729v1.pdf","comment":"The video demonstration can be accessed at\n  https://intuitive-robots.github.io/mp3_website/. arXiv admin note: text\n  overlap with arXiv:2210.09622"},{"id":"http://arxiv.org/abs/2212.01793v2","updated":"2023-06-22T08:09:16Z","published":"2022-12-04T10:45:42Z","title":"\\{kappa}HGCN: Tree-likeness Modeling via Continuous and Discrete\n  Curvature Learning","summary":"  The prevalence of tree-like structures, encompassing hierarchical structures\nand power law distributions, exists extensively in real-world applications,\nincluding recommendation systems, ecosystems, financial networks, social\nnetworks, etc. Recently, the exploitation of hyperbolic space for tree-likeness\nmodeling has garnered considerable attention owing to its exponential growth\nvolume. Compared to the flat Euclidean space, the curved hyperbolic space\nprovides a more amenable and embeddable room, especially for datasets\nexhibiting implicit tree-like architectures. However, the intricate nature of\nreal-world tree-like data presents a considerable challenge, as it frequently\ndisplays a heterogeneous composition of tree-like, flat, and circular regions.\nThe direct embedding of such heterogeneous structures into a homogeneous\nembedding space (i.e., hyperbolic space) inevitably leads to heavy distortions.\nTo mitigate the aforementioned shortage, this study endeavors to explore the\ncurvature between discrete structure and continuous learning space, aiming at\nencoding the message conveyed by the network topology in the learning process,\nthereby improving tree-likeness modeling. To the end, a curvature-aware\nhyperbolic graph convolutional neural network, \\{kappa}HGCN, is proposed, which\nutilizes the curvature to guide message passing and improve long-range\npropagation. Extensive experiments on node classification and link prediction\ntasks verify the superiority of the proposal as it consistently outperforms\nvarious competitive models by a large margin.\n","authors":["Menglin Yang","Min Zhou","Lujia Pan","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2212.01793v2.pdf","comment":"KDD 2023"},{"id":"http://arxiv.org/abs/2306.12726v1","updated":"2023-06-22T08:02:01Z","published":"2023-06-22T08:02:01Z","title":"On Exploring Node-feature and Graph-structure Diversities for Node Drop\n  Graph Pooling","summary":"  A pooling operation is essential for effective graph-level representation\nlearning, where the node drop pooling has become one mainstream graph pooling\ntechnology. However, current node drop pooling methods usually keep the top-k\nnodes according to their significance scores, which ignore the graph diversity\nin terms of the node features and the graph structures, thus resulting in\nsuboptimal graph-level representations. To address the aforementioned issue, we\npropose a novel plug-and-play score scheme and refer to it as MID, which\nconsists of a \\textbf{M}ultidimensional score space with two operations,\n\\textit{i.e.}, fl\\textbf{I}pscore and \\textbf{D}ropscore. Specifically, the\nmultidimensional score space depicts the significance of nodes through multiple\ncriteria; the flipscore encourages the maintenance of dissimilar node features;\nand the dropscore forces the model to notice diverse graph structures instead\nof being stuck in significant local structures. To evaluate the effectiveness\nof our proposed MID, we perform extensive experiments by applying it to a wide\nvariety of recent node drop pooling methods, including TopKPool, SAGPool,\nGSAPool, and ASAP. Specifically, the proposed MID can efficiently and\nconsistently achieve about 2.8\\% average improvements over the above four\nmethods on seventeen real-world graph classification datasets, including four\nsocial datasets (IMDB-BINARY, IMDB-MULTI, REDDIT-BINARY, and COLLAB), and\nthirteen biochemical datasets (D\\&D, PROTEINS, NCI1, MUTAG, PTC-MR, NCI109,\nENZYMES, MUTAGENICITY, FRANKENSTEIN, HIV, BBBP, TOXCAST, and TOX21). Code is\navailable at~\\url{https://github.com/whuchuang/mid}.\n","authors":["Chuang Liu","Yibing Zhan","Baosheng Yu","Liu Liu","Bo Du","Wenbin Hu","Tongliang Liu"],"pdf_url":"https://arxiv.org/pdf/2306.12726v1.pdf","comment":"14 pages, 14 figures"},{"id":"http://arxiv.org/abs/2305.11554v2","updated":"2023-06-22T07:58:56Z","published":"2023-05-19T09:54:21Z","title":"ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via\n  Tool Embeddings","summary":"  Augmenting large language models (LLMs) with external tools has emerged as a\npromising approach to solving complex problems. However, traditional methods,\nwhich finetune LLMs with tool demonstration data, can be both costly and\nrestricted to a predefined set of tools. Recent in-context learning paradigm\nalleviates these issues, but the limited context length only allows for a few\nshots of demonstrations, leading to suboptimal understandings of the tools.\nMoreover, when there are numerous tools to choose from, in-context learning\ncould completely fail to work. In this paper, we propose an alternative\napproach, $\\textbf{ToolkenGPT}$, which combines the benefits of both sides. Our\napproach represents each $\\underline{tool}$ as a to$\\underline{ken}$\n($\\textit{toolken}$) and learns an embedding for it, enabling tool calls in the\nsame way as generating a regular word token. Once a toolken is triggered, the\nLLM is prompted to complete arguments for the tool to execute. ToolkenGPT\noffers the flexibility to plug in an arbitrary number of tools by expanding the\nset of toolkens on the fly. In addition, it improves tool use by allowing\nextensive demonstration data for learning the toolken embeddings. In diverse\ndomains, including numerical reasoning, knowledge-based question answering, and\nembodied plan generation, our approach effectively augments LLMs with tools and\nsubstantially outperforms various latest baselines. ToolkenGPT demonstrates the\npromising ability to use relevant tools from a large tool set in complex\nscenarios.\n","authors":["Shibo Hao","Tianyang Liu","Zhen Wang","Zhiting Hu"],"pdf_url":"https://arxiv.org/pdf/2305.11554v2.pdf","comment":"Add code link and appendix. Code:\n  https://github.com/Ber666/ToolkenGPT"},{"id":"http://arxiv.org/abs/2306.12714v1","updated":"2023-06-22T07:47:18Z","published":"2023-06-22T07:47:18Z","title":"Toward Leveraging Pre-Trained Self-Supervised Frontends for Automatic\n  Singing Voice Understanding Tasks: Three Case Studies","summary":"  Automatic singing voice understanding tasks, such as singer identification,\nsinging voice transcription, and singing technique classification, benefit from\ndata-driven approaches that utilize deep learning techniques. These approaches\nwork well even under the rich diversity of vocal and noisy samples owing to\ntheir representation ability. However, the limited availability of labeled data\nremains a significant obstacle to achieving satisfactory performance. In recent\nyears, self-supervised learning models (SSL models) have been trained using\nlarge amounts of unlabeled data in the field of speech processing and music\nclassification. By fine-tuning these models for the target tasks, comparable\nperformance to conventional supervised learning can be achieved with limited\ntraining data. Therefore, in this paper, we investigate the effectiveness of\nSSL models for various singing voice recognition tasks. We report the results\nof experiments comparing SSL models for three different tasks (i.e., singer\nidentification, singing voice transcription, and singing technique\nclassification) as initial exploration and aim to discuss these findings.\nExperimental results show that each SSL model achieves comparable performance\nand sometimes outperforms compared to state-of-the-art methods on each task. We\nalso conducted a layer-wise analysis to further understand the behavior of the\nSSL models.\n","authors":["Yuya Yamamoto"],"pdf_url":"https://arxiv.org/pdf/2306.12714v1.pdf","comment":"Submitted to APSIPA 2023"},{"id":"http://arxiv.org/abs/2306.12703v1","updated":"2023-06-22T07:14:02Z","published":"2023-06-22T07:14:02Z","title":"OptIForest: Optimal Isolation Forest for Anomaly Detection","summary":"  Anomaly detection plays an increasingly important role in various fields for\ncritical tasks such as intrusion detection in cybersecurity, financial risk\ndetection, and human health monitoring. A variety of anomaly detection methods\nhave been proposed, and a category based on the isolation forest mechanism\nstands out due to its simplicity, effectiveness, and efficiency, e.g., iForest\nis often employed as a state-of-the-art detector for real deployment. While the\nmajority of isolation forests use the binary structure, a framework LSHiForest\nhas demonstrated that the multi-fork isolation tree structure can lead to\nbetter detection performance. However, there is no theoretical work answering\nthe fundamentally and practically important question on the optimal tree\nstructure for an isolation forest with respect to the branching factor. In this\npaper, we establish a theory on isolation efficiency to answer the question and\ndetermine the optimal branching factor for an isolation tree. Based on the\ntheoretical underpinning, we design a practical optimal isolation forest\nOptIForest incorporating clustering based learning to hash which enables more\ninformation to be learned from data for better isolation quality. The rationale\nof our approach relies on a better bias-variance trade-off achieved by bias\nreduction in OptIForest. Extensive experiments on a series of benchmarking\ndatasets for comparative and ablation studies demonstrate that our approach can\nefficiently and robustly achieve better detection performance in general than\nthe state-of-the-arts including the deep learning based methods.\n","authors":["Haolong Xiang","Xuyun Zhang","Hongsheng Hu","Lianyong Qi","Wanchun Dou","Mark Dras","Amin Beheshti","Xiaolong Xu"],"pdf_url":"https://arxiv.org/pdf/2306.12703v1.pdf","comment":"This paper has been accepted by International Joint Conference on\n  Artificial Intelligence (IJCAI-23)"},{"id":"http://arxiv.org/abs/2305.05480v2","updated":"2023-06-22T07:12:15Z","published":"2023-05-09T14:30:29Z","title":"Investigating the effect of sub-word segmentation on the performance of\n  transformer language models","summary":"  We would like to explore how morphemes can affect the performance of a\nlanguage model. We trained GPT-2 and Bert model with StateMorph for both\nFinnish and Russian, which is a morpheme segmenting algorithm. As a comparison,\nwe also trained a model with BPE and Morfessor. Our preliminary result shows\nthat StateMorph can help the model to converge more efficiently and achieve a\nbetter validation score.\n","authors":["Jue Hou","Anisia Katinskaia","Anh-Duc Vu","Roman Yangarber"],"pdf_url":"https://arxiv.org/pdf/2305.05480v2.pdf","comment":"This submission is undergoing a major revision, and will be back\n  online as soon as possible -- once we have completed the experiments and have\n  new results"},{"id":"http://arxiv.org/abs/2306.12700v1","updated":"2023-06-22T07:06:45Z","published":"2023-06-22T07:06:45Z","title":"Accelerated Training via Incrementally Growing Neural Networks using\n  Variance Transfer and Learning Rate Adaptation","summary":"  We develop an approach to efficiently grow neural networks, within which\nparameterization and optimization strategies are designed by considering their\neffects on the training dynamics. Unlike existing growing methods, which follow\nsimple replication heuristics or utilize auxiliary gradient-based local\noptimization, we craft a parameterization scheme which dynamically stabilizes\nweight, activation, and gradient scaling as the architecture evolves, and\nmaintains the inference functionality of the network. To address the\noptimization difficulty resulting from imbalanced training effort distributed\nto subnetworks fading in at different growth phases, we propose a learning rate\nadaption mechanism that rebalances the gradient contribution of these separate\nsubcomponents. Experimental results show that our method achieves comparable or\nbetter accuracy than training large fixed-size models, while saving a\nsubstantial portion of the original computation budget for training. We\ndemonstrate that these gains translate into real wall-clock training speedups.\n","authors":["Xin Yuan","Pedro Savarese","Michael Maire"],"pdf_url":"https://arxiv.org/pdf/2306.12700v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.02566v2","updated":"2023-06-22T06:49:33Z","published":"2022-11-04T16:34:03Z","title":"scikit-fda: A Python Package for Functional Data Analysis","summary":"  The library scikit-fda is a Python package for Functional Data Analysis\n(FDA). It provides a comprehensive set of tools for representation,\npreprocessing, and exploratory analysis of functional data. The library is\nbuilt upon and integrated in Python's scientific ecosystem. In particular, it\nconforms to the scikit-learn application programming interface so as to take\nadvantage of the functionality for machine learning provided by this package:\npipelines, model selection, and hyperparameter tuning, among others. The\nscikit-fda package has been released as free and open-source software under a\n3-Clause BSD license and is open to contributions from the FDA community. The\nlibrary's extensive documentation includes step-by-step tutorials and detailed\nexamples of use.\n","authors":["Carlos Ramos-Carreño","José Luis Torrecilla","Miguel Carbajo-Berrocal","Pablo Marcos","Alberto Suárez"],"pdf_url":"https://arxiv.org/pdf/2211.02566v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12691v1","updated":"2023-06-22T06:33:12Z","published":"2023-06-22T06:33:12Z","title":"Slimmable Encoders for Flexible Split DNNs in Bandwidth and Resource\n  Constrained IoT Systems","summary":"  The execution of large deep neural networks (DNN) at mobile edge devices\nrequires considerable consumption of critical resources, such as energy, while\nimposing demands on hardware capabilities. In approaches based on edge\ncomputing the execution of the models is offloaded to a compute-capable device\npositioned at the edge of 5G infrastructures. The main issue of the latter\nclass of approaches is the need to transport information-rich signals over\nwireless links with limited and time-varying capacity. The recent split\ncomputing paradigm attempts to resolve this impasse by distributing the\nexecution of DNN models across the layers of the systems to reduce the amount\nof data to be transmitted while imposing minimal computing load on mobile\ndevices. In this context, we propose a novel split computing approach based on\nslimmable ensemble encoders. The key advantage of our design is the ability to\nadapt computational load and transmitted data size in real-time with minimal\noverhead and time. This is in contrast with existing approaches, where the same\nadaptation requires costly context switching and model loading. Moreover, our\nmodel outperforms existing solutions in terms of compression efficacy and\nexecution time, especially in the context of weak mobile devices. We present a\ncomprehensive comparison with the most advanced split computing solutions, as\nwell as an experimental evaluation on GPU-less devices.\n","authors":["Juliano S. Assine","J. C. S. Santos Filho","Eduardo Valle","Marco Levorato"],"pdf_url":"https://arxiv.org/pdf/2306.12691v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12689v1","updated":"2023-06-22T06:23:31Z","published":"2023-06-22T06:23:31Z","title":"Vec2Vec: A Compact Neural Network Approach for Transforming Text\n  Embeddings with High Fidelity","summary":"  Vector embeddings have become ubiquitous tools for many language-related\ntasks. A leading embedding model is OpenAI's text-ada-002 which can embed\napproximately 6,000 words into a 1,536-dimensional vector. While powerful,\ntext-ada-002 is not open source and is only available via API. We trained a\nsimple neural network to convert open-source 768-dimensional MPNet embeddings\ninto text-ada-002 embeddings. We compiled a subset of 50,000 online food\nreviews. We calculated MPNet and text-ada-002 embeddings for each review and\ntrained a simple neural network to for 75 epochs. The neural network was\ndesigned to predict the corresponding text-ada-002 embedding for a given MPNET\nembedding. Our model achieved an average cosine similarity of 0.932 on 10,000\nunseen reviews in our held-out test dataset. We manually assessed the quality\nof our predicted embeddings for vector search over text-ada-002-embedded\nreviews. While not as good as real text-ada-002 embeddings, predicted\nembeddings were able to retrieve highly relevant reviews. Our final model,\nVec2Vec, is lightweight (<80 MB) and fast. Future steps include training a\nneural network with a more sophisticated architecture and a larger dataset of\npaired embeddings to achieve greater performance. The ability to convert\nbetween and align embedding spaces may be helpful for interoperability,\nlimiting dependence on proprietary models, protecting data privacy, reducing\ncosts, and offline operations.\n","authors":["Andrew Kean Gao"],"pdf_url":"https://arxiv.org/pdf/2306.12689v1.pdf","comment":"14 pages, 6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2306.12688v1","updated":"2023-06-22T06:21:45Z","published":"2023-06-22T06:21:45Z","title":"Towards quantum enhanced adversarial robustness in machine learning","summary":"  Machine learning algorithms are powerful tools for data driven tasks such as\nimage classification and feature detection, however their vulnerability to\nadversarial examples - input samples manipulated to fool the algorithm -\nremains a serious challenge. The integration of machine learning with quantum\ncomputing has the potential to yield tools offering not only better accuracy\nand computational efficiency, but also superior robustness against adversarial\nattacks. Indeed, recent work has employed quantum mechanical phenomena to\ndefend against adversarial attacks, spurring the rapid development of the field\nof quantum adversarial machine learning (QAML) and potentially yielding a new\nsource of quantum advantage. Despite promising early results, there remain\nchallenges towards building robust real-world QAML tools. In this review we\ndiscuss recent progress in QAML and identify key challenges. We also suggest\nfuture research directions which could determine the route to practicality for\nQAML approaches as quantum computing hardware scales up and noise levels are\nreduced.\n","authors":["Maxwell T. West","Shu-Lok Tsang","Jia S. Low","Charles D. Hill","Christopher Leckie","Lloyd C. L. Hollenberg","Sarah M. Erfani","Muhammad Usman"],"pdf_url":"https://arxiv.org/pdf/2306.12688v1.pdf","comment":"10 Pages, 4 Figures"},{"id":"http://arxiv.org/abs/2306.12687v1","updated":"2023-06-22T06:18:40Z","published":"2023-06-22T06:18:40Z","title":"Explainable Representations for Relation Prediction in Knowledge Graphs","summary":"  Knowledge graphs represent real-world entities and their relations in a\nsemantically-rich structure supported by ontologies. Exploring this data with\nmachine learning methods often relies on knowledge graph embeddings, which\nproduce latent representations of entities that preserve structural and local\ngraph neighbourhood properties, but sacrifice explainability. However, in tasks\nsuch as link or relation prediction, understanding which specific features\nbetter explain a relation is crucial to support complex or critical\napplications.\n  We propose SEEK, a novel approach for explainable representations to support\nrelation prediction in knowledge graphs. It is based on identifying relevant\nshared semantic aspects (i.e., subgraphs) between entities and learning\nrepresentations for each subgraph, producing a multi-faceted and explainable\nrepresentation.\n  We evaluate SEEK on two real-world highly complex relation prediction tasks:\nprotein-protein interaction prediction and gene-disease association prediction.\nOur extensive analysis using established benchmarks demonstrates that SEEK\nachieves significantly better performance than standard learning representation\nmethods while identifying both sufficient and necessary explanations based on\nshared semantic aspects.\n","authors":["Rita T. Sousa","Sara Silva","Catia Pesquita"],"pdf_url":"https://arxiv.org/pdf/2306.12687v1.pdf","comment":"16 pages, 3 figures"},{"id":"http://arxiv.org/abs/2306.12678v1","updated":"2023-06-22T05:48:25Z","published":"2023-06-22T05:48:25Z","title":"Outlier-robust Estimation of a Sparse Linear Model Using Invexity","summary":"  In this paper, we study problem of estimating a sparse regression vector with\ncorrect support in the presence of outlier samples. The inconsistency of\nlasso-type methods is well known in this scenario. We propose a combinatorial\nversion of outlier-robust lasso which also identifies clean samples.\nSubsequently, we use these clean samples to make a good estimation. We also\nprovide a novel invex relaxation for the combinatorial problem and provide\nprovable theoretical guarantees for this relaxation. Finally, we conduct\nexperiments to validate our theory and compare our results against standard\nlasso.\n","authors":["Adarsh Barik","Jean Honorio"],"pdf_url":"https://arxiv.org/pdf/2306.12678v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06778v2","updated":"2023-06-22T05:19:54Z","published":"2023-06-11T21:18:40Z","title":"Approximation Algorithms for Fair Range Clustering","summary":"  This paper studies the fair range clustering problem in which the data points\nare from different demographic groups and the goal is to pick $k$ centers with\nthe minimum clustering cost such that each group is at least minimally\nrepresented in the centers set and no group dominates the centers set. More\nprecisely, given a set of $n$ points in a metric space $(P,d)$ where each point\nbelongs to one of the $\\ell$ different demographics (i.e., $P = P_1 \\uplus P_2\n\\uplus \\cdots \\uplus P_\\ell$) and a set of $\\ell$ intervals $[\\alpha_1,\n\\beta_1], \\cdots, [\\alpha_\\ell, \\beta_\\ell]$ on desired number of centers from\neach group, the goal is to pick a set of $k$ centers $C$ with minimum\n$\\ell_p$-clustering cost (i.e., $(\\sum_{v\\in P} d(v,C)^p)^{1/p}$) such that for\neach group $i\\in \\ell$, $|C\\cap P_i| \\in [\\alpha_i, \\beta_i]$. In particular,\nthe fair range $\\ell_p$-clustering captures fair range $k$-center, $k$-median\nand $k$-means as its special cases. In this work, we provide efficient constant\nfactor approximation algorithms for fair range $\\ell_p$-clustering for all\nvalues of $p\\in [1,\\infty)$.\n","authors":["Sèdjro S. Hotegni","Sepideh Mahabadi","Ali Vakilian"],"pdf_url":"https://arxiv.org/pdf/2306.06778v2.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2306.12673v1","updated":"2023-06-22T05:16:58Z","published":"2023-06-22T05:16:58Z","title":"Identifying and Disentangling Spurious Features in Pretrained Image\n  Representations","summary":"  Neural networks employ spurious correlations in their predictions, resulting\nin decreased performance when these correlations do not hold. Recent works\nsuggest fixing pretrained representations and training a classification head\nthat does not use spurious features. We investigate how spurious features are\nrepresented in pretrained representations and explore strategies for removing\ninformation about spurious features. Considering the Waterbirds dataset and a\nfew pretrained representations, we find that even with full knowledge of\nspurious features, their removal is not straightforward due to entangled\nrepresentation. To address this, we propose a linear autoencoder training\nmethod to separate the representation into core, spurious, and other features.\nWe propose two effective spurious feature removal approaches that are applied\nto the encoding and significantly improve classification performance measured\nby worst group accuracy.\n","authors":["Rafayel Darbinyan","Hrayr Harutyunyan","Aram H. Markosyan","Hrant Khachatrian"],"pdf_url":"https://arxiv.org/pdf/2306.12673v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06024v3","updated":"2023-06-22T05:15:25Z","published":"2023-06-09T16:42:52Z","title":"Self-Interpretable Time Series Prediction with Counterfactual\n  Explanations","summary":"  Interpretable time series prediction is crucial for safety-critical areas\nsuch as healthcare and autonomous driving. Most existing methods focus on\ninterpreting predictions by assigning important scores to segments of time\nseries. In this paper, we take a different and more challenging route and aim\nat developing a self-interpretable model, dubbed Counterfactual Time Series\n(CounTS), which generates counterfactual and actionable explanations for time\nseries predictions. Specifically, we formalize the problem of time series\ncounterfactual explanations, establish associated evaluation protocols, and\npropose a variational Bayesian deep learning model equipped with counterfactual\ninference capability of time series abduction, action, and prediction. Compared\nwith state-of-the-art baselines, our self-interpretable model can generate\nbetter counterfactual explanations while maintaining comparable prediction\naccuracy.\n","authors":["Jingquan Yan","Hao Wang"],"pdf_url":"https://arxiv.org/pdf/2306.06024v3.pdf","comment":"ICML 2023 Oral. Code will be available at\n  https://github.com/Wang-ML-Lab/self-interpretable-time-series"},{"id":"http://arxiv.org/abs/2306.11207v2","updated":"2023-06-22T05:01:16Z","published":"2023-06-20T00:14:47Z","title":"Quilt-1M: One Million Image-Text Pairs for Histopathology","summary":"  Recent accelerations in multi-modal applications have been made possible with\nthe plethora of image and text data available online. However, the scarcity of\nanalogous data in the medical field, specifically in histopathology, has halted\ncomparable progress. To enable similar representation learning for\nhistopathology, we turn to YouTube, an untapped resource of videos, offering\n$1,087$ hours of valuable educational histopathology videos from expert\nclinicians. From YouTube, we curate Quilt: a large-scale vision-language\ndataset consisting of $768,826$ image and text pairs. Quilt was automatically\ncurated using a mixture of models, including large language models, handcrafted\nalgorithms, human knowledge databases, and automatic speech recognition. In\ncomparison, the most comprehensive datasets curated for histopathology amass\nonly around $200$K samples. We combine Quilt with datasets from other sources,\nincluding Twitter, research papers, and the internet in general, to create an\neven larger dataset: Quilt-1M, with $1$M paired image-text samples, marking it\nas the largest vision-language histopathology dataset to date. We demonstrate\nthe value of Quilt-1M by fine-tuning a pre-trained CLIP model. Our model\noutperforms state-of-the-art models on both zero-shot and linear probing tasks\nfor classifying new histopathology images across $13$ diverse patch-level\ndatasets of $8$ different sub-pathologies and cross-modal retrieval tasks.\n","authors":["Wisdom Oluchi Ikezogwo","Mehmet Saygin Seyfioglu","Fatemeh Ghezloo","Dylan Stefan Chan Geva","Fatwir Sheikh Mohammed","Pavan Kumar Anand","Ranjay Krishna","Linda Shapiro"],"pdf_url":"https://arxiv.org/pdf/2306.11207v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12670v1","updated":"2023-06-22T05:00:11Z","published":"2023-06-22T05:00:11Z","title":"Generalized Low-Rank Update: Model Parameter Bounds for Low-Rank\n  Training Data Modifications","summary":"  In this study, we have developed an incremental machine learning (ML) method\nthat efficiently obtains the optimal model when a small number of instances or\nfeatures are added or removed. This problem holds practical importance in model\nselection, such as cross-validation (CV) and feature selection. Among the class\nof ML methods known as linear estimators, there exists an efficient model\nupdate framework called the low-rank update that can effectively handle changes\nin a small number of rows and columns within the data matrix. However, for ML\nmethods beyond linear estimators, there is currently no comprehensive framework\navailable to obtain knowledge about the updated solution within a specific\ncomputational complexity. In light of this, our study introduces a method\ncalled the Generalized Low-Rank Update (GLRU) which extends the low-rank update\nframework of linear estimators to ML methods formulated as a certain class of\nregularized empirical risk minimization, including commonly used methods such\nas SVM and logistic regression. The proposed GLRU method not only expands the\nrange of its applicability but also provides information about the updated\nsolutions with a computational complexity proportional to the amount of dataset\nchanges. To demonstrate the effectiveness of the GLRU method, we conduct\nexperiments showcasing its efficiency in performing cross-validation and\nfeature selection compared to other baseline methods.\n","authors":["Hiroyuki Hanada","Noriaki Hashimoto","Kouichi Taji","Ichiro Takeuchi"],"pdf_url":"https://arxiv.org/pdf/2306.12670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12659v1","updated":"2023-06-22T03:56:38Z","published":"2023-06-22T03:56:38Z","title":"Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of\n  General-Purpose Large Language Models","summary":"  Sentiment analysis is a vital tool for uncovering insights from financial\narticles, news, and social media, shaping our understanding of market\nmovements. Despite the impressive capabilities of large language models (LLMs)\nin financial natural language processing (NLP), they still struggle with\naccurately interpreting numerical values and grasping financial context,\nlimiting their effectiveness in predicting financial sentiment. In this paper,\nwe introduce a simple yet effective instruction tuning approach to address\nthese issues. By transforming a small portion of supervised financial sentiment\nanalysis data into instruction data and fine-tuning a general-purpose LLM with\nthis method, we achieve remarkable advancements in financial sentiment\nanalysis. In the experiment, our approach outperforms state-of-the-art\nsupervised sentiment analysis models, as well as widely used LLMs like ChatGPT\nand LLaMAs, particularly in scenarios where numerical understanding and\ncontextual comprehension are vital.\n","authors":["Boyu Zhang","Hongyang Yang","Xiao-Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2306.12659v1.pdf","comment":"FinLLM Symposium at IJCAI 2023"},{"id":"http://arxiv.org/abs/2306.12658v1","updated":"2023-06-22T03:55:36Z","published":"2023-06-22T03:55:36Z","title":"Fitted Value Iteration Methods for Bicausal Optimal Transport","summary":"  We develop a fitted value iteration (FVI) method to compute bicausal optimal\ntransport (OT) where couplings have an adapted structure. Based on the dynamic\nprogramming formulation, FVI adopts a function class to approximate the value\nfunctions in bicausal OT. Under the concentrability condition and approximate\ncompleteness assumption, we prove the sample complexity using (local)\nRademacher complexity. Furthermore, we demonstrate that multilayer neural\nnetworks with appropriate structures satisfy the crucial assumptions required\nin sample complexity proofs. Numerical experiments reveal that FVI outperforms\nlinear programming and adapted Sinkhorn methods in scalability as the time\nhorizon increases, while still maintaining acceptable accuracy.\n","authors":["Erhan Bayraktar","Bingyan Han"],"pdf_url":"https://arxiv.org/pdf/2306.12658v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.02572v2","updated":"2023-06-22T03:41:43Z","published":"2023-04-05T16:44:36Z","title":"Evaluating Online Bandit Exploration In Large-Scale Recommender System","summary":"  Bandit learning has been an increasingly popular design choice for\nrecommender system. Despite the strong interest in bandit learning from the\ncommunity, there remains multiple bottlenecks that prevent many bandit learning\napproaches from productionalization. One major bottleneck is how to test the\neffectiveness of bandit algorithm with fairness and without data leakage.\nDifferent from supervised learning algorithms, bandit learning algorithms\nemphasize greatly on the data collection process through their explorative\nnature. Such explorative behavior may induce unfair evaluation in a classic A/B\ntest setting. In this work, we apply upper confidence bound (UCB) to our large\nscale short video recommender system and present a test framework for the\nproduction bandit learning life-cycle with a new set of metrics. Extensive\nexperiment results show that our experiment design is able to fairly evaluate\nthe performance of bandit learning in the recommender system.\n","authors":["Hongbo Guo","Ruben Naeff","Alex Nikulkov","Zheqing Zhu"],"pdf_url":"https://arxiv.org/pdf/2304.02572v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.14007v3","updated":"2023-06-22T03:14:34Z","published":"2022-08-30T06:24:07Z","title":"Finding neural signatures for obesity through feature selection on\n  source-localized EEG","summary":"  Obesity is a serious issue in the modern society and is often associated to\nsignificantly reduced quality of life. Current research conducted to explore\nobesity-related neurological evidences using electroencephalography (EEG) data\nare limited to traditional approaches. In this study, we developed a novel\nmachine learning model to identify brain networks of obese females using alpha\nband functional connectivity features derived from EEG data. An overall\nclassification accuracy of 0.937 is achieved. Our finding suggests that the\nobese brain is characterized by a dysfunctional network in which the areas that\nresponsible for processing self-referential information and environmental\ncontext information are impaired.\n","authors":["Yuan Yue","Dirk De Ridder","Patrick Manning","Samantha Ross","Jeremiah D. Deng"],"pdf_url":"https://arxiv.org/pdf/2208.14007v3.pdf","comment":"4 pages, 3 figures, conference submission"},{"id":"http://arxiv.org/abs/2306.12646v1","updated":"2023-06-22T03:08:42Z","published":"2023-06-22T03:08:42Z","title":"Learnability and Algorithm for Continual Learning","summary":"  This paper studies the challenging continual learning (CL) setting of Class\nIncremental Learning (CIL). CIL learns a sequence of tasks consisting of\ndisjoint sets of concepts or classes. At any time, a single model is built that\ncan be applied to predict/classify test instances of any classes learned thus\nfar without providing any task related information for each test instance.\nAlthough many techniques have been proposed for CIL, they are mostly empirical.\nIt has been shown recently that a strong CIL system needs a strong within-task\nprediction (WP) and a strong out-of-distribution (OOD) detection for each task.\nHowever, it is still not known whether CIL is actually learnable. This paper\nshows that CIL is learnable. Based on the theory, a new CIL algorithm is also\nproposed. Experimental results demonstrate its effectiveness.\n","authors":["Gyuhak Kim","Changnan Xiao","Tatsuya Konishi","Bing Liu"],"pdf_url":"https://arxiv.org/pdf/2306.12646v1.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2306.11768v2","updated":"2023-06-22T03:05:21Z","published":"2023-06-20T14:21:58Z","title":"A Systematic Survey in Geometric Deep Learning for Structure-based Drug\n  Design","summary":"  Structure-based drug design (SBDD), which utilizes the three-dimensional\ngeometry of proteins to identify potential drug candidates, is becoming\nincreasingly vital in drug discovery. However, traditional methods based on\nphysiochemical modeling and experts' domain knowledge are time-consuming and\nlaborious. The recent advancements in geometric deep learning, which integrates\nand processes 3D geometric data, coupled with the availability of accurate\nprotein 3D structure predictions from tools like AlphaFold, have significantly\npropelled progress in structure-based drug design. In this paper, we\nsystematically review the recent progress of geometric deep learning for\nstructure-based drug design. We start with a brief discussion of the mainstream\ntasks in structure-based drug design, commonly used 3D protein representations\nand representative predictive/generative models. Then we delve into detailed\nreviews for each task (binding site prediction, binding pose generation,\n\\emph{de novo} molecule generation, linker design, and binding affinity\nprediction), including the problem setup, representative methods, datasets, and\nevaluation metrics. Finally, we conclude this survey with the current\nchallenges and highlight potential opportunities of geometric deep learning for\nstructure-based drug design.\n","authors":["Zaixi Zhang","Jiaxian Yan","Qi Liu","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2306.11768v2.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2306.12640v1","updated":"2023-06-22T02:50:16Z","published":"2023-06-22T02:50:16Z","title":"On Addressing the Limitations of Graph Neural Networks","summary":"  This report gives a summary of two problems about graph convolutional\nnetworks (GCNs): over-smoothing and heterophily challenges, and outlines future\ndirections to explore.\n","authors":["Sitao Luan"],"pdf_url":"https://arxiv.org/pdf/2306.12640v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2109.05641,\n  arXiv:2210.07606"},{"id":"http://arxiv.org/abs/2306.11338v2","updated":"2023-06-22T02:20:38Z","published":"2023-06-20T07:14:37Z","title":"FDINet: Protecting against DNN Model Extraction via Feature Distortion\n  Index","summary":"  Machine Learning as a Service (MLaaS) platforms have gained popularity due to\ntheir accessibility, cost-efficiency, scalability, and rapid development\ncapabilities. However, recent research has highlighted the vulnerability of\ncloud-based models in MLaaS to model extraction attacks. In this paper, we\nintroduce FDINET, a novel defense mechanism that leverages the feature\ndistribution of deep neural network (DNN) models. Concretely, by analyzing the\nfeature distribution from the adversary's queries, we reveal that the feature\ndistribution of these queries deviates from that of the model's training set.\nBased on this key observation, we propose Feature Distortion Index (FDI), a\nmetric designed to quantitatively measure the feature distribution deviation of\nreceived queries. The proposed FDINET utilizes FDI to train a binary detector\nand exploits FDI similarity to identify colluding adversaries from distributed\nextraction attacks. We conduct extensive experiments to evaluate FDINET against\nsix state-of-the-art extraction attacks on four benchmark datasets and four\npopular model architectures. Empirical results demonstrate the following\nfindings FDINET proves to be highly effective in detecting model extraction,\nachieving a 100% detection accuracy on DFME and DaST. FDINET is highly\nefficient, using just 50 queries to raise an extraction alarm with an average\nconfidence of 96.08% for GTSRB. FDINET exhibits the capability to identify\ncolluding adversaries with an accuracy exceeding 91%. Additionally, it\ndemonstrates the ability to detect two types of adaptive attacks.\n","authors":["Hongwei Yao","Zheng Li","Haiqin Weng","Feng Xue","Kui Ren","Zhan Qin"],"pdf_url":"https://arxiv.org/pdf/2306.11338v2.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.10234v2","updated":"2023-06-22T01:46:21Z","published":"2023-06-17T02:25:56Z","title":"Federated Few-shot Learning","summary":"  Federated Learning (FL) enables multiple clients to collaboratively learn a\nmachine learning model without exchanging their own local data. In this way,\nthe server can exploit the computational power of all clients and train the\nmodel on a larger set of data samples among all clients. Although such a\nmechanism is proven to be effective in various fields, existing works generally\nassume that each client preserves sufficient data for training. In practice,\nhowever, certain clients may only contain a limited number of samples (i.e.,\nfew-shot samples). For example, the available photo data taken by a specific\nuser with a new mobile device is relatively rare. In this scenario, existing FL\nefforts typically encounter a significant performance drop on these clients.\nTherefore, it is urgent to develop a few-shot model that can generalize to\nclients with limited data under the FL scenario. In this paper, we refer to\nthis novel problem as federated few-shot learning. Nevertheless, the problem\nremains challenging due to two major reasons: the global data variance among\nclients (i.e., the difference in data distributions among clients) and the\nlocal data insufficiency in each client (i.e., the lack of adequate local data\nfor training). To overcome these two challenges, we propose a novel federated\nfew-shot learning framework with two separately updated models and dedicated\ntraining strategies to reduce the adverse impact of global data variance and\nlocal data insufficiency. Extensive experiments on four prevalent datasets that\ncover news articles and images validate the effectiveness of our framework\ncompared with the state-of-the-art baselines. Our code is provided at\nhttps://github.com/SongW-SW/F2L.\n","authors":["Song Wang","Xingbo Fu","Kaize Ding","Chen Chen","Huiyuan Chen","Jundong Li"],"pdf_url":"https://arxiv.org/pdf/2306.10234v2.pdf","comment":"SIGKDD 2023"},{"id":"http://arxiv.org/abs/2212.10535v2","updated":"2023-06-22T01:37:02Z","published":"2022-12-20T18:46:16Z","title":"A Survey of Deep Learning for Mathematical Reasoning","summary":"  Mathematical reasoning is a fundamental aspect of human intelligence and is\napplicable in various fields, including science, engineering, finance, and\neveryday life. The development of artificial intelligence (AI) systems capable\nof solving math problems and proving theorems has garnered significant interest\nin the fields of machine learning and natural language processing. For example,\nmathematics serves as a testbed for aspects of reasoning that are challenging\nfor powerful deep learning models, driving new algorithmic and modeling\nadvances. On the other hand, recent advances in large-scale neural language\nmodels have opened up new benchmarks and opportunities to use deep learning for\nmathematical reasoning. In this survey paper, we review the key tasks,\ndatasets, and methods at the intersection of mathematical reasoning and deep\nlearning over the past decade. We also evaluate existing benchmarks and\nmethods, and discuss future research directions in this domain.\n","authors":["Pan Lu","Liang Qiu","Wenhao Yu","Sean Welleck","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2212.10535v2.pdf","comment":"Accepted to ACL 2023. The repository is available at\n  https://github.com/lupantech/dl4math"},{"id":"http://arxiv.org/abs/2306.12627v1","updated":"2023-06-22T01:33:47Z","published":"2023-06-22T01:33:47Z","title":"Targeted collapse regularized autoencoder for anomaly detection: black\n  hole at the center","summary":"  Autoencoders have been extensively used in the development of recent anomaly\ndetection techniques. The premise of their application is based on the notion\nthat after training the autoencoder on normal training data, anomalous inputs\nwill exhibit a significant reconstruction error. Consequently, this enables a\nclear differentiation between normal and anomalous samples. In practice,\nhowever, it is observed that autoencoders can generalize beyond the normal\nclass and achieve a small reconstruction error on some of the anomalous\nsamples. To improve the performance, various techniques propose additional\ncomponents and more sophisticated training procedures. In this work, we propose\na remarkably straightforward alternative: instead of adding neural network\ncomponents, involved computations, and cumbersome training, we complement the\nreconstruction loss with a computationally light term that regulates the norm\nof representations in the latent space. The simplicity of our approach\nminimizes the requirement for hyperparameter tuning and customization for new\napplications which, paired with its permissive data modality constraint,\nenhances the potential for successful adoption across a broad range of\napplications. We test the method on various visual and tabular benchmarks and\ndemonstrate that the technique matches and frequently outperforms alternatives.\nWe also provide a theoretical analysis and numerical simulations that help\ndemonstrate the underlying process that unfolds during training and how it can\nhelp with anomaly detection. This mitigates the black-box nature of\nautoencoder-based anomaly detection algorithms and offers an avenue for further\ninvestigation of advantages, fail cases, and potential new directions.\n","authors":["Amin Ghafourian","Huanyi Shui","Devesh Upadhyay","Rajesh Gupta","Dimitar Filev","Iman Soltani Bozchalooi"],"pdf_url":"https://arxiv.org/pdf/2306.12627v1.pdf","comment":"16 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2306.12625v1","updated":"2023-06-22T01:29:50Z","published":"2023-06-22T01:29:50Z","title":"Communication-Efficient Federated Learning through Importance Sampling","summary":"  The high communication cost of sending model updates from the clients to the\nserver is a significant bottleneck for scalable federated learning (FL). Among\nexisting approaches, state-of-the-art bitrate-accuracy tradeoffs have been\nachieved using stochastic compression methods -- in which the client $n$ sends\na sample from a client-only probability distribution $q_{\\phi^{(n)}}$, and the\nserver estimates the mean of the clients' distributions using these samples.\nHowever, such methods do not take full advantage of the FL setup where the\nserver, throughout the training process, has side information in the form of a\npre-data distribution $p_{\\theta}$ that is close to the client's distribution\n$q_{\\phi^{(n)}}$ in Kullback-Leibler (KL) divergence. In this work, we exploit\nthis closeness between the clients' distributions $q_{\\phi^{(n)}}$'s and the\nside information $p_{\\theta}$ at the server, and propose a framework that\nrequires approximately $D_{KL}(q_{\\phi^{(n)}}|| p_{\\theta})$ bits of\ncommunication. We show that our method can be integrated into many existing\nstochastic compression frameworks such as FedPM, Federated SGLD, and QSGD to\nattain the same (and often higher) test accuracy with up to $50$ times\nreduction in the bitrate.\n","authors":["Berivan Isik","Francesco Pase","Deniz Gunduz","Sanmi Koyejo","Tsachy Weissman","Michele Zorzi"],"pdf_url":"https://arxiv.org/pdf/2306.12625v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.04335v2","updated":"2023-06-22T01:29:12Z","published":"2023-05-07T17:08:21Z","title":"Classification Tree Pruning Under Covariate Shift","summary":"  We consider the problem of \\emph{pruning} a classification tree, that is,\nselecting a suitable subtree that balances bias and variance, in common\nsituations with inhomogeneous training data. Namely, assuming access to mostly\ndata from a distribution $P_{X, Y}$, but little data from a desired\ndistribution $Q_{X, Y}$ with different $X$-marginals, we present the first\nefficient procedure for optimal pruning in such situations, when\ncross-validation and other penalized variants are grossly inadequate.\nOptimality is derived with respect to a notion of \\emph{average discrepancy}\n$P_{X} \\to Q_{X}$ (averaged over $X$ space) which significantly relaxes a\nrecent notion -- termed \\emph{transfer-exponent} -- shown to tightly capture\nthe limits of classification under such a distribution shift. Our relaxed\nnotion can be viewed as a measure of \\emph{relative dimension} between\ndistributions, as it relates to existing notions of information such as the\nMinkowski and Renyi dimensions.\n","authors":["Nicholas Galbraith","Samory Kpotufe"],"pdf_url":"https://arxiv.org/pdf/2305.04335v2.pdf","comment":"38 pages, 8 figures"},{"id":"http://arxiv.org/abs/2306.12619v1","updated":"2023-06-22T01:14:47Z","published":"2023-06-22T01:14:47Z","title":"Class-Incremental Learning based on Label Generation","summary":"  Despite the great success of pre-trained language models, it is still a\nchallenge to use these models for continual learning, especially for the\nclass-incremental learning (CIL) setting due to catastrophic forgetting (CF).\nThis paper reports our finding that if we formulate CIL as a continual label\ngeneration problem, CF is drastically reduced and the generalizable\nrepresentations of pre-trained models can be better retained. We thus propose a\nnew CIL method (VAG) that also leverages the sparsity of vocabulary to focus\nthe generation and creates pseudo-replay samples by using label semantics.\nExperimental results show that VAG outperforms baselines by a large margin.\n","authors":["Yijia Shao","Yiduo Guo","Dongyan Zhao","Bing Liu"],"pdf_url":"https://arxiv.org/pdf/2306.12619v1.pdf","comment":"12 pages, ACL 2023 Main Conference"},{"id":"http://arxiv.org/abs/2306.11971v2","updated":"2023-06-22T00:51:09Z","published":"2023-06-21T01:53:01Z","title":"AdCraft: An Advanced Reinforcement Learning Benchmark Environment for\n  Search Engine Marketing Optimization","summary":"  We introduce AdCraft, a novel benchmark environment for the Reinforcement\nLearning (RL) community distinguished by its stochastic and non-stationary\nproperties. The environment simulates bidding and budgeting dynamics within\nSearch Engine Marketing (SEM), a digital marketing technique utilizing paid\nadvertising to enhance the visibility of websites on search engine results\npages (SERPs). The performance of SEM advertisement campaigns depends on\nseveral factors, including keyword selection, ad design, bid management, budget\nadjustments, and performance monitoring. Deep RL recently emerged as a\npotential strategy to optimize campaign profitability within the complex and\ndynamic landscape of SEM but it requires substantial data, which may be costly\nor infeasible to acquire in practice. Our customizable environment enables\npractitioners to assess and enhance the robustness of RL algorithms pertinent\nto SEM bid and budget management without such costs. Through a series of\nexperiments within the environment, we demonstrate the challenges imposed by\nsparsity and non-stationarity on agent convergence and performance. We hope\nthese challenges further encourage discourse and development around effective\nstrategies for managing real-world uncertainties.\n","authors":["Maziar Gomrokchi","Owen Levin","Jeffrey Roach","Jonah White"],"pdf_url":"https://arxiv.org/pdf/2306.11971v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12047v2","updated":"2023-06-22T00:40:37Z","published":"2023-06-21T06:30:56Z","title":"Corrector Operator to Enhance Accuracy and Reliability of Neural\n  Operator Surrogates of Nonlinear Variational Boundary-Value Problems","summary":"  This work focuses on developing methods for approximating the solution\noperators of a class of parametric partial differential equations via neural\noperators. Neural operators have several challenges, including the issue of\ngenerating appropriate training data, cost-accuracy trade-offs, and nontrivial\nhyperparameter tuning. The unpredictability of the accuracy of neural operators\nimpacts their applications in downstream problems of inference, optimization,\nand control. A framework is proposed based on the linear variational problem\nthat gives the correction to the prediction furnished by neural operators. The\noperator associated with the corrector problem is referred to as the corrector\noperator. Numerical results involving a nonlinear diffusion model in two\ndimensions with PCANet-type neural operators show almost two orders of increase\nin the accuracy of approximations when neural operators are corrected using the\nproposed scheme. Further, topology optimization involving a nonlinear diffusion\nmodel is considered to highlight the limitations of neural operators and the\nefficacy of the correction scheme. Optimizers with neural operator surrogates\nare seen to make significant errors (as high as 80 percent). However, the\nerrors are much lower (below 7 percent) when neural operators are corrected\nfollowing the proposed method.\n","authors":["Prashant K. Jha","J. Tinsley Oden"],"pdf_url":"https://arxiv.org/pdf/2306.12047v2.pdf","comment":"34 pages, 14 figures"},{"id":"http://arxiv.org/abs/2306.12612v1","updated":"2023-06-22T00:23:37Z","published":"2023-06-22T00:23:37Z","title":"RobustNeuralNetworks.jl: a Package for Machine Learning and Data-Driven\n  Control with Certified Robustness","summary":"  Neural networks are typically sensitive to small input perturbations, leading\nto unexpected or brittle behaviour. We present RobustNeuralNetworks.jl: a Julia\npackage for neural network models that are constructed to naturally satisfy a\nset of user-defined robustness constraints. The package is based on the\nrecently proposed Recurrent Equilibrium Network (REN) and Lipschitz-Bounded\nDeep Network (LBDN) model classes, and is designed to interface directly with\nJulia's most widely-used machine learning package, Flux.jl. We discuss the\ntheory behind our model parameterization, give an overview of the package, and\nprovide a tutorial demonstrating its use in image classification, reinforcement\nlearning, and nonlinear state-observer design.\n","authors":["Nicholas H. Barbara","Max Revay","Ruigang Wang","Jing Cheng","Ian R. Manchester"],"pdf_url":"https://arxiv.org/pdf/2306.12612v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2305.03138v2","updated":"2023-06-22T14:30:17Z","published":"2023-05-04T20:42:51Z","title":"A Subjective Dataset for Multi-Screen Video Streaming Applications","summary":"  In modern-era video streaming systems, videos are streamed and displayed on a\nwide range of devices. Such devices vary from large-screen UHD and HDTVs to\nmedium-screen Desktop PCs and Laptops to smaller-screen devices such as mobile\nphones and tablets. It is well known that a video is perceived differently when\ndisplayed on different devices. The viewing experience for a particular video\non smaller screen devices such as smartphones and tablets, which have high\npixel density, will be different with respect to the case where the same video\nis played on a large screen device such as a TV or PC monitor. Being able to\nmodel such relative differences in perception effectively can help in the\ndesign of better quality metrics and in the design of more efficient and\noptimized encoding profiles, leading to lower storage, encoding, and\ntransmission costs. This paper presents a new, open-source dataset consisting\nof subjective ratings for various encoded video sequences of different\nresolutions and bitrates (quality) when viewed on three devices of varying\nscreen sizes: TV, Tablet, and Mobile. Along with the subjective scores, an\nevaluation of some of the most famous and commonly used open-source objective\nquality metrics is also presented. It is observed that the performance of the\nmetrics varies a lot across different device types, with the recently\nstandardized ITU-T P.1204.3 Model, on average, outperforming their\nfull-reference counterparts. The dataset consisting of the videos, along with\ntheir subjective and objective scores, is available freely on Github at\nhttps://github.com/NabajeetBarman/Multiscreen-Dataset.\n","authors":["Nabajeet Barman","Yuriy Reznik","Maria G. Martini"],"pdf_url":"https://arxiv.org/pdf/2305.03138v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.02437v3","updated":"2023-06-22T13:00:56Z","published":"2022-10-05T17:57:29Z","title":"ASVspoof 2021: Towards Spoofed and Deepfake Speech Detection in the Wild","summary":"  Benchmarking initiatives support the meaningful comparison of competing\nsolutions to prominent problems in speech and language processing. Successive\nbenchmarking evaluations typically reflect a progressive evolution from ideal\nlab conditions towards to those encountered in the wild. ASVspoof, the spoofing\nand deepfake detection initiative and challenge series, has followed the same\ntrend. This article provides a summary of the ASVspoof 2021 challenge and the\nresults of 54 participating teams that submitted to the evaluation phase. For\nthe logical access (LA) task, results indicate that countermeasures are robust\nto newly introduced encoding and transmission effects. Results for the physical\naccess (PA) task indicate the potential to detect replay attacks in real, as\nopposed to simulated physical spaces, but a lack of robustness to variations\nbetween simulated and real acoustic environments. The Deepfake (DF) task, new\nto the 2021 edition, targets solutions to the detection of manipulated,\ncompressed speech data posted online. While detection solutions offer some\nresilience to compression effects, they lack generalization across different\nsource datasets. In addition to a summary of the top-performing systems for\neach task, new analyses of influential data factors and results for hidden data\nsubsets, the article includes a review of post-challenge results, an outline of\nthe principal challenge limitations and a road-map for the future of ASVspoof.\n","authors":["Xuechen Liu","Xin Wang","Md Sahidullah","Jose Patino","Héctor Delgado","Tomi Kinnunen","Massimiliano Todisco","Junichi Yamagishi","Nicholas Evans","Andreas Nautsch","Kong Aik Lee"],"pdf_url":"https://arxiv.org/pdf/2210.02437v3.pdf","comment":"IEEE/ACM Transactions on Audio, Speech, and Language Processing"},{"id":"http://arxiv.org/abs/2306.12829v1","updated":"2023-06-22T12:04:37Z","published":"2023-06-22T12:04:37Z","title":"Relevance-Based Compression of Cataract Surgery Videos","summary":"  In the last decade, the need for storing videos from cataract surgery has\nincreased significantly. Hospitals continue to improve their imaging and\nrecording devices (e.g., microscopes and cameras used in microscopic surgery,\nsuch as ophthalmology) to enhance their post-surgical processing efficiency.\nThe video recordings enable a lot of user-cases after the actual surgery, for\nexample, teaching, documentation, and forensics. However, videos recorded from\noperations are typically stored in the internal archive without any\ndomain-specific compression, leading to a massive storage space consumption. In\nthis work, we propose a relevance-based compression scheme for videos from\ncataract surgery, which is based on content specifics of particular cataract\nsurgery phases. We evaluate our compression scheme with three state-of-the-art\nvideo codecs, namely H.264/AVC, H.265/HEVC, and AV1, and ask medical experts to\nevaluate the visual quality of encoded videos. Our results show significant\nsavings, in particular up to 95.94% when using H.264/AVC, up to 98.71% when\nusing H.265/HEVC, and up to 98.82% when using AV1.\n","authors":["Natalia Mathá","Klaus Schoeffmann","Konstantin Schekotihin","Stephanie Sarny","Doris Putzgruber-Adamitsch","Yosuf El-Shabrawi"],"pdf_url":"https://arxiv.org/pdf/2306.12829v1.pdf","comment":"11 pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2306.12790v1","updated":"2023-06-22T10:45:49Z","published":"2023-06-22T10:45:49Z","title":"DiffWA: Diffusion Models for Watermark Attack","summary":"  With the rapid development of deep neural networks(DNNs), many robust blind\nwatermarking algorithms and frameworks have been proposed and achieved good\nresults. At present, the watermark attack algorithm can not compete with the\nwatermark addition algorithm. And many watermark attack algorithms only care\nabout interfering with the normal extraction of the watermark, and the\nwatermark attack will cause great visual loss to the image. To this end, we\npropose DiffWA, a conditional diffusion model with distance guidance for\nwatermark attack, which can restore the image while removing the embedded\nwatermark. The core of our method is training an image-to-image conditional\ndiffusion model on unwatermarked images and guiding the conditional model using\na distance guidance when sampling so that the model will generate unwatermarked\nimages which is similar to original images. We conducted experiments on\nCIFAR-10 using our proposed models. The results shows that the model can remove\nthe watermark with good effect and make the bit error rate of watermark\nextraction higher than 0.4. At the same time, the attacked image will maintain\ngood visual effect with PSNR more than 31 and SSIM more than 0.97 compared with\nthe original image.\n","authors":["Xinyu Li"],"pdf_url":"https://arxiv.org/pdf/2306.12790v1.pdf","comment":null}]},"2023-06-26T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2306.14899v1","updated":"2023-06-26T17:59:55Z","published":"2023-06-26T17:59:55Z","title":"FunQA: Towards Surprising Video Comprehension","summary":"  Surprising videos, e.g., funny clips, creative performances, or visual\nillusions, attract significant attention. Enjoyment of these videos is not\nsimply a response to visual stimuli; rather, it hinges on the human capacity to\nunderstand (and appreciate) commonsense violations depicted in these videos. We\nintroduce FunQA, a challenging video question answering (QA) dataset\nspecifically designed to evaluate and enhance the depth of video reasoning\nbased on counter-intuitive and fun videos. Unlike most video QA benchmarks\nwhich focus on less surprising contexts, e.g., cooking or instructional videos,\nFunQA covers three previously unexplored types of surprising videos: 1)\nHumorQA, 2) CreativeQA, and 3) MagicQA. For each subset, we establish rigorous\nQA tasks designed to assess the model's capability in counter-intuitive\ntimestamp localization, detailed video description, and reasoning around\ncounter-intuitiveness. We also pose higher-level tasks, such as attributing a\nfitting and vivid title to the video, and scoring the video creativity. In\ntotal, the FunQA benchmark consists of 312K free-text QA pairs derived from\n4.3K video clips, spanning a total of 24 video hours. Extensive experiments\nwith existing VideoQA models reveal significant performance gaps for the FunQA\nvideos across spatial-temporal reasoning, visual-centered reasoning, and\nfree-text generation.\n","authors":["Binzhu Xie","Sicheng Zhang","Zitang Zhou","Bo Li","Yuanhan Zhang","Jack Hessel","Jingkang Yang","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2306.14899v1.pdf","comment":"Ask VLMs about humor, creation, and magics. Project Page:\n  https://funqa-benchmark.github.io/ Codebase:\n  https://github.com/Jingkang50/FunQA"},{"id":"http://arxiv.org/abs/2306.14898v1","updated":"2023-06-26T17:59:50Z","published":"2023-06-26T17:59:50Z","title":"InterCode: Standardizing and Benchmarking Interactive Coding with\n  Execution Feedback","summary":"  Humans write code in a fundamentally interactive manner and rely on constant\nexecution feedback to correct errors, resolve ambiguities, and decompose tasks.\nWhile LLMs have recently exhibited promising coding capabilities, current\ncoding benchmarks mostly consider a static instruction-to-code sequence\ntransduction process, which has the potential for error propagation and a\ndisconnect between the generated code and its final execution environment. To\naddress this gap, we introduce InterCode, a lightweight, flexible, and\neasy-to-use framework of interactive coding as a standard reinforcement\nlearning (RL) environment, with code as actions and execution feedback as\nobservations. Our framework is language and platform agnostic, uses\nself-contained Docker environments to provide safe and reproducible execution,\nand is compatible out-of-the-box with traditional seq2seq coding methods, while\nenabling the development of new methods for interactive code generation. We use\nInterCode to create two interactive code environments with Bash and SQL as\naction spaces, leveraging data from the static Spider and NL2Bash datasets. We\ndemonstrate InterCode's viability as a testbed by evaluating multiple\nstate-of-the-art LLMs configured with different prompting strategies such as\nReAct and Plan & Solve. Our results showcase the benefits of interactive code\ngeneration and demonstrate that InterCode can serve as a challenging benchmark\nfor advancing code understanding and generation capabilities. InterCode is\ndesigned to be easily extensible and can even be used to incorporate new tasks\nsuch as Capture the Flag, a popular coding puzzle that is inherently multi-step\nand involves multiple programming languages. Project site with code and data:\nhttps://intercode-benchmark.github.io\n","authors":["John Yang","Akshara Prabhakar","Karthik Narasimhan","Shunyu Yao"],"pdf_url":"https://arxiv.org/pdf/2306.14898v1.pdf","comment":"Project site with code and data:\n  https://intercode-benchmark.github.io"},{"id":"http://arxiv.org/abs/2306.14893v1","updated":"2023-06-26T17:59:24Z","published":"2023-06-26T17:59:24Z","title":"LongCoder: A Long-Range Pre-trained Language Model for Code Completion","summary":"  In this paper, we introduce a new task for code completion that focuses on\nhandling long code input and propose a sparse Transformer model, called\nLongCoder, to address this task. LongCoder employs a sliding window mechanism\nfor self-attention and introduces two types of globally accessible tokens -\nbridge tokens and memory tokens - to improve performance and efficiency. Bridge\ntokens are inserted throughout the input sequence to aggregate local\ninformation and facilitate global interaction, while memory tokens are included\nto highlight important statements that may be invoked later and need to be\nmemorized, such as package imports and definitions of classes, functions, or\nstructures. We conduct experiments on a newly constructed dataset that contains\nlonger code context and the publicly available CodeXGLUE benchmark.\nExperimental results demonstrate that LongCoder achieves superior performance\non code completion tasks compared to previous models while maintaining\ncomparable efficiency in terms of computational resources during inference. All\nthe codes and data are available at https://github.com/microsoft/CodeBERT.\n","authors":["Daya Guo","Canwen Xu","Nan Duan","Jian Yin","Julian McAuley"],"pdf_url":"https://arxiv.org/pdf/2306.14893v1.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2306.14870v1","updated":"2023-06-26T17:33:21Z","published":"2023-06-26T17:33:21Z","title":"Composing Parameter-Efficient Modules with Arithmetic Operations","summary":"  As an efficient alternative to conventional full finetuning,\nparameter-efficient finetuning (PEFT) is becoming the prevailing method to\nadapt pretrained language models. In PEFT, a lightweight module is learned on\neach dataset while the underlying pretrained language model remains unchanged,\nresulting in multiple compact modules representing diverse skills when applied\nto various domains and tasks. In this paper, we propose to compose these\nparameter-efficient modules through linear arithmetic operations in the weight\nspace, thereby integrating different module capabilities. Specifically, we\nfirst define addition and negation operators for the module, and then further\ncompose these two basic operators to perform flexible arithmetic. Our approach\nrequires \\emph{no additional training} and enables highly flexible module\ncomposition. We apply different arithmetic operations to compose the\nparameter-efficient modules for (1) distribution generalization, (2)\nmulti-tasking, (3) unlearning, and (4) domain transfer. Additionally, we extend\nour approach to detoxify Alpaca-LoRA, the latest instruction-tuned large\nlanguage model based on LLaMA. Empirical results demonstrate that our approach\nproduces new and effective parameter-efficient modules that significantly\noutperform existing ones across all settings.\n","authors":["Jinghan Zhang","Shiqi Chen","Junteng Liu","Junxian He"],"pdf_url":"https://arxiv.org/pdf/2306.14870v1.pdf","comment":"Preprint. Code is available at\n  https://github.com/SJTU-LIT/PEM_composition"},{"id":"http://arxiv.org/abs/2306.14866v1","updated":"2023-06-26T17:27:31Z","published":"2023-06-26T17:27:31Z","title":"Enriching the NArabizi Treebank: A Multifaceted Approach to Supporting\n  an Under-Resourced Language","summary":"  In this paper we address the scarcity of annotated data for NArabizi, a\nRomanized form of North African Arabic used mostly on social media, which poses\nchallenges for Natural Language Processing (NLP). We introduce an enriched\nversion of NArabizi Treebank (Seddah et al., 2020) with three main\ncontributions: the addition of two novel annotation layers (named entity\nrecognition and offensive language detection) and a re-annotation of the\ntokenization, morpho-syntactic and syntactic layers that ensure annotation\nconsistency. Our experimental results, using different tokenization schemes,\nshowcase the value of our contributions and highlight the impact of working\nwith non-gold tokenization for NER and dependency parsing. To facilitate future\nresearch, we make these annotations publicly available. Our enhanced NArabizi\nTreebank paves the way for creating sophisticated language models and NLP tools\nfor this under-represented language.\n","authors":["Riabi Arij","Mahamdi Menel","Seddah Djamé"],"pdf_url":"https://arxiv.org/pdf/2306.14866v1.pdf","comment":"Accepted to the 17th Linguistic Annotation Workshop (LAW-XVII),\n  co-located with ACL 2023"},{"id":"http://arxiv.org/abs/2306.14828v1","updated":"2023-06-26T16:34:37Z","published":"2023-06-26T16:34:37Z","title":"HonestBait: Forward References for Attractive but Faithful Headline\n  Generation","summary":"  Current methods for generating attractive headlines often learn directly from\ndata, which bases attractiveness on the number of user clicks and views.\nAlthough clicks or views do reflect user interest, they can fail to reveal how\nmuch interest is raised by the writing style and how much is due to the event\nor topic itself. Also, such approaches can lead to harmful inventions by\nover-exaggerating the content, aggravating the spread of false information. In\nthis work, we propose HonestBait, a novel framework for solving these issues\nfrom another aspect: generating headlines using forward references (FRs), a\nwriting technique often used for clickbait. A self-verification process is\nincluded during training to avoid spurious inventions. We begin with a\npreliminary user study to understand how FRs affect user interest, after which\nwe present PANCO1, an innovative dataset containing pairs of fake news with\nverified news for attractive but faithful news headline generation. Automatic\nmetrics and human evaluations show that our framework yields more attractive\nresults (+11.25% compared to human-written verified news headlines) while\nmaintaining high veracity, which helps promote real information to fight\nagainst fake news.\n","authors":["Chih-Yao Chen","Dennis Wu","Lun-Wei Ku"],"pdf_url":"https://arxiv.org/pdf/2306.14828v1.pdf","comment":"Accepted to ACL 2023 Findings"},{"id":"http://arxiv.org/abs/2306.14827v1","updated":"2023-06-26T16:34:02Z","published":"2023-06-26T16:34:02Z","title":"Vietnamese multi-document summary using subgraph selection approach --\n  VLSP 2022 AbMuSu Shared Task","summary":"  Document summarization is a task to generate afluent, condensed summary for a\ndocument, andkeep important information. A cluster of documents serves as the\ninput for multi-document summarizing (MDS), while the cluster summary serves as\nthe output. In this paper, we focus on transforming the extractive MDS problem\ninto subgraph selection. Approaching the problem in the form of graphs helps to\ncapture simultaneously the relationship between sentences in the same document\nand between sentences in the same cluster based on exploiting the overall graph\nstructure and selected subgraphs. Experiments have been implemented on the\nVietnamese dataset published in VLSP Evaluation Campaign 2022. This model\ncurrently results in the top 10 participating teams reported on the ROUGH-2\n$F\\_1$ measure on the public test set.\n","authors":["Huu-Thin Nguyen","Tam Doan Thanh","Cam-Van Thi Nguyen"],"pdf_url":"https://arxiv.org/pdf/2306.14827v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2110.12645 by other authors"},{"id":"http://arxiv.org/abs/2306.14824v1","updated":"2023-06-26T16:32:47Z","published":"2023-06-26T16:32:47Z","title":"Kosmos-2: Grounding Multimodal Large Language Models to the World","summary":"  We introduce Kosmos-2, a Multimodal Large Language Model (MLLM), enabling new\ncapabilities of perceiving object descriptions (e.g., bounding boxes) and\ngrounding text to the visual world. Specifically, we represent refer\nexpressions as links in Markdown, i.e., ``[text span](bounding boxes)'', where\nobject descriptions are sequences of location tokens. Together with multimodal\ncorpora, we construct large-scale data of grounded image-text pairs (called\nGrIT) to train the model. In addition to the existing capabilities of MLLMs\n(e.g., perceiving general modalities, following instructions, and performing\nin-context learning), Kosmos-2 integrates the grounding capability into\ndownstream applications. We evaluate Kosmos-2 on a wide range of tasks,\nincluding (i) multimodal grounding, such as referring expression comprehension,\nand phrase grounding, (ii) multimodal referring, such as referring expression\ngeneration, (iii) perception-language tasks, and (iv) language understanding\nand generation. This work lays out the foundation for the development of\nEmbodiment AI and sheds light on the big convergence of language, multimodal\nperception, action, and world modeling, which is a key step toward artificial\ngeneral intelligence. Data, demo, and pretrained models are available at\nhttps://aka.ms/kosmos-2.\n","authors":["Zhiliang Peng","Wenhui Wang","Li Dong","Yaru Hao","Shaohan Huang","Shuming Ma","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2306.14824v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2306.14822v1","updated":"2023-06-26T16:28:33Z","published":"2023-06-26T16:28:33Z","title":"Label-Aware Hyperbolic Embeddings for Fine-grained Emotion\n  Classification","summary":"  Fine-grained emotion classification (FEC) is a challenging task.\nSpecifically, FEC needs to handle subtle nuance between labels, which can be\ncomplex and confusing. Most existing models only address text classification\nproblem in the euclidean space, which we believe may not be the optimal\nsolution as labels of close semantic (e.g., afraid and terrified) may not be\ndifferentiated in such space, which harms the performance. In this paper, we\npropose HypEmo, a novel framework that can integrate hyperbolic embeddings to\nimprove the FEC task. First, we learn label embeddings in the hyperbolic space\nto better capture their hierarchical structure, and then our model projects\ncontextualized representations to the hyperbolic space to compute the distance\nbetween samples and labels. Experimental results show that incorporating such\ndistance to weight cross entropy loss substantially improves the performance\nwith significantly higher efficiency. We evaluate our proposed model on two\nbenchmark datasets and found 4.8% relative improvement compared to the previous\nstate of the art with 43.2% fewer parameters and 76.9% less training time. Code\nis available at https: //github.com/dinobby/HypEmo.\n","authors":["Chih-Yao Chen","Tun-Min Hung","Yi-Li Hsu","Lun-Wei Ku"],"pdf_url":"https://arxiv.org/pdf/2306.14822v1.pdf","comment":"Accepted to ACL 2023"},{"id":"http://arxiv.org/abs/2305.18391v2","updated":"2023-06-26T16:15:48Z","published":"2023-05-28T11:17:30Z","title":"MemeGraphs: Linking Memes to Knowledge Graphs","summary":"  Memes are a popular form of communicating trends and ideas in social media\nand on the internet in general, combining the modalities of images and text.\nThey can express humor and sarcasm but can also have offensive content.\nAnalyzing and classifying memes automatically is challenging since their\ninterpretation relies on the understanding of visual elements, language, and\nbackground knowledge. Thus, it is important to meaningfully represent these\nsources and the interaction between them in order to classify a meme as a\nwhole. In this work, we propose to use scene graphs, that express images in\nterms of objects and their visual relations, and knowledge graphs as structured\nrepresentations for meme classification with a Transformer-based architecture.\nWe compare our approach with ImgBERT, a multimodal model that uses only learned\n(instead of structured) representations of the meme, and observe consistent\nimprovements. We further provide a dataset with human graph annotations that we\ncompare to automatically generated graphs and entity linking. Analysis shows\nthat automatic methods link more entities than human annotators and that\nautomatically generated graphs are better suited for hatefulness classification\nin memes.\n","authors":["Vasiliki Kougia","Simon Fetzel","Thomas Kirchmair","Erion Çano","Sina Moayed Baharlou","Sahand Sharifzadeh","Benjamin Roth"],"pdf_url":"https://arxiv.org/pdf/2305.18391v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14806v1","updated":"2023-06-26T16:05:59Z","published":"2023-06-26T16:05:59Z","title":"A Positive-Unlabeled Metric Learning Framework for Document-Level\n  Relation Extraction with Incomplete Labeling","summary":"  The goal of document-level relation extraction (RE) is to identify relations\nbetween entities that span multiple sentences. Recently, incomplete labeling in\ndocument-level RE has received increasing attention, and some studies have used\nmethods such as positive-unlabeled learning to tackle this issue, but there is\nstill a lot of room for improvement. Motivated by this, we propose a\npositive-augmentation and positive-mixup positive-unlabeled metric learning\nframework (P3M). Specifically, we formulate document-level RE as a metric\nlearning problem. We aim to pull the distance closer between entity pair\nembedding and their corresponding relation embedding, while pushing it farther\naway from the none-class relation embedding. Additionally, we adapt the\npositive-unlabeled learning to this loss objective. In order to improve the\ngeneralizability of the model, we use dropout to augment positive samples and\npropose a positive-none-class mixup method. Extensive experiments show that P3M\nimproves the F1 score by approximately 4-10 points in document-level RE with\nincomplete labeling, and achieves state-of-the-art results in fully labeled\nscenarios. Furthermore, P3M has also demonstrated robustness to prior\nestimation bias in incomplete labeled scenarios.\n","authors":["Ye Wang","Huazheng Pan","Tao Zhang","Wen Wu","Wenxin Hu"],"pdf_url":"https://arxiv.org/pdf/2306.14806v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14795v1","updated":"2023-06-26T15:53:02Z","published":"2023-06-26T15:53:02Z","title":"MotionGPT: Human Motion as a Foreign Language","summary":"  Though the advancement of pre-trained large language models unfolds, the\nexploration of building a unified model for language and other multi-modal\ndata, such as motion, remains challenging and untouched so far. Fortunately,\nhuman motion displays a semantic coupling akin to human language, often\nperceived as a form of body language. By fusing language data with large-scale\nmotion models, motion-language pre-training that can enhance the performance of\nmotion-related tasks becomes feasible. Driven by this insight, we propose\nMotionGPT, a unified, versatile, and user-friendly motion-language model to\nhandle multiple motion-relevant tasks. Specifically, we employ the discrete\nvector quantization for human motion and transfer 3D motion into motion tokens,\nsimilar to the generation process of word tokens. Building upon this \"motion\nvocabulary\", we perform language modeling on both motion and text in a unified\nmanner, treating human motion as a specific language. Moreover, inspired by\nprompt learning, we pre-train MotionGPT with a mixture of motion-language data\nand fine-tune it on prompt-based question-and-answer tasks. Extensive\nexperiments demonstrate that MotionGPT achieves state-of-the-art performances\non multiple motion tasks including text-driven motion generation, motion\ncaptioning, motion prediction, and motion in-between.\n","authors":["Biao Jiang","Xin Chen","Wen Liu","Jingyi Yu","Gang Yu","Tao Chen"],"pdf_url":"https://arxiv.org/pdf/2306.14795v1.pdf","comment":"https://github.com/OpenMotionLab/MotionGPT"},{"id":"http://arxiv.org/abs/2306.14790v1","updated":"2023-06-26T15:48:05Z","published":"2023-06-26T15:48:05Z","title":"Automatic Assessment of Divergent Thinking in Chinese Language with\n  TransDis: A Transformer-Based Language Model Approach","summary":"  Language models have been increasingly popular for automatic creativity\nassessment, generating semantic distances to objectively measure the quality of\ncreative ideas. However, there is currently a lack of an automatic assessment\nsystem for evaluating creative ideas in the Chinese language. To address this\ngap, we developed TransDis, a scoring system using transformer-based language\nmodels, capable of providing valid originality (quality) and flexibility\n(variety) scores for Alternative Uses Task (AUT) responses in Chinese. Study 1\ndemonstrated that the latent model-rated originality factor, comprised of three\ntransformer-based models, strongly predicted human originality ratings, and the\nmodel-rated flexibility strongly correlated with human flexibility ratings as\nwell. Criterion validity analyses indicated that model-rated originality and\nflexibility positively correlated to other creativity measures, demonstrating\nsimilar validity to human ratings. Study 2 & 3 showed that TransDis effectively\ndistinguished participants instructed to provide creative vs. common uses\n(Study 2) and participants instructed to generate ideas in a flexible vs.\npersistent way (Study 3). Our findings suggest that TransDis can be a reliable\nand low-cost tool for measuring idea originality and flexibility in Chinese\nlanguage, potentially paving the way for automatic creativity assessment in\nother languages. We offer an open platform to compute originality and\nflexibility for AUT responses in Chinese and over 50 other languages\n(https://osf.io/59jv2/).\n","authors":["Tianchen Yang","Qifan Zhang","Zhaoyang Sun","Yubo Hou"],"pdf_url":"https://arxiv.org/pdf/2306.14790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.17760v2","updated":"2023-06-26T15:37:55Z","published":"2023-05-28T16:04:48Z","title":"Language Models are Bounded Pragmatic Speakers","summary":"  How do language models \"think\"? This paper formulates a probabilistic\ncognitive model called the bounded pragmatic speaker, which can characterize\nthe operation of different variations of language models. Specifically, we\ndemonstrate that large language models fine-tuned with reinforcement learning\nfrom human feedback (Ouyang et al., 2022) embody a model of thought that\nconceptually resembles a fast-and-slow model (Kahneman, 2011), which\npsychologists have attributed to humans. We discuss the limitations of\nreinforcement learning from human feedback as a fast-and-slow model of thought\nand propose avenues for expanding this framework. In essence, our research\nhighlights the value of adopting a cognitive probabilistic modeling approach to\ngain insights into the comprehension, evaluation, and advancement of language\nmodels.\n","authors":["Khanh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2305.17760v2.pdf","comment":"Proceedings of the First Workshop on Theory of Mind in Communicating\n  Agents at (TOM @ ICML 2023)"},{"id":"http://arxiv.org/abs/2306.11222v2","updated":"2023-06-26T15:34:57Z","published":"2023-06-20T01:16:11Z","title":"LoSparse: Structured Compression of Large Language Models based on\n  Low-Rank and Sparse Approximation","summary":"  Transformer models have achieved remarkable results in various natural\nlanguage tasks, but they are often prohibitively large, requiring massive\nmemories and computational resources. To reduce the size and complexity of\nthese models, we propose LoSparse (Low-Rank and Sparse approximation), a novel\nmodel compression technique that approximates a weight matrix by the sum of a\nlow-rank matrix and a sparse matrix. Our method combines the advantages of both\nlow-rank approximations and pruning, while avoiding their limitations. Low-rank\napproximation compresses the coherent and expressive parts in neurons, while\npruning removes the incoherent and non-expressive parts in neurons. Pruning\nenhances the diversity of low-rank approximations, and low-rank approximation\nprevents pruning from losing too many expressive neurons. We evaluate our\nmethod on natural language understanding, question answering, and natural\nlanguage generation tasks. We show that it significantly outperforms existing\ncompression methods.\n","authors":["Yixiao Li","Yifan Yu","Qingru Zhang","Chen Liang","Pengcheng He","Weizhu Chen","Tuo Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.11222v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14764v1","updated":"2023-06-26T15:17:54Z","published":"2023-06-26T15:17:54Z","title":"Uncovering Political Hate Speech During Indian Election Campaign: A New\n  Low-Resource Dataset and Baselines","summary":"  The detection of hate speech in political discourse is a critical issue, and\nthis becomes even more challenging in low-resource languages. To address this\nissue, we introduce a new dataset named IEHate, which contains 11,457 manually\nannotated Hindi tweets related to the Indian Assembly Election Campaign from\nNovember 1, 2021, to March 9, 2022. We performed a detailed analysis of the\ndataset, focusing on the prevalence of hate speech in political communication\nand the different forms of hateful language used. Additionally, we benchmark\nthe dataset using a range of machine learning, deep learning, and\ntransformer-based algorithms. Our experiments reveal that the performance of\nthese models can be further improved, highlighting the need for more advanced\ntechniques for hate speech detection in low-resource languages. In particular,\nthe relatively higher score of human evaluation over algorithms emphasizes the\nimportance of utilizing both human and automated approaches for effective hate\nspeech moderation. Our IEHate dataset can serve as a valuable resource for\nresearchers and practitioners working on developing and evaluating hate speech\ndetection techniques in low-resource languages. Overall, our work underscores\nthe importance of addressing the challenges of identifying and mitigating hate\nspeech in political discourse, particularly in the context of low-resource\nlanguages. The dataset and resources for this work are made available at\nhttps://github.com/Farhan-jafri/Indian-Election.\n","authors":["Farhan Ahmad Jafri","Mohammad Aman Siddiqui","Surendrabikram Thapa","Kritesh Rauniyar","Usman Naseem","Imran Razzak"],"pdf_url":"https://arxiv.org/pdf/2306.14764v1.pdf","comment":"Accepted to ICWSM Workshop (MEDIATE)"},{"id":"http://arxiv.org/abs/2306.14754v1","updated":"2023-06-26T15:09:51Z","published":"2023-06-26T15:09:51Z","title":"Représentation graphique de la langue des signes française et\n  édition logicielle","summary":"  Cet article propose une m\\'ethode pour d\\'efinir une forme graphique\n\\'editable standardis\\'ee pour les langues des signes, ainsi qu'une proposition\n\"AZVD\" et un \\'editeur logiciel associ\\'e. Inspir\\'ee d'une part par les\nr\\'egularit\\'es observ\\'ees dans les pratiques spontan\\'ees de locuteurs\npratiquant la sch\\'ematisation, la d\\'emarche tente garantir un syst\\`eme\nqualifi\\'e d'adoptable. Li\\'ee d'autre part au mod\\`ele formel de\nrepr\\'esentation AZee, elle vise \\'egalement \\`a sp\\'ecifier un syst\\`eme dont\ntoutes les productions ont une lecture d\\'etermin\\'ee au point o\\`u elles sont\nautomatiquement synth\\'etisables par un avatar.\n  --\n  This paper proposes a definition method for an editable standard graphical\nform of Sign Language discourse representation. It also puts forward a\ntentative system \"AZVD\", and presents an associated software editor. The system\nis inspired by the regularities observed in spontaneous diagrams produced by\nsome language users, in order to make it as adoptable as possible. Moreover, it\nis built upon the formal representation model AZee, so that any graphical\ninstance produced by the system determines its own read-out form, to the point\nthat they can be automatically synthesised by an avatar.\n","authors":["Michael Filhol","Thomas von Ascheberg"],"pdf_url":"https://arxiv.org/pdf/2306.14754v1.pdf","comment":"in French language"},{"id":"http://arxiv.org/abs/2306.14728v1","updated":"2023-06-26T14:29:05Z","published":"2023-06-26T14:29:05Z","title":"Learn over Past, Evolve for Future: Forecasting Temporal Trends for Fake\n  News Detection","summary":"  Fake news detection has been a critical task for maintaining the health of\nthe online news ecosystem. However, very few existing works consider the\ntemporal shift issue caused by the rapidly-evolving nature of news data in\npractice, resulting in significant performance degradation when training on\npast data and testing on future data. In this paper, we observe that the\nappearances of news events on the same topic may display discernible patterns\nover time, and posit that such patterns can assist in selecting training\ninstances that could make the model adapt better to future data. Specifically,\nwe design an effective framework FTT (Forecasting Temporal Trends), which could\nforecast the temporal distribution patterns of news data and then guide the\ndetector to fast adapt to future distribution. Experiments on the real-world\ntemporally split dataset demonstrate the superiority of our proposed framework.\nThe code is available at https://github.com/ICTMCG/FTT-ACL23.\n","authors":["Beizhe Hu","Qiang Sheng","Juan Cao","Yongchun Zhu","Danding Wang","Zhengjia Wang","Zhiwei Jin"],"pdf_url":"https://arxiv.org/pdf/2306.14728v1.pdf","comment":"Accepted at ACL 2023"},{"id":"http://arxiv.org/abs/2306.14704v1","updated":"2023-06-26T13:54:47Z","published":"2023-06-26T13:54:47Z","title":"Ontology Enrichment from Texts: A Biomedical Dataset for Concept\n  Discovery and Placement","summary":"  Mentions of new concepts appear regularly in texts and require automated\napproaches to harvest and place them into Knowledge Bases (KB), e.g.,\nontologies and taxonomies. Existing datasets suffer from three issues, (i)\nmostly assuming that a new concept is pre-discovered and cannot support\nout-of-KB mention discovery; (ii) only using the concept label as the input\nalong with the KB and thus lacking the contexts of a concept label; and (iii)\nmostly focusing on concept placement w.r.t a taxonomy of atomic concepts,\ninstead of complex concepts, i.e., with logical operators. To address these\nissues, we propose a new benchmark, adapting MedMentions dataset (PubMed\nabstracts) with SNOMED CT versions in 2014 and 2017 under the Diseases\nsub-category and the broader categories of Clinical finding, Procedure, and\nPharmaceutical / biologic product. We provide usage on the evaluation with the\ndataset for out-of-KB mention discovery and concept placement, adapting recent\nLarge Language Model based methods.\n","authors":["Hang Dong","Jiaoyan Chen","Yuan He","Ian Horrocks"],"pdf_url":"https://arxiv.org/pdf/2306.14704v1.pdf","comment":"The dataset, data construction scripts, and baseline implementation\n  are available at https://zenodo.org/record/8043690 (Zenodo) and\n  https://github.com/KRR-Oxford/OET (GitHub)"},{"id":"http://arxiv.org/abs/2306.14696v1","updated":"2023-06-26T13:43:06Z","published":"2023-06-26T13:43:06Z","title":"How About Kind of Generating Hedges using End-to-End Neural Models?","summary":"  Hedging is a strategy for softening the impact of a statement in\nconversation. In reducing the strength of an expression, it may help to avoid\nembarrassment (more technically, ``face threat'') to one's listener. For this\nreason, it is often found in contexts of instruction, such as tutoring. In this\nwork, we develop a model of hedge generation based on i) fine-tuning\nstate-of-the-art language models trained on human-human tutoring data, followed\nby ii) reranking to select the candidate that best matches the expected hedging\nstrategy within a candidate pool using a hedge classifier. We apply this method\nto a natural peer-tutoring corpus containing a significant number of\ndisfluencies, repetitions, and repairs. The results show that generation in\nthis noisy environment is feasible with reranking. By conducting an error\nanalysis for both approaches, we reveal the challenges faced by systems\nattempting to accomplish both social and task-oriented goals in conversation.\n","authors":["Alafate Abulimiti","Chloé Clavel","Justine Cassell"],"pdf_url":"https://arxiv.org/pdf/2306.14696v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.12493v3","updated":"2023-06-26T12:28:10Z","published":"2023-05-21T16:08:04Z","title":"Contextualized End-to-End Speech Recognition with Contextual Phrase\n  Prediction Network","summary":"  Contextual information plays a crucial role in speech recognition\ntechnologies and incorporating it into the end-to-end speech recognition models\nhas drawn immense interest recently. However, previous deep bias methods lacked\nexplicit supervision for bias tasks. In this study, we introduce a contextual\nphrase prediction network for an attention-based deep bias method. This network\npredicts context phrases in utterances using contextual embeddings and\ncalculates bias loss to assist in the training of the contextualized model. Our\nmethod achieved a significant word error rate (WER) reduction across various\nend-to-end speech recognition models. Experiments on the LibriSpeech corpus\nshow that our proposed model obtains a 12.1% relative WER improvement over the\nbaseline model, and the WER of the context phrases decreases relatively by\n40.5%. Moreover, by applying a context phrase filtering strategy, we also\neffectively eliminate the WER degradation when using a larger biasing list.\n","authors":["Kaixun Huang","Ao Zhang","Zhanheng Yang","Pengcheng Guo","Bingshen Mu","Tianyi Xu","Lei Xie"],"pdf_url":"https://arxiv.org/pdf/2305.12493v3.pdf","comment":"Accepted by interspeech2023"},{"id":"http://arxiv.org/abs/2306.14633v1","updated":"2023-06-26T12:12:54Z","published":"2023-06-26T12:12:54Z","title":"JSEEGraph: Joint Structured Event Extraction as Graph Parsing","summary":"  We propose a graph-based event extraction framework JSEEGraph that approaches\nthe task of event extraction as general graph parsing in the tradition of\nMeaning Representation Parsing. It explicitly encodes entities and events in a\nsingle semantic graph, and further has the flexibility to encode a wider range\nof additional IE relations and jointly infer individual tasks. JSEEGraph\nperforms in an end-to-end manner via general graph parsing: (1) instead of flat\nsequence labelling, nested structures between entities/triggers are efficiently\nencoded as separate nodes in the graph, allowing for nested and overlapping\nentities and triggers; (2) both entities, relations, and events can be encoded\nin the same graph, where entities and event triggers are represented as nodes\nand entity relations and event arguments are constructed via edges; (3) joint\ninference avoids error propagation and enhances the interpolation of different\nIE tasks. We experiment on two benchmark datasets of varying structural\ncomplexities; ACE05 and Rich ERE, covering three languages: English, Chinese,\nand Spanish. Experimental results show that JSEEGraph can handle nested event\nstructures, that it is beneficial to solve different IE tasks jointly, and that\nevent argument extraction in particular benefits from entity extraction. Our\ncode and models are released as open-source.\n","authors":["Huiling You","Samia Touileb","Lilja Øvrelid"],"pdf_url":"https://arxiv.org/pdf/2306.14633v1.pdf","comment":"To appear in *SEM 2023"},{"id":"http://arxiv.org/abs/2306.14610v1","updated":"2023-06-26T11:35:22Z","published":"2023-06-26T11:35:22Z","title":"SugarCrepe: Fixing Hackable Benchmarks for Vision-Language\n  Compositionality","summary":"  In the last year alone, a surge of new benchmarks to measure compositional\nunderstanding of vision-language models have permeated the machine learning\necosystem. Given an image, these benchmarks probe a model's ability to identify\nits associated caption amongst a set of compositional distractors.\nSurprisingly, we find significant biases in all these benchmarks rendering them\nhackable. This hackability is so dire that blind models with no access to the\nimage outperform state-of-the-art vision-language models. To remedy this\nrampant vulnerability, we introduce SugarCrepe, a new benchmark for\nvision-language compositionality evaluation. We employ large language models,\ninstead of rule-based templates used in previous benchmarks, to generate fluent\nand sensical hard negatives, and utilize an adversarial refinement mechanism to\nmaximally reduce biases. We re-evaluate state-of-the-art models and recently\nproposed compositionality inducing strategies, and find that their improvements\nwere hugely overestimated, suggesting that more innovation is needed in this\nimportant direction. We release SugarCrepe and the code for evaluation at:\nhttps://github.com/RAIVNLab/sugar-crepe.\n","authors":["Cheng-Yu Hsieh","Jieyu Zhang","Zixian Ma","Aniruddha Kembhavi","Ranjay Krishna"],"pdf_url":"https://arxiv.org/pdf/2306.14610v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14608v1","updated":"2023-06-26T11:32:05Z","published":"2023-06-26T11:32:05Z","title":"Factorised Speaker-environment Adaptive Training of Conformer Speech\n  Recognition Systems","summary":"  Rich sources of variability in natural speech present significant challenges\nto current data intensive speech recognition technologies. To model both\nspeaker and environment level diversity, this paper proposes a novel Bayesian\nfactorised speaker-environment adaptive training and test time adaptation\napproach for Conformer ASR models. Speaker and environment level\ncharacteristics are separately modeled using compact hidden output transforms,\nwhich are then linearly or hierarchically combined to represent any\nspeaker-environment combination. Bayesian learning is further utilized to model\nthe adaptation parameter uncertainty. Experiments on the 300-hr WHAM noise\ncorrupted Switchboard data suggest that factorised adaptation consistently\noutperforms the baseline and speaker label only adapted Conformers by up to\n3.1% absolute (10.4% relative) word error rate reductions. Further analysis\nshows the proposed method offers potential for rapid adaption to unseen\nspeaker-environment conditions.\n","authors":["Jiajun Deng","Guinan Li","Xurong Xie","Zengrui Jin","Mingyu Cui","Tianzi Wang","Shujie Hu","Mengzhe Geng","Xunying Liu"],"pdf_url":"https://arxiv.org/pdf/2306.14608v1.pdf","comment":"Accepted by INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2306.14592v1","updated":"2023-06-26T11:00:35Z","published":"2023-06-26T11:00:35Z","title":"Transfer Learning across Several Centuries: Machine and Historian\n  Integrated Method to Decipher Royal Secretary's Diary","summary":"  A named entity recognition and classification plays the first and foremost\nimportant role in capturing semantics in data and anchoring in translation as\nwell as downstream study for history. However, NER in historical text has faced\nchallenges such as scarcity of annotated corpus, multilanguage variety, various\nnoise, and different convention far different from the contemporary language\nmodel. This paper introduces Korean historical corpus (Diary of Royal secretary\nwhich is named SeungJeongWon) recorded over several centuries and recently\nadded with named entity information as well as phrase markers which historians\ncarefully annotated. We fined-tuned the language model on history corpus,\nconducted extensive comparative experiments using our language model and\npretrained muti-language models. We set up the hypothesis of combination of\ntime and annotation information and tested it based on statistical t test. Our\nfinding shows that phrase markers clearly improve the performance of NER model\nin predicting unseen entity in documents written far different time period. It\nalso shows that each of phrase marker and corpus-specific trained model does\nnot improve the performance. We discuss the future research directions and\npractical strategies to decipher the history document.\n","authors":["Sojung Lucia Kim","Taehong Jang","Joonmo Ahn","Hyungil Lee","Jaehyuk Lee"],"pdf_url":"https://arxiv.org/pdf/2306.14592v1.pdf","comment":"7 pages, 9 figures"},{"id":"http://arxiv.org/abs/2306.14583v1","updated":"2023-06-26T10:48:50Z","published":"2023-06-26T10:48:50Z","title":"Exploring the Robustness of Large Language Models for Solving\n  Programming Problems","summary":"  Using large language models (LLMs) for source code has recently gained\nattention. LLMs, such as Transformer-based models like Codex and ChatGPT, have\nbeen shown to be highly capable of solving a wide range of programming\nproblems. However, the extent to which LLMs understand problem descriptions and\ngenerate programs accordingly or just retrieve source code from the most\nrelevant problem in training data based on superficial cues has not been\ndiscovered yet. To explore this research question, we conduct experiments to\nunderstand the robustness of several popular LLMs, CodeGen and GPT-3.5 series\nmodels, capable of tackling code generation tasks in introductory programming\nproblems. Our experimental results show that CodeGen and Codex are sensitive to\nthe superficial modifications of problem descriptions and significantly impact\ncode generation performance. Furthermore, we observe that Codex relies on\nvariable names, as randomized variables decrease the solved rate significantly.\nHowever, the state-of-the-art (SOTA) models, such as InstructGPT and ChatGPT,\nshow higher robustness to superficial modifications and have an outstanding\ncapability for solving programming problems. This highlights the fact that\nslight modifications to the prompts given to the LLMs can greatly affect code\ngeneration performance, and careful formatting of prompts is essential for\nhigh-quality code generation, while the SOTA models are becoming more robust to\nperturbations.\n","authors":["Atsushi Shirafuji","Yutaka Watanobe","Takumi Ito","Makoto Morishita","Yuki Nakamura","Yusuke Oda","Jun Suzuki"],"pdf_url":"https://arxiv.org/pdf/2306.14583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14580v1","updated":"2023-06-26T10:45:16Z","published":"2023-06-26T10:45:16Z","title":"TransERR: Translation-based Knowledge Graph Completion via Efficient\n  Relation Rotation","summary":"  This paper presents translation-based knowledge graph completion method via\nefficient relation rotation (TransERR), a straightforward yet effective\nalternative to traditional translation-based knowledge graph completion models.\nDifferent from the previous translation-based models, TransERR encodes\nknowledge graphs in the hypercomplex-valued space, thus enabling it to possess\na higher degree of translation freedom in mining latent information between the\nhead and tail entities. To further minimize the translation distance, TransERR\nadaptively rotates the head entity and the tail entity with their corresponding\nunit quaternions, which are learnable in model training. The experiments on 7\nbenchmark datasets validate the effectiveness and the generalization of\nTransERR. The results also indicate that TransERR can better encode large-scale\ndatasets with fewer parameters than the previous translation-based models. Our\ncode is available at: \\url{https://github.com/dellixx/TransERR}.\n","authors":["Jiang Li","Xiangdong Su"],"pdf_url":"https://arxiv.org/pdf/2306.14580v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14565v1","updated":"2023-06-26T10:26:33Z","published":"2023-06-26T10:26:33Z","title":"Aligning Large Multi-Modal Model with Robust Instruction Tuning","summary":"  Despite the promising progress in multi-modal tasks, current large\nmulti-modal models (LMM) are prone to hallucinating inconsistent descriptions\nwith respect to the associated image and human instructions. This paper\naddresses this issue by introducing the first large and diverse visual\ninstruction tuning dataset, named Large-scale Robust Visual (LRV)-Instruction.\nOur dataset consists of 120k visual instructions generated by GPT4, covering 16\nvision-and-language tasks with open-ended instructions and answers. Unlike\nexisting studies that primarily focus on positive instruction samples, we\ndesign LRV-Instruction to include both positive and negative instructions for\nmore robust visual instruction tuning. Our negative instructions are designed\nat two semantic levels: (i) Nonexistent Element Manipulation and (ii) Existent\nElement Manipulation. To efficiently measure the hallucination generated by\nLMMs, we propose GPT4-Assisted Visual Instruction Evaluation (GAVIE), a novel\napproach to evaluate visual instruction tuning without the need for\nhuman-annotated groundtruth answers and can adapt to diverse instruction\nformats. We conduct comprehensive experiments to investigate the hallucination\nof LMMs. Our results demonstrate that existing LMMs exhibit significant\nhallucination when presented with our negative instructions, particularly with\nExistent Element Manipulation instructions. Moreover, by finetuning MiniGPT4 on\nLRV-Instruction, we successfully mitigate hallucination while improving\nperformance on public datasets using less training data compared to\nstate-of-the-art methods. Additionally, we observed that a balanced ratio of\npositive and negative instances in the training data leads to a more robust\nmodel. Our project link is available at https://fuxiaoliu.github.io/LRV/.\n","authors":["Fuxiao Liu","Kevin Lin","Linjie Li","Jianfeng Wang","Yaser Yacoob","Lijuan Wang"],"pdf_url":"https://arxiv.org/pdf/2306.14565v1.pdf","comment":"35 pages, 27 figures. Under Review"},{"id":"http://arxiv.org/abs/2301.04388v3","updated":"2023-06-26T09:31:53Z","published":"2023-01-11T10:20:56Z","title":"Perceive and predict: self-supervised speech representation based loss\n  functions for speech enhancement","summary":"  Recent work in the domain of speech enhancement has explored the use of\nself-supervised speech representations to aid in the training of neural speech\nenhancement models. However, much of this work focuses on using the deepest or\nfinal outputs of self supervised speech representation models, rather than the\nearlier feature encodings. The use of self supervised representations in such a\nway is often not fully motivated. In this work it is shown that the distance\nbetween the feature encodings of clean and noisy speech correlate strongly with\npsychoacoustically motivated measures of speech quality and intelligibility, as\nwell as with human Mean Opinion Score (MOS) ratings. Experiments using this\ndistance as a loss function are performed and improved performance over the use\nof STFT spectrogram distance based loss as well as other common loss functions\nfrom speech enhancement literature is demonstrated using objective measures\nsuch as perceptual evaluation of speech quality (PESQ) and short-time objective\nintelligibility (STOI).\n","authors":["George Close","William Ravenscroft","Thomas Hain","Stefan Goetze"],"pdf_url":"https://arxiv.org/pdf/2301.04388v3.pdf","comment":"4 pages, accepted at ICASSP 2023"},{"id":"http://arxiv.org/abs/2306.14517v1","updated":"2023-06-26T08:48:08Z","published":"2023-06-26T08:48:08Z","title":"Cross-Lingual Cross-Age Group Adaptation for Low-Resource Elderly Speech\n  Emotion Recognition","summary":"  Speech emotion recognition plays a crucial role in human-computer\ninteractions. However, most speech emotion recognition research is biased\ntoward English-speaking adults, which hinders its applicability to other\ndemographic groups in different languages and age groups. In this work, we\nanalyze the transferability of emotion recognition across three different\nlanguages--English, Mandarin Chinese, and Cantonese; and 2 different age\ngroups--adults and the elderly. To conduct the experiment, we develop an\nEnglish-Mandarin speech emotion benchmark for adults and the elderly, BiMotion,\nand a Cantonese speech emotion dataset, YueMotion. This study concludes that\ndifferent language and age groups require specific speech features, thus making\ncross-lingual inference an unsuitable method. However, cross-group data\naugmentation is still beneficial to regularize the model, with linguistic\ndistance being a significant influence on cross-lingual transferability. We\nrelease publicly release our code at https://github.com/HLTCHKUST/elderly_ser.\n","authors":["Samuel Cahyawijaya","Holy Lovenia","Willy Chung","Rita Frieske","Zihan Liu","Pascale Fung"],"pdf_url":"https://arxiv.org/pdf/2306.14517v1.pdf","comment":"Accepted in INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2306.14514v1","updated":"2023-06-26T08:45:47Z","published":"2023-06-26T08:45:47Z","title":"Data-Driven Approach for Formality-Sensitive Machine Translation:\n  Language-Specific Handling and Synthetic Data Generation","summary":"  In this paper, we introduce a data-driven approach for Formality-Sensitive\nMachine Translation (FSMT) that caters to the unique linguistic properties of\nfour target languages. Our methodology centers on two core strategies: 1)\nlanguage-specific data handling, and 2) synthetic data generation using\nlarge-scale language models and empirical prompt engineering. This approach\ndemonstrates a considerable improvement over the baseline, highlighting the\neffectiveness of data-centric techniques. Our prompt engineering strategy\nfurther improves performance by producing superior synthetic translation\nexamples.\n","authors":["Seugnjun Lee","Hyeonseok Moon","Chanjun Park","Heuiseok Lim"],"pdf_url":"https://arxiv.org/pdf/2306.14514v1.pdf","comment":"Accepted for Data-centric Machine Learning Research (DMLR) Workshop\n  at ICML 2023"},{"id":"http://arxiv.org/abs/2306.14470v1","updated":"2023-06-26T07:23:47Z","published":"2023-06-26T07:23:47Z","title":"Knowledge Graph-Augmented Korean Generative Commonsense Reasoning","summary":"  Generative commonsense reasoning refers to the task of generating acceptable\nand logical assumptions about everyday situations based on commonsense\nunderstanding. By utilizing an existing dataset such as Korean CommonGen,\nlanguage generation models can learn commonsense reasoning specific to the\nKorean language. However, language models often fail to consider the\nrelationships between concepts and the deep knowledge inherent to concepts. To\naddress these limitations, we propose a method to utilize the Korean knowledge\ngraph data for text generation. Our experimental result shows that the proposed\nmethod can enhance the efficiency of Korean commonsense inference, thereby\nunderlining the significance of employing supplementary data.\n","authors":["Dahyun Jung","Jaehyung Seo","Jaewook Lee","Chanjun Park","Heuiseok Lim"],"pdf_url":"https://arxiv.org/pdf/2306.14470v1.pdf","comment":"Accepted for Data-centric Machine Learning Research (DMLR) Workshop\n  at ICML 2023"},{"id":"http://arxiv.org/abs/2306.14457v1","updated":"2023-06-26T07:00:38Z","published":"2023-06-26T07:00:38Z","title":"Fauno: The Italian Large Language Model that will leave you senza\n  parole!","summary":"  This paper presents Fauno, the first and largest open-source Italian\nconversational Large Language Model (LLM). Our goal with Fauno is to\ndemocratize the study of LLMs in Italian, demonstrating that obtaining a\nfine-tuned conversational bot with a single GPU is possible. In addition, we\nrelease a collection of datasets for conversational AI in Italian. The datasets\non which we fine-tuned Fauno include various topics such as general question\nanswering, computer science, and medical questions. We release our code and\ndatasets on \\url{https://github.com/RSTLess-research/Fauno-Italian-LLM}\n","authors":["Andrea Bacciu","Giovanni Trappolini","Andrea Santilli","Emanuele Rodolà","Fabrizio Silvestri"],"pdf_url":"https://arxiv.org/pdf/2306.14457v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.10276v5","updated":"2023-06-26T06:50:03Z","published":"2023-05-17T15:07:50Z","title":"Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models","summary":"  In this paper, we take the initiative to investigate the performance of LLMs\non complex planning tasks that require LLMs to understand a virtual spatial\nenvironment simulated via natural language and act correspondingly in text. We\npropose a benchmark named Natural Language Planning and Action (Natala)\ncomposed of a set of novel tasks: Brick World, NLVR-based Manipulations, and\nNatural Language Navigation. We found that current popular LLMs such as ChatGPT\nstill lack abilities in complex planning. This arises a question -- do the LLMs\nhave a good understanding of the environments described in natural language, or\nmaybe other alternatives such as symbolic representations are neater and hence\nbetter to be understood by LLMs? To this end, we propose a novel method called\nCoS (Chain-of-Symbol Prompting) that represents the complex environments with\ncondensed symbolic spatial representations during the chained intermediate\nthinking steps. CoS is easy to use and does not need additional training on\nLLMs. Extensive experiments indicate that CoS clearly surpasses the performance\nof the Chain-of-Thought (CoT) Prompting in all three planning tasks with even\nfewer tokens used in the inputs compared with CoT on ChatGPT and InstructGPT.\nThe performance gain is strong, by up to 60.8% accuracy (from 31.8% to 92.6%)\non Brick World for ChatGPT. CoS also reduces the number of tokens in the prompt\nobviously, by up to 65.8% of the tokens (from 407 to 139) for the intermediate\nsteps from demonstrations on Brick World. Code and data available at:\nhttps://github.com/hanxuhu/chain-of-symbol-planning\n","authors":["Hanxu Hu","Hongyuan Lu","Huajian Zhang","Wai Lam","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.10276v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.14732v5","updated":"2023-06-26T06:39:15Z","published":"2023-04-28T10:15:25Z","title":"Search-in-the-Chain: Towards Accurate, Credible and Traceable Large\n  Language Models for Knowledge-intensive Tasks","summary":"  Making the contents generated by Large Language Model (LLM) such as ChatGPT,\naccurate, credible and traceable is crucial, especially in complex\nknowledge-intensive tasks that require multi-step reasoning and each of which\nneeds knowledge to solve. Introducing Information Retrieval (IR) to provide LLM\nwith external knowledge is good potential to solve this problem. However, where\nand how to introduce IR into LLM is a big challenge. Previous work has the\ndisadvantage that the wrong knowledge retrieved by IR misleads the LLM or\nbreaks the reasoning chain of LLM. In this paper, we propose a novel framework\ncalled Search-in-the-Chain (SearChain) for the interaction between LLM and IR\nto solve the challenges. First, LLM generates the global reasoning chain called\nChain-of-Query (CoQ) where each node consists of an IR-oriented query and the\nanswer to the query. Second, IR verifies the answer of each node of CoQ, it\ncorrects the answer that is not consistent with the retrieved information when\nIR gives high confidence, which improves the credibility. Third, LLM can mark\nits missing knowledge in CoQ and IR can provide this knowledge to LLM. These\nthree operations improve the accuracy of LLM for complex knowledge-intensive\ntasks in terms of reasoning ability and knowledge. Finally, SearChain generates\nthe reasoning process and marks references to supporting documents for each\nreasoning step, which improves traceability. SearChain transforms the topology\nof reasoning from chain to tree, which can modify the reasoning direction.\nExperiment shows that SearChain outperforms baselines on complex\nknowledge-intensive tasks including multi-hop question-answering, slot filling,\nfact checking, and long-form question-answering.\n","authors":["Shicheng Xu","Liang Pang","Huawei Shen","Xueqi Cheng","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2304.14732v5.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2306.14422v1","updated":"2023-06-26T05:04:58Z","published":"2023-06-26T05:04:58Z","title":"The Singing Voice Conversion Challenge 2023","summary":"  We present the latest iteration of the voice conversion challenge (VCC)\nseries, a bi-annual scientific event aiming to compare and understand different\nvoice conversion (VC) systems based on a common dataset. This year we shifted\nour focus to singing voice conversion (SVC), thus named the challenge the\nSinging Voice Conversion Challenge (SVCC). A new database was constructed for\ntwo tasks, namely in-domain and cross-domain SVC. The challenge was run for two\nmonths, and in total we received 26 submissions, including 2 baselines. Through\na large-scale crowd-sourced listening test, we observed that for both tasks,\nalthough human-level naturalness was achieved by the top system, no team was\nable to obtain a similarity score as high as the target speakers. Also, as\nexpected, cross-domain SVC is harder than in-domain SVC, especially in the\nsimilarity aspect. We also investigated whether existing objective measurements\nwere able to predict perceptual performance, and found that only few of them\ncould reach a significant correlation.\n","authors":["Wen-Chin Huang","Lester Phillip Violeta","Songxiang Liu","Jiatong Shi","Yusuke Yasuda","Tomoki Toda"],"pdf_url":"https://arxiv.org/pdf/2306.14422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.13398v3","updated":"2023-06-26T04:24:50Z","published":"2021-10-26T04:03:45Z","title":"Unified Instance and Knowledge Alignment Pretraining for Aspect-based\n  Sentiment Analysis","summary":"  Aspect-based Sentiment Analysis (ABSA) aims to determine the sentiment\npolarity towards an aspect. Because of the expensive and limited labelled data,\nthe pretraining strategy has become the de-facto standard for ABSA. However,\nthere always exists severe domain shift between the pretraining and downstream\nABSA datasets, hindering the effective knowledge transfer when directly\nfinetuning and making the downstream task performs sub-optimal. To mitigate\nsuch domain shift, we introduce a unified alignment pretraining framework into\nthe vanilla pretrain-finetune pipeline with both instance- and knowledge-level\nalignments. Specifically, we first devise a novel coarse-to-fine retrieval\nsampling approach to select target domain-related instances from the\nlarge-scale pretraining dataset, thus aligning the instances between\npretraining and target domains (First Stage). Then, we introduce a knowledge\nguidance-based strategy to further bridge the domain gap at the knowledge\nlevel. In practice, we formulate the model pretrained on the sampled instances\ninto a knowledge guidance model and a learner model, respectively. On the\ntarget dataset, we design an on-the-fly teacher-student joint fine-tuning\napproach to progressively transfer the knowledge from the knowledge guidance\nmodel to the learner model (Second Stage). Thereby, the learner model can\nmaintain more domain-invariant knowledge when learning new knowledge from the\ntarget dataset. In the Third Stage, the learner model is finetuned to better\nadapt its learned knowledge to the target dataset. Extensive experiments and\nanalyses on several ABSA benchmarks demonstrate the effectiveness and\nuniversality of our proposed pretraining framework. Our source code and models\nare publicly available at https://github.com/WHU-ZQH/UIKA.\n","authors":["Juhua Liu","Qihuang Zhong","Liang Ding","Hua Jin","Bo Du","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2110.13398v3.pdf","comment":"Accepted by IEEE TASLP 2023"},{"id":"http://arxiv.org/abs/2305.08493v2","updated":"2023-06-26T03:50:55Z","published":"2023-05-15T09:50:15Z","title":"Creative Data Generation: A Review Focusing on Text and Poetry","summary":"  The rapid advancement in machine learning has led to a surge in automatic\ndata generation, making it increasingly challenging to differentiate between\nnaturally or human-generated data and machine-generated data. Despite these\nadvancements, the generation of creative data remains a challenge. This paper\naims to investigate and comprehend the essence of creativity, both in general\nand within the context of natural language generation. We review various\napproaches to creative writing devices and tasks, with a specific focus on the\ngeneration of poetry. We aim to shed light on the challenges and opportunities\nin the field of creative data generation.\n","authors":["Mohamad Elzohbi","Richard Zhao"],"pdf_url":"https://arxiv.org/pdf/2305.08493v2.pdf","comment":"10 pages, 2 figures, accepted for the International Conference on\n  Computational Creativity 2023 (ICCC'23)"},{"id":"http://arxiv.org/abs/2306.14393v1","updated":"2023-06-26T03:06:57Z","published":"2023-06-26T03:06:57Z","title":"Constraint-aware and Ranking-distilled Token Pruning for Efficient\n  Transformer Inference","summary":"  Deploying pre-trained transformer models like BERT on downstream tasks in\nresource-constrained scenarios is challenging due to their high inference cost,\nwhich grows rapidly with input sequence length. In this work, we propose a\nconstraint-aware and ranking-distilled token pruning method ToP, which\nselectively removes unnecessary tokens as input sequence passes through layers,\nallowing the model to improve online inference speed while preserving accuracy.\nToP overcomes the limitation of inaccurate token importance ranking in the\nconventional self-attention mechanism through a ranking-distilled token\ndistillation technique, which distills effective token rankings from the final\nlayer of unpruned models to early layers of pruned models. Then, ToP introduces\na coarse-to-fine pruning approach that automatically selects the optimal subset\nof transformer layers and optimizes token pruning decisions within these layers\nthrough improved $L_0$ regularization. Extensive experiments on GLUE benchmark\nand SQuAD tasks demonstrate that ToP outperforms state-of-the-art token pruning\nand model compression methods with improved accuracy and speedups. ToP reduces\nthe average FLOPs of BERT by 8.1x while achieving competitive accuracy on GLUE,\nand provides a real latency speedup of up to 7.4x on an Intel CPU.\n","authors":["Junyan Li","Li Lyna Zhang","Jiahang Xu","Yujing Wang","Shaoguang Yan","Yunqing Xia","Yuqing Yang","Ting Cao","Hao Sun","Weiwei Deng","Qi Zhang","Mao Yang"],"pdf_url":"https://arxiv.org/pdf/2306.14393v1.pdf","comment":"KDD 2023"},{"id":"http://arxiv.org/abs/2306.13307v2","updated":"2023-06-26T02:48:53Z","published":"2023-06-23T05:55:19Z","title":"Towards Effective and Compact Contextual Representation for Conformer\n  Transducer Speech Recognition Systems","summary":"  Current ASR systems are mainly trained and evaluated at the utterance level.\nLong range cross utterance context can be incorporated. A key task is to derive\na suitable compact representation of the most relevant history contexts. In\ncontrast to previous researches based on either LSTM-RNN encoded histories that\nattenuate the information from longer range contexts, or frame level\nconcatenation of transformer context embeddings, in this paper compact\nlow-dimensional cross utterance contextual features are learned in the\nConformer-Transducer Encoder using specially designed attention pooling layers\nthat are applied over efficiently cached preceding utterances history vectors.\nExperiments on the 1000-hr Gigaspeech corpus demonstrate that the proposed\ncontextualized streaming Conformer-Transducers outperform the baseline using\nutterance internal context only with statistically significant WER reductions\nof 0.7% to 0.5% absolute (4.3% to 3.1% relative) on the dev and test data.\n","authors":["Mingyu Cui","Jiawen Kang","Jiajun Deng","Xi Yin","Yutao Xie","Xie Chen","Xunying Liu"],"pdf_url":"https://arxiv.org/pdf/2306.13307v2.pdf","comment":"Accepted by INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2303.12816v2","updated":"2023-06-26T02:45:15Z","published":"2023-03-22T07:34:33Z","title":"From Wide to Deep: Dimension Lifting Network for Parameter-efficient\n  Knowledge Graph Embedding","summary":"  Knowledge graph embedding (KGE) that maps entities and relations into vector\nrepresentations is essential for downstream tasks. Conventional KGE methods\nrequire relatively high-dimensional entity representations to preserve the\nstructural information of knowledge graph, but lead to oversized model\nparameters. Recent methods reduce model parameters by adopting low-dimensional\nentity representations, while developing techniques (e.g., knowledge\ndistillation) to compensate for the reduced dimension. However, such operations\nproduce degraded model accuracy and limited reduction of model parameters.\nSpecifically, we view the concatenation of all entity representations as an\nembedding layer, and then conventional KGE methods that adopt high-dimensional\nentity representations equal to enlarging the width of the embedding layer to\ngain expressiveness. To achieve parameter efficiency without sacrificing\naccuracy, we instead increase the depth and propose a deeper embedding network\nfor entity representations, i.e., a narrow embedding layer and a multi-layer\ndimension lifting network (LiftNet). Experiments on three public datasets show\nthat the proposed method (implemented based on TransE and DistMult) with\n4-dimensional entity representations achieves more accurate link prediction\nresults than counterpart parameter-efficient KGE methods and strong KGE\nbaselines, including TransE and DistMult with 512-dimensional entity\nrepresentations.\n","authors":["Borui Cai","Yong Xiang","Longxiang Gao","Di Wu","He Zhang","Jiong Jin","Tom Luan"],"pdf_url":"https://arxiv.org/pdf/2303.12816v2.pdf","comment":"The experimental results in Table II are faulty, will withdraw and\n  resumit it when the correction is done"},{"id":"http://arxiv.org/abs/2302.13939v3","updated":"2023-06-26T02:38:07Z","published":"2023-02-27T16:43:04Z","title":"SpikeGPT: Generative Pre-trained Language Model with Spiking Neural\n  Networks","summary":"  As the size of large language models continue to scale, so does the\ncomputational resources required to run it. Spiking Neural Networks (SNNs) have\nemerged as an energy-efficient approach to deep learning that leverage sparse\nand event-driven activations to reduce the computational overhead associated\nwith model inference. While they have become competitive with non-spiking\nmodels on many computer vision tasks, SNNs have also proven to be more\nchallenging to train. As a result, their performance lags behind modern deep\nlearning, and we are yet to see the effectiveness of SNNs in language\ngeneration. In this paper, inspired by the Receptance Weighted Key Value (RWKV)\nlanguage model, we successfully implement `SpikeGPT', a generative language\nmodel with binary, event-driven spiking activation units. We train the proposed\nmodel on two model variants: 45M and 216M parameters. To the best of our\nknowledge, SpikeGPT is the largest backpropagation-trained SNN model to date,\nrendering it suitable for both the generation and comprehension of natural\nlanguage. We achieve this by modifying the transformer block to replace\nmulti-head self attention to reduce quadratic computational complexity O(N^2)\nto linear complexity O(N) with increasing sequence length. Input tokens are\ninstead streamed in sequentially to our attention mechanism (as with typical\nSNNs). Our preliminary experiments show that SpikeGPT remains competitive with\nnon-spiking models on tested benchmarks, while maintaining 20x fewer operations\nwhen processed on neuromorphic hardware that can leverage sparse, event-driven\nactivations.\n","authors":["Rui-Jie Zhu","Qihang Zhao","Guoqi Li","Jason K. Eshraghian"],"pdf_url":"https://arxiv.org/pdf/2302.13939v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14377v1","updated":"2023-06-26T01:40:28Z","published":"2023-06-26T01:40:28Z","title":"Synthetic Alone: Exploring the Dark Side of Synthetic Data for\n  Grammatical Error Correction","summary":"  Data-centric AI approach aims to enhance the model performance without\nmodifying the model and has been shown to impact model performance positively.\nWhile recent attention has been given to data-centric AI based on synthetic\ndata, due to its potential for performance improvement, data-centric AI has\nlong been exclusively validated using real-world data and publicly available\nbenchmark datasets. In respect of this, data-centric AI still highly depends on\nreal-world data, and the verification of models using synthetic data has not\nyet been thoroughly carried out. Given the challenges above, we ask the\nquestion: Does data quality control (noise injection and balanced data), a\ndata-centric AI methodology acclaimed to have a positive impact, exhibit the\nsame positive impact in models trained solely with synthetic data? To address\nthis question, we conducted comparative analyses between models trained on\nsynthetic and real-world data based on grammatical error correction (GEC) task.\nOur experimental results reveal that the data quality control method has a\npositive impact on models trained with real-world data, as previously reported\nin existing studies, while a negative impact is observed in models trained\nsolely on synthetic data.\n","authors":["Chanjun Park","Seonmin Koo","Seolhwa Lee","Jaehyung Seo","Sugyeong Eo","Hyeonseok Moon","Heuiseok Lim"],"pdf_url":"https://arxiv.org/pdf/2306.14377v1.pdf","comment":"Accepted for Data-centric Machine Learning Research (DMLR) Workshop\n  at ICML 2023"},{"id":"http://arxiv.org/abs/2306.14374v1","updated":"2023-06-26T01:33:58Z","published":"2023-06-26T01:33:58Z","title":"Transcending Traditional Boundaries: Leveraging Inter-Annotator\n  Agreement (IAA) for Enhancing Data Management Operations (DMOps)","summary":"  This paper presents a novel approach of leveraging Inter-Annotator Agreement\n(IAA), traditionally used for assessing labeling consistency, to optimize Data\nManagement Operations (DMOps). We advocate for the use of IAA in predicting the\nlabeling quality of individual annotators, leading to cost and time efficiency\nin data production. Additionally, our work highlights the potential of IAA in\nforecasting document difficulty, thereby boosting the data construction\nprocess's overall efficiency. This research underscores IAA's broader\napplication potential in data-driven research optimization and holds\nsignificant implications for large-scale data projects prioritizing efficiency,\ncost reduction, and high-quality data.\n","authors":["Damrin Kim","NamHyeok Kim","Chanjun Park","Harksoo Kim"],"pdf_url":"https://arxiv.org/pdf/2306.14374v1.pdf","comment":"Accepted for Data-centric Machine Learning Research (DMLR) Workshop\n  at ICML 2023"},{"id":"http://arxiv.org/abs/2306.14373v1","updated":"2023-06-26T01:28:58Z","published":"2023-06-26T01:28:58Z","title":"Inter-Annotator Agreement in the Wild: Uncovering Its Emerging Roles and\n  Considerations in Real-World Scenarios","summary":"  Inter-Annotator Agreement (IAA) is commonly used as a measure of label\nconsistency in natural language processing tasks. However, in real-world\nscenarios, IAA has various roles and implications beyond its traditional usage.\nIn this paper, we not only consider IAA as a measure of consistency but also as\na versatile tool that can be effectively utilized in practical applications.\nMoreover, we discuss various considerations and potential concerns when\napplying IAA and suggest strategies for effectively navigating these\nchallenges.\n","authors":["NamHyeok Kim","Chanjun Park"],"pdf_url":"https://arxiv.org/pdf/2306.14373v1.pdf","comment":"Accepted for Data-centric Machine Learning Research (DMLR) Workshop\n  at ICML 2023"},{"id":"http://arxiv.org/abs/2306.09869v2","updated":"2023-06-26T01:03:07Z","published":"2023-06-16T14:30:41Z","title":"Energy-Based Cross Attention for Bayesian Context Update in\n  Text-to-Image Diffusion Models","summary":"  Despite the remarkable performance of text-to-image diffusion models in image\ngeneration tasks, recent studies have raised the issue that generated images\nsometimes cannot capture the intended semantic contents of the text prompts,\nwhich phenomenon is often called semantic misalignment. To address this, here\nwe present a novel energy-based model (EBM) framework. Specifically, we first\nformulate EBMs of latent image representations and text embeddings in each\ncross-attention layer of the denoising autoencoder. Then, we obtain the\ngradient of the log posterior of context vectors, which can be updated and\ntransferred to the subsequent cross-attention layer, thereby implicitly\nminimizing a nested hierarchy of energy functions. Our latent EBMs further\nallow zero-shot compositional generation as a linear combination of\ncross-attention outputs from different contexts. Using extensive experiments,\nwe demonstrate that the proposed method is highly effective in handling various\nimage generation tasks, including multi-concept generation, text-guided image\ninpainting, and real and synthetic image editing.\n","authors":["Geon Yeong Park","Jeongsol Kim","Beomsu Kim","Sang Wan Lee","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2306.09869v2.pdf","comment":"Code: https://github.com/EnergyAttention/Energy-Based-CrossAttention"},{"id":"http://arxiv.org/abs/2306.15112v1","updated":"2023-06-26T23:38:24Z","published":"2023-06-26T23:38:24Z","title":"FeedbackMap: a tool for making sense of open-ended survey responses","summary":"  Analyzing open-ended survey responses is a crucial yet challenging task for\nsocial scientists, non-profit organizations, and educational institutions, as\nthey often face the trade-off between obtaining rich data and the burden of\nreading and coding textual responses. This demo introduces FeedbackMap, a\nweb-based tool that uses natural language processing techniques to facilitate\nthe analysis of open-ended survey responses. FeedbackMap lets researchers\ngenerate summaries at multiple levels, identify interesting response examples,\nand visualize the response space through embeddings. We discuss the importance\nof examining survey results from multiple perspectives and the potential biases\nintroduced by summarization methods, emphasizing the need for critical\nevaluation of the representation and omission of respondent voices.\n","authors":["Doug Beeferman","Nabeel Gillani"],"pdf_url":"https://arxiv.org/pdf/2306.15112v1.pdf","comment":"Demo at CSCW 2023"},{"id":"http://arxiv.org/abs/2305.07011v2","updated":"2023-06-26T23:35:10Z","published":"2023-05-11T17:53:29Z","title":"Region-Aware Pretraining for Open-Vocabulary Object Detection with\n  Vision Transformers","summary":"  We present Region-aware Open-vocabulary Vision Transformers (RO-ViT) - a\ncontrastive image-text pretraining recipe to bridge the gap between image-level\npretraining and open-vocabulary object detection. At the pretraining phase, we\npropose to randomly crop and resize regions of positional embeddings instead of\nusing the whole image positional embeddings. This better matches the use of\npositional embeddings at region-level in the detection finetuning phase. In\naddition, we replace the common softmax cross entropy loss in contrastive\nlearning with focal loss to better learn the informative yet difficult\nexamples. Finally, we leverage recent advances in novel object proposals to\nimprove open-vocabulary detection finetuning. We evaluate our full model on the\nLVIS and COCO open-vocabulary detection benchmarks and zero-shot transfer.\nRO-ViT achieves a state-of-the-art 32.4 $AP_r$ on LVIS, surpassing the best\nexisting approach by +6.1 points in addition to competitive zero-shot transfer\ndetection. Surprisingly, RO-ViT improves the image-level representation as well\nand achieves the state of the art on 9 out of 12 metrics on COCO and Flickr\nimage-text retrieval benchmarks, outperforming competitive approaches with\nlarger models.\n","authors":["Dahun Kim","Anelia Angelova","Weicheng Kuo"],"pdf_url":"https://arxiv.org/pdf/2305.07011v2.pdf","comment":"CVPR 2023 (Highlight); adds LAION-2B result"},{"id":"http://arxiv.org/abs/2306.15103v1","updated":"2023-06-26T22:51:01Z","published":"2023-06-26T22:51:01Z","title":"Structured Dialogue Discourse Parsing","summary":"  Dialogue discourse parsing aims to uncover the internal structure of a\nmulti-participant conversation by finding all the discourse~\\emph{links} and\ncorresponding~\\emph{relations}. Previous work either treats this task as a\nseries of independent multiple-choice problems, in which the link existence and\nrelations are decoded separately, or the encoding is restricted to only local\ninteraction, ignoring the holistic structural information. In contrast, we\npropose a principled method that improves upon previous work from two\nperspectives: encoding and decoding. From the encoding side, we perform\nstructured encoding on the adjacency matrix followed by the matrix-tree\nlearning algorithm, where all discourse links and relations in the dialogue are\njointly optimized based on latent tree-level distribution. From the decoding\nside, we perform structured inference using the modified Chiu-Liu-Edmonds\nalgorithm, which explicitly generates the labeled multi-root non-projective\nspanning tree that best captures the discourse structure. In addition, unlike\nin previous work, we do not rely on hand-crafted features; this improves the\nmodel's robustness. Experiments show that our method achieves new\nstate-of-the-art, surpassing the previous model by 2.3 on STAC and 1.5 on\nMolweni (F1 scores). \\footnote{Code released\nat~\\url{https://github.com/chijames/structured_dialogue_discourse_parsing}.}\n","authors":["Ta-Chung Chi","Alexander I. Rudnicky"],"pdf_url":"https://arxiv.org/pdf/2306.15103v1.pdf","comment":"9 pages, accepted at SIGDIAL 2022"},{"id":"http://arxiv.org/abs/2110.12646v2","updated":"2023-06-26T22:44:04Z","published":"2021-10-25T05:15:01Z","title":"Zero-Shot Dialogue Disentanglement by Self-Supervised Entangled Response\n  Selection","summary":"  Dialogue disentanglement aims to group utterances in a long and\nmulti-participant dialogue into threads. This is useful for discourse analysis\nand downstream applications such as dialogue response selection, where it can\nbe the first step to construct a clean context/response set. Unfortunately,\nlabeling all~\\emph{reply-to} links takes quadratic effort w.r.t the number of\nutterances: an annotator must check all preceding utterances to identify the\none to which the current utterance is a reply. In this paper, we are the first\nto propose a~\\textbf{zero-shot} dialogue disentanglement solution. Firstly, we\ntrain a model on a multi-participant response selection dataset harvested from\nthe web which is not annotated; we then apply the trained model to perform\nzero-shot dialogue disentanglement. Without any labeled data, our model can\nachieve a cluster F1 score of 25. We also fine-tune the model using various\namounts of labeled data. Experiments show that with only 10\\% of the data, we\nachieve nearly the same performance of using the full dataset\\footnote{Code is\nreleased at\n\\url{https://github.com/chijames/zero_shot_dialogue_disentanglement}}.\n","authors":["Ta-Chung Chi","Alexander I. Rudnicky"],"pdf_url":"https://arxiv.org/pdf/2110.12646v2.pdf","comment":"6 pages, accepted by EMNLP 2021. Update Acknowledgment"},{"id":"http://arxiv.org/abs/2210.17432v2","updated":"2023-06-26T22:31:06Z","published":"2022-10-31T16:02:00Z","title":"SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for\n  Text Generation and Modular Control","summary":"  Despite the growing success of diffusion models in continuous-valued domains\n(e.g., images), similar efforts for discrete domains such as text have yet to\nmatch the performance of autoregressive language models. In this work, we\npresent SSD-LM -- a diffusion-based language model with two key design choices.\nFirst, SSD-LM is semi-autoregressive, iteratively generating blocks of text,\nallowing for flexible output length at decoding time while enabling local\nbidirectional context updates. Second, it is simplex-based, performing\ndiffusion on the natural vocabulary space rather than a learned latent space,\nallowing us to incorporate classifier guidance and modular control using\noff-the-shelf classifiers without any adaptation. We evaluate SSD-LM on\nunconstrained text generation benchmarks, and show that it matches or\noutperforms strong autoregressive GPT-2 models across standard quality and\ndiversity metrics, while vastly outperforming diffusion-based baselines. On\ncontrolled text generation, SSD-LM also outperforms competitive baselines, with\nan extra advantage in modularity.\n","authors":["Xiaochuang Han","Sachin Kumar","Yulia Tsvetkov"],"pdf_url":"https://arxiv.org/pdf/2210.17432v2.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2306.15091v1","updated":"2023-06-26T22:14:04Z","published":"2023-06-26T22:14:04Z","title":"Understanding In-Context Learning via Supportive Pretraining Data","summary":"  In-context learning (ICL) improves language models' performance on a variety\nof NLP tasks by simply demonstrating a handful of examples at inference time.\nIt is not well understood why ICL ability emerges, as the model has never been\nspecifically trained on such demonstrations. Unlike prior work that explores\nimplicit mechanisms behind ICL, we study ICL via investigating the pretraining\ndata. Specifically, we first adapt an iterative, gradient-based approach to\nfind a small subset of pretraining data that supports ICL. We observe that a\ncontinued pretraining on this small subset significantly improves the model's\nICL ability, by up to 18%. We then compare the supportive subset constrastively\nwith random subsets of pretraining data and discover: (1) The supportive\npretraining data to ICL do not have a higher domain relevance to downstream\ntasks. (2) The supportive pretraining data have a higher mass of rarely\noccurring, long-tail tokens. (3) The supportive pretraining data are\nchallenging examples where the information gain from long-range context is\nbelow average, indicating learning to incorporate difficult long-range context\nencourages ICL. Our work takes a first step towards understanding ICL via\nanalyzing instance-level pretraining data. Our insights have a potential to\nenhance the ICL ability of language models by actively guiding the construction\nof pretraining data in the future.\n","authors":["Xiaochuang Han","Daniel Simig","Todor Mihaylov","Yulia Tsvetkov","Asli Celikyilmaz","Tianlu Wang"],"pdf_url":"https://arxiv.org/pdf/2306.15091v1.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2306.15087v1","updated":"2023-06-26T22:07:33Z","published":"2023-06-26T22:07:33Z","title":"WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+ Bias in\n  Large Language Models","summary":"  We present WinoQueer: a benchmark specifically designed to measure whether\nlarge language models (LLMs) encode biases that are harmful to the LGBTQ+\ncommunity. The benchmark is community-sourced, via application of a novel\nmethod that generates a bias benchmark from a community survey. We apply our\nbenchmark to several popular LLMs and find that off-the-shelf models generally\ndo exhibit considerable anti-queer bias. Finally, we show that LLM bias against\na marginalized community can be somewhat mitigated by finetuning on data\nwritten about or by members of that community, and that social media text\nwritten by community members is more effective than news text written about the\ncommunity by non-members. Our method for community-in-the-loop benchmark\ndevelopment provides a blueprint for future researchers to develop\ncommunity-driven, harms-grounded LLM benchmarks for other marginalized\ncommunities.\n","authors":["Virginia K. Felkner","Ho-Chun Herbert Chang","Eugene Jang","Jonathan May"],"pdf_url":"https://arxiv.org/pdf/2306.15087v1.pdf","comment":"Accepted to ACL 2023 (main conference). Camera-ready version"},{"id":"http://arxiv.org/abs/2306.15063v1","updated":"2023-06-26T21:05:20Z","published":"2023-06-26T21:05:20Z","title":"Pretraining task diversity and the emergence of non-Bayesian in-context\n  learning for regression","summary":"  Pretrained transformers exhibit the remarkable ability of in-context learning\n(ICL): they can learn tasks from just a few examples provided in the prompt\nwithout updating any weights. This raises a foundational question: can ICL\nsolve fundamentally $\\textit{new}$ tasks that are very different from those\nseen during pretraining? To probe this question, we examine ICL's performance\non linear regression while varying the diversity of tasks in the pretraining\ndataset. We empirically demonstrate a $\\textit{task diversity threshold}$ for\nthe emergence of ICL. Below this threshold, the pretrained transformer cannot\nsolve unseen regression tasks as it behaves like a Bayesian estimator with the\n$\\textit{non-diverse pretraining task distribution}$ as the prior. Beyond this\nthreshold, the transformer significantly outperforms this estimator; its\nbehavior aligns with that of ridge regression, corresponding to a Gaussian\nprior over $\\textit{all tasks}$, including those not seen during pretraining.\nThese results highlight that, when pretrained on data with task diversity\ngreater than the threshold, transformers $\\textit{can}$ solve fundamentally new\ntasks in-context. Importantly, this capability hinges on it deviating from the\nBayes optimal estimator with the pretraining distribution as the prior. This\nstudy underscores, in a concrete example, the critical role of task diversity,\nalongside data and model scale, in the emergence of ICL. Code is available at\nhttps://github.com/mansheej/icl-task-diversity.\n","authors":["Allan Raventós","Mansheej Paul","Feng Chen","Surya Ganguli"],"pdf_url":"https://arxiv.org/pdf/2306.15063v1.pdf","comment":"The first two authors contributed equally"},{"id":"http://arxiv.org/abs/2306.13230v2","updated":"2023-06-26T20:55:56Z","published":"2023-06-22T22:29:40Z","title":"DiversiGATE: A Comprehensive Framework for Reliable Large Language\n  Models","summary":"  In this paper, we introduce DiversiGATE, a unified framework that\nconsolidates diverse methodologies for LLM verification. The proposed framework\ncomprises two main components: Diversification and Aggregation which provide a\nholistic perspective on existing verification approaches, such as\nSelf-Consistency, Math Prompter and WebGPT. Furthermore, we propose a novel\n`SelfLearner' model that conforms to the DiversiGATE framework which can learn\nfrom its own outputs and refine its performance over time, leading to improved\naccuracy. To evaluate the effectiveness of SelfLearner, we conducted a rigorous\nseries of experiments, including tests on synthetic data as well as on popular\narithmetic reasoning benchmarks such as GSM8K. Our results demonstrate that our\napproach outperforms traditional LLMs, achieving a considerable 54.8% -> 61.8%\nimprovement on the GSM8K benchmark.\n","authors":["Shima Imani","Ali Beyram","Harsh Shrivastava"],"pdf_url":"https://arxiv.org/pdf/2306.13230v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15006v1","updated":"2023-06-26T18:43:46Z","published":"2023-06-26T18:43:46Z","title":"DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species\n  Genome","summary":"  Decoding the linguistic intricacies of the genome is a crucial problem in\nbiology, and pre-trained foundational models such as DNABERT and Nucleotide\nTransformer have made significant strides in this area. Existing works have\nlargely hinged on k-mer, fixed-length permutations of A, T, C, and G, as the\ntoken of the genome language due to its simplicity. However, we argue that the\ncomputation and sample inefficiencies introduced by k-mer tokenization are\nprimary obstacles in developing large genome foundational models. We provide\nconceptual and empirical insights into genome tokenization, building on which\nwe propose to replace k-mer tokenization with Byte Pair Encoding (BPE), a\nstatistics-based data compression algorithm that constructs tokens by\niteratively merging the most frequent co-occurring genome segment in the\ncorpus. We demonstrate that BPE not only overcomes the limitations of k-mer\ntokenization but also benefits from the computational efficiency of\nnon-overlapping tokenization. Based on these insights, we introduce DNABERT-2,\na refined genome foundation model that adapts an efficient tokenizer and\nemploys multiple strategies to overcome input length constraints, reduce time\nand memory expenditure, and enhance model capability. Furthermore, we identify\nthe absence of a comprehensive and standardized benchmark for genome\nunderstanding as another significant impediment to fair comparative analysis.\nIn response, we propose the Genome Understanding Evaluation (GUE), a\ncomprehensive multi-species genome classification dataset that amalgamates $28$\ndistinct datasets across $7$ tasks, with input lengths ranging from $70$ to\n$1000$. Through comprehensive experiments on the GUE benchmark, we demonstrate\nthat DNABERT-2 achieves comparable performance to the state-of-the-art model\nwith $21 \\times$ fewer parameters and approximately $56 \\times$ less GPU time\nin pre-training.\n","authors":["Zhihan Zhou","Yanrong Ji","Weijian Li","Pratik Dutta","Ramana Davuluri","Han Liu"],"pdf_url":"https://arxiv.org/pdf/2306.15006v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.07591v2","updated":"2023-06-26T18:05:48Z","published":"2022-11-14T18:16:48Z","title":"Imagination is All You Need! Curved Contrastive Learning for Abstract\n  Sequence Modeling Utilized on Long Short-Term Dialogue Planning","summary":"  Inspired by the curvature of space-time (Einstein, 1921), we introduce Curved\nContrastive Learning (CCL), a novel representation learning technique for\nlearning the relative turn distance between utterance pairs in multi-turn\ndialogues. The resulting bi-encoder models can guide transformers as a response\nranking model towards a goal in a zero-shot fashion by projecting the goal\nutterance and the corresponding reply candidates into a latent space. Here the\ncosine similarity indicates the distance/reachability of a candidate utterance\ntoward the corresponding goal. Furthermore, we explore how these\nforward-entailing language representations can be utilized for assessing the\nlikelihood of sequences by the entailment strength i.e. through the cosine\nsimilarity of its individual members (encoded separately) as an emergent\nproperty in the curved space. These non-local properties allow us to imagine\nthe likelihood of future patterns in dialogues, specifically by\nordering/identifying future goal utterances that are multiple turns away, given\na dialogue context. As part of our analysis, we investigate characteristics\nthat make conversations (un)plannable and find strong evidence of planning\ncapability over multiple turns (in 61.56% over 3 turns) in conversations from\nthe DailyDialog (Li et al., 2017) dataset. Finally, we show how we achieve\nhigher efficiency in sequence modeling tasks compared to previous work thanks\nto our relativistic approach, where only the last utterance needs to be encoded\nand computed during inference.\n","authors":["Justus-Jonas Erker","Stefan Schaffer","Gerasimos Spanakis"],"pdf_url":"https://arxiv.org/pdf/2211.07591v2.pdf","comment":"Accepted in ACL 2023 Findings"},{"id":"http://arxiv.org/abs/2306.04050v2","updated":"2023-06-26T18:03:12Z","published":"2023-06-06T22:42:00Z","title":"LLMZip: Lossless Text Compression using Large Language Models","summary":"  We provide new estimates of an asymptotic upper bound on the entropy of\nEnglish using the large language model LLaMA-7B as a predictor for the next\ntoken given a window of past tokens. This estimate is significantly smaller\nthan currently available estimates in \\cite{cover1978convergent},\n\\cite{lutati2023focus}. A natural byproduct is an algorithm for lossless\ncompression of English text which combines the prediction from the large\nlanguage model with a lossless compression scheme. Preliminary results from\nlimited experiments suggest that our scheme outperforms state-of-the-art text\ncompression schemes such as BSC, ZPAQ, and paq8h.\n","authors":["Chandra Shekhara Kaushik Valmeekam","Krishna Narayanan","Dileep Kalathil","Jean-Francois Chamberland","Srinivas Shakkottai"],"pdf_url":"https://arxiv.org/pdf/2306.04050v2.pdf","comment":"7 pages, 4 figures, 4 tables, preprint, added results on using LLMs\n  with arithmetic coding"},{"id":"http://arxiv.org/abs/2306.14939v1","updated":"2023-06-26T17:30:35Z","published":"2023-06-26T17:30:35Z","title":"The Art of Embedding Fusion: Optimizing Hate Speech Detection","summary":"  Hate speech detection is a challenging natural language processing task that\nrequires capturing linguistic and contextual nuances. Pre-trained language\nmodels (PLMs) offer rich semantic representations of text that can improve this\ntask. However there is still limited knowledge about ways to effectively\ncombine representations across PLMs and leverage their complementary strengths.\nIn this work, we shed light on various combination techniques for several PLMs\nand comprehensively analyze their effectiveness. Our findings show that\ncombining embeddings leads to slight improvements but at a high computational\ncost and the choice of combination has marginal effect on the final outcome. We\nalso make our codebase public at\nhttps://github.com/aflah02/The-Art-of-Embedding-Fusion-Optimizing-Hate-Speech-Detection .\n","authors":["Mohammad Aflah Khan","Neemesh Yadav","Mohit Jain","Sanyam Goyal"],"pdf_url":"https://arxiv.org/pdf/2306.14939v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15447v1","updated":"2023-06-26T17:18:44Z","published":"2023-06-26T17:18:44Z","title":"Are aligned neural networks adversarially aligned?","summary":"  Large language models are now tuned to align with the goals of their\ncreators, namely to be \"helpful and harmless.\" These models should respond\nhelpfully to user questions, but refuse to answer requests that could cause\nharm. However, adversarial users can construct inputs which circumvent attempts\nat alignment. In this work, we study to what extent these models remain\naligned, even when interacting with an adversarial user who constructs\nworst-case inputs (adversarial examples). These inputs are designed to cause\nthe model to emit harmful content that would otherwise be prohibited. We show\nthat existing NLP-based optimization attacks are insufficiently powerful to\nreliably attack aligned text models: even when current NLP-based attacks fail,\nwe can find adversarial inputs with brute force. As a result, the failure of\ncurrent attacks should not be seen as proof that aligned text models remain\naligned under adversarial inputs.\n  However the recent trend in large-scale ML models is multimodal models that\nallow users to provide images that influence the text that is generated. We\nshow these models can be easily attacked, i.e., induced to perform arbitrary\nun-aligned behavior through adversarial perturbation of the input image. We\nconjecture that improved NLP attacks may demonstrate this same level of\nadversarial control over text-only models.\n","authors":["Nicholas Carlini","Milad Nasr","Christopher A. Choquette-Choo","Matthew Jagielski","Irena Gao","Anas Awadalla","Pang Wei Koh","Daphne Ippolito","Katherine Lee","Florian Tramer","Ludwig Schmidt"],"pdf_url":"https://arxiv.org/pdf/2306.15447v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14933v1","updated":"2023-06-26T11:35:47Z","published":"2023-06-26T11:35:47Z","title":"Integrating Bidirectional Long Short-Term Memory with Subword Embedding\n  for Authorship Attribution","summary":"  The problem of unveiling the author of a given text document from multiple\ncandidate authors is called authorship attribution. Manifold word-based\nstylistic markers have been successfully used in deep learning methods to deal\nwith the intrinsic problem of authorship attribution. Unfortunately, the\nperformance of word-based authorship attribution systems is limited by the\nvocabulary of the training corpus. Literature has recommended character-based\nstylistic markers as an alternative to overcome the hidden word problem.\nHowever, character-based methods often fail to capture the sequential\nrelationship of words in texts which is a chasm for further improvement. The\nquestion addressed in this paper is whether it is possible to address the\nambiguity of hidden words in text documents while preserving the sequential\ncontext of words. Consequently, a method based on bidirectional long short-term\nmemory (BLSTM) with a 2-dimensional convolutional neural network (CNN) is\nproposed to capture sequential writing styles for authorship attribution. The\nBLSTM was used to obtain the sequential relationship among characteristics\nusing subword information. The 2-dimensional CNN was applied to understand the\nlocal syntactical position of the style from unlabeled input text. The proposed\nmethod was experimentally evaluated against numerous state-of-the-art methods\nacross the public corporal of CCAT50, IMDb62, Blog50, and Twitter50.\nExperimental results indicate accuracy improvement of 1.07\\%, and 0.96\\% on\nCCAT50 and Twitter, respectively, and produce comparable results on the\nremaining datasets.\n","authors":["Abiodun Modupe","Turgay Celik","Vukosi Marivate","Oludayo O. Olugbara"],"pdf_url":"https://arxiv.org/pdf/2306.14933v1.pdf","comment":"8 pages, 4 figure"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2306.14899v1","updated":"2023-06-26T17:59:55Z","published":"2023-06-26T17:59:55Z","title":"FunQA: Towards Surprising Video Comprehension","summary":"  Surprising videos, e.g., funny clips, creative performances, or visual\nillusions, attract significant attention. Enjoyment of these videos is not\nsimply a response to visual stimuli; rather, it hinges on the human capacity to\nunderstand (and appreciate) commonsense violations depicted in these videos. We\nintroduce FunQA, a challenging video question answering (QA) dataset\nspecifically designed to evaluate and enhance the depth of video reasoning\nbased on counter-intuitive and fun videos. Unlike most video QA benchmarks\nwhich focus on less surprising contexts, e.g., cooking or instructional videos,\nFunQA covers three previously unexplored types of surprising videos: 1)\nHumorQA, 2) CreativeQA, and 3) MagicQA. For each subset, we establish rigorous\nQA tasks designed to assess the model's capability in counter-intuitive\ntimestamp localization, detailed video description, and reasoning around\ncounter-intuitiveness. We also pose higher-level tasks, such as attributing a\nfitting and vivid title to the video, and scoring the video creativity. In\ntotal, the FunQA benchmark consists of 312K free-text QA pairs derived from\n4.3K video clips, spanning a total of 24 video hours. Extensive experiments\nwith existing VideoQA models reveal significant performance gaps for the FunQA\nvideos across spatial-temporal reasoning, visual-centered reasoning, and\nfree-text generation.\n","authors":["Binzhu Xie","Sicheng Zhang","Zitang Zhou","Bo Li","Yuanhan Zhang","Jack Hessel","Jingkang Yang","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2306.14899v1.pdf","comment":"Ask VLMs about humor, creation, and magics. Project Page:\n  https://funqa-benchmark.github.io/ Codebase:\n  https://github.com/Jingkang50/FunQA"},{"id":"http://arxiv.org/abs/2306.14895v1","updated":"2023-06-26T17:59:31Z","published":"2023-06-26T17:59:31Z","title":"Large Multimodal Models: Notes on CVPR 2023 Tutorial","summary":"  This tutorial note summarizes the presentation on ``Large Multimodal Models:\nTowards Building and Surpassing Multimodal GPT-4'', a part of CVPR 2023\ntutorial on ``Recent Advances in Vision Foundation Models''. The tutorial\nconsists of three parts. We first introduce the background on recent GPT-like\nlarge models for vision-and-language modeling to motivate the research in\ninstruction-tuned large multimodal models (LMMs). As a pre-requisite, we\ndescribe the basics of instruction-tuning in large language models, which is\nfurther extended to the multimodal space. Lastly, we illustrate how to build\nthe minimum prototype of multimodal GPT-4 like models with the open-source\nresource, and review the recently emerged topics.\n","authors":["Chunyuan Li"],"pdf_url":"https://arxiv.org/pdf/2306.14895v1.pdf","comment":"27 pages, 24 figures; Tutorial website:\n  https://vlp-tutorial.github.io/"},{"id":"http://arxiv.org/abs/2306.14896v1","updated":"2023-06-26T17:59:31Z","published":"2023-06-26T17:59:31Z","title":"RVT: Robotic View Transformer for 3D Object Manipulation","summary":"  For 3D object manipulation, methods that build an explicit 3D representation\nperform better than those relying only on camera images. But using explicit 3D\nrepresentations like voxels comes at large computing cost, adversely affecting\nscalability. In this work, we propose RVT, a multi-view transformer for 3D\nmanipulation that is both scalable and accurate. Some key features of RVT are\nan attention mechanism to aggregate information across views and re-rendering\nof the camera input from virtual views around the robot workspace. In\nsimulations, we find that a single RVT model works well across 18 RLBench tasks\nwith 249 task variations, achieving 26% higher relative success than the\nexisting state-of-the-art method (PerAct). It also trains 36X faster than\nPerAct for achieving the same performance and achieves 2.3X the inference speed\nof PerAct. Further, RVT can perform a variety of manipulation tasks in the real\nworld with just a few ($\\sim$10) demonstrations per task. Visual results, code,\nand trained model are provided at https://robotic-view-transformer.github.io/.\n","authors":["Ankit Goyal","Jie Xu","Yijie Guo","Valts Blukis","Yu-Wei Chao","Dieter Fox"],"pdf_url":"https://arxiv.org/pdf/2306.14896v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14891v1","updated":"2023-06-26T17:58:00Z","published":"2023-06-26T17:58:00Z","title":"Fuzzy-Conditioned Diffusion and Diffusion Projection Attention Applied\n  to Facial Image Correction","summary":"  Image diffusion has recently shown remarkable performance in image synthesis\nand implicitly as an image prior. Such a prior has been used with conditioning\nto solve the inpainting problem, but only supporting binary user-based\nconditioning. We derive a fuzzy-conditioned diffusion, where implicit diffusion\npriors can be exploited with controllable strength. Our fuzzy conditioning can\nbe applied pixel-wise, enabling the modification of different image components\nto varying degrees. Additionally, we propose an application to facial image\ncorrection, where we combine our fuzzy-conditioned diffusion with\ndiffusion-derived attention maps. Our map estimates the degree of anomaly, and\nwe obtain it by projecting on the diffusion space. We show how our approach\nalso leads to interpretable and autonomous facial image correction.\n","authors":["Majed El Helou"],"pdf_url":"https://arxiv.org/pdf/2306.14891v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.09344v2","updated":"2023-06-26T17:57:37Z","published":"2023-06-15T17:59:50Z","title":"DreamSim: Learning New Dimensions of Human Visual Similarity using\n  Synthetic Data","summary":"  Current perceptual similarity metrics operate at the level of pixels and\npatches. These metrics compare images in terms of their low-level colors and\ntextures, but fail to capture mid-level similarities and differences in image\nlayout, object pose, and semantic content. In this paper, we develop a\nperceptual metric that assesses images holistically. Our first step is to\ncollect a new dataset of human similarity judgments over image pairs that are\nalike in diverse ways. Critical to this dataset is that judgments are nearly\nautomatic and shared by all observers. To achieve this we use recent\ntext-to-image models to create synthetic pairs that are perturbed along various\ndimensions. We observe that popular perceptual metrics fall short of explaining\nour new data, and we introduce a new metric, DreamSim, tuned to better align\nwith human perception. We analyze how our metric is affected by different\nvisual attributes, and find that it focuses heavily on foreground objects and\nsemantic content while also being sensitive to color and layout. Notably,\ndespite being trained on synthetic data, our metric generalizes to real images,\ngiving strong results on retrieval and reconstruction tasks. Furthermore, our\nmetric outperforms both prior learned metrics and recent large vision models on\nthese tasks.\n","authors":["Stephanie Fu","Netanel Tamir","Shobhita Sundaram","Lucy Chai","Richard Zhang","Tali Dekel","Phillip Isola"],"pdf_url":"https://arxiv.org/pdf/2306.09344v2.pdf","comment":"Website: https://dreamsim-nights.github.io/ Code:\n  https://github.com/ssundaram21/dreamsim; Fixed in-text citation, figure\n  alignment, and typos"},{"id":"http://arxiv.org/abs/2306.14879v1","updated":"2023-06-26T17:50:02Z","published":"2023-06-26T17:50:02Z","title":"Domain-Scalable Unpaired Image Translation via Latent Space Anchoring","summary":"  Unpaired image-to-image translation (UNIT) aims to map images between two\nvisual domains without paired training data. However, given a UNIT model\ntrained on certain domains, it is difficult for current methods to incorporate\nnew domains because they often need to train the full model on both existing\nand new domains. To address this problem, we propose a new domain-scalable UNIT\nmethod, termed as latent space anchoring, which can be efficiently extended to\nnew visual domains and does not need to fine-tune encoders and decoders of\nexisting domains. Our method anchors images of different domains to the same\nlatent space of frozen GANs by learning lightweight encoder and regressor\nmodels to reconstruct single-domain images. In the inference phase, the learned\nencoders and decoders of different domains can be arbitrarily combined to\ntranslate images between any two domains without fine-tuning. Experiments on\nvarious datasets show that the proposed method achieves superior performance on\nboth standard and domain-scalable UNIT tasks in comparison with the\nstate-of-the-art methods.\n","authors":["Siyu Huang","Jie An","Donglai Wei","Zudi Lin","Jiebo Luo","Hanspeter Pfister"],"pdf_url":"https://arxiv.org/pdf/2306.14879v1.pdf","comment":"Accepeted to IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI). Code is available at\n  https://github.com/siyuhuang/Latent-Space-Anchoring"},{"id":"http://arxiv.org/abs/2306.14878v1","updated":"2023-06-26T17:48:25Z","published":"2023-06-26T17:48:25Z","title":"Restart Sampling for Improving Generative Processes","summary":"  Generative processes that involve solving differential equations, such as\ndiffusion models, frequently necessitate balancing speed and quality. ODE-based\nsamplers are fast but plateau in performance while SDE-based samplers deliver\nhigher sample quality at the cost of increased sampling time. We attribute this\ndifference to sampling errors: ODE-samplers involve smaller discretization\nerrors while stochasticity in SDE contracts accumulated errors. Based on these\nfindings, we propose a novel sampling algorithm called Restart in order to\nbetter balance discretization errors and contraction. The sampling method\nalternates between adding substantial noise in additional forward steps and\nstrictly following a backward ODE. Empirically, Restart sampler surpasses\nprevious SDE and ODE samplers in both speed and accuracy. Restart not only\noutperforms the previous best SDE results, but also accelerates the sampling\nspeed by 10-fold / 2-fold on CIFAR-10 / ImageNet $64 \\times 64$. In addition,\nit attains significantly better sample quality than ODE samplers within\ncomparable sampling times. Moreover, Restart better balances text-image\nalignment/visual quality versus diversity than previous samplers in the\nlarge-scale text-to-image Stable Diffusion model pre-trained on LAION $512\n\\times 512$. Code is available at\nhttps://github.com/Newbeeer/diffusion_restart_sampling\n","authors":["Yilun Xu","Mingyang Deng","Xiang Cheng","Yonglong Tian","Ziming Liu","Tommi Jaakkola"],"pdf_url":"https://arxiv.org/pdf/2306.14878v1.pdf","comment":"Code is available at\n  https://github.com/Newbeeer/diffusion_restart_sampling"},{"id":"http://arxiv.org/abs/2306.14875v1","updated":"2023-06-26T17:44:36Z","published":"2023-06-26T17:44:36Z","title":"A Fully Unsupervised Instance Segmentation Technique for White Blood\n  Cell Images","summary":"  White blood cells, also known as leukocytes are group of heterogeneously\nnucleated cells which act as salient immune system cells. These are originated\nin the bone marrow and are found in blood, plasma, and lymph tissues.\nLeukocytes kill the bacteria, virus and other kind of pathogens which invade\nhuman body through phagocytosis that in turn results immunity. Detection of a\nwhite blood cell count can reveal camouflaged infections and warn doctors about\nchronic medical conditions such as autoimmune diseases, immune deficiencies,\nand blood disorders. Segmentation plays an important role in identification of\nwhite blood cells (WBC) from microscopic image analysis. The goal of\nsegmentation in a microscopic image is to divide the image into different\ndistinct regions. In our paper, we tried to propose a novel instance\nsegmentation method for segmenting the WBCs containing both the nucleus and the\ncytoplasm, from bone marrow images.\n","authors":["Shrijeet Biswas","Amartya Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2306.14875v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.11243v2","updated":"2023-06-26T17:43:18Z","published":"2022-07-22T17:55:39Z","title":"Multiface: A Dataset for Neural Face Rendering","summary":"  Photorealistic avatars of human faces have come a long way in recent years,\nyet research along this area is limited by a lack of publicly available,\nhigh-quality datasets covering both, dense multi-view camera captures, and rich\nfacial expressions of the captured subjects. In this work, we present\nMultiface, a new multi-view, high-resolution human face dataset collected from\n13 identities at Reality Labs Research for neural face rendering. We introduce\nMugsy, a large scale multi-camera apparatus to capture high-resolution\nsynchronized videos of a facial performance. The goal of Multiface is to close\nthe gap in accessibility to high quality data in the academic community and to\nenable research in VR telepresence. Along with the release of the dataset, we\nconduct ablation studies on the influence of different model architectures\ntoward the model's interpolation capacity of novel viewpoint and expressions.\nWith a conditional VAE model serving as our baseline, we found that adding\nspatial bias, texture warp field, and residual connections improves performance\non novel view synthesis. Our code and data is available at:\nhttps://github.com/facebookresearch/multiface\n","authors":["Cheng-hsin Wuu","Ningyuan Zheng","Scott Ardisson","Rohan Bali","Danielle Belko","Eric Brockmeyer","Lucas Evans","Timothy Godisart","Hyowon Ha","Xuhua Huang","Alexander Hypes","Taylor Koska","Steven Krenn","Stephen Lombardi","Xiaomin Luo","Kevyn McPhail","Laura Millerschoen","Michal Perdoch","Mark Pitts","Alexander Richard","Jason Saragih","Junko Saragih","Takaaki Shiratori","Tomas Simon","Matt Stewart","Autumn Trimble","Xinshuo Weng","David Whitewolf","Chenglei Wu","Shoou-I Yu","Yaser Sheikh"],"pdf_url":"https://arxiv.org/pdf/2207.11243v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.09310v2","updated":"2023-06-26T17:20:37Z","published":"2023-06-15T17:46:16Z","title":"Infinite Photorealistic Worlds using Procedural Generation","summary":"  We introduce Infinigen, a procedural generator of photorealistic 3D scenes of\nthe natural world. Infinigen is entirely procedural: every asset, from shape to\ntexture, is generated from scratch via randomized mathematical rules, using no\nexternal source and allowing infinite variation and composition. Infinigen\noffers broad coverage of objects and scenes in the natural world including\nplants, animals, terrains, and natural phenomena such as fire, cloud, rain, and\nsnow. Infinigen can be used to generate unlimited, diverse training data for a\nwide range of computer vision tasks including object detection, semantic\nsegmentation, optical flow, and 3D reconstruction. We expect Infinigen to be a\nuseful resource for computer vision research and beyond. Please visit\nhttps://infinigen.org for videos, code and pre-generated data.\n","authors":["Alexander Raistrick","Lahav Lipson","Zeyu Ma","Lingjie Mei","Mingzhe Wang","Yiming Zuo","Karhan Kayan","Hongyu Wen","Beining Han","Yihan Wang","Alejandro Newell","Hei Law","Ankit Goyal","Kaiyu Yang","Jia Deng"],"pdf_url":"https://arxiv.org/pdf/2306.09310v2.pdf","comment":"Accepted to CVPR 2023, Camera Ready Version. Update 06/26/23: Change\n  the open-source license to BSD"},{"id":"http://arxiv.org/abs/2304.06714v3","updated":"2023-06-26T17:12:09Z","published":"2023-04-13T17:59:01Z","title":"Single-Stage Diffusion NeRF: A Unified Approach to 3D Generation and\n  Reconstruction","summary":"  3D-aware image synthesis encompasses a variety of tasks, such as scene\ngeneration and novel view synthesis from images. Despite numerous task-specific\nmethods, developing a comprehensive model remains challenging. In this paper,\nwe present SSDNeRF, a unified approach that employs an expressive diffusion\nmodel to learn a generalizable prior of neural radiance fields (NeRF) from\nmulti-view images of diverse objects. Previous studies have used two-stage\napproaches that rely on pretrained NeRFs as real data to train diffusion\nmodels. In contrast, we propose a new single-stage training paradigm with an\nend-to-end objective that jointly optimizes a NeRF auto-decoder and a latent\ndiffusion model, enabling simultaneous 3D reconstruction and prior learning,\neven from sparsely available views. At test time, we can directly sample the\ndiffusion prior for unconditional generation, or combine it with arbitrary\nobservations of unseen objects for NeRF reconstruction. SSDNeRF demonstrates\nrobust results comparable to or better than leading task-specific methods in\nunconditional generation and single/sparse-view 3D reconstruction.\n","authors":["Hansheng Chen","Jiatao Gu","Anpei Chen","Wei Tian","Zhuowen Tu","Lingjie Liu","Hao Su"],"pdf_url":"https://arxiv.org/pdf/2304.06714v3.pdf","comment":"Project page: https://lakonik.github.io/ssdnerf. V3 note: fixed\n  erroneous results in Tab. 2"},{"id":"http://arxiv.org/abs/2306.14846v1","updated":"2023-06-26T16:57:03Z","published":"2023-06-26T16:57:03Z","title":"ViNT: A Foundation Model for Visual Navigation","summary":"  General-purpose pre-trained models (\"foundation models\") have enabled\npractitioners to produce generalizable solutions for individual machine\nlearning problems with datasets that are significantly smaller than those\nrequired for learning from scratch. Such models are typically trained on large\nand diverse datasets with weak supervision, consuming much more training data\nthan is available for any individual downstream application. In this paper, we\ndescribe the Visual Navigation Transformer (ViNT), a foundation model that aims\nto bring the success of general-purpose pre-trained models to vision-based\nrobotic navigation. ViNT is trained with a general goal-reaching objective that\ncan be used with any navigation dataset, and employs a flexible\nTransformer-based architecture to learn navigational affordances and enable\nefficient adaptation to a variety of downstream navigational tasks. ViNT is\ntrained on a number of existing navigation datasets, comprising hundreds of\nhours of robotic navigation from a variety of different robotic platforms, and\nexhibits positive transfer, outperforming specialist models trained on singular\ndatasets. ViNT can be augmented with diffusion-based subgoal proposals to\nexplore novel environments, and can solve kilometer-scale navigation problems\nwhen equipped with long-range heuristics. ViNT can also be adapted to novel\ntask specifications with a technique inspired by prompt-tuning, where the goal\nencoder is replaced by an encoding of another task modality (e.g., GPS\nwaypoints or routing commands) embedded into the same space of goal tokens.\nThis flexibility and ability to accommodate a variety of downstream problem\ndomains establishes ViNT as an effective foundation model for mobile robotics.\nFor videos, code, and model checkpoints, see our project page at\nhttps://visualnav-transformer.github.io.\n","authors":["Dhruv Shah","Ajay Sridhar","Nitish Dashora","Kyle Stachowicz","Kevin Black","Noriaki Hirose","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2306.14846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14840v1","updated":"2023-06-26T16:48:20Z","published":"2023-06-26T16:48:20Z","title":"A Flyweight CNN with Adaptive Decoder for Schistosoma mansoni Egg\n  Detection","summary":"  Schistosomiasis mansoni is an endemic parasitic disease in more than seventy\ncountries, whose diagnosis is commonly performed by visually counting the\nparasite eggs in microscopy images of fecal samples. State-of-the-art (SOTA)\nobject detection algorithms are based on heavyweight neural networks,\nunsuitable for automating the diagnosis in the laboratory routine. We\ncircumvent the problem by presenting a flyweight Convolutional Neural Network\n(CNN) that weighs thousands of times less than SOTA object detectors. The\nkernels in our approach are learned layer-by-layer from attention regions\nindicated by user-drawn scribbles on very few training images. Representative\nkernels are visually identified and selected to improve performance with\nreduced computational cost. Another innovation is a single-layer adaptive\ndecoder whose convolutional weights are automatically defined for each image\non-the-fly. The experiments show that our CNN can outperform three SOTA\nbaselines according to five measures, being also suitable for CPU execution in\nthe laboratory routine, processing approximately four images a second for each\navailable thread.\n","authors":["Leonardo de Melo Joao","Azael de Melo e Sousa","Bianca Martins dos Santos","Silvio Jamil Ferzoli Guimaraes","Jancarlo Ferreira Gomes","Ewa Kijak","Alexandre Xavier Falcao"],"pdf_url":"https://arxiv.org/pdf/2306.14840v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14824v1","updated":"2023-06-26T16:32:47Z","published":"2023-06-26T16:32:47Z","title":"Kosmos-2: Grounding Multimodal Large Language Models to the World","summary":"  We introduce Kosmos-2, a Multimodal Large Language Model (MLLM), enabling new\ncapabilities of perceiving object descriptions (e.g., bounding boxes) and\ngrounding text to the visual world. Specifically, we represent refer\nexpressions as links in Markdown, i.e., ``[text span](bounding boxes)'', where\nobject descriptions are sequences of location tokens. Together with multimodal\ncorpora, we construct large-scale data of grounded image-text pairs (called\nGrIT) to train the model. In addition to the existing capabilities of MLLMs\n(e.g., perceiving general modalities, following instructions, and performing\nin-context learning), Kosmos-2 integrates the grounding capability into\ndownstream applications. We evaluate Kosmos-2 on a wide range of tasks,\nincluding (i) multimodal grounding, such as referring expression comprehension,\nand phrase grounding, (ii) multimodal referring, such as referring expression\ngeneration, (iii) perception-language tasks, and (iv) language understanding\nand generation. This work lays out the foundation for the development of\nEmbodiment AI and sheds light on the big convergence of language, multimodal\nperception, action, and world modeling, which is a key step toward artificial\ngeneral intelligence. Data, demo, and pretrained models are available at\nhttps://aka.ms/kosmos-2.\n","authors":["Zhiliang Peng","Wenhui Wang","Li Dong","Yaru Hao","Shaohan Huang","Shuming Ma","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2306.14824v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2306.14814v1","updated":"2023-06-26T16:18:20Z","published":"2023-06-26T16:18:20Z","title":"Probabilistic Risk Assessment of an Obstacle Detection System for GoA 4\n  Freight Trains","summary":"  In this paper, a quantitative risk assessment approach is discussed for the\ndesign of an obstacle detection function for low-speed freight trains with\ngrade of automation (GoA)~4. In this 5-step approach, starting with single\ndetection channels and ending with a three-out-of-three (3oo3) model\nconstructed of three independent dual-channel modules and a voter, a\nprobabilistic assessment is exemplified, using a combination of statistical\nmethods and parametric stochastic model checking. It is illustrated that, under\ncertain not unreasonable assumptions, the resulting hazard rate becomes\nacceptable for specific application settings. The statistical approach for\nassessing the residual risk of misclassifications in convolutional neural\nnetworks and conventional image processing software suggests that high\nconfidence can be placed into the safety-critical obstacle detection function,\neven though its implementation involves realistic machine learning\nuncertainties.\n","authors":["Mario Gleirscher","Anne E. Haxthausen","Jan Peleska"],"pdf_url":"https://arxiv.org/pdf/2306.14814v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14812v1","updated":"2023-06-26T16:16:46Z","published":"2023-06-26T16:16:46Z","title":"MOVESe: MOVablE and Moving LiDAR Scene Segmentation with Improved\n  Navigation in Seg-label free settings","summary":"  Accurate detection of movable and moving objects in LiDAR is of vital\nimportance for navigation. Most existing works focus on extracting and removing\nmoving objects during navigation. Movable objects like pedestrians, parked\nvehicles, etc. although static may move in the future. This leads to erroneous\nnavigation and accidents. In such cases, it becomes necessary to detect\npotentially movable objects. To this end, we present a learning-based approach\nthat segments movable and moving objects by generating static parts of scenes\nthat are otherwise occluded. Our model performs superior to existing baselines\non static LiDAR reconstructions using 3 datasets including a challenging sparse\nindustrial dataset. We achieve this without the assistance of any segmentation\nlabels because such labels might not always be available for less popular yet\nimportant settings like industrial environments. The non-movable static parts\nof the scene generated by our model are of vital importance for downstream\nnavigation for SLAM. The movable objects detected by our model can be fed to a\ndownstream 3D detector for aiding navigation. Though we do not use\nsegmentation, we evaluate our method against navigation baselines that use it\nto remove dynamic objects for SLAM. Through extensive experiments on several\ndatasets, we showcase that our model surpasses these baselines on navigation.\n","authors":["Prashant Kumar","Onkar Susladkar","Dhruv Makwana","Anurag Mittal","Prem Kumar Kalra"],"pdf_url":"https://arxiv.org/pdf/2306.14812v1.pdf","comment":"10 pages, 7 figures, 4 tables"},{"id":"http://arxiv.org/abs/2305.18391v2","updated":"2023-06-26T16:15:48Z","published":"2023-05-28T11:17:30Z","title":"MemeGraphs: Linking Memes to Knowledge Graphs","summary":"  Memes are a popular form of communicating trends and ideas in social media\nand on the internet in general, combining the modalities of images and text.\nThey can express humor and sarcasm but can also have offensive content.\nAnalyzing and classifying memes automatically is challenging since their\ninterpretation relies on the understanding of visual elements, language, and\nbackground knowledge. Thus, it is important to meaningfully represent these\nsources and the interaction between them in order to classify a meme as a\nwhole. In this work, we propose to use scene graphs, that express images in\nterms of objects and their visual relations, and knowledge graphs as structured\nrepresentations for meme classification with a Transformer-based architecture.\nWe compare our approach with ImgBERT, a multimodal model that uses only learned\n(instead of structured) representations of the meme, and observe consistent\nimprovements. We further provide a dataset with human graph annotations that we\ncompare to automatically generated graphs and entity linking. Analysis shows\nthat automatic methods link more entities than human annotators and that\nautomatically generated graphs are better suited for hatefulness classification\nin memes.\n","authors":["Vasiliki Kougia","Simon Fetzel","Thomas Kirchmair","Erion Çano","Sina Moayed Baharlou","Sahand Sharifzadeh","Benjamin Roth"],"pdf_url":"https://arxiv.org/pdf/2305.18391v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14810v1","updated":"2023-06-26T16:12:35Z","published":"2023-06-26T16:12:35Z","title":"Robust Wind Turbine Blade Segmentation from RGB Images in the Wild","summary":"  With the relentless growth of the wind industry, there is an imperious need\nto design automatic data-driven solutions for wind turbine maintenance. As\nstructural health monitoring mainly relies on visual inspections, the first\nstage in any automatic solution is to identify the blade region on the image.\nThus, we propose a novel segmentation algorithm that strengthens the U-Net\nresults by a tailored loss, which pools the focal loss with a contiguity\nregularization term. To attain top performing results, a set of additional\nsteps are proposed to ensure a reliable, generic, robust and efficient\nalgorithm. First, we leverage our prior knowledge on the images by filling the\nholes enclosed by temporarily-classified blade pixels and by the image\nboundaries. Subsequently, the mislead classified pixels are successfully\namended by training an on-the-fly random forest. Our algorithm demonstrates its\neffectiveness reaching a non-trivial 97.39% of accuracy.\n","authors":["Raül Pérez-Gonzalo","Andreas Espersen","Antonio Agudo"],"pdf_url":"https://arxiv.org/pdf/2306.14810v1.pdf","comment":"Accepted to ICIP 2023"},{"id":"http://arxiv.org/abs/2306.11837v2","updated":"2023-06-26T16:11:04Z","published":"2023-06-20T18:45:49Z","title":"Brain Anatomy Prior Modeling to Forecast Clinical Progression of\n  Cognitive Impairment with Structural MRI","summary":"  Brain structural MRI has been widely used to assess the future progression of\ncognitive impairment (CI). Previous learning-based studies usually suffer from\nthe issue of small-sized labeled training data, while there exist a huge amount\nof structural MRIs in large-scale public databases. Intuitively, brain\nanatomical structures derived from these public MRIs (even without\ntask-specific label information) can be used to boost CI progression trajectory\nprediction. However, previous studies seldom take advantage of such brain\nanatomy prior. To this end, this paper proposes a brain anatomy prior modeling\n(BAPM) framework to forecast the clinical progression of cognitive impairment\nwith small-sized target MRIs by exploring anatomical brain structures.\nSpecifically, the BAPM consists of a pretext model and a downstream model, with\na shared brain anatomy-guided encoder to model brain anatomy prior explicitly.\nBesides the encoder, the pretext model also contains two decoders for two\nauxiliary tasks (i.e., MRI reconstruction and brain tissue segmentation), while\nthe downstream model relies on a predictor for classification. The brain\nanatomy-guided encoder is pre-trained with the pretext model on 9,344 auxiliary\nMRIs without diagnostic labels for anatomy prior modeling. With this encoder\nfrozen, the downstream model is then fine-tuned on limited target MRIs for\nprediction. We validate the BAPM on two CI-related studies with T1-weighted\nMRIs from 448 subjects. Experimental results suggest the effectiveness of BAPM\nin (1) four CI progression prediction tasks, (2) MR image reconstruction, and\n(3) brain tissue segmentation, compared with several state-of-the-art methods.\n","authors":["Lintao Zhang","Jinjian Wu","Lihong Wang","Li Wang","David C. Steffens","Shijun Qiu","Guy G. Potter","Mingxia Liu"],"pdf_url":"https://arxiv.org/pdf/2306.11837v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14795v1","updated":"2023-06-26T15:53:02Z","published":"2023-06-26T15:53:02Z","title":"MotionGPT: Human Motion as a Foreign Language","summary":"  Though the advancement of pre-trained large language models unfolds, the\nexploration of building a unified model for language and other multi-modal\ndata, such as motion, remains challenging and untouched so far. Fortunately,\nhuman motion displays a semantic coupling akin to human language, often\nperceived as a form of body language. By fusing language data with large-scale\nmotion models, motion-language pre-training that can enhance the performance of\nmotion-related tasks becomes feasible. Driven by this insight, we propose\nMotionGPT, a unified, versatile, and user-friendly motion-language model to\nhandle multiple motion-relevant tasks. Specifically, we employ the discrete\nvector quantization for human motion and transfer 3D motion into motion tokens,\nsimilar to the generation process of word tokens. Building upon this \"motion\nvocabulary\", we perform language modeling on both motion and text in a unified\nmanner, treating human motion as a specific language. Moreover, inspired by\nprompt learning, we pre-train MotionGPT with a mixture of motion-language data\nand fine-tune it on prompt-based question-and-answer tasks. Extensive\nexperiments demonstrate that MotionGPT achieves state-of-the-art performances\non multiple motion tasks including text-driven motion generation, motion\ncaptioning, motion prediction, and motion in-between.\n","authors":["Biao Jiang","Xin Chen","Wen Liu","Jingyi Yu","Gang Yu","Tao Chen"],"pdf_url":"https://arxiv.org/pdf/2306.14795v1.pdf","comment":"https://github.com/OpenMotionLab/MotionGPT"},{"id":"http://arxiv.org/abs/2304.08486v2","updated":"2023-06-26T15:47:27Z","published":"2023-04-17T17:59:26Z","title":"BenchMD: A Benchmark for Unified Learning on Medical Images and Sensors","summary":"  Medical data poses a daunting challenge for AI algorithms: it exists in many\ndifferent modalities, experiences frequent distribution shifts, and suffers\nfrom a scarcity of examples and labels. Recent advances, including transformers\nand self-supervised learning, promise a more universal approach that can be\napplied flexibly across these diverse conditions. To measure and drive progress\nin this direction, we present BenchMD: a benchmark that tests how well unified,\nmodality-agnostic methods, including architectures and training techniques\n(e.g. self-supervised learning, ImageNet pretraining),perform on a diverse\narray of clinically-relevant medical tasks. BenchMD combines 19 publicly\navailable datasets for 7 medical modalities, including 1D sensor data, 2D\nimages, and 3D volumetric scans. Our benchmark reflects real-world data\nconstraints by evaluating methods across a range of dataset sizes, including\nchallenging few-shot settings that incentivize the use of pretraining. Finally,\nwe evaluate performance on out-of-distribution data collected at different\nhospitals than the training data, representing naturally-occurring distribution\nshifts that frequently degrade the performance of medical AI models. Our\nbaseline results demonstrate that no unified learning technique achieves strong\nperformance across all modalities, leaving ample room for improvement on the\nbenchmark. Code is released at https://github.com/rajpurkarlab/BenchMD.\n","authors":["Kathryn Wantlin","Chenwei Wu","Shih-Cheng Huang","Oishi Banerjee","Farah Dadabhoy","Veeral Vipin Mehta","Ryan Wonhee Han","Fang Cao","Raja R. Narayan","Errol Colak","Adewole Adamson","Laura Heacock","Geoffrey H. Tison","Alex Tamkin","Pranav Rajpurkar"],"pdf_url":"https://arxiv.org/pdf/2304.08486v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14789v1","updated":"2023-06-26T15:46:49Z","published":"2023-06-26T15:46:49Z","title":"Segmentation of Industrial Burner Flames: A Comparative Study from\n  Traditional Image Processing to Machine and Deep Learning","summary":"  In many industrial processes, such as power generation, chemical production,\nand waste management, accurately monitoring industrial burner flame\ncharacteristics is crucial for safe and efficient operation. A key step\ninvolves separating the flames from the background through binary segmentation.\nDecades of machine vision research have produced a wide range of possible\nsolutions, from traditional image processing to traditional machine learning\nand modern deep learning methods. In this work, we present a comparative study\nof multiple segmentation approaches, namely Global Thresholding, Region\nGrowing, Support Vector Machines, Random Forest, Multilayer Perceptron, U-Net,\nand DeepLabV3+, that are evaluated on a public benchmark dataset of industrial\nburner flames. We provide helpful insights and guidance for researchers and\npractitioners aiming to select an appropriate approach for the binary\nsegmentation of industrial burner flames and beyond. For the highest accuracy,\ndeep learning is the leading approach, while for fast and simple solutions,\ntraditional image processing techniques remain a viable option.\n","authors":["Steven Landgraf","Markus Hillemann","Moritz Aberle","Valentin Jung","Markus Ulrich"],"pdf_url":"https://arxiv.org/pdf/2306.14789v1.pdf","comment":"8 Pages, 5 figures, submitted to the Geospatial Week 2023"},{"id":"http://arxiv.org/abs/2306.14780v1","updated":"2023-06-26T15:40:15Z","published":"2023-06-26T15:40:15Z","title":"INDEXITY: a web-based collaborative tool for medical video annotation","summary":"  This technical report presents Indexity 1.4.0, a web-based tool designed for\nmedical video annotation in surgical data science projects. We describe the\nmain features available for the management of videos, annotations, ontology and\nusers, as well as the global software architecture.\n","authors":["Jean-Paul Mazellier","Méline Bour-Lang","Sabrina Bourouis","Johan Moreau","Aimable Muzuri","Olivier Schweitzer","Aslan Vatsaev","Julien Waechter","Emilie Wernert","Frederic Woelffel","Alexandre Hostettler","Nicolas Padoy","Flavien Bridault"],"pdf_url":"https://arxiv.org/pdf/2306.14780v1.pdf","comment":"7 pages, 7 figures, technical report"},{"id":"http://arxiv.org/abs/2306.06208v2","updated":"2023-06-26T15:38:42Z","published":"2023-06-05T23:07:01Z","title":"A Differential Testing Framework to Evaluate Image Recognition Model\n  Robustness","summary":"  Image recognition tasks typically use deep learning and require enormous\nprocessing power, thus relying on hardware accelerators like GPUs and TPUs for\nfast, timely processing. Failure in real-time image recognition tasks can occur\ndue to sub-optimal mapping on hardware accelerators during model deployment,\nwhich may lead to timing uncertainty and erroneous behavior. Mapping on\nhardware accelerators is done through multiple software components like deep\nlearning frameworks, compilers, device libraries, that we refer to as the\ncomputational environment. Owing to the increased use of image recognition\ntasks in safety-critical applications like autonomous driving and medical\nimaging, it is imperative to assess their robustness to changes in the\ncomputational environment, as the impact of parameters like deep learning\nframeworks, compiler optimizations, and hardware devices on model performance\nand correctness is not well understood.\n  In this paper we present a differential testing framework, which allows deep\nlearning model variant generation, execution, differential analysis and testing\nfor a number of computational environment parameters. Using our framework, we\nconduct an empirical study of robustness analysis of three popular image\nrecognition models using the ImageNet dataset, assessing the impact of changing\ndeep learning frameworks, compiler optimizations, and hardware devices. We\nreport the impact in terms of misclassifications and inference time differences\nacross different settings. In total, we observed up to 72% output label\ndifferences across deep learning frameworks, and up to 82% unexpected\nperformance degradation in terms of inference time, when applying compiler\noptimizations. Using the analysis tools in our framework, we also perform fault\nanalysis to understand the reasons for the observed differences.\n","authors":["Nikolaos Louloudakis","Perry Gibson","José Cano","Ajitha Rajan"],"pdf_url":"https://arxiv.org/pdf/2306.06208v2.pdf","comment":"12 pages, 10 figures, 2 tables. arXiv admin note: text overlap with\n  arXiv:2211.00471"},{"id":"http://arxiv.org/abs/2306.14775v1","updated":"2023-06-26T15:35:27Z","published":"2023-06-26T15:35:27Z","title":"Parameter-Level Soft-Masking for Continual Learning","summary":"  Existing research on task incremental learning in continual learning has\nprimarily focused on preventing catastrophic forgetting (CF). Although several\ntechniques have achieved learning with no CF, they attain it by letting each\ntask monopolize a sub-network in a shared network, which seriously limits\nknowledge transfer (KT) and causes over-consumption of the network capacity,\ni.e., as more tasks are learned, the performance deteriorates. The goal of this\npaper is threefold: (1) overcoming CF, (2) encouraging KT, and (3) tackling the\ncapacity problem. A novel technique (called SPG) is proposed that soft-masks\n(partially blocks) parameter updating in training based on the importance of\neach parameter to old tasks. Each task still uses the full network, i.e., no\nmonopoly of any part of the network by any task, which enables maximum KT and\nreduction in capacity usage. To our knowledge, this is the first work that\nsoft-masks a model at the parameter-level for continual learning. Extensive\nexperiments demonstrate the effectiveness of SPG in achieving all three\nobjectives. More notably, it attains significant transfer of knowledge not only\namong similar tasks (with shared knowledge) but also among dissimilar tasks\n(with little shared knowledge) while mitigating CF.\n","authors":["Tatsuya Konishi","Mori Kurokawa","Chihiro Ono","Zixuan Ke","Gyuhak Kim","Bing Liu"],"pdf_url":"https://arxiv.org/pdf/2306.14775v1.pdf","comment":"ICML2023"},{"id":"http://arxiv.org/abs/2306.13302v2","updated":"2023-06-26T15:27:29Z","published":"2023-06-23T05:36:17Z","title":"An Overview about Emerging Technologies of Autonomous Driving","summary":"  Since DARPA started Grand Challenges in 2004 and Urban Challenges in 2007,\nautonomous driving has been the most active field of AI applications. This\npaper gives an overview about technical aspects of autonomous driving\ntechnologies and open problems. We investigate the major fields of self-driving\nsystems, such as perception, mapping and localization, prediction, planning and\ncontrol, simulation, V2X and safety etc. Especially we elaborate on all these\nissues in a framework of data closed loop, a popular platform to solve the long\ntailed autonomous driving problems.\n","authors":["Yu Huang","Yue Chen","Zijiang Yang"],"pdf_url":"https://arxiv.org/pdf/2306.13302v2.pdf","comment":"18 pages. arXiv admin note: text overlap with arXiv:2007.07218,\n  arXiv:2202.02818 by other authors"},{"id":"http://arxiv.org/abs/2302.00952v2","updated":"2023-06-26T15:14:45Z","published":"2023-02-02T08:44:12Z","title":"QR-CLIP: Introducing Explicit Open-World Knowledge for Location and Time\n  Reasoning","summary":"  Daily images may convey abstract meanings that require us to memorize and\ninfer profound information from them. To encourage such human-like reasoning,\nin this work, we teach machines to predict where and when it was taken rather\nthan performing basic tasks like traditional segmentation or classification.\nInspired by Horn's QR theory, we designed a novel QR-CLIP model consisting of\ntwo components: 1) the Quantity module first retrospects more open-world\nknowledge as the candidate language inputs; 2) the Relevance module carefully\nestimates vision and language cues and infers the location and time.\nExperiments show our QR-CLIP's effectiveness, and it outperforms the previous\nSOTA on each task by an average of about 10% and 130% relative lift in terms of\nlocation and time reasoning. This study lays a technical foundation for\nlocation and time reasoning and suggests that effectively introducing\nopen-world knowledge is one of the panaceas for the tasks.\n","authors":["Weimin Shi","Mingchen Zhuge","Zhong Zhou","Dehong Gao","Deng-Ping Fan"],"pdf_url":"https://arxiv.org/pdf/2302.00952v2.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2306.13566v2","updated":"2023-06-26T15:13:31Z","published":"2023-06-23T15:38:22Z","title":"The MI-Motion Dataset and Benchmark for 3D Multi-Person Motion\n  Prediction","summary":"  3D multi-person motion prediction is a challenging task that involves\nmodeling individual behaviors and interactions between people. Despite the\nemergence of approaches for this task, comparing them is difficult due to the\nlack of standardized training settings and benchmark datasets. In this paper,\nwe introduce the Multi-Person Interaction Motion (MI-Motion) Dataset, which\nincludes skeleton sequences of multiple individuals collected by motion capture\nsystems and refined and synthesized using a game engine. The dataset contains\n167k frames of interacting people's skeleton poses and is categorized into 5\ndifferent activity scenes. To facilitate research in multi-person motion\nprediction, we also provide benchmarks to evaluate the performance of\nprediction methods in three settings: short-term, long-term, and\nultra-long-term prediction. Additionally, we introduce a novel baseline\napproach that leverages graph and temporal convolutional networks, which has\ndemonstrated competitive results in multi-person motion prediction. We believe\nthat the proposed MI-Motion benchmark dataset and baseline will facilitate\nfuture research in this area, ultimately leading to better understanding and\nmodeling of multi-person interactions.\n","authors":["Xiaogang Peng","Xiao Zhou","Yikai Luo","Hao Wen","Yu Ding","Zizhao Wu"],"pdf_url":"https://arxiv.org/pdf/2306.13566v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14752v1","updated":"2023-06-26T15:09:02Z","published":"2023-06-26T15:09:02Z","title":"MedLSAM: Localize and Segment Anything Model for 3D Medical Images","summary":"  The Segment Anything Model (SAM) has recently emerged as a groundbreaking\nmodel in the field of image segmentation. Nevertheless, both the original SAM\nand its medical adaptations necessitate slice-by-slice annotations, which\ndirectly increase the annotation workload with the size of the dataset. We\npropose MedLSAM to address this issue, ensuring a constant annotation workload\nirrespective of dataset size and thereby simplifying the annotation process.\nOur model introduces a few-shot localization framework capable of localizing\nany target anatomical part within the body. To achieve this, we develop a\nLocalize Anything Model for 3D Medical Images (MedLAM), utilizing two\nself-supervision tasks: relative distance regression (RDR) and multi-scale\nsimilarity (MSS) across a comprehensive dataset of 14,012 CT scans. We then\nestablish a methodology for accurate segmentation by integrating MedLAM with\nSAM. By annotating only six extreme points across three directions on a few\ntemplates, our model can autonomously identify the target anatomical region on\nall data scheduled for annotation. This allows our framework to generate a 2D\nbounding box for every slice of the image, which are then leveraged by SAM to\ncarry out segmentations. We conducted experiments on two 3D datasets covering\n38 organs and found that MedLSAM matches the performance of SAM and its medical\nadaptations while requiring only minimal extreme point annotations for the\nentire dataset. Furthermore, MedLAM has the potential to be seamlessly\nintegrated with future 3D SAM models, paving the way for enhanced performance.\nOur code is public at\n\\href{https://github.com/openmedlab/MedLSAM}{https://github.com/openmedlab/MedLSAM}.\n","authors":["Wenhui Lei","Xu Wei","Xiaofan Zhang","Kang Li","Shaoting Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.14752v1.pdf","comment":"Work in Progress. Code is public at\n  https://github.com/openmedlab/MedLSAM"},{"id":"http://arxiv.org/abs/2306.14749v1","updated":"2023-06-26T15:03:47Z","published":"2023-06-26T15:03:47Z","title":"A denoised Mean Teacher for domain adaptive point cloud registration","summary":"  Point cloud-based medical registration promises increased computational\nefficiency, robustness to intensity shifts, and anonymity preservation but is\nlimited by the inefficacy of unsupervised learning with similarity metrics.\nSupervised training on synthetic deformations is an alternative but, in turn,\nsuffers from the domain gap to the real domain. In this work, we aim to tackle\nthis gap through domain adaptation. Self-training with the Mean Teacher is an\nestablished approach to this problem but is impaired by the inherent noise of\nthe pseudo labels from the teacher. As a remedy, we present a denoised\nteacher-student paradigm for point cloud registration, comprising two\ncomplementary denoising strategies. First, we propose to filter pseudo labels\nbased on the Chamfer distances of teacher and student registrations, thus\npreventing detrimental supervision by the teacher. Second, we make the teacher\ndynamically synthesize novel training pairs with noise-free labels by warping\nits moving inputs with the predicted deformations. Evaluation is performed for\ninhale-to-exhale registration of lung vessel trees on the public PVT dataset\nunder two domain shifts. Our method surpasses the baseline Mean Teacher by\n13.5/62.8%, consistently outperforms diverse competitors, and sets a new\nstate-of-the-art accuracy (TRE=2.31mm). Code is available at\nhttps://github.com/multimodallearning/denoised_mt_pcd_reg.\n","authors":["Alexander Bigalke","Mattias P. Heinrich"],"pdf_url":"https://arxiv.org/pdf/2306.14749v1.pdf","comment":"early accepted at MICCAI 2023"},{"id":"http://arxiv.org/abs/2306.14725v1","updated":"2023-06-26T14:21:18Z","published":"2023-06-26T14:21:18Z","title":"Error correcting 2D-3D cascaded network for myocardial infarct scar\n  segmentation on late gadolinium enhancement cardiac magnetic resonance images","summary":"  Late gadolinium enhancement (LGE) cardiac magnetic resonance (CMR) imaging is\nconsidered the in vivo reference standard for assessing infarct size (IS) and\nmicrovascular obstruction (MVO) in ST-elevation myocardial infarction (STEMI)\npatients. However, the exact quantification of those markers of myocardial\ninfarct severity remains challenging and very time-consuming. As LGE\ndistribution patterns can be quite complex and hard to delineate from the blood\npool or epicardial fat, automatic segmentation of LGE CMR images is\nchallenging. In this work, we propose a cascaded framework of two-dimensional\nand three-dimensional convolutional neural networks (CNNs) which enables to\ncalculate the extent of myocardial infarction in a fully automated way. By\nartificially generating segmentation errors which are characteristic for 2D\nCNNs during training of the cascaded framework we are enforcing the detection\nand correction of 2D segmentation errors and hence improve the segmentation\naccuracy of the entire method. The proposed method was trained and evaluated in\na five-fold cross validation using the training dataset from the EMIDEC\nchallenge. We perform comparative experiments where our framework outperforms\nstate-of-the-art methods of the EMIDEC challenge, as well as 2D and 3D nnU-Net.\nFurthermore, in extensive ablation studies we show the advantages that come\nwith the proposed error correcting cascaded method.\n","authors":["Matthias Schwab","Mathias Pamminger","Christian Kremser","Daniel Obmann","Markus Haltmeier","Agnes Mayr"],"pdf_url":"https://arxiv.org/pdf/2306.14725v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14709v1","updated":"2023-06-26T13:57:05Z","published":"2023-06-26T13:57:05Z","title":"Self-supervised novel 2D view synthesis of large-scale scenes with\n  efficient multi-scale voxel carving","summary":"  The task of generating novel views of real scenes is increasingly important\nnowadays when AI models become able to create realistic new worlds. In many\npractical applications, it is important for novel view synthesis methods to\nstay grounded in the physical world as much as possible, while also being able\nto imagine it from previously unseen views. While most current methods are\ndeveloped and tested in virtual environments with small scenes and no errors in\npose and depth information, we push the boundaries to the real-world domain of\nlarge scales in the new context of UAVs. Our algorithmic contributions are two\nfolds. First, we manage to stay anchored in the real 3D world, by introducing\nan efficient multi-scale voxel carving method, which is able to accommodate\nsignificant noises in pose, depth, and illumination variations, while being\nable to reconstruct the view of the world from drastically different poses at\ntest time. Second, our final high-resolution output is efficiently self-trained\non data automatically generated by the voxel carving module, which gives it the\nflexibility to adapt efficiently to any scene. We demonstrated the\neffectiveness of our method on highly complex and large-scale scenes in real\nenvironments while outperforming the current state-of-the-art. Our code is\npublicly available: https://github.com/onorabil/MSVC.\n","authors":["Alexandra Budisteanu","Dragos Costea","Alina Marcu","Marius Leordeanu"],"pdf_url":"https://arxiv.org/pdf/2306.14709v1.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2303.07327v2","updated":"2023-06-26T13:56:52Z","published":"2023-03-13T17:45:39Z","title":"Unsupervised HDR Image and Video Tone Mapping via Contrastive Learning","summary":"  Capturing high dynamic range (HDR) images (videos) is attractive because it\ncan reveal the details in both dark and bright regions. Since the mainstream\nscreens only support low dynamic range (LDR) content, tone mapping algorithm is\nrequired to compress the dynamic range of HDR images (videos). Although image\ntone mapping has been widely explored, video tone mapping is lagging behind,\nespecially for the deep-learning-based methods, due to the lack of HDR-LDR\nvideo pairs. In this work, we propose a unified framework (IVTMNet) for\nunsupervised image and video tone mapping. To improve unsupervised training, we\npropose domain and instance based contrastive learning loss. Instead of using a\nuniversal feature extractor, such as VGG to extract the features for similarity\nmeasurement, we propose a novel latent code, which is an aggregation of the\nbrightness and contrast of extracted features, to measure the similarity of\ndifferent pairs. We totally construct two negative pairs and three positive\npairs to constrain the latent codes of tone mapped results. For the network\nstructure, we propose a spatial-feature-enhanced (SFE) module to enable\ninformation exchange and transformation of nonlocal regions. For video tone\nmapping, we propose a temporal-feature-replaced (TFR) module to efficiently\nutilize the temporal correlation and improve the temporal consistency of video\ntone-mapped results. We construct a large-scale unpaired HDR-LDR video dataset\nto facilitate the unsupervised training process for video tone mapping.\nExperimental results demonstrate that our method outperforms state-of-the-art\nimage and video tone mapping methods. Our code and dataset are available at\nhttps://github.com/cao-cong/UnCLTMO.\n","authors":["Cong Cao","Huanjing Yue","Xin Liu","Jingyu Yang"],"pdf_url":"https://arxiv.org/pdf/2303.07327v2.pdf","comment":"Accepted by IEEE Transactions on Circuits and Systems for Video\n  Technology (TCSVT)"},{"id":"http://arxiv.org/abs/2306.14708v1","updated":"2023-06-26T13:55:57Z","published":"2023-06-26T13:55:57Z","title":"A Simple and Effective Baseline for Attentional Generative Adversarial\n  Networks","summary":"  Synthesising a text-to-image model of high-quality images by guiding the\ngenerative model through the Text description is an innovative and challenging\ntask. In recent years, AttnGAN based on the Attention mechanism to guide GAN\ntraining has been proposed, SD-GAN, which adopts a self-distillation technique\nto improve the performance of the generator and the quality of image\ngeneration, and Stack-GAN++, which gradually improves the details and quality\nof the image by stacking multiple generators and discriminators. However, this\nseries of improvements to GAN all have redundancy to a certain extent, which\naffects the generation performance and complexity to a certain extent. We use\nthe popular simple and effective idea (1) to remove redundancy structure and\nimprove the backbone network of AttnGAN. (2) to integrate and reconstruct\nmultiple losses of DAMSM. Our improvements have significantly improved the\nmodel size and training efficiency while ensuring that the model's performance\nis unchanged and finally proposed our \\textbf{SEAttnGAN}. Code is avalilable at\nhttps://github.com/jmyissb/SEAttnGAN.\n","authors":["Mingyu Jin","Chong Zhang","Qinkai Yu","Haochen Xue","Xiaobo Jin","Xi Yang }"],"pdf_url":"https://arxiv.org/pdf/2306.14708v1.pdf","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2306.14687v1","updated":"2023-06-26T13:32:09Z","published":"2023-06-26T13:32:09Z","title":"GSMorph: Gradient Surgery for cine-MRI Cardiac Deformable Registration","summary":"  Deep learning-based deformable registration methods have been widely\ninvestigated in diverse medical applications. Learning-based deformable\nregistration relies on weighted objective functions trading off registration\naccuracy and smoothness of the deformation field. Therefore, they inevitably\nrequire tuning the hyperparameter for optimal registration performance. Tuning\nthe hyperparameters is highly computationally expensive and introduces\nundesired dependencies on domain knowledge. In this study, we construct a\nregistration model based on the gradient surgery mechanism, named GSMorph, to\nachieve a hyperparameter-free balance on multiple losses. In GSMorph, we\nreformulate the optimization procedure by projecting the gradient of similarity\nloss orthogonally to the plane associated with the smoothness constraint,\nrather than additionally introducing a hyperparameter to balance these two\ncompeting terms. Furthermore, our method is model-agnostic and can be merged\ninto any deep registration network without introducing extra parameters or\nslowing down inference. In this study, We compared our method with\nstate-of-the-art (SOTA) deformable registration approaches over two publicly\navailable cardiac MRI datasets. GSMorph proves superior to five SOTA\nlearning-based registration models and two conventional registration\ntechniques, SyN and Demons, on both registration accuracy and smoothness.\n","authors":["Haoran Dou","Ning Bi","Luyi Han","Yuhao Huang","Ritse Mann","Xin Yang","Dong Ni","Nishant Ravikumar","Alejandro F. Frangi","Yunzhi Huang"],"pdf_url":"https://arxiv.org/pdf/2306.14687v1.pdf","comment":"Accepted at MICCAI 2023"},{"id":"http://arxiv.org/abs/2306.14685v1","updated":"2023-06-26T13:30:38Z","published":"2023-06-26T13:30:38Z","title":"DiffSketcher: Text Guided Vector Sketch Synthesis through Latent\n  Diffusion Models","summary":"  Even though trained mainly on images, we discover that pretrained diffusion\nmodels show impressive power in guiding sketch synthesis. In this paper, we\npresent DiffSketcher, an innovative algorithm that creates vectorized free-hand\nsketches using natural language input. DiffSketcher is developed based on a\npre-trained text-to-image diffusion model. It performs the task by directly\noptimizing a set of Bezier curves with an extended version of the score\ndistillation sampling (SDS) loss, which allows us to use a raster-level\ndiffusion model as a prior for optimizing a parametric vectorized sketch\ngenerator. Furthermore, we explore attention maps embedded in the diffusion\nmodel for effective stroke initialization to speed up the generation process.\nThe generated sketches demonstrate multiple levels of abstraction while\nmaintaining recognizability, underlying structure, and essential visual details\nof the subject drawn. Our experiments show that DiffSketcher achieves greater\nquality than prior work.\n","authors":["Ximing Xing","Chuang Wang","Haitao Zhou","Jing Zhang","Qian Yu","Dong Xu"],"pdf_url":"https://arxiv.org/pdf/2306.14685v1.pdf","comment":"13 pages. arXiv admin note: text overlap with arXiv:2209.14988 by\n  other authors"},{"id":"http://arxiv.org/abs/2306.14680v1","updated":"2023-06-26T13:23:52Z","published":"2023-06-26T13:23:52Z","title":"A Conditional Flow Variational Autoencoder for Controllable Synthesis of\n  Virtual Populations of Anatomy","summary":"  Generating virtual populations (VPs) of anatomy is essential for conducting\nin-silico trials of medical devices. Typically, the generated VP should capture\nsufficient variability while remaining plausible, and should reflect specific\ncharacteristics and patient demographics observed in real populations. It is\ndesirable in several applications to synthesize VPs in a \\textit{controlled}\nmanner, where relevant covariates are used to conditionally synthesise virtual\npopulations that fit specific target patient populations/characteristics. We\npropose to equip a conditional variational autoencoder (cVAE) with normalizing\nflows to boost the flexibility and complexity of the approximate posterior\nlearned, leading to enhanced flexibility for controllable synthesis of VPs of\nanatomical structures. We demonstrate the performance of our conditional-flow\nVAE using a dataset of cardiac left ventricles acquired from 2360 patients,\nwith associated demographic information and clinical measurements (used as\ncovariates/conditioning information). The obtained results indicate the\nsuperiority of the proposed method for conditional synthesis of virtual\npopulations of cardiac left ventricles relative to a cVAE. Conditional\nsynthesis performance was assessed in terms of generalisation and specificity\nerrors, and in terms of the ability to preserve clinical relevant biomarkers in\nthe synthesised VPs, I.e. left ventricular blood pool and myocardial volume,\nrelative to the observed real population.\n","authors":["Haoran Dou","Nishant Ravikumar","Alejandro F. Frangi"],"pdf_url":"https://arxiv.org/pdf/2306.14680v1.pdf","comment":"Accepted at MICCAI 2023"},{"id":"http://arxiv.org/abs/2306.14678v1","updated":"2023-06-26T13:19:37Z","published":"2023-06-26T13:19:37Z","title":"Faithful Synthesis of Low-dose Contrast-enhanced Brain MRI Scans using\n  Noise-preserving Conditional GANs","summary":"  Today Gadolinium-based contrast agents (GBCA) are indispensable in Magnetic\nResonance Imaging (MRI) for diagnosing various diseases. However, GBCAs are\nexpensive and may accumulate in patients with potential side effects, thus\ndose-reduction is recommended. Still, it is unclear to which extent the GBCA\ndose can be reduced while preserving the diagnostic value -- especially in\npathological regions. To address this issue, we collected brain MRI scans at\nnumerous non-standard GBCA dosages and developed a conditional GAN model for\nsynthesizing corresponding images at fractional dose levels. Along with the\nadversarial loss, we advocate a novel content loss function based on the\nWasserstein distance of locally paired patch statistics for the faithful\npreservation of noise. Our numerical experiments show that conditional GANs are\nsuitable for generating images at different GBCA dose levels and can be used to\naugment datasets for virtual contrast models. Moreover, our model can be\ntransferred to openly available datasets such as BraTS, where non-standard GBCA\ndosage images do not exist.\n","authors":["Thomas Pinetz","Erich Kobler","Robert Haase","Katerina Deike-Hofmann","Alexander Radbruch","Alexander Effland"],"pdf_url":"https://arxiv.org/pdf/2306.14678v1.pdf","comment":"Early accepted by MICCAI 2023"},{"id":"http://arxiv.org/abs/2211.12853v2","updated":"2023-06-26T13:18:32Z","published":"2022-11-23T10:53:37Z","title":"BAD-NeRF: Bundle Adjusted Deblur Neural Radiance Fields","summary":"  Neural Radiance Fields (NeRF) have received considerable attention recently,\ndue to its impressive capability in photo-realistic 3D reconstruction and novel\nview synthesis, given a set of posed camera images. Earlier work usually\nassumes the input images are of good quality. However, image degradation (e.g.\nimage motion blur in low-light conditions) can easily happen in real-world\nscenarios, which would further affect the rendering quality of NeRF. In this\npaper, we present a novel bundle adjusted deblur Neural Radiance Fields\n(BAD-NeRF), which can be robust to severe motion blurred images and inaccurate\ncamera poses. Our approach models the physical image formation process of a\nmotion blurred image, and jointly learns the parameters of NeRF and recovers\nthe camera motion trajectories during exposure time. In experiments, we show\nthat by directly modeling the real physical image formation process, BAD-NeRF\nachieves superior performance over prior works on both synthetic and real\ndatasets. Code and data are available at https://github.com/WU-CVGL/BAD-NeRF.\n","authors":["Peng Wang","Lingzhe Zhao","Ruijie Ma","Peidong Liu"],"pdf_url":"https://arxiv.org/pdf/2211.12853v2.pdf","comment":"Accepted to CVPR 2023, Project page:\n  https://wangpeng000.github.io/BAD-NeRF/"},{"id":"http://arxiv.org/abs/2203.01587v2","updated":"2023-06-26T13:13:08Z","published":"2022-03-03T09:30:55Z","title":"Multi-Tailed Vision Transformer for Efficient Inference","summary":"  Recently, Vision Transformer (ViT) has achieved promising performance in\nimage recognition and gradually serves as a powerful backbone in various vision\ntasks. To satisfy the sequential input of Transformer, the tail of ViT first\nsplits each image into a sequence of visual tokens with a fixed length. Then\nthe following self-attention layers constructs the global relationship between\ntokens to produce useful representation for the downstream tasks. Empirically,\nrepresenting the image with more tokens leads to better performance, yet the\nquadratic computational complexity of self-attention layer to the number of\ntokens could seriously influence the efficiency of ViT's inference. For\ncomputational reduction, a few pruning methods progressively prune\nuninformative tokens in the Transformer encoder, while leaving the number of\ntokens before the Transformer untouched. In fact, fewer tokens as the input for\nthe Transformer encoder can directly reduce the following computational cost.\nIn this spirit, we propose a Multi-Tailed Vision Transformer (MT-ViT) in the\npaper. MT-ViT adopts multiple tails to produce visual sequences of different\nlengths for the following Transformer encoder. A tail predictor is introduced\nto decide which tail is the most efficient for the image to produce accurate\nprediction. Both modules are optimized in an end-to-end fashion, with the\nGumbel-Softmax trick. Experiments on ImageNet-1K demonstrate that MT-ViT can\nachieve a significant reduction on FLOPs with no degradation of the accuracy\nand outperform other compared methods in both accuracy and FLOPs.\n","authors":["Yunke Wang","Bo Du","Wenyuan Wang","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2203.01587v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13585v2","updated":"2023-06-26T13:04:21Z","published":"2023-06-23T16:13:43Z","title":"A Semi-Paired Approach For Label-to-Image Translation","summary":"  Data efficiency, or the ability to generalize from a few labeled data,\nremains a major challenge in deep learning. Semi-supervised learning has\nthrived in traditional recognition tasks alleviating the need for large amounts\nof labeled data, yet it remains understudied in image-to-image translation\n(I2I) tasks. In this work, we introduce the first semi-supervised (semi-paired)\nframework for label-to-image translation, a challenging subtask of I2I which\ngenerates photorealistic images from semantic label maps. In the semi-paired\nsetting, the model has access to a small set of paired data and a larger set of\nunpaired images and labels. Instead of using geometrical transformations as a\npretext task like previous works, we leverage an input reconstruction task by\nexploiting the conditional discriminator on the paired data as a reverse\ngenerator. We propose a training algorithm for this shared network, and we\npresent a rare classes sampling algorithm to focus on under-represented\nclasses. Experiments on 3 standard benchmarks show that the proposed model\noutperforms state-of-the-art unsupervised and semi-supervised approaches, as\nwell as some fully supervised approaches while using a much smaller number of\npaired samples.\n","authors":["George Eskandar","Shuai Zhang","Mohamed Abdelsamad","Mark Youssef","Diandian Guo","Bin Yang"],"pdf_url":"https://arxiv.org/pdf/2306.13585v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14662v1","updated":"2023-06-26T12:54:28Z","published":"2023-06-26T12:54:28Z","title":"Cross Architecture Distillation for Face Recognition","summary":"  Transformers have emerged as the superior choice for face recognition tasks,\nbut their insufficient platform acceleration hinders their application on\nmobile devices. In contrast, Convolutional Neural Networks (CNNs) capitalize on\nhardware-compatible acceleration libraries. Consequently, it has become\nindispensable to preserve the distillation efficacy when transferring knowledge\nfrom a Transformer-based teacher model to a CNN-based student model, known as\nCross-Architecture Knowledge Distillation (CAKD). Despite its potential, the\ndeployment of CAKD in face recognition encounters two challenges: 1) the\nteacher and student share disparate spatial information for each pixel,\nobstructing the alignment of feature space, and 2) the teacher network is not\ntrained in the role of a teacher, lacking proficiency in handling\ndistillation-specific knowledge. To surmount these two constraints, 1) we first\nintroduce a Unified Receptive Fields Mapping module (URFM) that maps pixel\nfeatures of the teacher and student into local features with unified receptive\nfields, thereby synchronizing the pixel-wise spatial information of teacher and\nstudent. Subsequently, 2) we develop an Adaptable Prompting Teacher network\n(APT) that integrates prompts into the teacher, enabling it to manage\ndistillation-specific knowledge while preserving the model's discriminative\ncapacity. Extensive experiments on popular face benchmarks and two large-scale\nverification sets demonstrate the superiority of our method.\n","authors":["Weisong Zhao","Xiangyu Zhu","Zhixiang He","Xiao-Yu Zhang","Zhen Lei"],"pdf_url":"https://arxiv.org/pdf/2306.14662v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14658v1","updated":"2023-06-26T12:51:32Z","published":"2023-06-26T12:51:32Z","title":"Beyond AUROC & co. for evaluating out-of-distribution detection\n  performance","summary":"  While there has been a growing research interest in developing\nout-of-distribution (OOD) detection methods, there has been comparably little\ndiscussion around how these methods should be evaluated. Given their relevance\nfor safe(r) AI, it is important to examine whether the basis for comparing OOD\ndetection methods is consistent with practical needs. In this work, we take a\ncloser look at the go-to metrics for evaluating OOD detection, and question the\napproach of exclusively reducing OOD detection to a binary classification task\nwith little consideration for the detection threshold. We illustrate the\nlimitations of current metrics (AUROC & its friends) and propose a new metric -\nArea Under the Threshold Curve (AUTC), which explicitly penalizes poor\nseparation between ID and OOD samples. Scripts and data are available at\nhttps://github.com/glhr/beyond-auroc\n","authors":["Galadrielle Humblot-Renaux","Sergio Escalera","Thomas B. Moeslund"],"pdf_url":"https://arxiv.org/pdf/2306.14658v1.pdf","comment":"published in SAIAD CVPRW'23 (Safe Artificial Intelligence for All\n  Domains CVPR workshop)"},{"id":"http://arxiv.org/abs/2306.02851v3","updated":"2023-06-26T12:42:31Z","published":"2023-06-05T13:01:38Z","title":"Scene as Occupancy","summary":"  Human driver can easily describe the complex traffic scene by visual system.\nSuch an ability of precise perception is essential for driver's planning. To\nachieve this, a geometry-aware representation that quantizes the physical 3D\nscene into structured grid map with semantic labels per cell, termed as 3D\nOccupancy, would be desirable. Compared to the form of bounding box, a key\ninsight behind occupancy is that it could capture the fine-grained details of\ncritical obstacles in the scene, and thereby facilitate subsequent tasks. Prior\nor concurrent literature mainly concentrate on a single scene completion task,\nwhere we might argue that the potential of this occupancy representation might\nobsess broader impact. In this paper, we propose OccNet, a multi-view\nvision-centric pipeline with a cascade and temporal voxel decoder to\nreconstruct 3D occupancy. At the core of OccNet is a general occupancy\nembedding to represent 3D physical world. Such a descriptor could be applied\ntowards a wide span of driving tasks, including detection, segmentation and\nplanning. To validate the effectiveness of this new representation and our\nproposed algorithm, we propose OpenOcc, the first dense high-quality 3D\noccupancy benchmark built on top of nuScenes. Empirical experiments show that\nthere are evident performance gain across multiple tasks, e.g., motion planning\ncould witness a collision rate reduction by 15%-58%, demonstrating the\nsuperiority of our method.\n","authors":["Chonghao Sima","Wenwen Tong","Tai Wang","Li Chen","Silei Wu","Hanming Deng","Yi Gu","Lewei Lu","Ping Luo","Dahua Lin","Hongyang Li"],"pdf_url":"https://arxiv.org/pdf/2306.02851v3.pdf","comment":"Project link: https://github.com/OpenDriveLab/OccNet"},{"id":"http://arxiv.org/abs/2306.14650v1","updated":"2023-06-26T12:40:12Z","published":"2023-06-26T12:40:12Z","title":"PhD Thesis: Exploring the role of (self-)attention in cognitive and\n  computer vision architecture","summary":"  We investigate the role of attention and memory in complex reasoning tasks.\nWe analyze Transformer-based self-attention as a model and extend it with\nmemory. By studying a synthetic visual reasoning test, we refine the taxonomy\nof reasoning tasks. Incorporating self-attention with ResNet50, we enhance\nfeature maps using feature-based and spatial attention, achieving efficient\nsolving of challenging visual reasoning tasks. Our findings contribute to\nunderstanding the attentional needs of SVRT tasks. Additionally, we propose\nGAMR, a cognitive architecture combining attention and memory, inspired by\nactive vision theory. GAMR outperforms other architectures in sample\nefficiency, robustness, and compositionality, and shows zero-shot\ngeneralization on new reasoning tasks.\n","authors":["Mohit Vaishnav"],"pdf_url":"https://arxiv.org/pdf/2306.14650v1.pdf","comment":"PhD Thesis, 152 pages, 32 figures, 6 tables"},{"id":"http://arxiv.org/abs/2306.14646v1","updated":"2023-06-26T12:31:08Z","published":"2023-06-26T12:31:08Z","title":"Multi-View Attention Learning for Residual Disease Prediction of Ovarian\n  Cancer","summary":"  In the treatment of ovarian cancer, precise residual disease prediction is\nsignificant for clinical and surgical decision-making. However, traditional\nmethods are either invasive (e.g., laparoscopy) or time-consuming (e.g., manual\nanalysis). Recently, deep learning methods make many efforts in automatic\nanalysis of medical images. Despite the remarkable progress, most of them\nunderestimated the importance of 3D image information of disease, which might\nbrings a limited performance for residual disease prediction, especially in\nsmall-scale datasets. To this end, in this paper, we propose a novel Multi-View\nAttention Learning (MuVAL) method for residual disease prediction, which\nfocuses on the comprehensive learning of 3D Computed Tomography (CT) images in\na multi-view manner. Specifically, we first obtain multi-view of 3D CT images\nfrom transverse, coronal and sagittal views. To better represent the image\nfeatures in a multi-view manner, we further leverage attention mechanism to\nhelp find the more relevant slices in each view. Extensive experiments on a\ndataset of 111 patients show that our method outperforms existing deep-learning\nmethods.\n","authors":["Xiangneng Gao","Shulan Ruan","Jun Shi","Guoqing Hu","Wei Wei"],"pdf_url":"https://arxiv.org/pdf/2306.14646v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14644v1","updated":"2023-06-26T12:30:20Z","published":"2023-06-26T12:30:20Z","title":"PTVD: A Large-Scale Plot-Oriented Multimodal Dataset Based on Television\n  Dramas","summary":"  Art forms such as movies and television (TV) dramas are reflections of the\nreal world, which have attracted much attention from the multimodal learning\ncommunity recently. However, existing corpora in this domain share three\nlimitations: (1) annotated in a scene-oriented fashion, they ignore the\ncoherence within plots; (2) their text lacks empathy and seldom mentions\nsituational context; (3) their video clips fail to cover long-form relationship\ndue to short duration. To address these fundamental issues, using 1,106 TV\ndrama episodes and 24,875 informative plot-focused sentences written by\nprofessionals, with the help of 449 human annotators, we constructed PTVD, the\nfirst plot-oriented multimodal dataset in the TV domain. It is also the first\nnon-English dataset of its kind. Additionally, PTVD contains more than 26\nmillion bullet screen comments (BSCs), powering large-scale pre-training. Next,\naiming to open-source a strong baseline for follow-up works, we developed the\nmultimodal algorithm that attacks different cinema/TV modelling problems with a\nunified architecture. Extensive experiments on three cognitive-inspired tasks\nyielded a number of novel observations (some of them being quite\ncounter-intuition), further validating the value of PTVD in promoting\nmultimodal research. The dataset and codes are released at\n\\url{https://ptvd.github.io/}.\n","authors":["Chen Li","Xutan Peng","Teng Wang","Yixiao Ge","Mengyang Liu","Xuyuan Xu","Yexin Wang","Ying Shan"],"pdf_url":"https://arxiv.org/pdf/2306.14644v1.pdf","comment":"19 pages, 10 figures"},{"id":"http://arxiv.org/abs/2306.14640v1","updated":"2023-06-26T12:27:59Z","published":"2023-06-26T12:27:59Z","title":"3D-Aware Adversarial Makeup Generation for Facial Privacy Protection","summary":"  The privacy and security of face data on social media are facing\nunprecedented challenges as it is vulnerable to unauthorized access and\nidentification. A common practice for solving this problem is to modify the\noriginal data so that it could be protected from being recognized by malicious\nface recognition (FR) systems. However, such ``adversarial examples'' obtained\nby existing methods usually suffer from low transferability and poor image\nquality, which severely limits the application of these methods in real-world\nscenarios. In this paper, we propose a 3D-Aware Adversarial Makeup Generation\nGAN (3DAM-GAN). which aims to improve the quality and transferability of\nsynthetic makeup for identity information concealing. Specifically, a UV-based\ngenerator consisting of a novel Makeup Adjustment Module (MAM) and Makeup\nTransfer Module (MTM) is designed to render realistic and robust makeup with\nthe aid of symmetric characteristics of human faces. Moreover, a makeup attack\nmechanism with an ensemble training strategy is proposed to boost the\ntransferability of black-box models. Extensive experiment results on several\nbenchmark datasets demonstrate that 3DAM-GAN could effectively protect faces\nagainst various FR models, including both publicly available state-of-the-art\nmodels and commercial face verification APIs, such as Face++, Baidu and Aliyun.\n","authors":["Yueming Lyu","Yue Jiang","Ziwen He","Bo Peng","Yunfan Liu","Jing Dong"],"pdf_url":"https://arxiv.org/pdf/2306.14640v1.pdf","comment":"Accepted by TPAMI 2023"},{"id":"http://arxiv.org/abs/2306.13518v2","updated":"2023-06-26T12:24:26Z","published":"2023-06-23T14:35:17Z","title":"Segmentation and Tracking of Vegetable Plants by Exploiting Vegetable\n  Shape Feature for Precision Spray of Agricultural Robots","summary":"  With the increasing deployment of agricultural robots, the traditional manual\nspray of liquid fertilizer and pesticide is gradually being replaced by\nagricultural robots. For robotic precision spray application in vegetable\nfarms, accurate plant phenotyping through instance segmentation and robust\nplant tracking are of great importance and a prerequisite for the following\nspray action. Regarding the robust tracking of vegetable plants, to solve the\nchallenging problem of associating vegetables with similar color and texture in\nconsecutive images, in this paper, a novel method of Multiple Object Tracking\nand Segmentation (MOTS) is proposed for instance segmentation and tracking of\nmultiple vegetable plants. In our approach, contour and blob features are\nextracted to describe unique feature of each individual vegetable, and\nassociate the same vegetables in different images. By assigning a unique ID for\neach vegetable, it ensures the robot to spray each vegetable exactly once,\nwhile traversing along the farm rows. Comprehensive experiments including\nablation studies are conducted, which prove its superior performance over two\nState-Of-The-Art (SOTA) MOTS methods. Compared to the conventional MOTS\nmethods, the proposed method is able to re-identify objects which have gone out\nof the camera field of view and re-appear again using the proposed data\nassociation strategy, which is important to ensure each vegetable be sprayed\nonly once when the robot travels back and forth. Although the method is tested\non lettuce farm, it can be applied to other similar vegetables such as broccoli\nand canola. Both code and the dataset of this paper is publicly released for\nthe benefit of the community: https://github.com/NanH5837/LettuceMOTS.\n","authors":["Nan Hu","Daobilige Su","Shuo Wang","Xuechang Wang","Huiyu Zhong","Zimeng Wang","Yongliang Qiao","Yu Tan"],"pdf_url":"https://arxiv.org/pdf/2306.13518v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14638v1","updated":"2023-06-26T12:18:20Z","published":"2023-06-26T12:18:20Z","title":"FeSViBS: Federated Split Learning of Vision Transformer with Block\n  Sampling","summary":"  Data scarcity is a significant obstacle hindering the learning of powerful\nmachine learning models in critical healthcare applications. Data-sharing\nmechanisms among multiple entities (e.g., hospitals) can accelerate model\ntraining and yield more accurate predictions. Recently, approaches such as\nFederated Learning (FL) and Split Learning (SL) have facilitated collaboration\nwithout the need to exchange private data. In this work, we propose a framework\nfor medical imaging classification tasks called Federated Split learning of\nVision transformer with Block Sampling (FeSViBS). The FeSViBS framework builds\nupon the existing federated split vision transformer and introduces a block\nsampling module, which leverages intermediate features extracted by the Vision\nTransformer (ViT) at the server. This is achieved by sampling features (patch\ntokens) from an intermediate transformer block and distilling their information\ncontent into a pseudo class token before passing them back to the client. These\npseudo class tokens serve as an effective feature augmentation strategy and\nenhances the generalizability of the learned model. We demonstrate the utility\nof our proposed method compared to other SL and FL approaches on three publicly\navailable medical imaging datasets: HAM1000, BloodMNIST, and Fed-ISIC2019,\nunder both IID and non-IID settings. Code:\nhttps://github.com/faresmalik/FeSViBS\n","authors":["Faris Almalik","Naif Alkhunaizi","Ibrahim Almakky","Karthik Nandakumar"],"pdf_url":"https://arxiv.org/pdf/2306.14638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.02885v3","updated":"2023-06-26T12:17:11Z","published":"2022-10-05T12:13:04Z","title":"RankMe: Assessing the downstream performance of pretrained\n  self-supervised representations by their rank","summary":"  Joint-Embedding Self Supervised Learning (JE-SSL) has seen a rapid\ndevelopment, with the emergence of many method variations but only few\nprincipled guidelines that would help practitioners to successfully deploy\nthem. The main reason for that pitfall comes from JE-SSL's core principle of\nnot employing any input reconstruction therefore lacking visual cues of\nunsuccessful training. Adding non informative loss values to that, it becomes\ndifficult to deploy SSL on a new dataset for which no labels can help to judge\nthe quality of the learned representation. In this study, we develop a simple\nunsupervised criterion that is indicative of the quality of the learned JE-SSL\nrepresentations: their effective rank. Albeit simple and computationally\nfriendly, this method -- coined RankMe -- allows one to assess the performance\nof JE-SSL representations, even on different downstream datasets, without\nrequiring any labels. A further benefit of RankMe is that it does not have any\ntraining or hyper-parameters to tune. Through thorough empirical experiments\ninvolving hundreds of training episodes, we demonstrate how RankMe can be used\nfor hyperparameter selection with nearly no reduction in final performance\ncompared to the current selection method that involve a dataset's labels. We\nhope that RankMe will facilitate the deployment of JE-SSL towards domains that\ndo not have the opportunity to rely on labels for representations' quality\nassessment.\n","authors":["Quentin Garrido","Randall Balestriero","Laurent Najman","Yann Lecun"],"pdf_url":"https://arxiv.org/pdf/2210.02885v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14636v1","updated":"2023-06-26T12:15:06Z","published":"2023-06-26T12:15:06Z","title":"Localized Text-to-Image Generation for Free via Cross Attention Control","summary":"  Despite the tremendous success in text-to-image generative models, localized\ntext-to-image generation (that is, generating objects or features at specific\nlocations in an image while maintaining a consistent overall generation) still\nrequires either explicit training or substantial additional inference time. In\nthis work, we show that localized generation can be achieved by simply\ncontrolling cross attention maps during inference. With no additional training,\nmodel architecture modification or inference time, our proposed cross attention\ncontrol (CAC) provides new open-vocabulary localization abilities to standard\ntext-to-image models. CAC also enhances models that are already trained for\nlocalized generation when deployed at inference time. Furthermore, to assess\nlocalized text-to-image generation performance automatically, we develop a\nstandardized suite of evaluations using large pretrained recognition models.\nOur experiments show that CAC improves localized generation performance with\nvarious types of location information ranging from bounding boxes to semantic\nsegmentation maps, and enhances the compositional capability of\nstate-of-the-art text-to-image generative models.\n","authors":["Yutong He","Ruslan Salakhutdinov","J. Zico Kolter"],"pdf_url":"https://arxiv.org/pdf/2306.14636v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14628v1","updated":"2023-06-26T12:06:20Z","published":"2023-06-26T12:06:20Z","title":"An Integral Projection-based Semantic Autoencoder for Zero-Shot Learning","summary":"  Zero-shot Learning (ZSL) classification categorizes or predicts classes\n(labels) that are not included in the training set (unseen classes). Recent\nworks proposed different semantic autoencoder (SAE) models where the encoder\nembeds a visual feature vector space into the semantic space and the decoder\nreconstructs the original visual feature space. The objective is to learn the\nembedding by leveraging a source data distribution, which can be applied\neffectively to a different but related target data distribution. Such\nembedding-based methods are prone to domain shift problems and are vulnerable\nto biases. We propose an integral projection-based semantic autoencoder\n(IP-SAE) where an encoder projects a visual feature space concatenated with the\nsemantic space into a latent representation space. We force the decoder to\nreconstruct the visual-semantic data space. Due to this constraint, the\nvisual-semantic projection function preserves the discriminatory data included\ninside the original visual feature space. The enriched projection forces a more\nprecise reconstitution of the visual feature space invariant to the domain\nmanifold. Consequently, the learned projection function is less domain-specific\nand alleviates the domain shift problem. Our proposed IP-SAE model consolidates\na symmetric transformation function for embedding and projection, and thus, it\nprovides transparency for interpreting generative applications in ZSL.\nTherefore, in addition to outperforming state-of-the-art methods considering\nfour benchmark datasets, our analytical approach allows us to investigate\ndistinct characteristics of generative-based methods in the unique context of\nzero-shot inference.\n","authors":["William Heyden","Habib Ullah","M. Salman Siddiqui","Fadi Al Machot"],"pdf_url":"https://arxiv.org/pdf/2306.14628v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.02574v3","updated":"2023-06-26T12:01:56Z","published":"2022-06-03T08:04:12Z","title":"On the duality between contrastive and non-contrastive self-supervised\n  learning","summary":"  Recent approaches in self-supervised learning of image representations can be\ncategorized into different families of methods and, in particular, can be\ndivided into contrastive and non-contrastive approaches. While differences\nbetween the two families have been thoroughly discussed to motivate new\napproaches, we focus more on the theoretical similarities between them. By\ndesigning contrastive and covariance based non-contrastive criteria that can be\nrelated algebraically and shown to be equivalent under limited assumptions, we\nshow how close those families can be. We further study popular methods and\nintroduce variations of them, allowing us to relate this theoretical result to\ncurrent practices and show the influence (or lack thereof) of design choices on\ndownstream performance. Motivated by our equivalence result, we investigate the\nlow performance of SimCLR and show how it can match VICReg's with careful\nhyperparameter tuning, improving significantly over known baselines. We also\nchallenge the popular assumption that non-contrastive methods need large output\ndimensions. Our theoretical and quantitative results suggest that the numerical\ngaps between contrastive and non-contrastive methods in certain regimes can be\nclosed given better network design choices and hyperparameter tuning. The\nevidence shows that unifying different SOTA methods is an important direction\nto build a better understanding of self-supervised learning.\n","authors":["Quentin Garrido","Yubei Chen","Adrien Bardes","Laurent Najman","Yann Lecun"],"pdf_url":"https://arxiv.org/pdf/2206.02574v3.pdf","comment":"The Eleventh International Conference on Learning Representations,\n  2023, Kigali, Rwanda"},{"id":"http://arxiv.org/abs/2306.14620v1","updated":"2023-06-26T11:52:22Z","published":"2023-06-26T11:52:22Z","title":"Video object detection for privacy-preserving patient monitoring in\n  intensive care","summary":"  Patient monitoring in intensive care units, although assisted by biosensors,\nneeds continuous supervision of staff. To reduce the burden on staff members,\nIT infrastructures are built to record monitoring data and develop clinical\ndecision support systems. These systems, however, are vulnerable to artifacts\n(e.g. muscle movement due to ongoing treatment), which are often\nindistinguishable from real and potentially dangerous signals. Video recordings\ncould facilitate the reliable classification of biosignals using object\ndetection (OD) methods to find sources of unwanted artifacts. Due to privacy\nrestrictions, only blurred videos can be stored, which severely impairs the\npossibility to detect clinically relevant events such as interventions or\nchanges in patient status with standard OD methods. Hence, new kinds of\napproaches are necessary that exploit every kind of available information due\nto the reduced information content of blurred footage and that are at the same\ntime easily implementable within the IT infrastructure of a normal hospital. In\nthis paper, we propose a new method for exploiting information in the temporal\nsuccession of video frames. To be efficiently implementable using off-the-shelf\nobject detectors that comply with given hardware constraints, we repurpose the\nimage color channels to account for temporal consistency, leading to an\nimproved detection rate of the object classes. Our method outperforms a\nstandard YOLOv5 baseline model by +1.7% mAP@.5 while also training over ten\ntimes faster on our proprietary dataset. We conclude that this approach has\nshown effectiveness in the preliminary experiments and holds potential for more\ngeneral video OD in the future.\n","authors":["Raphael Emberger","Jens Michael Boss","Daniel Baumann","Marko Seric","Shufan Huo","Lukas Tuggener","Emanuela Keller","Thilo Stadelmann"],"pdf_url":"https://arxiv.org/pdf/2306.14620v1.pdf","comment":"4 pages, 3 figures, 2023 10th Swiss Conference on Data Science (SDS),\n  code available at https://github.com/raember/yolov5r_autodidact and\n  https://github.com/raember/VideoProc"},{"id":"http://arxiv.org/abs/2306.14610v1","updated":"2023-06-26T11:35:22Z","published":"2023-06-26T11:35:22Z","title":"SugarCrepe: Fixing Hackable Benchmarks for Vision-Language\n  Compositionality","summary":"  In the last year alone, a surge of new benchmarks to measure compositional\nunderstanding of vision-language models have permeated the machine learning\necosystem. Given an image, these benchmarks probe a model's ability to identify\nits associated caption amongst a set of compositional distractors.\nSurprisingly, we find significant biases in all these benchmarks rendering them\nhackable. This hackability is so dire that blind models with no access to the\nimage outperform state-of-the-art vision-language models. To remedy this\nrampant vulnerability, we introduce SugarCrepe, a new benchmark for\nvision-language compositionality evaluation. We employ large language models,\ninstead of rule-based templates used in previous benchmarks, to generate fluent\nand sensical hard negatives, and utilize an adversarial refinement mechanism to\nmaximally reduce biases. We re-evaluate state-of-the-art models and recently\nproposed compositionality inducing strategies, and find that their improvements\nwere hugely overestimated, suggesting that more innovation is needed in this\nimportant direction. We release SugarCrepe and the code for evaluation at:\nhttps://github.com/RAIVNLab/sugar-crepe.\n","authors":["Cheng-Yu Hsieh","Jieyu Zhang","Zixian Ma","Aniruddha Kembhavi","Ranjay Krishna"],"pdf_url":"https://arxiv.org/pdf/2306.14610v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14609v1","updated":"2023-06-26T11:32:40Z","published":"2023-06-26T11:32:40Z","title":"The race to robustness: exploiting fragile models for urban camouflage\n  and the imperative for machine learning security","summary":"  Adversarial Machine Learning (AML) represents the ability to disrupt Machine\nLearning (ML) algorithms through a range of methods that broadly exploit the\narchitecture of deep learning optimisation. This paper presents Distributed\nAdversarial Regions (DAR), a novel method that implements distributed\ninstantiations of computer vision-based AML attack methods that may be used to\ndisguise objects from image recognition in both white and black box settings.\nWe consider the context of object detection models used in urban environments,\nand benchmark the MobileNetV2, NasNetMobile and DenseNet169 models against a\nsubset of relevant images from the ImageNet dataset. We evaluate optimal\nparameters (size, number and perturbation method), and compare to\nstate-of-the-art AML techniques that perturb the entire image. We find that\nDARs can cause a reduction in confidence of 40.4% on average, but with the\nbenefit of not requiring the entire image, or the focal object, to be\nperturbed. The DAR method is a deliberately simple approach where the intention\nis to highlight how an adversary with very little skill could attack models\nthat may already be productionised, and to emphasise the fragility of\nfoundational object detection models. We present this as a contribution to the\nfield of ML security as well as AML. This paper contributes a novel adversarial\nmethod, an original comparison between DARs and other AML methods, and frames\nit in a new context - that of urban camouflage and the necessity for ML\nsecurity and model robustness.\n","authors":["Harriet Farlow","Matthew Garratt","Gavin Mount","Tim Lynar"],"pdf_url":"https://arxiv.org/pdf/2306.14609v1.pdf","comment":"Accepted to IEEE TENSYMP 2023"},{"id":"http://arxiv.org/abs/2306.14603v1","updated":"2023-06-26T11:27:55Z","published":"2023-06-26T11:27:55Z","title":"Learning with Difference Attention for Visually Grounded Self-supervised\n  Representations","summary":"  Recent works in self-supervised learning have shown impressive results on\nsingle-object images, but they struggle to perform well on complex multi-object\nimages as evidenced by their poor visual grounding. To demonstrate this\nconcretely, we propose visual difference attention (VDA) to compute visual\nattention maps in an unsupervised fashion by comparing an image with its\nsalient-regions-masked-out version. We use VDA to derive attention maps for\nstate-of-the art SSL methods and show they do not highlight all salient regions\nin an image accurately, suggesting their inability to learn strong\nrepresentations for downstream tasks like segmentation. Motivated by these\nlimitations, we cast VDA as a differentiable operation and propose a new\nlearning objective, Differentiable Difference Attention (DiDA) loss, which\nleads to substantial improvements in an SSL model's visually grounding to an\nimage's salient regions.\n","authors":["Aishwarya Agarwal","Srikrishna Karanam","Balaji Vasan Srinivasan"],"pdf_url":"https://arxiv.org/pdf/2306.14603v1.pdf","comment":"15 pages, 14 figures"},{"id":"http://arxiv.org/abs/2306.14601v1","updated":"2023-06-26T11:24:03Z","published":"2023-06-26T11:24:03Z","title":"Safe Navigation in Unstructured Environments by Minimizing Uncertainty\n  in Control and Perception","summary":"  Uncertainty in control and perception poses challenges for autonomous vehicle\nnavigation in unstructured environments, leading to navigation failures and\npotential vehicle damage. This paper introduces a framework that minimizes\ncontrol and perception uncertainty to ensure safe and reliable navigation. The\nframework consists of two uncertainty-aware models: a learning-based vehicle\ndynamics model and a self-supervised traversability estimation model. We train\na vehicle dynamics model that can quantify the epistemic uncertainty of the\nmodel to perform active exploration, resulting in the efficient collection of\ntraining data and effective avoidance of uncertain state-action spaces. In\naddition, we employ meta-learning to train a traversability cost prediction\nnetwork. The model can be trained with driving data from a variety of types of\nterrain, and it can online-adapt based on interaction experiences to reduce the\naleatoric uncertainty. Integrating the dynamics model and traversability cost\nprediction model with a sampling-based model predictive controller allows for\noptimizing trajectories that avoid uncertain terrains and state-action spaces.\nExperimental results demonstrate that the proposed method reduces uncertainty\nin prediction and improves stability in autonomous vehicle navigation in\nunstructured environments.\n","authors":["Junwon Seo","Jungwi Mun","Taekyung Kim"],"pdf_url":"https://arxiv.org/pdf/2306.14601v1.pdf","comment":"RSS 2023 Workshop on Inference and Decision Making for Autonomous\n  Vehicles (IDMAV)"},{"id":"http://arxiv.org/abs/2109.14525v4","updated":"2023-06-26T11:16:21Z","published":"2021-09-29T16:19:37Z","title":"DRAN: Detailed Region-Adaptive Normalization for Conditional Image\n  Synthesis","summary":"  In recent years, conditional image synthesis has attracted growing attention\ndue to its controllability in the image generation process. Although recent\nworks have achieved realistic results, most of them have difficulty handling\nfine-grained styles with subtle details. To address this problem, a novel\nnormalization module, named Detailed Region-Adaptive Normalization~(DRAN), is\nproposed. It adaptively learns both fine-grained and coarse-grained style\nrepresentations. Specifically, we first introduce a multi-level structure,\nSpatiality-aware Pyramid Pooling, to guide the model to learn coarse-to-fine\nfeatures. Then, to adaptively fuse different levels of styles, we propose\nDynamic Gating, making it possible to adaptively fuse different levels of\nstyles according to different spatial regions. Finally, we collect a new makeup\ndataset (Makeup-Complex dataset) that contains a wide range of complex makeup\nstyles with diverse poses and expressions. To evaluate the effectiveness and\nshow the general use of our method, we conduct a set of experiments on makeup\ntransfer and semantic image synthesis. Quantitative and qualitative experiments\nshow that equipped with DRAN, simple baseline models are able to achieve\npromising improvements in complex style transfer and detailed texture\nsynthesis. Both the code and the proposed dataset will be available at\nhttps://github.com/Yueming6568/DRAN-makeup.git.\n","authors":["Yueming Lyu","Peibin Chen","Jingna Sun","Bo Peng","Xu Wang","Jing Dong"],"pdf_url":"https://arxiv.org/pdf/2109.14525v4.pdf","comment":"Accepted by TMM 2023"},{"id":"http://arxiv.org/abs/2306.14596v1","updated":"2023-06-26T11:13:22Z","published":"2023-06-26T11:13:22Z","title":"Deep Learning for Cancer Prognosis Prediction Using Portrait Photos by\n  StyleGAN Embedding","summary":"  urvival prediction for cancer patients is critical for optimal treatment\nselection and patient management. Current patient survival prediction methods\ntypically extract survival information from patients' clinical record data or\nbiological and imaging data. In practice, experienced clinicians can have a\npreliminary assessment of patients' health status based on patients' observable\nphysical appearances, which are mainly facial features. However, such\nassessment is highly subjective. In this work, the efficacy of objectively\ncapturing and using prognostic information contained in conventional portrait\nphotographs using deep learning for survival predication purposes is\ninvestigated for the first time. A pre-trained StyleGAN2 model is fine-tuned on\na custom dataset of our cancer patients' photos to empower its generator with\ngenerative ability suitable for patients' photos. The StyleGAN2 is then used to\nembed the photographs to its highly expressive latent space. Utilizing the\nstate-of-the-art survival analysis models and based on StyleGAN's latent space\nphoto embeddings, this approach achieved a C-index of 0.677, which is notably\nhigher than chance and evidencing the prognostic value embedded in simple 2D\nfacial images. In addition, thanks to StyleGAN's interpretable latent space,\nour survival prediction model can be validated for relying on essential facial\nfeatures, eliminating any biases from extraneous information like clothing or\nbackground. Moreover, a health attribute is obtained from regression\ncoefficients, which has important potential value for patient care.\n","authors":["Amr Hagag","Ahmed Gomaa","Dominik Kornek","Andreas Maier","Rainer Fietkau","Christoph Bert","Florian Putz","Yixing Huang"],"pdf_url":"https://arxiv.org/pdf/2306.14596v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14590v1","updated":"2023-06-26T10:55:22Z","published":"2023-06-26T10:55:22Z","title":"CST-YOLO: A Novel Method for Blood Cell Detection Based on Improved\n  YOLOv7 and CNN-Swin Transformer","summary":"  Blood cell detection is a typical small-scale object detection problem in\ncomputer vision. In this paper, we propose a CST-YOLO model for blood cell\ndetection based on YOLOv7 architecture and enhance it with the CNN-Swin\nTransformer (CST), which is a new attempt at CNN-Transformer fusion. We also\nintroduce three other useful modules: Weighted Efficient Layer Aggregation\nNetworks (W-ELAN), Multiscale Channel Split (MCS), and Concatenate\nConvolutional Layers (CatConv) in our CST-YOLO to improve small-scale object\ndetection precision. Experimental results show that the proposed CST-YOLO\nachieves 92.7, 95.6, and 91.1 mAP@0.5 respectively on three blood cell\ndatasets, outperforming state-of-the-art object detectors, e.g., YOLOv5 and\nYOLOv7. Our code is available at https://github.com/mkang315/CST-YOLO.\n","authors":["Ming Kang","Chee-Ming Ting","Fung Fung Ting","Raphaël Phan"],"pdf_url":"https://arxiv.org/pdf/2306.14590v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14584v1","updated":"2023-06-26T10:51:18Z","published":"2023-06-26T10:51:18Z","title":"Methodology for generating synthetic labeled datasets for visual\n  container inspection","summary":"  Nowadays, containerized freight transport is one of the most important\ntransportation systems that is undergoing an automation process due to the Deep\nLearning success. However, it suffers from a lack of annotated data in order to\nincorporate state-of-the-art neural network models to its systems. In this\npaper we present an innovative methodology to generate a realistic, varied,\nbalanced, and labelled dataset for visual inspection task of containers in a\ndock environment. In addition, we validate this methodology with multiple\nvisual tasks recurrently found in the state of the art. We prove that the\ngenerated synthetic labelled dataset allows to train a deep neural network that\ncan be used in a real world scenario. On the other side, using this methodology\nwe provide the first open synthetic labelled dataset called SeaFront available\nin: https://datasets.vicomtech.org/di21-seafront/readme.txt.\n","authors":["Guillem Delgado","Andoni Cortés","Sara García","Estíbaliz Loyo","Maialen Berasategi","Nerea Aranjuelo"],"pdf_url":"https://arxiv.org/pdf/2306.14584v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.00050v2","updated":"2023-06-26T10:50:37Z","published":"2023-03-31T18:06:26Z","title":"kNN-Res: Residual Neural Network with kNN-Graph coherence for point\n  cloud registration","summary":"  In this paper, we present a residual neural network-based method for point\nset registration that preserves the topological structure of the target point\nset. Similar to coherent point drift (CPD), the registration (alignment)\nproblem is viewed as the movement of data points sampled from a target\ndistribution along a regularized displacement vector field. While the coherence\nconstraint in CPD is stated in terms of local motion coherence, the proposed\nregularization term relies on a global smoothness constraint as a proxy for\npreserving local topology. This makes CPD less flexible when the deformation is\nlocally rigid but globally non-rigid as in the case of multiple objects and\narticulate pose registration. A Jacobian-based cost function and\ngeometric-aware statistical distances are proposed to mitigate these issues.\nThe latter allows for measuring misalignment between the target and the\nreference. The justification for the k-Nearest Neighbour(kNN) graph\npreservation of target data, when the Jacobian cost is used, is also provided.\nFurther, to tackle the registration of high-dimensional point sets, a constant\ntime stochastic approximation of the Jacobian cost is introduced. The proposed\nmethod is illustrated on several 2-dimensional toy examples and tested on\nhigh-dimensional flow Cytometry datasets where the task is to align two\ndistributions of cells whilst preserving the kNN-graph in order to preserve the\nbiological signal of the transformed data. The implementation of the proposed\napproach is available at https://github.com/MuhammadSaeedBatikh/kNN-Res_Demo/\nunder the MIT license.\n","authors":["Muhammad S. Battikh","Dillon Hammill","Matthew Cook","Artem Lensky"],"pdf_url":"https://arxiv.org/pdf/2304.00050v2.pdf","comment":"27 pages, 13 figures"},{"id":"http://arxiv.org/abs/2306.14572v1","updated":"2023-06-26T10:33:45Z","published":"2023-06-26T10:33:45Z","title":"Feature Imitating Networks Enhance The Performance, Reliability And\n  Speed Of Deep Learning On Biomedical Image Processing Tasks","summary":"  Feature-Imitating-Networks (FINs) are neural networks with weights that are\ninitialized to approximate closed-form statistical features. In this work, we\nperform the first-ever evaluation of FINs for biomedical image processing\ntasks. We begin by training a set of FINs to imitate six common radiomics\nfeatures, and then compare the performance of networks with and without the\nFINs for three experimental tasks: COVID-19 detection from CT scans, brain\ntumor classification from MRI scans, and brain-tumor segmentation from MRI\nscans; we find that FINs provide best-in-class performance for all three tasks,\nwhile converging faster and more consistently when compared to networks with\nsimilar or greater representational power. The results of our experiments\nprovide evidence that FINs may provide state-of-the-art performance for a\nvariety of other biomedical image processing tasks.\n","authors":["Shangyang Min","Mohammad Mahdi Ghassemi","Tuka Alhanai"],"pdf_url":"https://arxiv.org/pdf/2306.14572v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14565v1","updated":"2023-06-26T10:26:33Z","published":"2023-06-26T10:26:33Z","title":"Aligning Large Multi-Modal Model with Robust Instruction Tuning","summary":"  Despite the promising progress in multi-modal tasks, current large\nmulti-modal models (LMM) are prone to hallucinating inconsistent descriptions\nwith respect to the associated image and human instructions. This paper\naddresses this issue by introducing the first large and diverse visual\ninstruction tuning dataset, named Large-scale Robust Visual (LRV)-Instruction.\nOur dataset consists of 120k visual instructions generated by GPT4, covering 16\nvision-and-language tasks with open-ended instructions and answers. Unlike\nexisting studies that primarily focus on positive instruction samples, we\ndesign LRV-Instruction to include both positive and negative instructions for\nmore robust visual instruction tuning. Our negative instructions are designed\nat two semantic levels: (i) Nonexistent Element Manipulation and (ii) Existent\nElement Manipulation. To efficiently measure the hallucination generated by\nLMMs, we propose GPT4-Assisted Visual Instruction Evaluation (GAVIE), a novel\napproach to evaluate visual instruction tuning without the need for\nhuman-annotated groundtruth answers and can adapt to diverse instruction\nformats. We conduct comprehensive experiments to investigate the hallucination\nof LMMs. Our results demonstrate that existing LMMs exhibit significant\nhallucination when presented with our negative instructions, particularly with\nExistent Element Manipulation instructions. Moreover, by finetuning MiniGPT4 on\nLRV-Instruction, we successfully mitigate hallucination while improving\nperformance on public datasets using less training data compared to\nstate-of-the-art methods. Additionally, we observed that a balanced ratio of\npositive and negative instances in the training data leads to a more robust\nmodel. Our project link is available at https://fuxiaoliu.github.io/LRV/.\n","authors":["Fuxiao Liu","Kevin Lin","Linjie Li","Jianfeng Wang","Yaser Yacoob","Lijuan Wang"],"pdf_url":"https://arxiv.org/pdf/2306.14565v1.pdf","comment":"35 pages, 27 figures. Under Review"},{"id":"http://arxiv.org/abs/2208.00632v2","updated":"2023-06-26T09:50:56Z","published":"2022-08-01T06:35:32Z","title":"Multi-spectral Vehicle Re-identification with Cross-directional\n  Consistency Network and a High-quality Benchmark","summary":"  To tackle the challenge of vehicle re-identification (Re-ID) in complex\nlighting environments and diverse scenes, multi-spectral sources like visible\nand infrared information are taken into consideration due to their excellent\ncomplementary advantages.\n  However, multi-spectral vehicle Re-ID suffers cross-modality discrepancy\ncaused by heterogeneous properties of different modalities as well as a big\nchallenge of the diverse appearance with different views in each identity.\n  Meanwhile, diverse environmental interference leads to heavy sample\ndistributional discrepancy in each modality.\n  In this work, we propose a novel cross-directional consistency network to\nsimultaneously overcome the discrepancies from both modality and sample\naspects.\n  In particular, we design a new cross-directional center loss to pull the\nmodality centers of each identity close to mitigate cross-modality discrepancy,\nwhile the sample centers of each identity close to alleviate the sample\ndiscrepancy. Such strategy can generate discriminative multi-spectral feature\nrepresentations for vehicle Re-ID.\n  In addition, we design an adaptive layer normalization unit to dynamically\nadjust individual feature distribution to handle distributional discrepancy of\nintra-modality features for robust learning.\n  To provide a comprehensive evaluation platform, we create a high-quality\nRGB-NIR-TIR multi-spectral vehicle Re-ID benchmark (MSVR310), including 310\ndifferent vehicles from a broad range of viewpoints, time spans and\nenvironmental complexities.\n  Comprehensive experiments on both created and public datasets demonstrate the\neffectiveness of the proposed approach comparing to the state-of-the-art\nmethods.\n","authors":["Aihua Zheng","Xianpeng Zhu","Zhiqi Ma","Chenglong Li","Jin Tang","Jixin Ma"],"pdf_url":"https://arxiv.org/pdf/2208.00632v2.pdf","comment":"Accepted by Information Fusion"},{"id":"http://arxiv.org/abs/2303.12145v3","updated":"2023-06-26T09:36:13Z","published":"2023-03-21T19:02:36Z","title":"Efficient Feature Distillation for Zero-shot Detection","summary":"  The large-scale vision-language models (e.g., CLIP) are leveraged by\ndifferent methods to detect unseen objects. However, most of these works\nrequire additional captions or images for training, which is not feasible in\nthe context of zero-shot detection. In contrast, the distillation-based method\nis an extra-data-free method, but it has its limitations. Specifically,\nexisting work creates distillation regions that are biased to the base\ncategories, which limits the distillation of novel category information and\nharms the distillation efficiency. Furthermore, directly using the raw feature\nfrom CLIP for distillation neglects the domain gap between the training data of\nCLIP and the detection datasets, which makes it difficult to learn the mapping\nfrom the image region to the vision-language feature space - an essential\ncomponent for detecting unseen objects. As a result, existing\ndistillation-based methods require an excessively long training schedule. To\nsolve these problems, we propose Efficient feature distillation for Zero-Shot\nDetection (EZSD). Firstly, EZSD adapts the CLIP's feature space to the target\ndetection domain by re-normalizing CLIP to bridge the domain gap; Secondly,\nEZSD uses CLIP to generate distillation proposals with potential novel\ninstances, to avoid the distillation being overly biased to the base\ncategories. Finally, EZSD takes advantage of semantic meaning for regression to\nfurther improve the model performance. As a result, EZSD achieves\nstate-of-the-art performance in the COCO zero-shot benchmark with a much\nshorter training schedule and outperforms previous work by 4% in LVIS overall\nsetting with 1/10 training time.\n","authors":["Zhuoming Liu","Xuefeng Hu","Ram Nevatia"],"pdf_url":"https://arxiv.org/pdf/2303.12145v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14544v1","updated":"2023-06-26T09:34:10Z","published":"2023-06-26T09:34:10Z","title":"A-STAR: Test-time Attention Segregation and Retention for Text-to-image\n  Synthesis","summary":"  While recent developments in text-to-image generative models have led to a\nsuite of high-performing methods capable of producing creative imagery from\nfree-form text, there are several limitations. By analyzing the cross-attention\nrepresentations of these models, we notice two key issues. First, for text\nprompts that contain multiple concepts, there is a significant amount of\npixel-space overlap (i.e., same spatial regions) among pairs of different\nconcepts. This eventually leads to the model being unable to distinguish\nbetween the two concepts and one of them being ignored in the final generation.\nNext, while these models attempt to capture all such concepts during the\nbeginning of denoising (e.g., first few steps) as evidenced by cross-attention\nmaps, this knowledge is not retained by the end of denoising (e.g., last few\nsteps). Such loss of knowledge eventually leads to inaccurate generation\noutputs. To address these issues, our key innovations include two test-time\nattention-based loss functions that substantially improve the performance of\npretrained baseline text-to-image diffusion models. First, our attention\nsegregation loss reduces the cross-attention overlap between attention maps of\ndifferent concepts in the text prompt, thereby reducing the confusion/conflict\namong various concepts and the eventual capture of all concepts in the\ngenerated output. Next, our attention retention loss explicitly forces\ntext-to-image diffusion models to retain cross-attention information for all\nconcepts across all denoising time steps, thereby leading to reduced\ninformation loss and the preservation of all concepts in the generated output.\n","authors":["Aishwarya Agarwal","Srikrishna Karanam","K J Joseph","Apoorv Saxena","Koustava Goswami","Balaji Vasan Srinivasan"],"pdf_url":"https://arxiv.org/pdf/2306.14544v1.pdf","comment":"15 pages, 16 figures"},{"id":"http://arxiv.org/abs/2306.14538v1","updated":"2023-06-26T09:21:13Z","published":"2023-06-26T09:21:13Z","title":"Learnable Differencing Center for Nighttime Depth Perception","summary":"  Depth completion is the task of recovering dense depth maps from sparse ones,\nusually with the help of color images. Existing image-guided methods perform\nwell on daytime depth perception self-driving benchmarks, but struggle in\nnighttime scenarios with poor visibility and complex illumination. To address\nthese challenges, we propose a simple yet effective framework called LDCNet.\nOur key idea is to use Recurrent Inter-Convolution Differencing (RICD) and\nIllumination-Affinitive Intra-Convolution Differencing (IAICD) to enhance the\nnighttime color images and reduce the negative effects of the varying\nillumination, respectively. RICD explicitly estimates global illumination by\ndifferencing two convolutions with different kernels, treating the\nsmall-kernel-convolution feature as the center of the large-kernel-convolution\nfeature in a new perspective. IAICD softly alleviates local relative light\nintensity by differencing a single convolution, where the center is dynamically\naggregated based on neighboring pixels and the estimated illumination map in\nRICD. On both nighttime depth completion and depth estimation tasks, extensive\nexperiments demonstrate the effectiveness of our LDCNet, reaching the state of\nthe art.\n","authors":["Zhiqiang Yan","Yupeng Zheng","Kun Wang","Xiang Li","Zhenyu Zhang","Shuo Chen","Jun Li","Jian Yang"],"pdf_url":"https://arxiv.org/pdf/2306.14538v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2306.14525v1","updated":"2023-06-26T09:01:35Z","published":"2023-06-26T09:01:35Z","title":"ParameterNet: Parameters Are All You Need for Large-scale Visual\n  Pretraining of Mobile Networks","summary":"  The large-scale visual pretraining has significantly improve the performance\nof large vision models. However, we observe the \\emph{low FLOPs pitfall} that\nthe existing low-FLOPs models cannot benefit from large-scale pretraining.\n  In this paper, we propose a general design principle of adding more\nparameters while maintaining low FLOPs for large-scale visual pretraining,\nnamed as ParameterNet. Dynamic convolutions are used for instance to equip the\nnetworks with more parameters and only slightly increase the FLOPs. The\nproposed ParameterNet scheme enables low-FLOPs networks to benefit from\nlarge-scale visual pretraining. Experiments on the large-scale ImageNet-22K\nhave shown the superiority of our ParameterNet scheme. For example,\nParameterNet-600M can achieve higher accuracy than the widely-used Swin\nTransformer (81.6\\% \\emph{vs.} 80.9\\%) and has much lower FLOPs (0.6G\n\\emph{vs.} 4.5G). The code will be released as soon (MindSpore:\nhttps://gitee.com/mindspore/models, PyTorch:\nhttps://github.com/huawei-noah/Efficient-AI-Backbones).\n","authors":["Kai Han","Yunhe Wang","Jianyuan Guo","Enhua Wu"],"pdf_url":"https://arxiv.org/pdf/2306.14525v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14518v1","updated":"2023-06-26T08:48:39Z","published":"2023-06-26T08:48:39Z","title":"Toward Fairness Through Fair Multi-Exit Framework for Dermatological\n  Disease Diagnosis","summary":"  Fairness has become increasingly pivotal in medical image recognition.\nHowever, without mitigating bias, deploying unfair medical AI systems could\nharm the interests of underprivileged populations. In this paper, we observe\nthat while features extracted from the deeper layers of neural networks\ngenerally offer higher accuracy, fairness conditions deteriorate as we extract\nfeatures from deeper layers. This phenomenon motivates us to extend the concept\nof multi-exit frameworks. Unlike existing works mainly focusing on accuracy,\nour multi-exit framework is fairness-oriented; the internal classifiers are\ntrained to be more accurate and fairer, with high extensibility to apply to\nmost existing fairness-aware frameworks. During inference, any instance with\nhigh confidence from an internal classifier is allowed to exit early.\nExperimental results show that the proposed framework can improve the fairness\ncondition over the state-of-the-art in two dermatological disease datasets.\n","authors":["Ching-Hao Chiu","Hao-Wei Chung","Yu-Jen Chen","Yiyu Shi","Tsung-Yi Ho"],"pdf_url":"https://arxiv.org/pdf/2306.14518v1.pdf","comment":"MICCAI2023"},{"id":"http://arxiv.org/abs/2306.14515v1","updated":"2023-06-26T08:46:00Z","published":"2023-06-26T08:46:00Z","title":"Optimizing Kernel-Target Alignment for cloud detection in multispectral\n  satellite images","summary":"  The optimization of Kernel-Target Alignment (TA) has been recently proposed\nas a way to reduce the number of hardware resources in quantum classifiers. It\nallows to exchange highly expressive and costly circuits to moderate size, task\noriented ones. In this work we propose a simple toy model to study the\noptimization landscape of the Kernel-Target Alignment. We find that for\nunderparameterized circuits the optimization landscape possess either many\nlocal extrema or becomes flat with narrow global extremum. We find the\ndependence of the width of the global extremum peak on the amount of data\nintroduced to the model. The experimental study was performed using\nmultispectral satellite data, and we targeted the cloud detection task, being\none of the most fundamental and important image analysis tasks in remote\nsensing.\n","authors":["Artur Miroszewski","Jakub Mielczarek","Filip Szczepanek","Grzegorz Czelusta","Bartosz Grabowski","Bertrand Le Saux","Jakub Nalepa"],"pdf_url":"https://arxiv.org/pdf/2306.14515v1.pdf","comment":"Prepared for IGARSS 2023 Proceedings, 4 pages, 4 figures"},{"id":"http://arxiv.org/abs/2211.00848v2","updated":"2023-06-26T08:27:52Z","published":"2022-11-02T03:34:35Z","title":"Heterogeneous Trajectory Forecasting via Risk and Scene Graph Learning","summary":"  Heterogeneous trajectory forecasting is critical for intelligent\ntransportation systems, but it is challenging because of the difficulty of\nmodeling the complex interaction relations among the heterogeneous road agents\nas well as their agent-environment constraints. In this work, we propose a risk\nand scene graph learning method for trajectory forecasting of heterogeneous\nroad agents, which consists of a Heterogeneous Risk Graph (HRG) and a\nHierarchical Scene Graph (HSG) from the aspects of agent category and their\nmovable semantic regions. HRG groups each kind of road agent and calculates\ntheir interaction adjacency matrix based on an effective collision risk metric.\nHSG of the driving scene is modeled by inferring the relationship between road\nagents and road semantic layout aligned by the road scene grammar. Based on\nthis formulation, we can obtain effective trajectory forecasting in driving\nsituations, and superior performance to other state-of-the-art approaches is\ndemonstrated by exhaustive experiments on the nuScenes, ApolloScape, and\nArgoverse datasets.\n","authors":["Jianwu Fang","Chen Zhu","Pu Zhang","Hongkai Yu","Jianru Xue"],"pdf_url":"https://arxiv.org/pdf/2211.00848v2.pdf","comment":"accepted by IEEE Transactions on Intelligent Transportation Systems,\n  2023"},{"id":"http://arxiv.org/abs/2306.14505v1","updated":"2023-06-26T08:24:37Z","published":"2023-06-26T08:24:37Z","title":"AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation\n  on MRI Brain Tumor","summary":"  Magnetic resonance imaging (MRI) is commonly used for brain tumor\nsegmentation, which is critical for patient evaluation and treatment planning.\nTo reduce the labor and expertise required for labeling, weakly-supervised\nsemantic segmentation (WSSS) methods with class activation mapping (CAM) have\nbeen proposed. However, existing CAM methods suffer from low resolution due to\nstrided convolution and pooling layers, resulting in inaccurate predictions. In\nthis study, we propose a novel CAM method, Attentive Multiple-Exit CAM\n(AME-CAM), that extracts activation maps from multiple resolutions to\nhierarchically aggregate and improve prediction accuracy. We evaluate our\nmethod on the BraTS 2021 dataset and show that it outperforms state-of-the-art\nmethods.\n","authors":["Yu-Jen Chen","Xinrong Hu","Yiyu Shi","Tsung-Yi Ho"],"pdf_url":"https://arxiv.org/pdf/2306.14505v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2306.05476"},{"id":"http://arxiv.org/abs/2306.05476v2","updated":"2023-06-26T08:16:59Z","published":"2023-06-08T18:01:08Z","title":"A Novel Confidence Induced Class Activation Mapping for MRI Brain Tumor\n  Segmentation","summary":"  Magnetic resonance imaging (MRI) is a commonly used technique for brain tumor\nsegmentation, which is critical for evaluating patients and planning treatment.\nTo make the labeling process less laborious and dependent on expertise,\nweakly-supervised semantic segmentation (WSSS) methods using class activation\nmapping (CAM) have been proposed. However, current CAM-based WSSS methods\ngenerate the object localization map using internal neural network information,\nsuch as gradient or trainable parameters, which can lead to suboptimal\nsolutions. To address these issues, we propose the confidence-induced CAM\n(Cfd-CAM), which calculates the weight of each feature map by using the\nconfidence of the target class. Our experiments on two brain tumor datasets\nshow that Cfd-CAM outperforms existing state-of-the-art methods under the same\nlevel of supervision. Overall, our proposed Cfd-CAM approach improves the\naccuracy of brain tumor segmentation and may provide valuable insights for\ndeveloping better WSSS methods for other medical imaging tasks.\n","authors":["Yu-Jen Chen","Yiyu Shi","Tsung-Yi Ho"],"pdf_url":"https://arxiv.org/pdf/2306.05476v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14492v1","updated":"2023-06-26T08:07:56Z","published":"2023-06-26T08:07:56Z","title":"A Badminton Recognition and Tracking System Based on Context\n  Multi-feature Fusion","summary":"  Ball recognition and tracking have traditionally been the main focus of\ncomputer vision researchers as a crucial component of sports video analysis.\nThe difficulties, such as the small ball size, blurry appearance, quick\nmovements, and so on, prevent many classic methods from performing well on ball\ndetection and tracking. In this paper, we present a method for detecting and\ntracking badminton balls. According to the characteristics of different ball\nspeeds, two trajectory clip trackers are designed based on different rules to\ncapture the correct trajectory of the ball. Meanwhile, combining contextual\ninformation, two rounds of detection from coarse-grained to fine-grained are\nused to solve the challenges encountered in badminton detection. The\nexperimental results show that the precision, recall, and F1-measure of our\nmethod, reach 100%, 72.6% and 84.1% with the data without occlusion,\nrespectively.\n","authors":["Xinyu Wang","Jianwei Li"],"pdf_url":"https://arxiv.org/pdf/2306.14492v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14490v1","updated":"2023-06-26T08:04:24Z","published":"2023-06-26T08:04:24Z","title":"TaiChi Action Capture and Performance Analysis with Multi-view RGB\n  Cameras","summary":"  Recent advances in computer vision and deep learning have influenced the\nfield of sports performance analysis for researchers to track and reconstruct\nfreely moving humans without any marker attachment. However, there are few\nworks for vision-based motion capture and intelligent analysis for professional\nTaiChi movement. In this paper, we propose a framework for TaiChi performance\ncapture and analysis with multi-view geometry and artificial intelligence\ntechnology. The main innovative work is as follows: 1) A multi-camera system\nsuitable for TaiChi motion capture is built and the multi-view TaiChi data is\ncollected and processed; 2) A combination of traditional visual method and\nimplicit neural radiance field is proposed to achieve sparse 3D skeleton fusion\nand dense 3D surface reconstruction. 3) The normalization modeling of movement\nsequences is carried out based on motion transfer, so as to realize TaiChi\nperformance analysis for different groups. We have carried out evaluation\nexperiments, and the experimental results have shown the efficiency of our\nmethod.\n","authors":["Jianwei Li","Siyu Mo","Yanfei Shen"],"pdf_url":"https://arxiv.org/pdf/2306.14490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14487v1","updated":"2023-06-26T07:57:03Z","published":"2023-06-26T07:57:03Z","title":"Iterative-in-Iterative Super-Resolution Biomedical Imaging Using One\n  Real Image","summary":"  Deep learning-based super-resolution models have the potential to\nrevolutionize biomedical imaging and diagnoses by effectively tackling various\nchallenges associated with early detection, personalized medicine, and clinical\nautomation. However, the requirement of an extensive collection of\nhigh-resolution images presents limitations for widespread adoption in clinical\npractice. In our experiment, we proposed an approach to effectively train the\ndeep learning-based super-resolution models using only one real image by\nleveraging self-generated high-resolution images. We employed a mixed metric of\nimage screening to automatically select images with a distribution similar to\nground truth, creating an incrementally curated training data set that\nencourages the model to generate improved images over time. After five training\niterations, the proposed deep learning-based super-resolution model experienced\na 7.5\\% and 5.49\\% improvement in structural similarity and\npeak-signal-to-noise ratio, respectively. Significantly, the model consistently\nproduces visually enhanced results for training, improving its performance\nwhile preserving the characteristics of original biomedical images. These\nfindings indicate a potential way to train a deep neural network in a\nself-revolution manner independent of real-world human data.\n","authors":["Yuanzheng Ma","Xinyue Wang","Benqi Zhao","Ying Xiao","Shijie Deng","Jian Song","Xun Guan"],"pdf_url":"https://arxiv.org/pdf/2306.14487v1.pdf","comment":"8 pages, SPIE conference, and will be submitted to APL journal"},{"id":"http://arxiv.org/abs/2306.14460v1","updated":"2023-06-26T07:03:56Z","published":"2023-06-26T07:03:56Z","title":"Hierarchical Matching and Reasoning for Multi-Query Image Retrieval","summary":"  As a promising field, Multi-Query Image Retrieval (MQIR) aims at searching\nfor the semantically relevant image given multiple region-specific text\nqueries. Existing works mainly focus on a single-level similarity between image\nregions and text queries, which neglects the hierarchical guidance of\nmulti-level similarities and results in incomplete alignments. Besides, the\nhigh-level semantic correlations that intrinsically connect different\nregion-query pairs are rarely considered. To address above limitations, we\npropose a novel Hierarchical Matching and Reasoning Network (HMRN) for MQIR. It\ndisentangles MQIR into three hierarchical semantic representations, which is\nresponsible to capture fine-grained local details, contextual global scopes,\nand high-level inherent correlations. HMRN comprises two modules: Scalar-based\nMatching (SM) module and Vector-based Reasoning (VR) module. Specifically, the\nSM module characterizes the multi-level alignment similarity, which consists of\na fine-grained local-level similarity and a context-aware global-level\nsimilarity. Afterwards, the VR module is developed to excavate the potential\nsemantic correlations among multiple region-query pairs, which further explores\nthe high-level reasoning similarity. Finally, these three-level similarities\nare aggregated into a joint similarity space to form the ultimate similarity.\nExtensive experiments on the benchmark dataset demonstrate that our HMRN\nsubstantially surpasses the current state-of-the-art methods. For instance,\ncompared with the existing best method Drill-down, the metric R@1 in the last\nround is improved by 23.4%. Our source codes will be released at\nhttps://github.com/LZH-053/HMRN.\n","authors":["Zhong Ji","Zhihao Li","Yan Zhang","Haoran Wang","Yanwei Pang","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2306.14460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14459v1","updated":"2023-06-26T07:02:07Z","published":"2023-06-26T07:02:07Z","title":"Histopathology Image Classification using Deep Manifold Contrastive\n  Learning","summary":"  Contrastive learning has gained popularity due to its robustness with good\nfeature representation performance. However, cosine distance, the commonly used\nsimilarity metric in contrastive learning, is not well suited to represent the\ndistance between two data points, especially on a nonlinear feature manifold.\nInspired by manifold learning, we propose a novel extension of contrastive\nlearning that leverages geodesic distance between features as a similarity\nmetric for histopathology whole slide image classification. To reduce the\ncomputational overhead in manifold learning, we propose geodesic-distance-based\nfeature clustering for efficient contrastive loss evaluation using prototypes\nwithout time-consuming pairwise feature similarity comparison. The efficacy of\nthe proposed method is evaluated on two real-world histopathology image\ndatasets. Results demonstrate that our method outperforms state-of-the-art\ncosine-distance-based contrastive learning methods.\n","authors":["Jing Wei Tan","Won-Ki Jeong"],"pdf_url":"https://arxiv.org/pdf/2306.14459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14451v1","updated":"2023-06-26T06:45:16Z","published":"2023-06-26T06:45:16Z","title":"Learning Prompt-Enhanced Context Features for Weakly-Supervised Video\n  Anomaly Detection","summary":"  Video anomaly detection under weak supervision is challenging due to the\nabsence of frame-level annotations during the training phase. Previous work has\nemployed graph convolution networks or self-attention mechanisms to model\ntemporal relations, along with multiple instance learning (MIL)-based\nclassification loss to learn discriminative features. However, most of them\nutilize multi-branches to capture local and global dependencies separately,\nleading to increased parameters and computational cost. Furthermore, the\nbinarized constraint of the MIL-based loss only ensures coarse-grained\ninterclass separability, ignoring fine-grained discriminability within\nanomalous classes. In this paper, we propose a weakly supervised anomaly\ndetection framework that emphasizes efficient context modeling and enhanced\nsemantic discriminability. To this end, we first construct a temporal context\naggregation (TCA) module that captures complete contextual information by\nreusing similarity matrix and adaptive fusion. Additionally, we propose a\nprompt-enhanced learning (PEL) module that incorporates semantic priors into\nthe model by utilizing knowledge-based prompts, aiming at enhancing the\ndiscriminative capacity of context features while ensuring separability between\nanomaly sub-classes. Furthermore, we introduce a score smoothing (SS) module in\nthe testing phase to suppress individual bias and reduce false alarms.\nExtensive experiments demonstrate the effectiveness of various components of\nour method, which achieves competitive performance with fewer parameters and\ncomputational effort on three challenging benchmarks: the UCF-crime,\nXD-violence, and ShanghaiTech datasets. The detection accuracy of some anomaly\nsub-classes is also improved with a great margin.\n","authors":["Yujiang Pu","Xiaoyu Wu","Shengjin Wang"],"pdf_url":"https://arxiv.org/pdf/2306.14451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14448v1","updated":"2023-06-26T06:34:53Z","published":"2023-06-26T06:34:53Z","title":"Progressive Energy-Based Cooperative Learning for Multi-Domain\n  Image-to-Image Translation","summary":"  This paper studies a novel energy-based cooperative learning framework for\nmulti-domain image-to-image translation. The framework consists of four\ncomponents: descriptor, translator, style encoder, and style generator. The\ndescriptor is a multi-head energy-based model that represents a multi-domain\nimage distribution. The components of translator, style encoder, and style\ngenerator constitute a diversified image generator. Specifically, given an\ninput image from a source domain, the translator turns it into a stylised\noutput image of the target domain according to a style code, which can be\ninferred by the style encoder from a reference image or produced by the style\ngenerator from a random noise. Since the style generator is represented as an\ndomain-specific distribution of style codes, the translator can provide a\none-to-many transformation (i.e., diversified generation) between source domain\nand target domain. To train our framework, we propose a likelihood-based\nmulti-domain cooperative learning algorithm to jointly train the multi-domain\ndescriptor and the diversified image generator (including translator, style\nencoder, and style generator modules) via multi-domain MCMC teaching, in which\nthe descriptor guides the diversified image generator to shift its probability\ndensity toward the data distribution, while the diversified image generator\nuses its randomly translated images to initialize the descriptor's Langevin\ndynamics process for efficient sampling.\n","authors":["Weinan Song","Yaxuan Zhu","Lei He","Yingnian Wu","Jianwen Xie"],"pdf_url":"https://arxiv.org/pdf/2306.14448v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05027v2","updated":"2023-06-26T06:24:42Z","published":"2023-02-10T02:56:01Z","title":"Deep Seam Prediction for Image Stitching Based on Selection Consistency\n  Loss","summary":"  Image stitching is to construct panoramic images with wider field of vision\n(FOV) from some images captured from different viewing positions. To solve the\nproblem of fusion ghosting in the stitched image, seam-driven methods avoid the\nmisalignment area to fuse images by predicting the best seam. Currently, as\nstandard tools of the OpenCV library, dynamic programming (DP) and GraphCut\n(GC) are still the only commonly used seam prediction methods despite the fact\nthat they were both proposed two decades ago. However, GC can get excellent\nseam quality but poor real-time performance while DP method has good efficiency\nbut poor seam quality. In this paper, we propose a deep learning based seam\nprediction method (DSeam) for the sake of high seam quality with high\nefficiency. To overcome the difficulty of the seam description in network and\nno GroundTruth for training we design a selective consistency loss combining\nthe seam shape constraint and seam quality constraint to supervise the network\nlearning. By the constraint of the selection of consistency loss, we implicitly\ndefined the mask boundaries as seams and transform seam prediction into mask\nprediction. To our knowledge, the proposed DSeam is the first deep learning\nbased seam prediction method for image stitching. Extensive experimental\nresults well demonstrate the superior performance of our proposed Dseam method\nwhich is 15 times faster than the classic GC seam prediction method in OpenCV\n2.4.9 with similar seam quality.\n","authors":["Senmao Cheng","Fan Yang","Zhi Chen","Nanjun Yuan","Wenbing Tao"],"pdf_url":"https://arxiv.org/pdf/2302.05027v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14442v1","updated":"2023-06-26T06:13:43Z","published":"2023-06-26T06:13:43Z","title":"Topology Estimation of Simulated 4D Image Data by Combining Downscaling\n  and Convolutional Neural Networks","summary":"  Four-dimensional image-type data can quickly become prohibitively large, and\nit may not be feasible to directly apply methods, such as persistent homology\nor convolutional neural networks, to determine the topological characteristics\nof these data because they can encounter complexity issues. This study aims to\ndetermine the Betti numbers of large four-dimensional image-type data. The\nexperiments use synthetic data, and demonstrate that it is possible to\ncircumvent these issues by applying downscaling methods to the data prior to\ntraining a convolutional neural network, even when persistent homology software\nindicates that downscaling can significantly alter the homology of the training\ndata. When provided with downscaled test data, the neural network can estimate\nthe Betti numbers of the original samples with reasonable accuracy.\n","authors":["Khalil Mathieu Hannouch","Stephan Chalup"],"pdf_url":"https://arxiv.org/pdf/2306.14442v1.pdf","comment":"22 pages, 4 figures, 7 tables, 1 appendix"},{"id":"http://arxiv.org/abs/2306.14435v1","updated":"2023-06-26T06:04:09Z","published":"2023-06-26T06:04:09Z","title":"DragDiffusion: Harnessing Diffusion Models for Interactive Point-based\n  Image Editing","summary":"  Precise and controllable image editing is a challenging task that has\nattracted significant attention. Recently, DragGAN enables an interactive\npoint-based image editing framework and achieves impressive editing results\nwith pixel-level precision. However, since this method is based on generative\nadversarial networks (GAN), its generality is upper-bounded by the capacity of\nthe pre-trained GAN models. In this work, we extend such an editing framework\nto diffusion models and propose DragDiffusion. By leveraging large-scale\npretrained diffusion models, we greatly improve the applicability of\ninteractive point-based editing in real world scenarios. While most existing\ndiffusion-based image editing methods work on text embeddings, DragDiffusion\noptimizes the diffusion latent to achieve precise spatial control. Although\ndiffusion models generate images in an iterative manner, we empirically show\nthat optimizing diffusion latent at one single step suffices to generate\ncoherent results, enabling DragDiffusion to complete high-quality editing\nefficiently. Extensive experiments across a wide range of challenging cases\n(e.g., multi-objects, diverse object categories, various styles, etc.)\ndemonstrate the versatility and generality of DragDiffusion.\n","authors":["Yujun Shi","Chuhui Xue","Jiachun Pan","Wenqing Zhang","Vincent Y. F. Tan","Song Bai"],"pdf_url":"https://arxiv.org/pdf/2306.14435v1.pdf","comment":"Preliminary version. Work in Progress"},{"id":"http://arxiv.org/abs/2304.12520v3","updated":"2023-06-26T06:01:14Z","published":"2023-04-25T02:22:01Z","title":"Hint-Aug: Drawing Hints from Foundation Vision Transformers Towards\n  Boosted Few-Shot Parameter-Efficient Tuning","summary":"  Despite the growing demand for tuning foundation vision transformers (FViTs)\non downstream tasks, fully unleashing FViTs' potential under data-limited\nscenarios (e.g., few-shot tuning) remains a challenge due to FViTs' data-hungry\nnature. Common data augmentation techniques fall short in this context due to\nthe limited features contained in the few-shot tuning data. To tackle this\nchallenge, we first identify an opportunity for FViTs in few-shot tuning:\npretrained FViTs themselves have already learned highly representative features\nfrom large-scale pretraining data, which are fully preserved during widely used\nparameter-efficient tuning. We thus hypothesize that leveraging those learned\nfeatures to augment the tuning data can boost the effectiveness of few-shot\nFViT tuning. To this end, we propose a framework called Hint-based Data\nAugmentation (Hint-Aug), which aims to boost FViT in few-shot tuning by\naugmenting the over-fitted parts of tuning samples with the learned features of\npretrained FViTs. Specifically, Hint-Aug integrates two key enablers: (1) an\nAttentive Over-fitting Detector (AOD) to detect over-confident patches of\nfoundation ViTs for potentially alleviating their over-fitting on the few-shot\ntuning data and (2) a Confusion-based Feature Infusion (CFI) module to infuse\neasy-to-confuse features from the pretrained FViTs with the over-confident\npatches detected by the above AOD in order to enhance the feature diversity\nduring tuning. Extensive experiments and ablation studies on five datasets and\nthree parameter-efficient tuning techniques consistently validate Hint-Aug's\neffectiveness: 0.04% ~ 32.91% higher accuracy over the state-of-the-art (SOTA)\ndata augmentation method under various low-shot settings. For example, on the\nPet dataset, Hint-Aug achieves a 2.22% higher accuracy with 50% less training\ndata over SOTA data augmentation methods.\n","authors":["Zhongzhi Yu","Shang Wu","Yonggan Fu","Shunyao Zhang","Yingyan Lin"],"pdf_url":"https://arxiv.org/pdf/2304.12520v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.11242v2","updated":"2023-06-26T05:53:49Z","published":"2023-03-20T16:27:36Z","title":"Make Landscape Flatter in Differentially Private Federated Learning","summary":"  To defend the inference attacks and mitigate the sensitive information\nleakages in Federated Learning (FL), client-level Differentially Private FL\n(DPFL) is the de-facto standard for privacy protection by clipping local\nupdates and adding random noise. However, existing DPFL methods tend to make a\nsharper loss landscape and have poorer weight perturbation robustness,\nresulting in severe performance degradation. To alleviate these issues, we\npropose a novel DPFL algorithm named DP-FedSAM, which leverages gradient\nperturbation to mitigate the negative impact of DP. Specifically, DP-FedSAM\nintegrates Sharpness Aware Minimization (SAM) optimizer to generate local\nflatness models with better stability and weight perturbation robustness, which\nresults in the small norm of local updates and robustness to DP noise, thereby\nimproving the performance. From the theoretical perspective, we analyze in\ndetail how DP-FedSAM mitigates the performance degradation induced by DP.\nMeanwhile, we give rigorous privacy guarantees with R\\'enyi DP and present the\nsensitivity analysis of local updates. At last, we empirically confirm that our\nalgorithm achieves state-of-the-art (SOTA) performance compared with existing\nSOTA baselines in DPFL. Code is available at\nhttps://github.com/YMJS-Irfan/DP-FedSAM\n","authors":["Yifan Shi","Yingqi Liu","Kang Wei","Li Shen","Xueqian Wang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2303.11242v2.pdf","comment":"CVPR2023"},{"id":"http://arxiv.org/abs/2302.00491v3","updated":"2023-06-26T05:42:36Z","published":"2023-02-01T15:02:58Z","title":"Learning Prototype Classifiers for Long-Tailed Recognition","summary":"  The problem of long-tailed recognition (LTR) has received attention in recent\nyears due to the fundamental power-law distribution of objects in the\nreal-world. Most recent works in LTR use softmax classifiers that are biased in\nthat they correlate classifier norm with the amount of training data for a\ngiven class. In this work, we show that learning prototype classifiers\naddresses the biased softmax problem in LTR. Prototype classifiers can deliver\npromising results simply using Nearest-Class- Mean (NCM), a special case where\nprototypes are empirical centroids. We go one step further and propose to\njointly learn prototypes by using distances to prototypes in representation\nspace as the logit scores for classification. Further, we theoretically analyze\nthe properties of Euclidean distance based prototype classifiers that lead to\nstable gradient-based optimization which is robust to outliers. To enable\nindependent distance scales along each channel, we enhance Prototype\nclassifiers by learning channel-dependent temperature parameters. Our analysis\nshows that prototypes learned by Prototype classifiers are better separated\nthan empirical centroids. Results on four LTR benchmarks show that Prototype\nclassifier outperforms or is comparable to state-of-the-art methods. Our code\nis made available at\nhttps://github.com/saurabhsharma1993/prototype-classifier-ltr.\n","authors":["Saurabh Sharma","Yongqin Xian","Ning Yu","Ambuj Singh"],"pdf_url":"https://arxiv.org/pdf/2302.00491v3.pdf","comment":"Accepted at IJCAI-23"},{"id":"http://arxiv.org/abs/2206.08920v6","updated":"2023-06-26T05:40:58Z","published":"2022-06-17T17:57:13Z","title":"VectorMapNet: End-to-end Vectorized HD Map Learning","summary":"  Autonomous driving systems require High-Definition (HD) semantic maps to\nnavigate around urban roads. Existing solutions approach the semantic mapping\nproblem by offline manual annotation, which suffers from serious scalability\nissues. Recent learning-based methods produce dense rasterized segmentation\npredictions to construct maps. However, these predictions do not include\ninstance information of individual map elements and require heuristic\npost-processing to obtain vectorized maps. To tackle these challenges, we\nintroduce an end-to-end vectorized HD map learning pipeline, termed\nVectorMapNet. VectorMapNet takes onboard sensor observations and predicts a\nsparse set of polylines in the bird's-eye view. This pipeline can explicitly\nmodel the spatial relation between map elements and generate vectorized maps\nthat are friendly to downstream autonomous driving tasks. Extensive experiments\nshow that VectorMapNet achieve strong map learning performance on both nuScenes\nand Argoverse2 dataset, surpassing previous state-of-the-art methods by 14.2\nmAP and 14.6mAP. Qualitatively, VectorMapNet is capable of generating\ncomprehensive maps and capturing fine-grained details of road geometry. To the\nbest of our knowledge, VectorMapNet is the first work designed towards\nend-to-end vectorized map learning from onboard observations. Our project\nwebsite is available at\n\\url{https://tsinghua-mars-lab.github.io/vectormapnet/}.\n","authors":["Yicheng Liu","Tianyuan Yuan","Yue Wang","Yilun Wang","Hang Zhao"],"pdf_url":"https://arxiv.org/pdf/2206.08920v6.pdf","comment":"Accepted by ICML 2023"},{"id":"http://arxiv.org/abs/2306.12686v2","updated":"2023-06-26T05:11:17Z","published":"2023-06-22T06:18:29Z","title":"FlowFace++: Explicit Semantic Flow-supervised End-to-End Face Swapping","summary":"  This work proposes a novel face-swapping framework FlowFace++, utilizing\nexplicit semantic flow supervision and end-to-end architecture to facilitate\nshape-aware face-swapping. Specifically, our work pretrains a facial shape\ndiscriminator to supervise the face swapping network. The discriminator is\nshape-aware and relies on a semantic flow-guided operation to explicitly\ncalculate the shape discrepancies between the target and source faces, thus\noptimizing the face swapping network to generate highly realistic results. The\nface swapping network is a stack of a pre-trained face-masked autoencoder\n(MAE), a cross-attention fusion module, and a convolutional decoder. The MAE\nprovides a fine-grained facial image representation space, which is unified for\nthe target and source faces and thus facilitates final realistic results. The\ncross-attention fusion module carries out the source-to-target face swapping in\na fine-grained latent space while preserving other attributes of the target\nimage (e.g. expression, head pose, hair, background, illumination, etc).\nLastly, the convolutional decoder further synthesizes the swapping results\naccording to the face-swapping latent embedding from the cross-attention fusion\nmodule. Extensive quantitative and qualitative experiments on in-the-wild faces\ndemonstrate that our FlowFace++ outperforms the state-of-the-art significantly,\nparticularly while the source face is obstructed by uneven lighting or angle\noffset.\n","authors":["Yu Zhang","Hao Zeng","Bowen Ma","Wei Zhang","Zhimeng Zhang","Yu Ding","Tangjie Lv","Changjie Fan"],"pdf_url":"https://arxiv.org/pdf/2306.12686v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2212.02797"},{"id":"http://arxiv.org/abs/2209.01760v4","updated":"2023-06-26T04:59:53Z","published":"2022-09-05T04:39:16Z","title":"REQA: Coarse-to-fine Assessment of Image Quality to Alleviate the Range\n  Effect","summary":"  Blind image quality assessment (BIQA) of user generated content (UGC) suffers\nfrom the range effect which indicates that on the overall quality range, mean\nopinion score (MOS) and predicted MOS (pMOS) are well correlated; focusing on a\nparticular range, the correlation is lower. The reason for the range effect is\nthat the predicted deviations both in a wide range and in a narrow range\ndestroy the uniformity between MOS and pMOS. To tackle this problem, a novel\nmethod is proposed from coarse-grained metric to fine-grained prediction.\nFirstly, we design a rank-and-gradient loss for coarse-grained metric. The loss\nkeeps the order and grad consistency between pMOS and MOS, thereby reducing the\npredicted deviation in a wide range. Secondly, we propose multi-level tolerance\nloss to make fine-grained prediction. The loss is constrained by a decreasing\nthreshold to limite the predicted deviation in narrower and narrower ranges.\nFinally, we design a feedback network to conduct the coarse-to-fine assessment.\nOn the one hand, the network adopts feedback blocks to process multi-scale\ndistortion features iteratively and on the other hand, it fuses non-local\ncontext feature to the output of each iteration to acquire more quality-aware\nfeature representation. Experimental results demonstrate that the proposed\nmethod can alleviate the range effect compared to the state-of-the-art methods\neffectively.\n","authors":["Bingheng Li","Fushuo Huo"],"pdf_url":"https://arxiv.org/pdf/2209.01760v4.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2306.11605v2","updated":"2023-06-26T04:48:56Z","published":"2023-06-20T15:33:24Z","title":"Annotation Cost Efficient Active Learning for Content Based Image\n  Retrieval","summary":"  Deep metric learning (DML) based methods have been found very effective for\ncontent-based image retrieval (CBIR) in remote sensing (RS). For accurately\nlearning the model parameters of deep neural networks, most of the DML methods\nrequire a high number of annotated training images, which can be costly to\ngather. To address this problem, in this paper we present an annotation cost\nefficient active learning (AL) method (denoted as ANNEAL). The proposed method\naims to iteratively enrich the training set by annotating the most informative\nimage pairs as similar or dissimilar, while accurately modelling a deep metric\nspace. This is achieved by two consecutive steps. In the first step the\npairwise image similarity is modelled based on the available training set.\nThen, in the second step the most uncertain and diverse (i.e., informative)\nimage pairs are selected to be annotated. Unlike the existing AL methods for\nCBIR, at each AL iteration of ANNEAL a human expert is asked to annotate the\nmost informative image pairs as similar/dissimilar. This significantly reduces\nthe annotation cost compared to annotating images with land-use/land cover\nclass labels. Experimental results show the effectiveness of our method. The\ncode of ANNEAL is publicly available at https://git.tu-berlin.de/rsim/ANNEAL.\n","authors":["Julia Henkel","Genc Hoxha","Gencer Sumbul","Lars Möllenbrok","Begüm Demir"],"pdf_url":"https://arxiv.org/pdf/2306.11605v2.pdf","comment":"Accepted at IEEE International Geoscience and Remote Sensing\n  Symposium (IGARSS) 2023. Our code is available at\n  https://git.tu-berlin.de/rsim/ANNEAL"},{"id":"http://arxiv.org/abs/2306.14412v1","updated":"2023-06-26T04:19:33Z","published":"2023-06-26T04:19:33Z","title":"A Solution to CVPR'2023 AQTC Challenge: Video Alignment for Multi-Step\n  Inference","summary":"  Affordance-centric Question-driven Task Completion (AQTC) for Egocentric\nAssistant introduces a groundbreaking scenario. In this scenario, through\nlearning instructional videos, AI assistants provide users with step-by-step\nguidance on operating devices. In this paper, we present a solution for\nenhancing video alignment to improve multi-step inference. Specifically, we\nfirst utilize VideoCLIP to generate video-script alignment features.\nAfterwards, we ground the question-relevant content in instructional videos.\nThen, we reweight the multimodal context to emphasize prominent features.\nFinally, we adopt GRU to conduct multi-step inference. Through comprehensive\nexperiments, we demonstrate the effectiveness and superiority of our method,\nwhich secured the 2nd place in CVPR'2023 AQTC challenge. Our code is available\nat https://github.com/zcfinal/LOVEU-CVPR23-AQTC.\n","authors":["Chao Zhang","Shiwei Wu","Sirui Zhao","Tong Xu","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2306.14412v1.pdf","comment":"5 pages, 1 figure, technical report for track3 of CVPR 2023 LOVEU\n  challenge"},{"id":"http://arxiv.org/abs/2306.14408v1","updated":"2023-06-26T03:48:15Z","published":"2023-06-26T03:48:15Z","title":"Decompose and Realign: Tackling Condition Misalignment in Text-to-Image\n  Diffusion Models","summary":"  Text-to-image diffusion models have advanced towards more controllable\ngeneration via supporting various image conditions (e.g., depth map) beyond\ntext. However, these models are learned based on the premise of perfect\nalignment between the text and image conditions. If this alignment is not\nsatisfied, the final output could be either dominated by one condition, or\nambiguity may arise, failing to meet user expectations. To address this issue,\nwe present a training-free approach called \"Decompose and Realign'' to further\nimprove the controllability of existing models when provided with partially\naligned conditions. The ``Decompose'' phase separates conditions based on pair\nrelationships, computing scores individually for each pair. This ensures that\neach pair no longer has conflicting conditions. The \"Realign'' phase aligns\nthese independently calculated scores via a cross-attention mechanism to avoid\nnew conflicts when combing them back. Both qualitative and quantitative results\ndemonstrate the effectiveness of our approach in handling unaligned conditions,\nwhich performs favorably against recent methods and more importantly adds\nflexibility to the controllable image generation process.\n","authors":["Luozhou Wang","Guibao Shen","Yijun Li","Ying-cong Chen"],"pdf_url":"https://arxiv.org/pdf/2306.14408v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14406v1","updated":"2023-06-26T03:38:43Z","published":"2023-06-26T03:38:43Z","title":"TCEIP: Text Condition Embedded Regression Network for Dental Implant\n  Position Prediction","summary":"  When deep neural network has been proposed to assist the dentist in designing\nthe location of dental implant, most of them are targeting simple cases where\nonly one missing tooth is available. As a result, literature works do not work\nwell when there are multiple missing teeth and easily generate false\npredictions when the teeth are sparsely distributed. In this paper, we are\ntrying to integrate a weak supervision text, the target region, to the implant\nposition regression network, to address above issues. We propose a text\ncondition embedded implant position regression network (TCEIP), to embed the\ntext condition into the encoder-decoder framework for improvement of the\nregression performance. A cross-modal interaction that consists of cross-modal\nattention (CMA) and knowledge alignment module (KAM) is proposed to facilitate\nthe interaction between features of images and texts. The CMA module performs a\ncross-attention between the image feature and the text condition, and the KAM\nmitigates the knowledge gap between the image feature and the image encoder of\nthe CLIP. Extensive experiments on a dental implant dataset through five-fold\ncross-validation demonstrated that the proposed TCEIP achieves superior\nperformance than existing methods.\n","authors":["Xinquan Yang","Jinheng Xie","Xuguang Li","Xuechen Li","Xin Li","Linlin Shen","Yongqiang Deng"],"pdf_url":"https://arxiv.org/pdf/2306.14406v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.07461v2","updated":"2023-06-26T03:35:51Z","published":"2023-04-15T03:05:47Z","title":"Beta-Rank: A Robust Convolutional Filter Pruning Method For Imbalanced\n  Medical Image Analysis","summary":"  As deep neural networks include a high number of parameters and operations,\nit can be a challenge to implement these models on devices with limited\ncomputational resources. Despite the development of novel pruning methods\ntoward resource-efficient models, it has become evident that these models are\nnot capable of handling \"imbalanced\" and \"limited number of data points\". We\nproposed a novel filter pruning method by considering the input and output of\nfilters along with the values of the filters that deal with imbalanced datasets\nbetter than others. Our pruning method considers the fact that all information\nabout the importance of a filter may not be reflected in the value of the\nfilter. Instead, it is reflected in the changes made to the data after the\nfilter is applied to it. In this work, three methods are compared with the same\ntraining conditions except for the ranking values of each method, and 14\nmethods are compared from other papers. We demonstrated that our model\nperformed significantly better than other methods for imbalanced medical\ndatasets. For example, when we removed up to 58% of FLOPs for the IDRID dataset\nand up to 45% for the ISIC dataset, our model was able to yield an equivalent\n(or even superior) result to the baseline model. To evaluate FLOP and parameter\nreduction using our model in real-world settings, we built a smartphone app,\nwhere we demonstrated a reduction of up to 79% in memory usage and 72% in\nprediction time. All codes and parameters for training different models are\navailable at https://github.com/mohofar/Beta-Rank\n","authors":["Morteza Homayounfar","Mohamad Koohi-Moghadam","Reza Rawassizadeh","Varut Vardhanabhuti"],"pdf_url":"https://arxiv.org/pdf/2304.07461v2.pdf","comment":"13 pages, 3 figures, and 3 tables"},{"id":"http://arxiv.org/abs/2306.14399v1","updated":"2023-06-26T03:18:38Z","published":"2023-06-26T03:18:38Z","title":"Mutual Query Network for Multi-Modal Product Image Segmentation","summary":"  Product image segmentation is vital in e-commerce. Most existing methods\nextract the product image foreground only based on the visual modality, making\nit difficult to distinguish irrelevant products. As product titles contain\nabundant appearance information and provide complementary cues for product\nimage segmentation, we propose a mutual query network to segment products based\non both visual and linguistic modalities. First, we design a language query\nvision module to obtain the response of language description in image areas,\nthus aligning the visual and linguistic representations across modalities.\nThen, a vision query language module utilizes the correlation between visual\nand linguistic modalities to filter the product title and effectively suppress\nthe content irrelevant to the vision in the title. To promote the research in\nthis field, we also construct a Multi-Modal Product Segmentation dataset\n(MMPS), which contains 30,000 images and corresponding titles. The proposed\nmethod significantly outperforms the state-of-the-art methods on MMPS.\n","authors":["Yun Guo","Wei Feng","Zheng Zhang","Xiancong Ren","Yaoyu Li","Jingjing Lv","Xin Zhu","Zhangang Lin","Jingping Shao"],"pdf_url":"https://arxiv.org/pdf/2306.14399v1.pdf","comment":"Accepted by ICME2023"},{"id":"http://arxiv.org/abs/2306.14392v1","updated":"2023-06-26T03:04:53Z","published":"2023-06-26T03:04:53Z","title":"ContentCTR: Frame-level Live Streaming Click-Through Rate Prediction\n  with Multimodal Transformer","summary":"  In recent years, live streaming platforms have gained immense popularity as\nthey allow users to broadcast their videos and interact in real-time with hosts\nand peers. Due to the dynamic changes of live content, accurate recommendation\nmodels are crucial for enhancing user experience. However, most previous works\ntreat the live as a whole item and explore the Click-through-Rate (CTR)\nprediction framework on item-level, neglecting that the dynamic changes that\noccur even within the same live room. In this paper, we proposed a ContentCTR\nmodel that leverages multimodal transformer for frame-level CTR prediction.\nFirst, we present an end-to-end framework that can make full use of multimodal\ninformation, including visual frames, audio, and comments, to identify the most\nattractive live frames. Second, to prevent the model from collapsing into a\nmediocre solution, a novel pairwise loss function with first-order difference\nconstraints is proposed to utilize the contrastive information existing in the\nhighlight and non-highlight frames. Additionally, we design a temporal\ntext-video alignment module based on Dynamic Time Warping to eliminate noise\ncaused by the ambiguity and non-sequential alignment of visual and textual\ninformation. We conduct extensive experiments on both real-world scenarios and\npublic datasets, and our ContentCTR model outperforms traditional\nrecommendation models in capturing real-time content changes. Moreover, we\ndeploy the proposed method on our company platform, and the results of online\nA/B testing further validate its practical significance.\n","authors":["Jiaxin Deng","Dong Shen","Shiyao Wang","Xiangyu Wu","Fan Yang","Guorui Zhou","Gaofeng Meng"],"pdf_url":"https://arxiv.org/pdf/2306.14392v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13557v2","updated":"2023-06-26T02:54:29Z","published":"2023-06-23T15:31:09Z","title":"FPGA Implementation of Convolutional Neural Network for Real-Time\n  Handwriting Recognition","summary":"  Machine Learning (ML) has recently been a skyrocketing field in Computer\nScience. As computer hardware engineers, we are enthusiastic about hardware\nimplementations of popular software ML architectures to optimize their\nperformance, reliability, and resource usage. In this project, we designed a\nhighly-configurable, real-time device for recognizing handwritten letters and\ndigits using an Altera DE1 FPGA Kit. We followed various engineering standards,\nincluding IEEE-754 32-bit Floating-Point Standard, Video Graphics Array (VGA)\ndisplay protocol, Universal Asynchronous Receiver-Transmitter (UART) protocol,\nand Inter-Integrated Circuit (I2C) protocols to achieve the project goals.\nThese significantly improved our design in compatibility, reusability, and\nsimplicity in verifications. Following these standards, we designed a 32-bit\nfloating-point (FP) instruction set architecture (ISA). We developed a 5-stage\nRISC processor in System Verilog to manage image processing, matrix\nmultiplications, ML classifications, and user interfaces. Three different ML\narchitectures were implemented and evaluated on our design: Linear\nClassification (LC), a 784-64-10 fully connected neural network (NN), and a\nLeNet-like Convolutional Neural Network (CNN) with ReLU activation layers and\n36 classes (10 for the digits and 26 for the case-insensitive letters). The\ntraining processes were done in Python scripts, and the resulting kernels and\nweights were stored in hex files and loaded into the FPGA's SRAM units.\nConvolution, pooling, data management, and various other ML features were\nguided by firmware in our custom assembly language. This paper documents the\nhigh-level design block diagrams, interfaces between each System Verilog\nmodule, implementation details of our software and firmware components, and\nfurther discussions on potential impacts.\n","authors":["Shichen Qiao","Haining Qiu","Lingkai Zhao","Qikun Liu","Eric J. Hoffman"],"pdf_url":"https://arxiv.org/pdf/2306.13557v2.pdf","comment":"27 pages, 13 figures"},{"id":"http://arxiv.org/abs/2208.11602v2","updated":"2023-06-26T01:18:16Z","published":"2022-08-24T15:15:24Z","title":"Motion Robust High-Speed Light-Weighted Object Detection With Event\n  Camera","summary":"  In this work, we propose a motion robust and high-speed detection pipeline\nwhich better leverages the event data. First, we design an event stream\nrepresentation called temporal active focus (TAF), which efficiently utilizes\nthe spatial-temporal asynchronous event stream, constructing event tensors\nrobust to object motions. Then, we propose a module called the bifurcated\nfolding module (BFM), which encodes the rich temporal information in the TAF\ntensor at the input layer of the detector. Following this, we design a\nhigh-speed lightweight detector called agile event detector (AED) plus a simple\nbut effective data augmentation method, to enhance the detection accuracy and\nreduce the model's parameter. Experiments on two typical real-scene event\ncamera object detection datasets show that our method is competitive in terms\nof accuracy, efficiency, and the number of parameters. By classifying objects\ninto multiple motion levels based on the optical flow density metric, we\nfurther illustrated the robustness of our method for objects with different\nvelocities relative to the camera. The codes and trained models are available\nat https://github.com/HarmoniaLeo/FRLW-EvD .\n","authors":["Bingde Liu","Chang Xu","Wen Yang","Huai Yu","Lei Yu"],"pdf_url":"https://arxiv.org/pdf/2208.11602v2.pdf","comment":"Published in: IEEE Transactions on Instrumentation and Measurement\n  (Volume: 72) 2023"},{"id":"http://arxiv.org/abs/2306.09869v2","updated":"2023-06-26T01:03:07Z","published":"2023-06-16T14:30:41Z","title":"Energy-Based Cross Attention for Bayesian Context Update in\n  Text-to-Image Diffusion Models","summary":"  Despite the remarkable performance of text-to-image diffusion models in image\ngeneration tasks, recent studies have raised the issue that generated images\nsometimes cannot capture the intended semantic contents of the text prompts,\nwhich phenomenon is often called semantic misalignment. To address this, here\nwe present a novel energy-based model (EBM) framework. Specifically, we first\nformulate EBMs of latent image representations and text embeddings in each\ncross-attention layer of the denoising autoencoder. Then, we obtain the\ngradient of the log posterior of context vectors, which can be updated and\ntransferred to the subsequent cross-attention layer, thereby implicitly\nminimizing a nested hierarchy of energy functions. Our latent EBMs further\nallow zero-shot compositional generation as a linear combination of\ncross-attention outputs from different contexts. Using extensive experiments,\nwe demonstrate that the proposed method is highly effective in handling various\nimage generation tasks, including multi-concept generation, text-guided image\ninpainting, and real and synthetic image editing.\n","authors":["Geon Yeong Park","Jeongsol Kim","Beomsu Kim","Sang Wan Lee","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2306.09869v2.pdf","comment":"Code: https://github.com/EnergyAttention/Energy-Based-CrossAttention"},{"id":"http://arxiv.org/abs/2206.11752v3","updated":"2023-06-26T00:46:10Z","published":"2022-06-23T14:51:42Z","title":"CLAMP: Prompt-based Contrastive Learning for Connecting Language and\n  Animal Pose","summary":"  Animal pose estimation is challenging for existing image-based methods\nbecause of limited training data and large intra- and inter-species variances.\nMotivated by the progress of visual-language research, we propose that\npre-trained language models (e.g., CLIP) can facilitate animal pose estimation\nby providing rich prior knowledge for describing animal keypoints in text.\nHowever, we found that building effective connections between pre-trained\nlanguage models and visual animal keypoints is non-trivial since the gap\nbetween text-based descriptions and keypoint-based visual features about animal\npose can be significant. To address this issue, we introduce a novel\nprompt-based Contrastive learning scheme for connecting Language and AniMal\nPose (CLAMP) effectively. The CLAMP attempts to bridge the gap by adapting the\ntext prompts to the animal keypoints during network training. The adaptation is\ndecomposed into spatial-aware and feature-aware processes, and two novel\ncontrastive losses are devised correspondingly. In practice, the CLAMP enables\nthe first cross-modal animal pose estimation paradigm. Experimental results\nshow that our method achieves state-of-the-art performance under the\nsupervised, few-shot, and zero-shot settings, outperforming image-based methods\nby a large margin.\n","authors":["Xu Zhang","Wen Wang","Zhe Chen","Yufei Xu","Jing Zhang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2206.11752v3.pdf","comment":"CVPR2023"},{"id":"http://arxiv.org/abs/2306.14370v1","updated":"2023-06-26T00:39:32Z","published":"2023-06-26T00:39:32Z","title":"Pseudo-Trilateral Adversarial Training for Domain Adaptive\n  Traversability Prediction","summary":"  Traversability prediction is a fundamental perception capability for\nautonomous navigation. Deep neural networks (DNNs) have been widely used to\npredict traversability during the last decade. The performance of DNNs is\nsignificantly boosted by exploiting a large amount of data. However, the\ndiversity of data in different domains imposes significant gaps in the\nprediction performance. In this work, we make efforts to reduce the gaps by\nproposing a novel pseudo-trilateral adversarial model that adopts a\ncoarse-to-fine alignment (CALI) to perform unsupervised domain adaptation\n(UDA). Our aim is to transfer the perception model with high data efficiency,\neliminate the prohibitively expensive data labeling, and improve the\ngeneralization capability during the adaptation from easy-to-access source\ndomains to various challenging target domains. Existing UDA methods usually\nadopt a bilateral zero-sum game structure. We prove that our CALI model -- a\npseudo-trilateral game structure is advantageous over existing bilateral game\nstructures. This proposed work bridges theoretical analyses and algorithm\ndesigns, leading to an efficient UDA model with easy and stable training. We\nfurther develop a variant of CALI -- Informed CALI (ICALI), which is inspired\nby the recent success of mixup data augmentation techniques and mixes\ninformative regions based on the results of CALI. This mixture step provides an\nexplicit bridging between the two domains and exposes underperforming classes\nmore during training. We show the superiorities of our proposed models over\nmultiple baselines in several challenging domain adaptation setups. To further\nvalidate the effectiveness of our proposed models, we then combine our\nperception model with a visual planner to build a navigation system and show\nthe high reliability of our model in complex natural environments.\n","authors":["Zheng Chen","Durgakant Pushp","Jason M. Gregory","Lantao Liu"],"pdf_url":"https://arxiv.org/pdf/2306.14370v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2204.09617"},{"id":"http://arxiv.org/abs/2211.00519v2","updated":"2023-06-26T00:32:56Z","published":"2022-11-01T15:10:58Z","title":"Learning Neural Implicit Representations with Surface Signal\n  Parameterizations","summary":"  Neural implicit surface representations have recently emerged as popular\nalternative to explicit 3D object encodings, such as polygonal meshes,\ntabulated points, or voxels. While significant work has improved the geometric\nfidelity of these representations, much less attention is given to their final\nappearance. Traditional explicit object representations commonly couple the 3D\nshape data with auxiliary surface-mapped image data, such as diffuse color\ntextures and fine-scale geometric details in normal maps that typically require\na mapping of the 3D surface onto a plane, i.e., a surface parameterization;\nimplicit representations, on the other hand, cannot be easily textured due to\nlack of configurable surface parameterization. Inspired by this digital content\nauthoring methodology, we design a neural network architecture that implicitly\nencodes the underlying surface parameterization suitable for appearance data.\nAs such, our model remains compatible with existing mesh-based digital content\nwith appearance data. Motivated by recent work that overfits compact networks\nto individual 3D objects, we present a new weight-encoded neural implicit\nrepresentation that extends the capability of neural implicit surfaces to\nenable various common and important applications of texture mapping. Our method\noutperforms reasonable baselines and state-of-the-art alternatives.\n","authors":["Yanran Guan","Andrei Chubarau","Ruby Rao","Derek Nowrouzezahrai"],"pdf_url":"https://arxiv.org/pdf/2211.00519v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15117v1","updated":"2023-06-26T23:55:00Z","published":"2023-06-26T23:55:00Z","title":"Continual Learning for Out-of-Distribution Pedestrian Detection","summary":"  A continual learning solution is proposed to address the out-of-distribution\ngeneralization problem for pedestrian detection. While recent pedestrian\ndetection models have achieved impressive performance on various datasets, they\nremain sensitive to shifts in the distribution of the inference data. Our\nmethod adopts and modifies Elastic Weight Consolidation to a backbone object\ndetection network, in order to penalize the changes in the model weights based\non their importance towards the initially learned task. We show that when\ntrained with one dataset and fine-tuned on another, our solution learns the new\ndistribution and maintains its performance on the previous one, avoiding\ncatastrophic forgetting. We use two popular datasets, CrowdHuman and\nCityPersons for our cross-dataset experiments, and show considerable\nimprovements over standard fine-tuning, with a 9% and 18% miss rate percent\nreduction improvement in the CrowdHuman and CityPersons datasets, respectively.\n","authors":["Mahdiyar Molahasani","Ali Etemad","Michael Greenspan"],"pdf_url":"https://arxiv.org/pdf/2306.15117v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15114v1","updated":"2023-06-26T23:47:59Z","published":"2023-06-26T23:47:59Z","title":"Transfer: Cross Modality Knowledge Transfer using Adversarial Networks\n  -- A Study on Gesture Recognition","summary":"  Knowledge transfer across sensing technology is a novel concept that has been\nrecently explored in many application domains, including gesture-based human\ncomputer interaction. The main aim is to gather semantic or data driven\ninformation from a source technology to classify / recognize instances of\nunseen classes in the target technology. The primary challenge is the\nsignificant difference in dimensionality and distribution of feature sets\nbetween the source and the target technologies. In this paper, we propose\nTRANSFER, a generic framework for knowledge transfer between a source and a\ntarget technology. TRANSFER uses a language-based representation of a hand\ngesture, which captures a temporal combination of concepts such as handshape,\nlocation, and movement that are semantically related to the meaning of a word.\nBy utilizing a pre-specified syntactic structure and tokenizer, TRANSFER\nsegments a hand gesture into tokens and identifies individual components using\na token recognizer. The tokenizer in this language-based recognition system\nabstracts the low-level technology-specific characteristics to the machine\ninterface, enabling the design of a discriminator that learns\ntechnology-invariant features essential for recognition of gestures in both\nsource and target technologies. We demonstrate the usage of TRANSFER for three\ndifferent scenarios: a) transferring knowledge across technology by learning\ngesture models from video and recognizing gestures using WiFi, b) transferring\nknowledge from video to accelerometer, and d) transferring knowledge from\naccelerometer to WiFi signals.\n","authors":["Payal Kamboj","Ayan Banerjee","Sandeep K. S. Gupta"],"pdf_url":"https://arxiv.org/pdf/2306.15114v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.07011v2","updated":"2023-06-26T23:35:10Z","published":"2023-05-11T17:53:29Z","title":"Region-Aware Pretraining for Open-Vocabulary Object Detection with\n  Vision Transformers","summary":"  We present Region-aware Open-vocabulary Vision Transformers (RO-ViT) - a\ncontrastive image-text pretraining recipe to bridge the gap between image-level\npretraining and open-vocabulary object detection. At the pretraining phase, we\npropose to randomly crop and resize regions of positional embeddings instead of\nusing the whole image positional embeddings. This better matches the use of\npositional embeddings at region-level in the detection finetuning phase. In\naddition, we replace the common softmax cross entropy loss in contrastive\nlearning with focal loss to better learn the informative yet difficult\nexamples. Finally, we leverage recent advances in novel object proposals to\nimprove open-vocabulary detection finetuning. We evaluate our full model on the\nLVIS and COCO open-vocabulary detection benchmarks and zero-shot transfer.\nRO-ViT achieves a state-of-the-art 32.4 $AP_r$ on LVIS, surpassing the best\nexisting approach by +6.1 points in addition to competitive zero-shot transfer\ndetection. Surprisingly, RO-ViT improves the image-level representation as well\nand achieves the state of the art on 9 out of 12 metrics on COCO and Flickr\nimage-text retrieval benchmarks, outperforming competitive approaches with\nlarger models.\n","authors":["Dahun Kim","Anelia Angelova","Weicheng Kuo"],"pdf_url":"https://arxiv.org/pdf/2305.07011v2.pdf","comment":"CVPR 2023 (Highlight); adds LAION-2B result"},{"id":"http://arxiv.org/abs/2306.15111v1","updated":"2023-06-26T23:29:16Z","published":"2023-06-26T23:29:16Z","title":"Semi-Supervised Image Captioning with CLIP","summary":"  Image captioning, a fundamental task in vision-language understanding, seeks\nto generate accurate natural language descriptions for provided images. The\nCLIP model, with its rich semantic features learned from a large corpus of\nimage-text pairs, is well-suited for this task. In this paper, we present a\ntwo-stage semi-supervised image captioning approach that exploits the potential\nof CLIP encoding. Our model comprises a CLIP visual encoder, a mapping network,\nand a language model for text generation. In the initial stage, we train the\nmodel using a small labeled dataset by contrasting the generated captions with\nthe ground truth captions. In the subsequent stage, we continue the training\nusing unlabeled images, aiming to maximize the image-caption similarity based\non CLIP embeddings. Remarkably, despite utilizing less than 2% of the\nCOCO-captions, our approach delivers a performance comparable to\nstate-of-the-art models trained on the complete dataset. Furthermore, the\ncaptions generated by our approach are more distinctive, informative, and in\nline with human preference.\n","authors":["Chuanyang Jin"],"pdf_url":"https://arxiv.org/pdf/2306.15111v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.12032v2","updated":"2023-06-26T23:23:09Z","published":"2023-05-19T23:12:08Z","title":"The Waymo Open Sim Agents Challenge","summary":"  Simulation with realistic, interactive agents represents a key task for\nautonomous vehicle software development. In this work, we introduce the Waymo\nOpen Sim Agents Challenge (WOSAC). WOSAC is the first public challenge to\ntackle this task and propose corresponding metrics. The goal of the challenge\nis to stimulate the design of realistic simulators that can be used to evaluate\nand train a behavior model for autonomous driving. We outline our evaluation\nmethodology, present results for a number of different baseline simulation\nagent methods, and analyze several submissions to the 2023 competition which\nran from March 16, 2023 to May 23, 2023. The WOSAC evaluation server remains\nopen for submissions and we discuss open problems for the task.\n","authors":["Nico Montali","John Lambert","Paul Mougin","Alex Kuefler","Nick Rhinehart","Michelle Li","Cole Gulino","Tristan Emrich","Zoey Yang","Shimon Whiteson","Brandyn White","Dragomir Anguelov"],"pdf_url":"https://arxiv.org/pdf/2305.12032v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15110v1","updated":"2023-06-26T23:18:09Z","published":"2023-06-26T23:18:09Z","title":"Deep Transfer Learning for Intelligent Vehicle Perception: a Survey","summary":"  Deep learning-based intelligent vehicle perception has been developing\nprominently in recent years to provide a reliable source for motion planning\nand decision making in autonomous driving. A large number of powerful deep\nlearning-based methods can achieve excellent performance in solving various\nperception problems of autonomous driving. However, these deep learning methods\nstill have several limitations, for example, the assumption that lab-training\n(source domain) and real-testing (target domain) data follow the same feature\ndistribution may not be practical in the real world. There is often a dramatic\ndomain gap between them in many real-world cases. As a solution to this\nchallenge, deep transfer learning can handle situations excellently by\ntransferring the knowledge from one domain to another. Deep transfer learning\naims to improve task performance in a new domain by leveraging the knowledge of\nsimilar tasks learned in another domain before. Nevertheless, there are\ncurrently no survey papers on the topic of deep transfer learning for\nintelligent vehicle perception. To the best of our knowledge, this paper\nrepresents the first comprehensive survey on the topic of the deep transfer\nlearning for intelligent vehicle perception. This paper discusses the domain\ngaps related to the differences of sensor, data, and model for the intelligent\nvehicle perception. The recent applications, challenges, future researches in\nintelligent vehicle perception are also explored.\n","authors":["Xinyu Liu","Jinlong Li","Jin Ma","Huiming Sun","Zhigang Xu","Tianyun Zhang","Hongkai Yu"],"pdf_url":"https://arxiv.org/pdf/2306.15110v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.06299v3","updated":"2023-06-26T23:12:45Z","published":"2022-12-13T00:45:46Z","title":"Interpretable Diabetic Retinopathy Diagnosis based on Biomarker\n  Activation Map","summary":"  Deep learning classifiers provide the most accurate means of automatically\ndiagnosing diabetic retinopathy (DR) based on optical coherence tomography\n(OCT) and its angiography (OCTA). The power of these models is attributable in\npart to the inclusion of hidden layers that provide the complexity required to\nachieve a desired task. However, hidden layers also render algorithm outputs\ndifficult to interpret. Here we introduce a novel biomarker activation map\n(BAM) framework based on generative adversarial learning that allows clinicians\nto verify and understand classifiers decision-making. A data set including 456\nmacular scans were graded as non-referable or referable DR based on current\nclinical standards. A DR classifier that was used to evaluate our BAM was first\ntrained based on this data set. The BAM generation framework was designed by\ncombing two U-shaped generators to provide meaningful interpretability to this\nclassifier. The main generator was trained to take referable scans as input and\nproduce an output that would be classified by the classifier as non-referable.\nThe BAM is then constructed as the difference image between the output and\ninput of the main generator. To ensure that the BAM only highlights\nclassifier-utilized biomarkers an assistant generator was trained to do the\nopposite, producing scans that would be classified as referable by the\nclassifier from non-referable scans. The generated BAMs highlighted known\npathologic features including nonperfusion area and retinal fluid. A fully\ninterpretable classifier based on these highlights could help clinicians better\nutilize and verify automated DR diagnosis.\n","authors":["Pengxiao Zang","Tristan T. Hormel","Jie Wang","Yukun Guo","Steven T. Bailey","Christina J. Flaxel","David Huang","Thomas S. Hwang","Yali Jia"],"pdf_url":"https://arxiv.org/pdf/2212.06299v3.pdf","comment":"This paper has been accepted by IEEE TBME"},{"id":"http://arxiv.org/abs/2306.15073v1","updated":"2023-06-26T21:20:23Z","published":"2023-06-26T21:20:23Z","title":"CLERA: A Unified Model for Joint Cognitive Load and Eye Region Analysis\n  in the Wild","summary":"  Non-intrusive, real-time analysis of the dynamics of the eye region allows us\nto monitor humans' visual attention allocation and estimate their mental state\nduring the performance of real-world tasks, which can potentially benefit a\nwide range of human-computer interaction (HCI) applications. While commercial\neye-tracking devices have been frequently employed, the difficulty of\ncustomizing these devices places unnecessary constraints on the exploration of\nmore efficient, end-to-end models of eye dynamics. In this work, we propose\nCLERA, a unified model for Cognitive Load and Eye Region Analysis, which\nachieves precise keypoint detection and spatiotemporal tracking in a\njoint-learning framework. Our method demonstrates significant efficiency and\noutperforms prior work on tasks including cognitive load estimation, eye\nlandmark detection, and blink estimation. We also introduce a large-scale\ndataset of 30k human faces with joint pupil, eye-openness, and landmark\nannotation, which aims to support future HCI research on human factors and\neye-related analysis.\n","authors":["Li Ding","Jack Terwilliger","Aishni Parab","Meng Wang","Lex Fridman","Bruce Mehler","Bryan Reimer"],"pdf_url":"https://arxiv.org/pdf/2306.15073v1.pdf","comment":"ACM Transactions on Computer-Human Interaction"},{"id":"http://arxiv.org/abs/2306.15045v1","updated":"2023-06-26T20:04:23Z","published":"2023-06-26T20:04:23Z","title":"Action Anticipation with Goal Consistency","summary":"  In this paper, we address the problem of short-term action anticipation,\ni.e., we want to predict an upcoming action one second before it happens. We\npropose to harness high-level intent information to anticipate actions that\nwill take place in the future. To this end, we incorporate an additional goal\nprediction branch into our model and propose a consistency loss function that\nencourages the anticipated actions to conform to the high-level goal pursued in\nthe video. In our experiments, we show the effectiveness of the proposed\napproach and demonstrate that our method achieves state-of-the-art results on\ntwo large-scale datasets: Assembly101 and COIN.\n","authors":["Olga Zatsarynna","Juergen Gall"],"pdf_url":"https://arxiv.org/pdf/2306.15045v1.pdf","comment":"Accepted to ICIP 2023"},{"id":"http://arxiv.org/abs/2306.11180v2","updated":"2023-06-26T20:03:07Z","published":"2023-06-19T22:07:20Z","title":"Hyperbolic Active Learning for Semantic Segmentation under Domain Shift","summary":"  For the task of semantic segmentation (SS) under domain shift, active\nlearning (AL) acquisition strategies based on image regions and pseudo labels\nare state-of-the-art (SoA). The presence of diverse pseudo-labels within a\nregion identifies pixels between different classes, which is a labeling\nefficient active learning data acquisition strategy. However, by design,\npseudo-label variations are limited to only select the contours of classes,\nlimiting the final AL performance. We approach AL for SS in the Poincar\\'e\nhyperbolic ball model for the first time and leverage the variations of the\nradii of pixel embeddings within regions as a novel data acquisition strategy.\nThis stems from a novel geometric property of a hyperbolic space trained\nwithout enforced hierarchies, which we experimentally prove. Namely, classes\nare mapped into compact hyperbolic areas with a comparable intra-class radii\nvariance, as the model places classes of increasing explainable difficulty at\ndenser hyperbolic areas, i.e. closer to the Poincar\\'e ball edge. The variation\nof pixel embedding radii identifies well the class contours, but they also\nselect a few intra-class peculiar details, which boosts the final performance.\nOur proposed HALO (Hyperbolic Active Learning Optimization) surpasses the\nsupervised learning performance for the first time in AL for SS under domain\nshift, by only using a small portion of labels (i.e., 1%). The extensive\nexperimental analysis is based on two established benchmarks, i.e. GTAV\n$\\rightarrow$ Cityscapes and SYNTHIA $\\rightarrow$ Cityscapes, where we set a\nnew SoA. The code will be released.\n","authors":["Luca Franco","Paolo Mandica","Konstantinos Kallidromitis","Devin Guillory","Yu-Teng Li","Fabio Galasso"],"pdf_url":"https://arxiv.org/pdf/2306.11180v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15035v1","updated":"2023-06-26T19:49:44Z","published":"2023-06-26T19:49:44Z","title":"Optimized Vectorizing of Building Structures with Swap: High-Efficiency\n  Convolutional Channel-Swap Hybridization Strategy","summary":"  The building planar graph reconstruction, a.k.a. footprint reconstruction,\nwhich lies in the domain of computer vision and geoinformatics, has been long\nafflicted with the challenge of redundant parameters in conventional\nconvolutional models. Therefore, in this paper, we proposed an advanced and\nadaptive shift architecture, namely the Swap operation, which incorporates\nnon-exponential growth parameters while retaining analogous functionalities to\nintegrate local feature spatial information, resembling a high-dimensional\nconvolution operator. The Swap, cross-channel operation, architecture\nimplements the XOR operation to alternately exchange adjacent or diagonal\nfeatures, and then blends alternating channels through a 1x1 convolution\noperation to consolidate information from different channels. The SwapNN\narchitecture, on the other hand, incorporates a group-based parameter-sharing\nmechanism inspired by the convolutional neural network process and thereby\nsignificantly reducing the number of parameters. We validated our proposed\napproach through experiments on the SpaceNet corpus, a publicly available\ndataset annotated with 2,001 buildings across the cities of Los Angeles, Las\nVegas, and Paris. Our results demonstrate the effectiveness of this innovative\narchitecture in building planar graph reconstruction from 2D building images.\n","authors":["Moule Lin","Weipeng Jing","Chao Li","András Jung"],"pdf_url":"https://arxiv.org/pdf/2306.15035v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2306.15010v1","updated":"2023-06-26T18:49:09Z","published":"2023-06-26T18:49:09Z","title":"Efficient High-Resolution Template Matching with Vector Quantized\n  Nearest Neighbour Fields","summary":"  Template matching is a fundamental problem in computer vision and has\napplications in various fields, such as object detection, image registration,\nand object tracking. The current state-of-the-art methods rely on\nnearest-neighbour (NN) matching in which the query feature space is converted\nto NN space by representing each query pixel with its NN in the template\npixels. The NN-based methods have been shown to perform better in occlusions,\nchanges in appearance, illumination variations, and non-rigid transformations.\nHowever, NN matching scales poorly with high-resolution data and high feature\ndimensions. In this work, we present an NN-based template-matching method which\nefficiently reduces the NN computations and introduces filtering in the NN\nfields to consider deformations. A vector quantization step first represents\nthe template with $k$ features, then filtering compares the template and query\ndistributions over the $k$ features. We show that state-of-the-art performance\nwas achieved in low-resolution data, and our method outperforms previous\nmethods at higher resolution showing the robustness and scalability of the\napproach.\n","authors":["Ankit Gupta","Ida-Maria Sintorn"],"pdf_url":"https://arxiv.org/pdf/2306.15010v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.08229v2","updated":"2023-06-26T18:48:59Z","published":"2023-05-14T19:22:51Z","title":"A Hybrid 3D Eddy Detection Technique Based on Sea Surface Height and\n  Velocity Field","summary":"  Eddy detection is a critical task for ocean scientists to understand and\nanalyze ocean circulation. In this paper, we introduce a hybrid eddy detection\napproach that combines sea surface height (SSH) and velocity fields with\ngeometric criteria defining eddy behavior. Our approach searches for SSH minima\nand maxima, which oceanographers expect to find at the center of eddies.\nGeometric criteria are used to verify expected velocity field properties, such\nas net rotation and symmetry, by tracing velocity components along a circular\npath surrounding each eddy center. Progressive searches outward and into deeper\nlayers yield each eddy's 3D region of influence. Isolation of each eddy\nstructure from the dataset, using it's cylindrical footprint, facilitates\nvisualization of internal eddy structures using horizontal velocity, vertical\nvelocity, temperature and salinity. A quantitative comparison of Okubo-Weiss\nvorticity (OW) thresholding, the standard winding angle, and this new\nSSH-velocity hybrid methods of eddy detection as applied to the Red Sea dataset\nsuggests that detection results are highly dependent on the choices of method,\nthresholds, and criteria. Our new SSH-velocity hybrid detection approach has\nthe advantages of providing eddy structures with verified rotation properties,\n3D visualization of the internal structure of physical properties, and rapid\nefficient estimations of eddy footprints without calculating streamlines. Our\napproach combines visualization of internal structure and tracking overall\nmovement to support the study of the transport mechanisms key to understanding\nthe interaction of nutrient distribution and ocean circulation. Our method is\napplied to three different datasets to showcase the generality of its\napplication.\n","authors":["Weiping Hua","Karen Bemis","Dujuan Kang","Sedat Ozer","Deborah Silver"],"pdf_url":"https://arxiv.org/pdf/2305.08229v2.pdf","comment":"8 pages, 14 figures. Accepted by EnvirVis 2023. Project Link:\n  https://github.com/VizlabRutgers/Feature_Tracking"},{"id":"http://arxiv.org/abs/2306.15008v1","updated":"2023-06-26T18:46:47Z","published":"2023-06-26T18:46:47Z","title":"Spectral Analysis of Marine Debris in Simulated and Observed\n  Sentinel-2/MSI Images using Unsupervised Classification","summary":"  Marine litter poses significant threats to marine and coastal environments,\nwith its impacts ever-growing. Remote sensing provides an advantageous\nsupplement to traditional mitigation techniques, such as local cleaning\noperations and trawl net surveys, due to its capabilities for extensive\ncoverage and frequent observation. In this study, we used Radiative Transfer\nModel (RTM) simulated data and data from the Multispectral Instrument (MSI) of\nthe Sentinel-2 mission in combination with machine learning algorithms. Our aim\nwas to study the spectral behavior of marine plastic pollution and evaluate the\napplicability of RTMs within this research area. The results from the\nexploratory analysis and unsupervised classification using the KMeans algorithm\nindicate that the spectral behavior of pollutants is influenced by factors such\nas the type of polymer and pixel coverage percentage. The findings also reveal\nspectral characteristics and trends of association and differentiation among\nelements. The applied methodology is strongly dependent on the data, and if\nreapplied in new, more diverse, and detailed datasets, it can potentially\ngenerate even better results. These insights can guide future research in\nremote sensing applications for detecting marine plastic pollution.\n","authors":["Bianca Matos de Barros","Douglas Galimberti Barbosa","Cristiano Lima Hackmann"],"pdf_url":"https://arxiv.org/pdf/2306.15008v1.pdf","comment":"Manuscript submitted to Ocean and Coastal Research journal"},{"id":"http://arxiv.org/abs/2211.02892v2","updated":"2023-06-26T18:41:15Z","published":"2022-11-05T12:20:01Z","title":"SizeGAN: Improving Size Representation in Clothing Catalogs","summary":"  Online clothing catalogs lack diversity in body shape and garment size.\nBrands commonly display their garments on models of one or two sizes, rarely\nincluding plus-size models. To our knowledge, our paper presents the first\nmethod for generating images of garments and models in a new target size to\ntackle the size under-representation problem. Our primary technical\ncontribution is a conditional generative adversarial network that learns\ndeformation fields at multiple resolutions to realistically change the size of\nmodels and garments. Results from our two user studies show SizeGAN outperforms\nalternative methods along three dimensions -- realism, garment faithfulness,\nand size -- which are all important for real world use.\n","authors":["Kathleen M. Lewis","John Guttag"],"pdf_url":"https://arxiv.org/pdf/2211.02892v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14941v1","updated":"2023-06-26T17:54:24Z","published":"2023-06-26T17:54:24Z","title":"SIMF: Semantics-aware Interactive Motion Forecasting for Autonomous\n  Driving","summary":"  Autonomous vehicles require motion forecasting of their surrounding\nmulti-agents (pedestrians and vehicles) to make optimal decisions for\nnavigation. The existing methods focus on techniques to utilize the positions\nand velocities of these agents and fail to capture semantic information from\nthe scene. Moreover, to mitigate the increase in computational complexity\nassociated with the number of agents in the scene, some works leverage\nEuclidean distance to prune far-away agents. However, distance-based metric\nalone is insufficient to select relevant agents and accurately perform their\npredictions. To resolve these issues, we propose Semantics-aware Interactive\nMotion Forecasting (SIMF) method to capture semantics along with spatial\ninformation, and optimally select relevant agents for motion prediction.\nSpecifically, we achieve this by implementing a semantic-aware selection of\nrelevant agents from the scene and passing them through an attention mechanism\nto extract global encodings. These encodings along with agents' local\ninformation are passed through an encoder to obtain time-dependent latent\nvariables for a motion policy predicting the future trajectories. Our results\nshow that the proposed approach outperforms state-of-the-art baselines and\nprovides more accurate predictions in a scene-consistent manner.\n","authors":["Vidyaa Krishnan Nivash","Ahmed H. Qureshi"],"pdf_url":"https://arxiv.org/pdf/2306.14941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2103.03102v5","updated":"2023-06-26T17:50:00Z","published":"2021-03-02T02:10:54Z","title":"Benchmarking Robustness of Deep Learning Classifiers Using Two-Factor\n  Perturbation","summary":"  This paper adds to the fundamental body of work on benchmarking the\nrobustness of deep learning (DL) classifiers. We innovate a new benchmarking\nmethodology to evaluate robustness of DL classifiers. Also, we introduce a new\nfour-quadrant statistical visualization tool, including minimum accuracy,\nmaximum accuracy, mean accuracy, and coefficient of variation, for benchmarking\nrobustness of DL classifiers. To measure robust DL classifiers, we created a\ncomprehensive 69 benchmarking image set, including a clean set, sets with\nsingle factor perturbations, and sets with two-factor perturbation conditions.\nAfter collecting experimental results, we first report that using two-factor\nperturbed images improves both robustness and accuracy of DL classifiers. The\ntwo-factor perturbation includes (1) two digital perturbations (salt & pepper\nnoise and Gaussian noise) applied in both sequences, and (2) one digital\nperturbation (salt & pepper noise) and a geometric perturbation (rotation)\napplied in both sequences. All source codes, related image sets, and\npreliminary data, figures are shared on a GitHub website to support future\nacademic research and industry projects. The web resources locate at\nhttps://github.com/caperock/robustai\n","authors":["Wei Dai","Daniel Berleant"],"pdf_url":"https://arxiv.org/pdf/2103.03102v5.pdf","comment":"An updated version of the same title is at: arXiv:2203.01323"},{"id":"http://arxiv.org/abs/2306.14937v1","updated":"2023-06-26T15:37:04Z","published":"2023-06-26T15:37:04Z","title":"Minimum Description Length Clustering to Measure Meaningful Image\n  Complexity","summary":"  Existing image complexity metrics cannot distinguish meaningful content from\nnoise. This means that white noise images, which contain no meaningful\ninformation, are judged as highly complex. We present a new image complexity\nmetric through hierarchical clustering of patches. We use the minimum\ndescription length principle to determine the number of clusters and designate\ncertain points as outliers and, hence, correctly assign white noise a low\nscore. The presented method has similarities to theoretical ideas for measuring\nmeaningful complexity. We conduct experiments on seven different sets of\nimages, which show that our method assigns the most accurate scores to all\nimages considered. Additionally, comparing the different levels of the\nhierarchy of clusters can reveal how complexity manifests at different scales,\nfrom local detail to global structure. We then present ablation studies showing\nthe contribution of the components of our method, and that it continues to\nassign reasonable scores when the inputs are modified in certain ways,\nincluding the addition of Gaussian noise and the lowering of the resolution.\n","authors":["Louis Mahon","Thomas Lukasiewicz"],"pdf_url":"https://arxiv.org/pdf/2306.14937v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2306.14834v1","updated":"2023-06-26T16:39:39Z","published":"2023-06-26T16:39:39Z","title":"Scalable Neural Contextual Bandit for Recommender Systems","summary":"  High-quality recommender systems ought to deliver both innovative and\nrelevant content through effective and exploratory interactions with users.\nYet, supervised learning-based neural networks, which form the backbone of many\nexisting recommender systems, only leverage recognized user interests, falling\nshort when it comes to efficiently uncovering unknown user preferences. While\nthere has been some progress with neural contextual bandit algorithms towards\nenabling online exploration through neural networks, their onerous\ncomputational demands hinder widespread adoption in real-world recommender\nsystems. In this work, we propose a scalable sample-efficient neural contextual\nbandit algorithm for recommender systems. To do this, we design an epistemic\nneural network architecture, Epistemic Neural Recommendation (ENR), that\nenables Thompson sampling at a large scale. In two distinct large-scale\nexperiments with real-world tasks, ENR significantly boosts click-through rates\nand user ratings by at least 9% and 6% respectively compared to\nstate-of-the-art neural contextual bandit algorithms. Furthermore, it achieves\nequivalent performance with at least 29% fewer user interactions compared to\nthe best-performing baseline algorithm. Remarkably, while accomplishing these\nimprovements, ENR demands orders of magnitude fewer computational resources\nthan neural contextual bandit baseline algorithms.\n","authors":["Zheqing Zhu","Benjamin Van Roy"],"pdf_url":"https://arxiv.org/pdf/2306.14834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.10149v2","updated":"2023-06-26T15:43:04Z","published":"2023-04-20T08:16:07Z","title":"Is ChatGPT a Good Recommender? A Preliminary Study","summary":"  Recommendation systems have witnessed significant advancements and have been\nwidely used over the past decades. However, most traditional recommendation\nmethods are task-specific and therefore lack efficient generalization ability.\nRecently, the emergence of ChatGPT has significantly advanced NLP tasks by\nenhancing the capabilities of conversational models. Nonetheless, the\napplication of ChatGPT in the recommendation domain has not been thoroughly\ninvestigated. In this paper, we employ ChatGPT as a general-purpose\nrecommendation model to explore its potential for transferring extensive\nlinguistic and world knowledge acquired from large-scale corpora to\nrecommendation scenarios. Specifically, we design a set of prompts and evaluate\nChatGPT's performance on five recommendation scenarios. Unlike traditional\nrecommendation methods, we do not fine-tune ChatGPT during the entire\nevaluation process, relying only on the prompts themselves to convert\nrecommendation tasks into natural language tasks. Further, we explore the use\nof few-shot prompting to inject interaction information that contains user\npotential interest to help ChatGPT better understand user needs and interests.\nComprehensive experimental results on Amazon Beauty dataset show that ChatGPT\nhas achieved promising results in certain tasks and is capable of reaching the\nbaseline level in others. We conduct human evaluations on two\nexplainability-oriented tasks to more accurately evaluate the quality of\ncontents generated by different models. And the human evaluations show ChatGPT\ncan truly understand the provided information and generate clearer and more\nreasonable results. We hope that our study can inspire researchers to further\nexplore the potential of language models like ChatGPT to improve recommendation\nperformance and contribute to the advancement of the recommendation systems\nfield.\n","authors":["Junling Liu","Chao Liu","Peilin Zhou","Renjie Lv","Kang Zhou","Yan Zhang"],"pdf_url":"https://arxiv.org/pdf/2304.10149v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14712v1","updated":"2023-06-26T14:01:19Z","published":"2023-06-26T14:01:19Z","title":"Reciprocal Sequential Recommendation","summary":"  Reciprocal recommender system (RRS), considering a two-way matching between\ntwo parties, has been widely applied in online platforms like online dating and\nrecruitment. Existing RRS models mainly capture static user preferences, which\nhave neglected the evolving user tastes and the dynamic matching relation\nbetween the two parties. Although dynamic user modeling has been well-studied\nin sequential recommender systems, existing solutions are developed in a\nuser-oriented manner. Therefore, it is non-trivial to adapt sequential\nrecommendation algorithms to reciprocal recommendation. In this paper, we\nformulate RRS as a distinctive sequence matching task, and further propose a\nnew approach ReSeq for RRS, which is short for Reciprocal Sequential\nrecommendation. To capture dual-perspective matching, we propose to learn\nfine-grained sequence similarities by co-attention mechanism across different\ntime steps. Further, to improve the inference efficiency, we introduce the\nself-distillation technique to distill knowledge from the fine-grained matching\nmodule into the more efficient student module. In the deployment stage, only\nthe efficient student module is used, greatly speeding up the similarity\ncomputation. Extensive experiments on five real-world datasets from two\nscenarios demonstrate the effectiveness and efficiency of the proposed method.\nOur code is available at https://github.com/RUCAIBox/ReSeq/.\n","authors":["Bowen Zheng","Yupeng Hou","Wayne Xin Zhao","Yang Song","Hengshu Zhu"],"pdf_url":"https://arxiv.org/pdf/2306.14712v1.pdf","comment":"Accepted by RecSys 2023"},{"id":"http://arxiv.org/abs/2306.14644v1","updated":"2023-06-26T12:30:20Z","published":"2023-06-26T12:30:20Z","title":"PTVD: A Large-Scale Plot-Oriented Multimodal Dataset Based on Television\n  Dramas","summary":"  Art forms such as movies and television (TV) dramas are reflections of the\nreal world, which have attracted much attention from the multimodal learning\ncommunity recently. However, existing corpora in this domain share three\nlimitations: (1) annotated in a scene-oriented fashion, they ignore the\ncoherence within plots; (2) their text lacks empathy and seldom mentions\nsituational context; (3) their video clips fail to cover long-form relationship\ndue to short duration. To address these fundamental issues, using 1,106 TV\ndrama episodes and 24,875 informative plot-focused sentences written by\nprofessionals, with the help of 449 human annotators, we constructed PTVD, the\nfirst plot-oriented multimodal dataset in the TV domain. It is also the first\nnon-English dataset of its kind. Additionally, PTVD contains more than 26\nmillion bullet screen comments (BSCs), powering large-scale pre-training. Next,\naiming to open-source a strong baseline for follow-up works, we developed the\nmultimodal algorithm that attacks different cinema/TV modelling problems with a\nunified architecture. Extensive experiments on three cognitive-inspired tasks\nyielded a number of novel observations (some of them being quite\ncounter-intuition), further validating the value of PTVD in promoting\nmultimodal research. The dataset and codes are released at\n\\url{https://ptvd.github.io/}.\n","authors":["Chen Li","Xutan Peng","Teng Wang","Yixiao Ge","Mengyang Liu","Xuyuan Xu","Yexin Wang","Ying Shan"],"pdf_url":"https://arxiv.org/pdf/2306.14644v1.pdf","comment":"19 pages, 10 figures"},{"id":"http://arxiv.org/abs/2206.11561v3","updated":"2023-06-26T11:04:37Z","published":"2022-06-23T09:17:43Z","title":"ReuseKNN: Neighborhood Reuse for Differentially-Private KNN-Based\n  Recommendations","summary":"  User-based KNN recommender systems (UserKNN) utilize the rating data of a\ntarget user's k nearest neighbors in the recommendation process. This, however,\nincreases the privacy risk of the neighbors since their rating data might be\nexposed to other users or malicious parties. To reduce this risk, existing work\napplies differential privacy by adding randomness to the neighbors' ratings,\nwhich reduces the accuracy of UserKNN. In this work, we introduce ReuseKNN, a\nnovel differentially-private KNN-based recommender system. The main idea is to\nidentify small but highly reusable neighborhoods so that (i) only a minimal set\nof users requires protection with differential privacy, and (ii) most users do\nnot need to be protected with differential privacy, since they are only rarely\nexploited as neighbors. In our experiments on five diverse datasets, we make\ntwo key observations: Firstly, ReuseKNN requires significantly smaller\nneighborhoods, and thus, fewer neighbors need to be protected with differential\nprivacy compared to traditional UserKNN. Secondly, despite the small\nneighborhoods, ReuseKNN outperforms UserKNN and a fully differentially private\napproach in terms of accuracy. Overall, ReuseKNN leads to significantly less\nprivacy risk for users than in the case of UserKNN.\n","authors":["Peter Müllner","Elisabeth Lex","Markus Schedl","Dominik Kowald"],"pdf_url":"https://arxiv.org/pdf/2206.11561v3.pdf","comment":"29 pages, 10 figures, 6 tables, accepted at TIST"},{"id":"http://arxiv.org/abs/2306.14462v1","updated":"2023-06-26T07:04:47Z","published":"2023-06-26T07:04:47Z","title":"Multi-task Item-attribute Graph Pre-training for Strict Cold-start Item\n  Recommendation","summary":"  Recommendation systems suffer in the strict cold-start (SCS) scenario, where\nthe user-item interactions are entirely unavailable. The ID-based approaches\ncompletely fail to work. Cold-start recommenders, on the other hand, leverage\nitem contents to map the new items to the existing ones. However, the existing\nSCS recommenders explore item contents in coarse-grained manners that introduce\nnoise or information loss. Moreover, informative data sources other than item\ncontents, such as users' purchase sequences and review texts, are ignored. We\nexplore the role of the fine-grained item attributes in bridging the gaps\nbetween the existing and the SCS items and pre-train a knowledgeable\nitem-attribute graph for SCS item recommendation. Our proposed framework,\nColdGPT, models item-attribute correlations into an item-attribute graph by\nextracting fine-grained attributes from item contents. ColdGPT then transfers\nknowledge into the item-attribute graph from various available data sources,\ni.e., item contents, historical purchase sequences, and review texts of the\nexisting items, via multi-task learning. To facilitate the positive transfer,\nColdGPT designs submodules according to the natural forms of the data sources\nand coordinates the multiple pre-training tasks via unified\nalignment-and-uniformity losses. Our pre-trained item-attribute graph acts as\nan implicit, extendable item embedding matrix, which enables the SCS item\nembeddings to be easily acquired by inserting these items and propagating their\nattributes' embeddings. We carefully process three public datasets, i.e., Yelp,\nAmazon-home, and Amazon-sports, to guarantee the SCS setting for evaluation.\nExtensive experiments show that ColdGPT consistently outperforms the existing\nSCS recommenders by large margins and even surpasses models that are\npre-trained on 75-224 times more, cross-domain data on two out of four\ndatasets.\n","authors":["Yuwei Cao","Liangwei Yang","Chen Wang","Zhiwei Liu","Hao Peng","Chenyu You","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2306.14462v1.pdf","comment":"This work has been accepted as a FULL paper in RecSys 2023"},{"id":"http://arxiv.org/abs/2306.14400v1","updated":"2023-06-26T03:23:53Z","published":"2023-06-26T03:23:53Z","title":"Contrastive Multi-view Framework for Customer Lifetime Value Prediction","summary":"  Accurate customer lifetime value (LTV) prediction can help service providers\noptimize their marketing policies in customer-centric applications. However,\nthe heavy sparsity of consumption events and the interference of data variance\nand noise obstruct LTV estimation. Many existing LTV prediction methods\ndirectly train a single-view LTV predictor on consumption samples, which may\nyield inaccurate and even biased knowledge extraction. In this paper, we\npropose a contrastive multi-view framework for LTV prediction, which is a\nplug-and-play solution compatible with various backbone models. It synthesizes\nmultiple heterogeneous LTV regressors with complementary knowledge to improve\nmodel robustness and captures sample relatedness via contrastive learning to\nmitigate the dependency on data abundance. Concretely, we use a decomposed\nscheme that converts the LTV prediction problem into a combination of\nestimating consumption probability and payment amount. To alleviate the impact\nof noisy data on model learning, we propose a multi-view framework that jointly\noptimizes multiple types of regressors with diverse characteristics and\nadvantages to encode and fuse comprehensive knowledge. To fully exploit the\npotential of limited training samples, we propose a hybrid contrastive learning\nmethod to help capture the relatedness between samples in both classification\nand regression tasks. We conduct extensive experiments on a real-world game LTV\nprediction dataset and the results validate the effectiveness of our method. We\nhave deployed our solution online in Huawei's mobile game center and achieved\n32.26% of total payment amount gains.\n","authors":["Chuhan Wu","Jingjie Li","Qinglin Jia","Hong Zhu","Yuan Fang","Ruiming Tang"],"pdf_url":"https://arxiv.org/pdf/2306.14400v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15098v1","updated":"2023-06-26T22:31:15Z","published":"2023-06-26T22:31:15Z","title":"Off-Policy Evaluation of Ranking Policies under Diverse User Behavior","summary":"  Ranking interfaces are everywhere in online platforms. There is thus an ever\ngrowing interest in their Off-Policy Evaluation (OPE), aiming towards an\naccurate performance evaluation of ranking policies using logged data. A\nde-facto approach for OPE is Inverse Propensity Scoring (IPS), which provides\nan unbiased and consistent value estimate. However, it becomes extremely\ninaccurate in the ranking setup due to its high variance under large action\nspaces. To deal with this problem, previous studies assume either independent\nor cascade user behavior, resulting in some ranking versions of IPS. While\nthese estimators are somewhat effective in reducing the variance, all existing\nestimators apply a single universal assumption to every user, causing excessive\nbias and variance. Therefore, this work explores a far more general formulation\nwhere user behavior is diverse and can vary depending on the user context. We\nshow that the resulting estimator, which we call Adaptive IPS (AIPS), can be\nunbiased under any complex user behavior. Moreover, AIPS achieves the minimum\nvariance among all unbiased estimators based on IPS. We further develop a\nprocedure to identify the appropriate user behavior model to minimize the mean\nsquared error (MSE) of AIPS in a data-driven fashion. Extensive experiments\ndemonstrate that the empirical accuracy improvement can be significant,\nenabling effective OPE of ranking systems even under diverse user behavior.\n","authors":["Haruka Kiyohara","Masatoshi Uehara","Yusuke Narita","Nobuyuki Shimizu","Yasuo Yamamoto","Yuta Saito"],"pdf_url":"https://arxiv.org/pdf/2306.15098v1.pdf","comment":"KDD2023 Research track"},{"id":"http://arxiv.org/abs/2305.13250v2","updated":"2023-06-26T19:11:30Z","published":"2023-05-22T17:22:37Z","title":"Copy Recurrent Neural Network Structure Network","summary":"  Electronic Health Record (EHR) coding involves automatically classifying EHRs\ninto diagnostic codes. While most previous research treats this as a\nmulti-label classification task, generating probabilities for each code and\nselecting those above a certain threshold as labels, these approaches often\noverlook the challenge of identifying complex diseases. In this study, our\nfocus is on detecting complication diseases within EHRs.\n  We propose a novel coarse-to-fine ICD path generation framework called the\nCopy Recurrent Neural Network Structure Network (CRNNet), which employs a Path\nGenerator (PG) and a Path Discriminator (PD) for EHR coding. By using RNNs to\ngenerate sequential outputs and incorporating a copy module, we efficiently\nidentify complication diseases. Our method achieves a 57.30\\% ratio of complex\ndiseases in predictions, outperforming state-of-the-art and previous\napproaches.\n  Additionally, through an ablation study, we demonstrate that the copy\nmechanism plays a crucial role in detecting complex diseases.\n","authors":["Xiaofan Zhou","Xunzhu Tang"],"pdf_url":"https://arxiv.org/pdf/2305.13250v2.pdf","comment":"Need modification"},{"id":"http://arxiv.org/abs/2306.15010v1","updated":"2023-06-26T18:49:09Z","published":"2023-06-26T18:49:09Z","title":"Efficient High-Resolution Template Matching with Vector Quantized\n  Nearest Neighbour Fields","summary":"  Template matching is a fundamental problem in computer vision and has\napplications in various fields, such as object detection, image registration,\nand object tracking. The current state-of-the-art methods rely on\nnearest-neighbour (NN) matching in which the query feature space is converted\nto NN space by representing each query pixel with its NN in the template\npixels. The NN-based methods have been shown to perform better in occlusions,\nchanges in appearance, illumination variations, and non-rigid transformations.\nHowever, NN matching scales poorly with high-resolution data and high feature\ndimensions. In this work, we present an NN-based template-matching method which\nefficiently reduces the NN computations and introduces filtering in the NN\nfields to consider deformations. A vector quantization step first represents\nthe template with $k$ features, then filtering compares the template and query\ndistributions over the $k$ features. We show that state-of-the-art performance\nwas achieved in low-resolution data, and our method outperforms previous\nmethods at higher resolution showing the robustness and scalability of the\napproach.\n","authors":["Ankit Gupta","Ida-Maria Sintorn"],"pdf_url":"https://arxiv.org/pdf/2306.15010v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2306.14898v1","updated":"2023-06-26T17:59:50Z","published":"2023-06-26T17:59:50Z","title":"InterCode: Standardizing and Benchmarking Interactive Coding with\n  Execution Feedback","summary":"  Humans write code in a fundamentally interactive manner and rely on constant\nexecution feedback to correct errors, resolve ambiguities, and decompose tasks.\nWhile LLMs have recently exhibited promising coding capabilities, current\ncoding benchmarks mostly consider a static instruction-to-code sequence\ntransduction process, which has the potential for error propagation and a\ndisconnect between the generated code and its final execution environment. To\naddress this gap, we introduce InterCode, a lightweight, flexible, and\neasy-to-use framework of interactive coding as a standard reinforcement\nlearning (RL) environment, with code as actions and execution feedback as\nobservations. Our framework is language and platform agnostic, uses\nself-contained Docker environments to provide safe and reproducible execution,\nand is compatible out-of-the-box with traditional seq2seq coding methods, while\nenabling the development of new methods for interactive code generation. We use\nInterCode to create two interactive code environments with Bash and SQL as\naction spaces, leveraging data from the static Spider and NL2Bash datasets. We\ndemonstrate InterCode's viability as a testbed by evaluating multiple\nstate-of-the-art LLMs configured with different prompting strategies such as\nReAct and Plan & Solve. Our results showcase the benefits of interactive code\ngeneration and demonstrate that InterCode can serve as a challenging benchmark\nfor advancing code understanding and generation capabilities. InterCode is\ndesigned to be easily extensible and can even be used to incorporate new tasks\nsuch as Capture the Flag, a popular coding puzzle that is inherently multi-step\nand involves multiple programming languages. Project site with code and data:\nhttps://intercode-benchmark.github.io\n","authors":["John Yang","Akshara Prabhakar","Karthik Narasimhan","Shunyu Yao"],"pdf_url":"https://arxiv.org/pdf/2306.14898v1.pdf","comment":"Project site with code and data:\n  https://intercode-benchmark.github.io"},{"id":"http://arxiv.org/abs/2306.14893v1","updated":"2023-06-26T17:59:24Z","published":"2023-06-26T17:59:24Z","title":"LongCoder: A Long-Range Pre-trained Language Model for Code Completion","summary":"  In this paper, we introduce a new task for code completion that focuses on\nhandling long code input and propose a sparse Transformer model, called\nLongCoder, to address this task. LongCoder employs a sliding window mechanism\nfor self-attention and introduces two types of globally accessible tokens -\nbridge tokens and memory tokens - to improve performance and efficiency. Bridge\ntokens are inserted throughout the input sequence to aggregate local\ninformation and facilitate global interaction, while memory tokens are included\nto highlight important statements that may be invoked later and need to be\nmemorized, such as package imports and definitions of classes, functions, or\nstructures. We conduct experiments on a newly constructed dataset that contains\nlonger code context and the publicly available CodeXGLUE benchmark.\nExperimental results demonstrate that LongCoder achieves superior performance\non code completion tasks compared to previous models while maintaining\ncomparable efficiency in terms of computational resources during inference. All\nthe codes and data are available at https://github.com/microsoft/CodeBERT.\n","authors":["Daya Guo","Canwen Xu","Nan Duan","Jian Yin","Julian McAuley"],"pdf_url":"https://arxiv.org/pdf/2306.14893v1.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2306.14892v1","updated":"2023-06-26T17:58:50Z","published":"2023-06-26T17:58:50Z","title":"Supervised Pretraining Can Learn In-Context Reinforcement Learning","summary":"  Large transformer models trained on diverse datasets have shown a remarkable\nability to learn in-context, achieving high few-shot performance on tasks they\nwere not explicitly trained to solve. In this paper, we study the in-context\nlearning capabilities of transformers in decision-making problems, i.e.,\nreinforcement learning (RL) for bandits and Markov decision processes. To do\nso, we introduce and study Decision-Pretrained Transformer (DPT), a supervised\npretraining method where the transformer predicts an optimal action given a\nquery state and an in-context dataset of interactions, across a diverse set of\ntasks. This procedure, while simple, produces a model with several surprising\ncapabilities. We find that the pretrained transformer can be used to solve a\nrange of RL problems in-context, exhibiting both exploration online and\nconservatism offline, despite not being explicitly trained to do so. The model\nalso generalizes beyond the pretraining distribution to new tasks and\nautomatically adapts its decision-making strategies to unknown structure.\nTheoretically, we show DPT can be viewed as an efficient implementation of\nBayesian posterior sampling, a provably sample-efficient RL algorithm. We\nfurther leverage this connection to provide guarantees on the regret of the\nin-context algorithm yielded by DPT, and prove that it can learn faster than\nalgorithms used to generate the pretraining data. These results suggest a\npromising yet simple path towards instilling strong in-context decision-making\nabilities in transformers.\n","authors":["Jonathan N. Lee","Annie Xie","Aldo Pacchiano","Yash Chandak","Chelsea Finn","Ofir Nachum","Emma Brunskill"],"pdf_url":"https://arxiv.org/pdf/2306.14892v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14891v1","updated":"2023-06-26T17:58:00Z","published":"2023-06-26T17:58:00Z","title":"Fuzzy-Conditioned Diffusion and Diffusion Projection Attention Applied\n  to Facial Image Correction","summary":"  Image diffusion has recently shown remarkable performance in image synthesis\nand implicitly as an image prior. Such a prior has been used with conditioning\nto solve the inpainting problem, but only supporting binary user-based\nconditioning. We derive a fuzzy-conditioned diffusion, where implicit diffusion\npriors can be exploited with controllable strength. Our fuzzy conditioning can\nbe applied pixel-wise, enabling the modification of different image components\nto varying degrees. Additionally, we propose an application to facial image\ncorrection, where we combine our fuzzy-conditioned diffusion with\ndiffusion-derived attention maps. Our map estimates the degree of anomaly, and\nwe obtain it by projecting on the diffusion space. We show how our approach\nalso leads to interpretable and autonomous facial image correction.\n","authors":["Majed El Helou"],"pdf_url":"https://arxiv.org/pdf/2306.14891v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.09344v2","updated":"2023-06-26T17:57:37Z","published":"2023-06-15T17:59:50Z","title":"DreamSim: Learning New Dimensions of Human Visual Similarity using\n  Synthetic Data","summary":"  Current perceptual similarity metrics operate at the level of pixels and\npatches. These metrics compare images in terms of their low-level colors and\ntextures, but fail to capture mid-level similarities and differences in image\nlayout, object pose, and semantic content. In this paper, we develop a\nperceptual metric that assesses images holistically. Our first step is to\ncollect a new dataset of human similarity judgments over image pairs that are\nalike in diverse ways. Critical to this dataset is that judgments are nearly\nautomatic and shared by all observers. To achieve this we use recent\ntext-to-image models to create synthetic pairs that are perturbed along various\ndimensions. We observe that popular perceptual metrics fall short of explaining\nour new data, and we introduce a new metric, DreamSim, tuned to better align\nwith human perception. We analyze how our metric is affected by different\nvisual attributes, and find that it focuses heavily on foreground objects and\nsemantic content while also being sensitive to color and layout. Notably,\ndespite being trained on synthetic data, our metric generalizes to real images,\ngiving strong results on retrieval and reconstruction tasks. Furthermore, our\nmetric outperforms both prior learned metrics and recent large vision models on\nthese tasks.\n","authors":["Stephanie Fu","Netanel Tamir","Shobhita Sundaram","Lucy Chai","Richard Zhang","Tali Dekel","Phillip Isola"],"pdf_url":"https://arxiv.org/pdf/2306.09344v2.pdf","comment":"Website: https://dreamsim-nights.github.io/ Code:\n  https://github.com/ssundaram21/dreamsim; Fixed in-text citation, figure\n  alignment, and typos"},{"id":"http://arxiv.org/abs/2305.04876v2","updated":"2023-06-26T17:57:32Z","published":"2023-05-08T17:20:13Z","title":"Explainable Parallel RCNN with Novel Feature Representation for Time\n  Series Forecasting","summary":"  Accurate time series forecasting is a fundamental challenge in data science.\nIt is often affected by external covariates such as weather or human\nintervention, which in many applications, may be predicted with reasonable\naccuracy. We refer to them as predicted future covariates. However, existing\nmethods that attempt to predict time series in an iterative manner with\nautoregressive models end up with exponential error accumulations. Other\nstrategies hat consider the past and future in the encoder and decoder\nrespectively limit themselves by dealing with the historical and future data\nseparately. To address these limitations, a novel feature representation\nstrategy -- shifting -- is proposed to fuse the past data and future covariates\nsuch that their interactions can be considered. To extract complex dynamics in\ntime series, we develop a parallel deep learning framework composed of RNN and\nCNN, both of which are used hierarchically. We also utilize the skip connection\ntechnique to improve the model's performance. Extensive experiments on three\ndatasets reveal the effectiveness of our method. Finally, we demonstrate the\nmodel interpretability using the Grad-CAM algorithm.\n","authors":["Jimeng Shi","Rukmangadh Myana","Vitalii Stebliankin","Azam Shirali","Giri Narasimhan"],"pdf_url":"https://arxiv.org/pdf/2305.04876v2.pdf","comment":"20 pages, 12 figures"},{"id":"http://arxiv.org/abs/2306.14884v1","updated":"2023-06-26T17:53:05Z","published":"2023-06-26T17:53:05Z","title":"Learning to Modulate pre-trained Models in RL","summary":"  Reinforcement Learning (RL) has been successful in various domains like\nrobotics, game playing, and simulation. While RL agents have shown impressive\ncapabilities in their specific tasks, they insufficiently adapt to new tasks.\nIn supervised learning, this adaptation problem is addressed by large-scale\npre-training followed by fine-tuning to new down-stream tasks. Recently,\npre-training on multiple tasks has been gaining traction in RL. However,\nfine-tuning a pre-trained model often suffers from catastrophic forgetting,\nthat is, the performance on the pre-training tasks deteriorates when\nfine-tuning on new tasks. To investigate the catastrophic forgetting\nphenomenon, we first jointly pre-train a model on datasets from two benchmark\nsuites, namely Meta-World and DMControl. Then, we evaluate and compare a\nvariety of fine-tuning methods prevalent in natural language processing, both\nin terms of performance on new tasks, and how well performance on pre-training\ntasks is retained. Our study shows that with most fine-tuning approaches, the\nperformance on pre-training tasks deteriorates significantly. Therefore, we\npropose a novel method, Learning-to-Modulate (L2M), that avoids the degradation\nof learned skills by modulating the information flow of the frozen pre-trained\nmodel via a learnable modulation pool. Our method achieves state-of-the-art\nperformance on the Continual-World benchmark, while retaining performance on\nthe pre-training tasks. Finally, to aid future research in this area, we\nrelease a dataset encompassing 50 Meta-World and 16 DMControl tasks.\n","authors":["Thomas Schmied","Markus Hofmarcher","Fabian Paischer","Razvan Pascanu","Sepp Hochreiter"],"pdf_url":"https://arxiv.org/pdf/2306.14884v1.pdf","comment":"10 pages (+ references and appendix), Code:\n  https://github.com/ml-jku/L2M"},{"id":"http://arxiv.org/abs/2306.14878v1","updated":"2023-06-26T17:48:25Z","published":"2023-06-26T17:48:25Z","title":"Restart Sampling for Improving Generative Processes","summary":"  Generative processes that involve solving differential equations, such as\ndiffusion models, frequently necessitate balancing speed and quality. ODE-based\nsamplers are fast but plateau in performance while SDE-based samplers deliver\nhigher sample quality at the cost of increased sampling time. We attribute this\ndifference to sampling errors: ODE-samplers involve smaller discretization\nerrors while stochasticity in SDE contracts accumulated errors. Based on these\nfindings, we propose a novel sampling algorithm called Restart in order to\nbetter balance discretization errors and contraction. The sampling method\nalternates between adding substantial noise in additional forward steps and\nstrictly following a backward ODE. Empirically, Restart sampler surpasses\nprevious SDE and ODE samplers in both speed and accuracy. Restart not only\noutperforms the previous best SDE results, but also accelerates the sampling\nspeed by 10-fold / 2-fold on CIFAR-10 / ImageNet $64 \\times 64$. In addition,\nit attains significantly better sample quality than ODE samplers within\ncomparable sampling times. Moreover, Restart better balances text-image\nalignment/visual quality versus diversity than previous samplers in the\nlarge-scale text-to-image Stable Diffusion model pre-trained on LAION $512\n\\times 512$. Code is available at\nhttps://github.com/Newbeeer/diffusion_restart_sampling\n","authors":["Yilun Xu","Mingyang Deng","Xiang Cheng","Yonglong Tian","Ziming Liu","Tommi Jaakkola"],"pdf_url":"https://arxiv.org/pdf/2306.14878v1.pdf","comment":"Code is available at\n  https://github.com/Newbeeer/diffusion_restart_sampling"},{"id":"http://arxiv.org/abs/2306.14872v1","updated":"2023-06-26T17:38:45Z","published":"2023-06-26T17:38:45Z","title":"Geometry-Aware Approaches for Balancing Performance and Theoretical\n  Guarantees in Linear Bandits","summary":"  This paper is motivated by recent developments in the linear bandit\nliterature, which have revealed a discrepancy between the promising empirical\nperformance of algorithms such as Thompson sampling and Greedy, when compared\nto their pessimistic theoretical regret bounds. The challenge arises from the\nfact that while these algorithms may perform poorly in certain problem\ninstances, they generally excel in typical instances. To address this, we\npropose a new data-driven technique that tracks the geometry of the uncertainty\nellipsoid, enabling us to establish an instance-dependent frequentist regret\nbound for a broad class of algorithms, including Greedy, OFUL, and Thompson\nsampling. This result empowers us to identify and ``course-correct\" instances\nin which the base algorithms perform poorly. The course-corrected algorithms\nachieve the minimax optimal regret of order $\\tilde{\\mathcal{O}}(d\\sqrt{T})$,\nwhile retaining most of the desirable properties of the base algorithms. We\npresent simulation results to validate our findings and compare the performance\nof our algorithms with the baselines.\n","authors":["Yuwei Luo","Mohsen Bayati"],"pdf_url":"https://arxiv.org/pdf/2306.14872v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.09382v2","updated":"2023-06-26T17:31:30Z","published":"2023-06-15T12:59:04Z","title":"Sound Demixing Challenge 2023 Music Demixing Track Technical Report:\n  TFC-TDF-UNet v3","summary":"  In this report, we present our award-winning solutions for the Music Demixing\nTrack of Sound Demixing Challenge 2023. First, we propose TFC-TDF-UNet v3, a\ntime-efficient music source separation model that achieves state-of-the-art\nresults on the MUSDB benchmark. We then give full details regarding our\nsolutions for each Leaderboard, including a loss masking approach for\nnoise-robust training. Code for reproducing model training and final\nsubmissions is available at github.com/kuielab/sdx23.\n","authors":["Minseok Kim","Jun Hyung Lee","Soonyoung Jung"],"pdf_url":"https://arxiv.org/pdf/2306.09382v2.pdf","comment":"5 pages, 4 tables"},{"id":"http://arxiv.org/abs/2306.12001v2","updated":"2023-06-26T17:26:07Z","published":"2023-06-21T03:35:06Z","title":"An Overview of Catastrophic AI Risks","summary":"  Rapid advancements in artificial intelligence (AI) have sparked growing\nconcerns among experts, policymakers, and world leaders regarding the potential\nfor increasingly advanced AI systems to pose catastrophic risks. Although\nnumerous risks have been detailed separately, there is a pressing need for a\nsystematic discussion and illustration of the potential dangers to better\ninform efforts to mitigate them. This paper provides an overview of the main\nsources of catastrophic AI risks, which we organize into four categories:\nmalicious use, in which individuals or groups intentionally use AIs to cause\nharm; AI race, in which competitive environments compel actors to deploy unsafe\nAIs or cede control to AIs; organizational risks, highlighting how human\nfactors and complex systems can increase the chances of catastrophic accidents;\nand rogue AIs, describing the inherent difficulty in controlling agents far\nmore intelligent than humans. For each category of risk, we describe specific\nhazards, present illustrative stories, envision ideal scenarios, and propose\npractical suggestions for mitigating these dangers. Our goal is to foster a\ncomprehensive understanding of these risks and inspire collective and proactive\nefforts to ensure that AIs are developed and deployed in a safe manner.\nUltimately, we hope this will allow us to realize the benefits of this powerful\ntechnology while minimizing the potential for catastrophic outcomes.\n","authors":["Dan Hendrycks","Mantas Mazeika","Thomas Woodside"],"pdf_url":"https://arxiv.org/pdf/2306.12001v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13595v2","updated":"2023-06-26T17:18:16Z","published":"2023-06-23T16:35:00Z","title":"Autoencoders for Real-Time SUEP Detection","summary":"  Confining dark sectors with pseudo-conformal dynamics can produce Soft\nUnclustered Energy Patterns, or SUEPs, at the Large Hadron Collider: the\nproduction of dark quarks in proton-proton collisions leading to a dark shower\nand the high-multiplicity production of dark hadrons. The final experimental\nsignature is spherically-symmetric energy deposits by an anomalously large\nnumber of soft Standard Model particles with a transverse energy of a few\nhundred MeV. The dominant background for the SUEP search, if it gets produced\nvia gluon-gluon fusion, is multi-jet QCD events. We have developed a deep\nlearning-based Anomaly Detection technique to reject QCD jets and identify any\nanomalous signature, including SUEP, in real-time in the High-Level Trigger\nsystem of the Compact Muon Solenoid experiment at the Large Hadron Collider. A\ndeep convolutional neural autoencoder network has been trained using QCD events\nby taking transverse energy deposits in the inner tracker, electromagnetic\ncalorimeter, and hadron calorimeter sub-detectors as 3-channel image data. To\ntackle the biggest challenge of the task, due to the sparse nature of the data:\nonly ~0.5% of the total ~300 k image pixels have non-zero values, a\nnon-standard loss function, the inverse of the so-called Dice Loss, has been\nexploited. The trained autoencoder with learned spatial features of QCD jets\ncan detect 40% of the SUEP events, with a QCD event mistagging rate as low as\n2%. The model inference time has been measured using the Intel CoreTM i5-9600KF\nprocessor and found to be ~20 ms, which perfectly satisfies the High-Level\nTrigger system's latency of O(100) ms. Given the virtue of the unsupervised\nlearning of the autoencoders, the trained model can be applied to any new\nphysics model that predicts an experimental signature anomalous to QCD jets.\n","authors":["Simranjit Singh Chhibra","Nadezda Chernyavskaya","Benedikt Maier","Maurzio Pierini","Syed Hasan"],"pdf_url":"https://arxiv.org/pdf/2306.13595v2.pdf","comment":"9 pages, 9 figures, 1 table, 1 equation"},{"id":"http://arxiv.org/abs/2306.14861v1","updated":"2023-06-26T17:16:50Z","published":"2023-06-26T17:16:50Z","title":"Leveraging Task Structures for Improved Identifiability in Neural\n  Network Representations","summary":"  This work extends the theory of identifiability in supervised learning by\nconsidering the consequences of having access to a distribution of tasks. In\nsuch cases, we show that identifiability is achievable even in the case of\nregression, extending prior work restricted to the single-task classification\ncase. Furthermore, we show that the existence of a task distribution which\ndefines a conditional prior over latent variables reduces the equivalence class\nfor identifiability to permutations and scaling, a much stronger and more\nuseful result. When we further assume a causal structure over these tasks, our\napproach enables simple maximum marginal likelihood optimization together with\ndownstream applicability to causal representation learning. Empirically, we\nvalidate that our model outperforms more general unsupervised models in\nrecovering canonical representations for synthetic and real-world data.\n","authors":["Wenlin Chen","Julien Horwood","Juyeon Heo","José Miguel Hernández-Lobato"],"pdf_url":"https://arxiv.org/pdf/2306.14861v1.pdf","comment":"11 pages, 5 figures, 2 tables"},{"id":"http://arxiv.org/abs/2306.14859v1","updated":"2023-06-26T17:13:31Z","published":"2023-06-26T17:13:31Z","title":"Effective Minkowski Dimension of Deep Nonparametric Regression: Function\n  Approximation and Statistical Theories","summary":"  Existing theories on deep nonparametric regression have shown that when the\ninput data lie on a low-dimensional manifold, deep neural networks can adapt to\nthe intrinsic data structures. In real world applications, such an assumption\nof data lying exactly on a low dimensional manifold is stringent. This paper\nintroduces a relaxed assumption that the input data are concentrated around a\nsubset of $\\mathbb{R}^d$ denoted by $\\mathcal{S}$, and the intrinsic dimension\nof $\\mathcal{S}$ can be characterized by a new complexity notation -- effective\nMinkowski dimension. We prove that, the sample complexity of deep nonparametric\nregression only depends on the effective Minkowski dimension of $\\mathcal{S}$\ndenoted by $p$. We further illustrate our theoretical findings by considering\nnonparametric regression with an anisotropic Gaussian random design\n$N(0,\\Sigma)$, where $\\Sigma$ is full rank. When the eigenvalues of $\\Sigma$\nhave an exponential or polynomial decay, the effective Minkowski dimension of\nsuch an Gaussian random design is $p=\\mathcal{O}(\\sqrt{\\log n})$ or\n$p=\\mathcal{O}(n^\\gamma)$, respectively, where $n$ is the sample size and\n$\\gamma\\in(0,1)$ is a small constant depending on the polynomial decay rate.\nOur theory shows that, when the manifold assumption does not hold, deep neural\nnetworks can still adapt to the effective Minkowski dimension of the data, and\ncircumvent the curse of the ambient dimensionality for moderate sample sizes.\n","authors":["Zixuan Zhang","Minshuo Chen","Mengdi Wang","Wenjing Liao","Tuo Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.14859v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14858v1","updated":"2023-06-26T17:10:10Z","published":"2023-06-26T17:10:10Z","title":"Proportional Aggregation of Preferences for Sequential Decision Making","summary":"  We study the problem of fair sequential decision making given voter\npreferences. In each round, a decision rule must choose a decision from a set\nof alternatives where each voter reports which of these alternatives they\napprove. Instead of going with the most popular choice in each round, we aim\nfor proportional representation. We formalize this aim using axioms based on\nProportional Justified Representation (PJR), which were proposed in the\nliterature on multi-winner voting and were recently adapted to multi-issue\ndecision making. The axioms require that every group of $\\alpha\\%$ of the\nvoters, if it agrees in every round (i.e., approves a common alternative), then\nthose voters must approve at least $\\alpha\\%$ of the decisions. A stronger\nversion of the axioms requires that every group of $\\alpha\\%$ of the voters\nthat agrees in a $\\beta$ fraction of rounds must approve $\\beta\\cdot\\alpha\\%$\nof the decisions. We show that three attractive voting rules satisfy axioms of\nthis style. One of them (Sequential Phragm\\'en) makes its decisions online, and\nthe other two satisfy strengthened versions of the axioms but make decisions\nsemi-online (Method of Equal Shares) or fully offline (Proportional Approval\nVoting). The first two are polynomial-time computable, and the latter is based\non an NP-hard optimization, but it admits a polynomial-time local search\nalgorithm that satisfies the same axiomatic properties. We present empirical\nresults about the performance of these rules based on synthetic data and U.S.\npolitical elections. We also run experiments where votes are cast by preference\nmodels trained on user responses from the moral machine dataset about ethical\ndilemmas.\n","authors":["Nikhil Chandak","Shashwat Goel","Dominik Peters"],"pdf_url":"https://arxiv.org/pdf/2306.14858v1.pdf","comment":"35 pages"},{"id":"http://arxiv.org/abs/2306.14853v1","updated":"2023-06-26T17:07:54Z","published":"2023-06-26T17:07:54Z","title":"Near-Optimal Fully First-Order Algorithms for Finding Stationary Points\n  in Bilevel Optimization","summary":"  Bilevel optimization has various applications such as hyper-parameter\noptimization and meta-learning. Designing theoretically efficient algorithms\nfor bilevel optimization is more challenging than standard optimization because\nthe lower-level problem defines the feasibility set implicitly via another\noptimization problem. One tractable case is when the lower-level problem\npermits strong convexity. Recent works show that second-order methods can\nprovably converge to an $\\epsilon$-first-order stationary point of the problem\nat a rate of $\\tilde{\\mathcal{O}}(\\epsilon^{-2})$, yet these algorithms require\na Hessian-vector product oracle. Kwon et al. (2023) resolved the problem by\nproposing a first-order method that can achieve the same goal at a slower rate\nof $\\tilde{\\mathcal{O}}(\\epsilon^{-3})$. In this work, we provide an improved\nanalysis demonstrating that the first-order method can also find an\n$\\epsilon$-first-order stationary point within $\\tilde\n{\\mathcal{O}}(\\epsilon^{-2})$ oracle complexity, which matches the upper bounds\nfor second-order methods in the dependency on $\\epsilon$. Our analysis further\nleads to simple first-order algorithms that can achieve similar near-optimal\nrates in finding second-order stationary points and in distributed bilevel\nproblems.\n","authors":["Lesi Chen","Yaohua Ma","Jingzhao Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.14853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14852v1","updated":"2023-06-26T17:02:54Z","published":"2023-06-26T17:02:54Z","title":"CoarsenConf: Equivariant Coarsening with Aggregated Attention for\n  Molecular Conformer Generation","summary":"  Molecular conformer generation (MCG) is an important task in cheminformatics\nand drug discovery. The ability to efficiently generate low-energy 3D\nstructures can avoid expensive quantum mechanical simulations, leading to\naccelerated screenings and enhanced structural exploration. Several generative\nmodels have been developed for MCG, but many struggle to consistently produce\nhigh-quality conformers. To address these issues, we introduce CoarsenConf,\nwhich coarse-grains molecular graphs based on torsional angles and integrates\nthem into an SE(3)-equivariant hierarchical variational autoencoder. Through\nequivariant coarse-graining, we aggregate the fine-grained atomic coordinates\nof subgraphs connected via rotatable bonds, creating a variable-length\ncoarse-grained latent representation. Our model uses a novel aggregated\nattention mechanism to restore fine-grained coordinates from the coarse-grained\nlatent representation, enabling efficient autoregressive generation of large\nmolecules. Furthermore, our work expands current conformer generation\nbenchmarks and introduces new metrics to better evaluate the quality and\nviability of generated conformers. We demonstrate that CoarsenConf generates\nmore accurate conformer ensembles compared to prior generative models and\ntraditional cheminformatics methods.\n","authors":["Danny Reidenbach","Aditi S. Krishnapriyan"],"pdf_url":"https://arxiv.org/pdf/2306.14852v1.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2306.14851v1","updated":"2023-06-26T17:02:45Z","published":"2023-06-26T17:02:45Z","title":"Gain Confidence, Reduce Disappointment: A New Approach to\n  Cross-Validation for Sparse Regression","summary":"  Ridge regularized sparse regression involves selecting a subset of features\nthat explains the relationship between a design matrix and an output vector in\nan interpretable manner. To select the sparsity and robustness of linear\nregressors, techniques like leave-one-out cross-validation are commonly used\nfor hyperparameter tuning. However, cross-validation typically increases the\ncost of sparse regression by several orders of magnitude. Additionally,\nvalidation metrics are noisy estimators of the test-set error, with different\nhyperparameter combinations giving models with different amounts of noise.\nTherefore, optimizing over these metrics is vulnerable to out-of-sample\ndisappointment, especially in underdetermined settings. To address this, we\nmake two contributions. First, we leverage the generalization theory literature\nto propose confidence-adjusted variants of leave-one-out that display less\npropensity to out-of-sample disappointment. Second, we leverage ideas from the\nmixed-integer literature to obtain computationally tractable relaxations of\nconfidence-adjusted leave-one-out, thereby minimizing it without solving as\nmany MIOs. Our relaxations give rise to an efficient coordinate descent scheme\nwhich allows us to obtain significantly lower leave-one-out errors than via\nother methods in the literature. We validate our theory by demonstrating we\nobtain significantly sparser and comparably accurate solutions than via popular\nmethods like GLMNet and suffer from less out-of-sample disappointment. On\nsynthetic datasets, our confidence adjustment procedure generates significantly\nfewer false discoveries, and improves out-of-sample performance by 2-5%\ncompared to cross-validating without confidence adjustment. Across a suite of\n13 real datasets, a calibrated version of our procedure improves the test set\nerror by an average of 4% compared to cross-validating without confidence\nadjustment.\n","authors":["Ryan Cory-Wright","Andrés Gómez"],"pdf_url":"https://arxiv.org/pdf/2306.14851v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14846v1","updated":"2023-06-26T16:57:03Z","published":"2023-06-26T16:57:03Z","title":"ViNT: A Foundation Model for Visual Navigation","summary":"  General-purpose pre-trained models (\"foundation models\") have enabled\npractitioners to produce generalizable solutions for individual machine\nlearning problems with datasets that are significantly smaller than those\nrequired for learning from scratch. Such models are typically trained on large\nand diverse datasets with weak supervision, consuming much more training data\nthan is available for any individual downstream application. In this paper, we\ndescribe the Visual Navigation Transformer (ViNT), a foundation model that aims\nto bring the success of general-purpose pre-trained models to vision-based\nrobotic navigation. ViNT is trained with a general goal-reaching objective that\ncan be used with any navigation dataset, and employs a flexible\nTransformer-based architecture to learn navigational affordances and enable\nefficient adaptation to a variety of downstream navigational tasks. ViNT is\ntrained on a number of existing navigation datasets, comprising hundreds of\nhours of robotic navigation from a variety of different robotic platforms, and\nexhibits positive transfer, outperforming specialist models trained on singular\ndatasets. ViNT can be augmented with diffusion-based subgoal proposals to\nexplore novel environments, and can solve kilometer-scale navigation problems\nwhen equipped with long-range heuristics. ViNT can also be adapted to novel\ntask specifications with a technique inspired by prompt-tuning, where the goal\nencoder is replaced by an encoding of another task modality (e.g., GPS\nwaypoints or routing commands) embedded into the same space of goal tokens.\nThis flexibility and ability to accommodate a variety of downstream problem\ndomains establishes ViNT as an effective foundation model for mobile robotics.\nFor videos, code, and model checkpoints, see our project page at\nhttps://visualnav-transformer.github.io.\n","authors":["Dhruv Shah","Ajay Sridhar","Nitish Dashora","Kyle Stachowicz","Kevin Black","Noriaki Hirose","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2306.14846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02255v2","updated":"2023-06-26T16:39:41Z","published":"2023-03-03T23:02:23Z","title":"Finite-Sample Analysis of Learning High-Dimensional Single ReLU Neuron","summary":"  This paper considers the problem of learning a single ReLU neuron with\nsquared loss (a.k.a., ReLU regression) in the overparameterized regime, where\nthe input dimension can exceed the number of samples. We analyze a\nPerceptron-type algorithm called GLM-tron (Kakade et al., 2011) and provide its\ndimension-free risk upper bounds for high-dimensional ReLU regression in both\nwell-specified and misspecified settings. Our risk bounds recover several\nexisting results as special cases. Moreover, in the well-specified setting, we\nprovide an instance-wise matching risk lower bound for GLM-tron. Our upper and\nlower risk bounds provide a sharp characterization of the high-dimensional ReLU\nregression problems that can be learned via GLM-tron. On the other hand, we\nprovide some negative results for stochastic gradient descent (SGD) for ReLU\nregression with symmetric Bernoulli data: if the model is well-specified, the\nexcess risk of SGD is provably no better than that of GLM-tron ignoring\nconstant factors, for each problem instance; and in the noiseless case,\nGLM-tron can achieve a small risk while SGD unavoidably suffers from a constant\nrisk in expectation. These results together suggest that GLM-tron might be\npreferable to SGD for high-dimensional ReLU regression.\n","authors":["Jingfeng Wu","Difan Zou","Zixiang Chen","Vladimir Braverman","Quanquan Gu","Sham M. Kakade"],"pdf_url":"https://arxiv.org/pdf/2303.02255v2.pdf","comment":"ICML 2023 camera ready"},{"id":"http://arxiv.org/abs/2306.14818v1","updated":"2023-06-26T16:24:31Z","published":"2023-06-26T16:24:31Z","title":"Accelerating Molecular Graph Neural Networks via Knowledge Distillation","summary":"  Recent advances in graph neural networks (GNNs) have allowed molecular\nsimulations with accuracy on par with conventional gold-standard methods at a\nfraction of the computational cost. Nonetheless, as the field has been\nprogressing to bigger and more complex architectures, state-of-the-art GNNs\nhave become largely prohibitive for many large-scale applications. In this\npaper, we, for the first time, explore the utility of knowledge distillation\n(KD) for accelerating molecular GNNs. To this end, we devise KD strategies that\nfacilitate the distillation of hidden representations in directional and\nequivariant GNNs and evaluate their performance on the regression task of\nenergy and force prediction. We validate our protocols across different\nteacher-student configurations and demonstrate that they can boost the\npredictive accuracy of student models without altering their architecture. We\nalso conduct comprehensive optimization of various components of our framework,\nand investigate the potential of data augmentation to further enhance\nperformance. All in all, we manage to close as much as 59% of the gap in\npredictive accuracy between models like GemNet-OC and PaiNN with zero\nadditional cost at inference.\n","authors":["Filip Ekström Kelvinius","Dimitar Georgiev","Artur Petrov Toshev","Johannes Gasteiger"],"pdf_url":"https://arxiv.org/pdf/2306.14818v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13004v2","updated":"2023-06-26T16:22:34Z","published":"2023-06-22T16:04:16Z","title":"Can Differentiable Decision Trees Learn Interpretable Reward Functions?","summary":"  There is an increasing interest in learning reward functions that model human\nintent and human preferences. However, many frameworks use blackbox learning\nmethods that, while expressive, are difficult to interpret. We propose and\nevaluate a novel approach for learning expressive and interpretable reward\nfunctions from preferences using Differentiable Decision Trees (DDTs). Our\nexperiments across several domains, including Cartpole, Visual Gridworld\nenvironments and Atari games, provide evidence that that the tree structure of\nour learned reward function is useful in determining the extent to which the\nreward function is aligned with human preferences. We experimentally\ndemonstrate that using reward DDTs results in competitive performance when\ncompared with larger capacity deep neural network reward functions. We also\nobserve that the choice between soft and hard (argmax) output of reward DDT\nreveals a tension between wanting highly shaped rewards to ensure good RL\nperformance, while also wanting simple, non-shaped rewards to afford\ninterpretability.\n","authors":["Akansha Kalra","Daniel S. Brown"],"pdf_url":"https://arxiv.org/pdf/2306.13004v2.pdf","comment":"A version of this work is in submission at ICCV 2023"},{"id":"http://arxiv.org/abs/2306.14817v1","updated":"2023-06-26T16:22:33Z","published":"2023-06-26T16:22:33Z","title":"Black holes and the loss landscape in machine learning","summary":"  Understanding the loss landscape is an important problem in machine learning.\nOne key feature of the loss function, common to many neural network\narchitectures, is the presence of exponentially many low lying local minima.\nPhysical systems with similar energy landscapes may provide useful insights. In\nthis work, we point out that black holes naturally give rise to such\nlandscapes, owing to the existence of black hole entropy. For definiteness, we\nconsider 1/8 BPS black holes in $\\mathcal{N} = 8$ string theory. These provide\nan infinite family of potential landscapes arising in the microscopic\ndescriptions of corresponding black holes. The counting of minima amounts to\nblack hole microstate counting. Moreover, the exact numbers of the minima for\nthese landscapes are a priori known from dualities in string theory. Some of\nthe minima are connected by paths of low loss values, resembling mode\nconnectivity. We estimate the number of runs needed to find all the solutions.\nInitial explorations suggest that Stochastic Gradient Descent can find a\nsignificant fraction of the minima.\n","authors":["Pranav Kumar","Taniya Mandal","Swapnamay Mondal"],"pdf_url":"https://arxiv.org/pdf/2306.14817v1.pdf","comment":"32 pages, 4 figures"},{"id":"http://arxiv.org/abs/2306.14814v1","updated":"2023-06-26T16:18:20Z","published":"2023-06-26T16:18:20Z","title":"Probabilistic Risk Assessment of an Obstacle Detection System for GoA 4\n  Freight Trains","summary":"  In this paper, a quantitative risk assessment approach is discussed for the\ndesign of an obstacle detection function for low-speed freight trains with\ngrade of automation (GoA)~4. In this 5-step approach, starting with single\ndetection channels and ending with a three-out-of-three (3oo3) model\nconstructed of three independent dual-channel modules and a voter, a\nprobabilistic assessment is exemplified, using a combination of statistical\nmethods and parametric stochastic model checking. It is illustrated that, under\ncertain not unreasonable assumptions, the resulting hazard rate becomes\nacceptable for specific application settings. The statistical approach for\nassessing the residual risk of misclassifications in convolutional neural\nnetworks and conventional image processing software suggests that high\nconfidence can be placed into the safety-critical obstacle detection function,\neven though its implementation involves realistic machine learning\nuncertainties.\n","authors":["Mario Gleirscher","Anne E. Haxthausen","Jan Peleska"],"pdf_url":"https://arxiv.org/pdf/2306.14814v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.18391v2","updated":"2023-06-26T16:15:48Z","published":"2023-05-28T11:17:30Z","title":"MemeGraphs: Linking Memes to Knowledge Graphs","summary":"  Memes are a popular form of communicating trends and ideas in social media\nand on the internet in general, combining the modalities of images and text.\nThey can express humor and sarcasm but can also have offensive content.\nAnalyzing and classifying memes automatically is challenging since their\ninterpretation relies on the understanding of visual elements, language, and\nbackground knowledge. Thus, it is important to meaningfully represent these\nsources and the interaction between them in order to classify a meme as a\nwhole. In this work, we propose to use scene graphs, that express images in\nterms of objects and their visual relations, and knowledge graphs as structured\nrepresentations for meme classification with a Transformer-based architecture.\nWe compare our approach with ImgBERT, a multimodal model that uses only learned\n(instead of structured) representations of the meme, and observe consistent\nimprovements. We further provide a dataset with human graph annotations that we\ncompare to automatically generated graphs and entity linking. Analysis shows\nthat automatic methods link more entities than human annotators and that\nautomatically generated graphs are better suited for hatefulness classification\nin memes.\n","authors":["Vasiliki Kougia","Simon Fetzel","Thomas Kirchmair","Erion Çano","Sina Moayed Baharlou","Sahand Sharifzadeh","Benjamin Roth"],"pdf_url":"https://arxiv.org/pdf/2305.18391v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14810v1","updated":"2023-06-26T16:12:35Z","published":"2023-06-26T16:12:35Z","title":"Robust Wind Turbine Blade Segmentation from RGB Images in the Wild","summary":"  With the relentless growth of the wind industry, there is an imperious need\nto design automatic data-driven solutions for wind turbine maintenance. As\nstructural health monitoring mainly relies on visual inspections, the first\nstage in any automatic solution is to identify the blade region on the image.\nThus, we propose a novel segmentation algorithm that strengthens the U-Net\nresults by a tailored loss, which pools the focal loss with a contiguity\nregularization term. To attain top performing results, a set of additional\nsteps are proposed to ensure a reliable, generic, robust and efficient\nalgorithm. First, we leverage our prior knowledge on the images by filling the\nholes enclosed by temporarily-classified blade pixels and by the image\nboundaries. Subsequently, the mislead classified pixels are successfully\namended by training an on-the-fly random forest. Our algorithm demonstrates its\neffectiveness reaching a non-trivial 97.39% of accuracy.\n","authors":["Raül Pérez-Gonzalo","Andreas Espersen","Antonio Agudo"],"pdf_url":"https://arxiv.org/pdf/2306.14810v1.pdf","comment":"Accepted to ICIP 2023"},{"id":"http://arxiv.org/abs/2306.14809v1","updated":"2023-06-26T16:11:11Z","published":"2023-06-26T16:11:11Z","title":"Tanimoto Random Features for Scalable Molecular Machine Learning","summary":"  The Tanimoto coefficient is commonly used to measure the similarity between\nmolecules represented as discrete fingerprints, either as a distance metric or\na positive definite kernel. While many kernel methods can be accelerated using\nrandom feature approximations, at present there is a lack of such\napproximations for the Tanimoto kernel. In this paper we propose two kinds of\nnovel random features to allow this kernel to scale to large datasets, and in\nthe process discover a novel extension of the kernel to real vectors. We\ntheoretically characterize these random features, and provide error bounds on\nthe spectral norm of the Gram matrix. Experimentally, we show that the random\nfeatures proposed in this work are effective at approximating the Tanimoto\ncoefficient in real-world datasets and that the kernels explored in this work\nare useful for molecular property prediction and optimization tasks.\n","authors":["Austin Tripp","Sergio Bacallado","Sukriti Singh","José Miguel Hernández-Lobato"],"pdf_url":"https://arxiv.org/pdf/2306.14809v1.pdf","comment":"Work in progress: expect updates in the future. Article is 29 pages\n  with 9 figures"},{"id":"http://arxiv.org/abs/2306.14808v1","updated":"2023-06-26T16:08:26Z","published":"2023-06-26T16:08:26Z","title":"Maximum State Entropy Exploration using Predecessor and Successor\n  Representations","summary":"  Animals have a developed ability to explore that aids them in important tasks\nsuch as locating food, exploring for shelter, and finding misplaced items.\nThese exploration skills necessarily track where they have been so that they\ncan plan for finding items with relative efficiency. Contemporary exploration\nalgorithms often learn a less efficient exploration strategy because they\neither condition only on the current state or simply rely on making random\nopen-loop exploratory moves. In this work, we propose $\\eta\\psi$-Learning, a\nmethod to learn efficient exploratory policies by conditioning on past episodic\nexperience to make the next exploratory move. Specifically, $\\eta\\psi$-Learning\nlearns an exploration policy that maximizes the entropy of the state visitation\ndistribution of a single trajectory. Furthermore, we demonstrate how variants\nof the predecessor representation and successor representations can be combined\nto predict the state visitation entropy. Our experiments demonstrate the\nefficacy of $\\eta\\psi$-Learning to strategically explore the environment and\nmaximize the state coverage with limited samples.\n","authors":["Arnav Kumar Jain","Lucas Lehnert","Irina Rish","Glen Berseth"],"pdf_url":"https://arxiv.org/pdf/2306.14808v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.15994v2","updated":"2023-06-26T16:07:33Z","published":"2022-03-30T02:05:27Z","title":"Optimal Learning","summary":"  This paper studies the problem of learning an unknown function $f$ from given\ndata about $f$. The learning problem is to give an approximation $\\hat f$ to\n$f$ that predicts the values of $f$ away from the data. There are numerous\nsettings for this learning problem depending on (i) what additional information\nwe have about $f$ (known as a model class assumption), (ii) how we measure the\naccuracy of how well $\\hat f$ predicts $f$, (iii) what is known about the data\nand data sites, (iv) whether the data observations are polluted by noise. A\nmathematical description of the optimal performance possible (the smallest\npossible error of recovery) is known in the presence of a model class\nassumption. Under standard model class assumptions, it is shown in this paper\nthat a near optimal $\\hat f$ can be found by solving a certain discrete\nover-parameterized optimization problem with a penalty term. Here, near optimal\nmeans that the error is bounded by a fixed constant times the optimal error.\nThis explains the advantage of over-parameterization which is commonly used in\nmodern machine learning. The main results of this paper prove that\nover-parameterized learning with an appropriate loss function gives a near\noptimal approximation $\\hat f$ of the function $f$ from which the data is\ncollected. Quantitative bounds are given for how much over-parameterization\nneeds to be employed and how the penalization needs to be scaled in order to\nguarantee a near optimal recovery of $f$. An extension of these results to the\ncase where the data is polluted by additive deterministic noise is also given.\n","authors":["Peter Binev","Andrea Bonito","Ronald DeVore","Guergana Petrova"],"pdf_url":"https://arxiv.org/pdf/2203.15994v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.00290v3","updated":"2023-06-26T16:04:47Z","published":"2022-07-30T18:50:36Z","title":"A Gradient Smoothed Functional Algorithm with Truncated Cauchy Random\n  Perturbations for Stochastic Optimization","summary":"  In this paper, we present a stochastic gradient algorithm for minimizing a\nsmooth objective function that is an expectation over noisy cost samples, and\nonly the latter are observed for any given parameter. Our algorithm employs a\ngradient estimation scheme with random perturbations, which are formed using\nthe truncated Cauchy distribution from the delta sphere. We analyze the bias\nand variance of the proposed gradient estimator. Our algorithm is found to be\nparticularly useful in the case when the objective function is non-convex, and\nthe parameter dimension is high. From an asymptotic convergence analysis, we\nestablish that our algorithm converges almost surely to the set of stationary\npoints of the objective function and obtains the asymptotic convergence rate.\nWe also show that our algorithm avoids unstable equilibria, implying\nconvergence to local minima. Further, we perform a non-asymptotic convergence\nanalysis of our algorithm. In particular, we establish here a non-asymptotic\nbound for finding an epsilon-stationary point of the non-convex objective\nfunction. Finally, we demonstrate numerically through simulations that the\nperformance of our algorithm outperforms GSF, SPSA, and RDSA by a significant\nmargin over a few non-convex settings and further validate its performance over\nconvex (noisy) objectives.\n","authors":["Akash Mondal","Prashanth L. A.","Shalabh Bhatnagar"],"pdf_url":"https://arxiv.org/pdf/2208.00290v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14799v1","updated":"2023-06-26T15:58:13Z","published":"2023-06-26T15:58:13Z","title":"On Imitation in Mean-field Games","summary":"  We explore the problem of imitation learning (IL) in the context of\nmean-field games (MFGs), where the goal is to imitate the behavior of a\npopulation of agents following a Nash equilibrium policy according to some\nunknown payoff function. IL in MFGs presents new challenges compared to\nsingle-agent IL, particularly when both the reward function and the transition\nkernel depend on the population distribution. In this paper, departing from the\nexisting literature on IL for MFGs, we introduce a new solution concept called\nthe Nash imitation gap. Then we show that when only the reward depends on the\npopulation distribution, IL in MFGs can be reduced to single-agent IL with\nsimilar guarantees. However, when the dynamics is population-dependent, we\nprovide a novel upper-bound that suggests IL is harder in this setting. To\naddress this issue, we propose a new adversarial formulation where the\nreinforcement learning problem is replaced by a mean-field control (MFC)\nproblem, suggesting progress in IL within MFGs may have to build upon MFC.\n","authors":["Giorgia Ramponi","Pavel Kolev","Olivier Pietquin","Niao He","Mathieu Laurière","Matthieu Geist"],"pdf_url":"https://arxiv.org/pdf/2306.14799v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.00684v3","updated":"2023-06-26T15:51:59Z","published":"2023-06-01T13:58:06Z","title":"Balanced Training of Energy-Based Models with Adaptive Flow Sampling","summary":"  Energy-based models (EBMs) are versatile density estimation models that\ndirectly parameterize an unnormalized log density. Although very flexible, EBMs\nlack a specified normalization constant of the model, making the likelihood of\nthe model computationally intractable. Several approximate samplers and\nvariational inference techniques have been proposed to estimate the likelihood\ngradients for training. These techniques have shown promising results in\ngenerating samples, but little attention has been paid to the statistical\naccuracy of the estimated density, such as determining the relative importance\nof different classes in a dataset. In this work, we propose a new maximum\nlikelihood training algorithm for EBMs that uses a different type of generative\nmodel, normalizing flows (NF), which have recently been proposed to facilitate\nsampling. Our method fits an NF to an EBM during training so that an\nNF-assisted sampling scheme provides an accurate gradient for the EBMs at all\ntimes, ultimately leading to a fast sampler for generating new data.\n","authors":["Louis Grenioux","Éric Moulines","Marylou Gabrié"],"pdf_url":"https://arxiv.org/pdf/2306.00684v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14789v1","updated":"2023-06-26T15:46:49Z","published":"2023-06-26T15:46:49Z","title":"Segmentation of Industrial Burner Flames: A Comparative Study from\n  Traditional Image Processing to Machine and Deep Learning","summary":"  In many industrial processes, such as power generation, chemical production,\nand waste management, accurately monitoring industrial burner flame\ncharacteristics is crucial for safe and efficient operation. A key step\ninvolves separating the flames from the background through binary segmentation.\nDecades of machine vision research have produced a wide range of possible\nsolutions, from traditional image processing to traditional machine learning\nand modern deep learning methods. In this work, we present a comparative study\nof multiple segmentation approaches, namely Global Thresholding, Region\nGrowing, Support Vector Machines, Random Forest, Multilayer Perceptron, U-Net,\nand DeepLabV3+, that are evaluated on a public benchmark dataset of industrial\nburner flames. We provide helpful insights and guidance for researchers and\npractitioners aiming to select an appropriate approach for the binary\nsegmentation of industrial burner flames and beyond. For the highest accuracy,\ndeep learning is the leading approach, while for fast and simple solutions,\ntraditional image processing techniques remain a viable option.\n","authors":["Steven Landgraf","Markus Hillemann","Moritz Aberle","Valentin Jung","Markus Ulrich"],"pdf_url":"https://arxiv.org/pdf/2306.14789v1.pdf","comment":"8 Pages, 5 figures, submitted to the Geospatial Week 2023"},{"id":"http://arxiv.org/abs/2306.14787v1","updated":"2023-06-26T15:46:08Z","published":"2023-06-26T15:46:08Z","title":"Distributive Pre-Training of Generative Modeling Using Matrix-Product\n  States","summary":"  Tensor networks have recently found applications in machine learning for both\nsupervised learning and unsupervised learning. The most common approaches for\ntraining these models are gradient descent methods. In this work, we consider\nan alternative training scheme utilizing basic tensor network operations, e.g.,\nsummation and compression. The training algorithm is based on compressing the\nsuperposition state constructed from all the training data in product state\nrepresentation. The algorithm could be parallelized easily and only iterates\nthrough the dataset once. Hence, it serves as a pre-training algorithm. We\nbenchmark the algorithm on the MNIST dataset and show reasonable results for\ngenerating new images and classification tasks. Furthermore, we provide an\ninterpretation of the algorithm as a compressed quantum kernel density\nestimation for the probability amplitude of input data.\n","authors":["Sheng-Hsuan Lin","Olivier Kuijpers","Sebastian Peterhansl","Frank Pollmann"],"pdf_url":"https://arxiv.org/pdf/2306.14787v1.pdf","comment":"7+2 pages, 1+2 figures; Position paper in QTNML Workshop, NeurIPS\n  2021; See\n  https://tensorworkshop.github.io/NeurIPS2021/accepted_papers/MPS_MNIST.pdf"},{"id":"http://arxiv.org/abs/2306.06208v2","updated":"2023-06-26T15:38:42Z","published":"2023-06-05T23:07:01Z","title":"A Differential Testing Framework to Evaluate Image Recognition Model\n  Robustness","summary":"  Image recognition tasks typically use deep learning and require enormous\nprocessing power, thus relying on hardware accelerators like GPUs and TPUs for\nfast, timely processing. Failure in real-time image recognition tasks can occur\ndue to sub-optimal mapping on hardware accelerators during model deployment,\nwhich may lead to timing uncertainty and erroneous behavior. Mapping on\nhardware accelerators is done through multiple software components like deep\nlearning frameworks, compilers, device libraries, that we refer to as the\ncomputational environment. Owing to the increased use of image recognition\ntasks in safety-critical applications like autonomous driving and medical\nimaging, it is imperative to assess their robustness to changes in the\ncomputational environment, as the impact of parameters like deep learning\nframeworks, compiler optimizations, and hardware devices on model performance\nand correctness is not well understood.\n  In this paper we present a differential testing framework, which allows deep\nlearning model variant generation, execution, differential analysis and testing\nfor a number of computational environment parameters. Using our framework, we\nconduct an empirical study of robustness analysis of three popular image\nrecognition models using the ImageNet dataset, assessing the impact of changing\ndeep learning frameworks, compiler optimizations, and hardware devices. We\nreport the impact in terms of misclassifications and inference time differences\nacross different settings. In total, we observed up to 72% output label\ndifferences across deep learning frameworks, and up to 82% unexpected\nperformance degradation in terms of inference time, when applying compiler\noptimizations. Using the analysis tools in our framework, we also perform fault\nanalysis to understand the reasons for the observed differences.\n","authors":["Nikolaos Louloudakis","Perry Gibson","José Cano","Ajitha Rajan"],"pdf_url":"https://arxiv.org/pdf/2306.06208v2.pdf","comment":"12 pages, 10 figures, 2 tables. arXiv admin note: text overlap with\n  arXiv:2211.00471"},{"id":"http://arxiv.org/abs/2305.17760v2","updated":"2023-06-26T15:37:55Z","published":"2023-05-28T16:04:48Z","title":"Language Models are Bounded Pragmatic Speakers","summary":"  How do language models \"think\"? This paper formulates a probabilistic\ncognitive model called the bounded pragmatic speaker, which can characterize\nthe operation of different variations of language models. Specifically, we\ndemonstrate that large language models fine-tuned with reinforcement learning\nfrom human feedback (Ouyang et al., 2022) embody a model of thought that\nconceptually resembles a fast-and-slow model (Kahneman, 2011), which\npsychologists have attributed to humans. We discuss the limitations of\nreinforcement learning from human feedback as a fast-and-slow model of thought\nand propose avenues for expanding this framework. In essence, our research\nhighlights the value of adopting a cognitive probabilistic modeling approach to\ngain insights into the comprehension, evaluation, and advancement of language\nmodels.\n","authors":["Khanh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2305.17760v2.pdf","comment":"Proceedings of the First Workshop on Theory of Mind in Communicating\n  Agents at (TOM @ ICML 2023)"},{"id":"http://arxiv.org/abs/2306.14775v1","updated":"2023-06-26T15:35:27Z","published":"2023-06-26T15:35:27Z","title":"Parameter-Level Soft-Masking for Continual Learning","summary":"  Existing research on task incremental learning in continual learning has\nprimarily focused on preventing catastrophic forgetting (CF). Although several\ntechniques have achieved learning with no CF, they attain it by letting each\ntask monopolize a sub-network in a shared network, which seriously limits\nknowledge transfer (KT) and causes over-consumption of the network capacity,\ni.e., as more tasks are learned, the performance deteriorates. The goal of this\npaper is threefold: (1) overcoming CF, (2) encouraging KT, and (3) tackling the\ncapacity problem. A novel technique (called SPG) is proposed that soft-masks\n(partially blocks) parameter updating in training based on the importance of\neach parameter to old tasks. Each task still uses the full network, i.e., no\nmonopoly of any part of the network by any task, which enables maximum KT and\nreduction in capacity usage. To our knowledge, this is the first work that\nsoft-masks a model at the parameter-level for continual learning. Extensive\nexperiments demonstrate the effectiveness of SPG in achieving all three\nobjectives. More notably, it attains significant transfer of knowledge not only\namong similar tasks (with shared knowledge) but also among dissimilar tasks\n(with little shared knowledge) while mitigating CF.\n","authors":["Tatsuya Konishi","Mori Kurokawa","Chihiro Ono","Zixuan Ke","Gyuhak Kim","Bing Liu"],"pdf_url":"https://arxiv.org/pdf/2306.14775v1.pdf","comment":"ICML2023"},{"id":"http://arxiv.org/abs/2306.11222v2","updated":"2023-06-26T15:34:57Z","published":"2023-06-20T01:16:11Z","title":"LoSparse: Structured Compression of Large Language Models based on\n  Low-Rank and Sparse Approximation","summary":"  Transformer models have achieved remarkable results in various natural\nlanguage tasks, but they are often prohibitively large, requiring massive\nmemories and computational resources. To reduce the size and complexity of\nthese models, we propose LoSparse (Low-Rank and Sparse approximation), a novel\nmodel compression technique that approximates a weight matrix by the sum of a\nlow-rank matrix and a sparse matrix. Our method combines the advantages of both\nlow-rank approximations and pruning, while avoiding their limitations. Low-rank\napproximation compresses the coherent and expressive parts in neurons, while\npruning removes the incoherent and non-expressive parts in neurons. Pruning\nenhances the diversity of low-rank approximations, and low-rank approximation\nprevents pruning from losing too many expressive neurons. We evaluate our\nmethod on natural language understanding, question answering, and natural\nlanguage generation tasks. We show that it significantly outperforms existing\ncompression methods.\n","authors":["Yixiao Li","Yifan Yu","Qingru Zhang","Chen Liang","Pengcheng He","Weizhu Chen","Tuo Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.11222v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.09850v2","updated":"2023-06-26T15:27:47Z","published":"2023-06-16T13:47:04Z","title":"Practical Sharpness-Aware Minimization Cannot Converge All the Way to\n  Optima","summary":"  Sharpness-Aware Minimization (SAM) is an optimizer that takes a descent step\nbased on the gradient at a perturbation $y_t = x_t + \\rho \\frac{\\nabla\nf(x_t)}{\\lVert \\nabla f(x_t) \\rVert}$ of the current point $x_t$. Existing\nstudies prove convergence of SAM for smooth functions, but they do so by\nassuming decaying perturbation size $\\rho$ and/or no gradient normalization in\n$y_t$, which is detached from practice. To address this gap, we study\ndeterministic/stochastic versions of SAM with practical configurations (i.e.,\nconstant $\\rho$ and gradient normalization in $y_t$) and explore their\nconvergence properties on smooth functions with (non)convexity assumptions.\nPerhaps surprisingly, in many scenarios, we find out that SAM has limited\ncapability to converge to global minima or stationary points. For smooth\nstrongly convex functions, we show that while deterministic SAM enjoys tight\nglobal convergence rates of $\\tilde \\Theta(\\frac{1}{T^2})$, the convergence\nbound of stochastic SAM suffers an inevitable additive term $O(\\rho^2)$,\nindicating convergence only up to neighborhoods of optima. In fact, such\n$O(\\rho^2)$ factors arise for stochastic SAM in all the settings we consider,\nand also for deterministic SAM in nonconvex cases; importantly, we prove by\nexamples that such terms are unavoidable. Our results highlight vastly\ndifferent characteristics of SAM with vs. without decaying perturbation size or\ngradient normalization, and suggest that the intuitions gained from one version\nmay not apply to the other.\n","authors":["Dongkuk Si","Chulhee Yun"],"pdf_url":"https://arxiv.org/pdf/2306.09850v2.pdf","comment":"39 pages. v2 adds/corrects a couple of citations"},{"id":"http://arxiv.org/abs/2306.14770v1","updated":"2023-06-26T15:26:24Z","published":"2023-06-26T15:26:24Z","title":"ProtoDiff: Learning to Learn Prototypical Networks by Task-Guided\n  Diffusion","summary":"  Prototype-based meta-learning has emerged as a powerful technique for\naddressing few-shot learning challenges. However, estimating a deterministic\nprototype using a simple average function from a limited number of examples\nremains a fragile process. To overcome this limitation, we introduce ProtoDiff,\na novel framework that leverages a task-guided diffusion model during the\nmeta-training phase to gradually generate prototypes, thereby providing\nefficient class representations. Specifically, a set of prototypes is optimized\nto achieve per-task prototype overfitting, enabling accurately obtaining the\noverfitted prototypes for individual tasks. Furthermore, we introduce a\ntask-guided diffusion process within the prototype space, enabling the\nmeta-learning of a generative process that transitions from a vanilla prototype\nto an overfitted prototype. ProtoDiff gradually generates task-specific\nprototypes from random noise during the meta-test stage, conditioned on the\nlimited samples available for the new task. Furthermore, to expedite training\nand enhance ProtoDiff's performance, we propose the utilization of residual\nprototype learning, which leverages the sparsity of the residual prototype. We\nconduct thorough ablation studies to demonstrate its ability to accurately\ncapture the underlying prototype distribution and enhance generalization. The\nnew state-of-the-art performance on within-domain, cross-domain, and few-task\nfew-shot classification further substantiates the benefit of ProtoDiff.\n","authors":["Yingjun Du","Zehao Xiao","Shengcai Liao","Cees Snoek"],"pdf_url":"https://arxiv.org/pdf/2306.14770v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2303.11138v2","updated":"2023-06-26T15:16:42Z","published":"2023-03-20T14:15:52Z","title":"Fault Detection via Occupation Kernel Principal Component Analysis","summary":"  The reliable operation of automatic systems is heavily dependent on the\nability to detect faults in the underlying dynamical system. While traditional\nmodel-based methods have been widely used for fault detection, data-driven\napproaches have garnered increasing attention due to their ease of deployment\nand minimal need for expert knowledge. In this paper, we present a novel\nprincipal component analysis (PCA) method that uses occupation kernels.\nOccupation kernels result in feature maps that are tailored to the measured\ndata, have inherent noise-robustness due to the use of integration, and can\nutilize irregularly sampled system trajectories of variable lengths for PCA.\nThe occupation kernel PCA method is used to develop a reconstruction error\napproach to fault detection and its efficacy is validated using numerical\nsimulations.\n","authors":["Zachary Morrison","Benjamin P. Russo","Yingzhao Lian","Rushikesh Kamalapurkar"],"pdf_url":"https://arxiv.org/pdf/2303.11138v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14759v1","updated":"2023-06-26T15:13:36Z","published":"2023-06-26T15:13:36Z","title":"PMaF: Deep Declarative Layers for Principal Matrix Features","summary":"  We explore two differentiable deep declarative layers, namely least squares\non sphere (LESS) and implicit eigen decomposition (IED), for learning the\nprincipal matrix features (PMaF). This can be used to represent data features\nwith a low-dimension vector containing dominant information from a\nhigh-dimension matrix. We first solve the problems with iterative optimization\nin the forward pass and then backpropagate the solution for implicit gradients\nunder a bi-level optimization framework. Particularly, adaptive descent steps\nwith the backtracking line search method and descent decay in the tangent space\nare studied to improve the forward pass efficiency of LESS. Meanwhile,\nexploited data structures are used to greatly reduce the computational\ncomplexity in the backward pass of LESS and IED. Empirically, we demonstrate\nthe superiority of our layers over the off-the-shelf baselines by comparing the\nsolution optimality and computational requirements.\n","authors":["Zhiwei Xu","Hao Wang","Yanbin Liu","Stephen Gould"],"pdf_url":"https://arxiv.org/pdf/2306.14759v1.pdf","comment":"Accepted to the Differentiable Almost Everything Workshop of the\n  International Conference on Machine Learning (ICML) 2023"},{"id":"http://arxiv.org/abs/2306.14744v1","updated":"2023-06-26T14:59:56Z","published":"2023-06-26T14:59:56Z","title":"ChiPFormer: Transferable Chip Placement via Offline Decision Transformer","summary":"  Placement is a critical step in modern chip design, aiming to determine the\npositions of circuit modules on the chip canvas. Recent works have shown that\nreinforcement learning (RL) can improve human performance in chip placement.\nHowever, such an RL-based approach suffers from long training time and low\ntransfer ability in unseen chip circuits. To resolve these challenges, we cast\nthe chip placement as an offline RL formulation and present ChiPFormer that\nenables learning a transferable placement policy from fixed offline data.\nChiPFormer has several advantages that prior arts do not have. First,\nChiPFormer can exploit offline placement designs to learn transferable policies\nmore efficiently in a multi-task setting. Second, ChiPFormer can promote\neffective finetuning for unseen chip circuits, reducing the placement runtime\nfrom hours to minutes. Third, extensive experiments on 32 chip circuits\ndemonstrate that ChiPFormer achieves significantly better placement quality\nwhile reducing the runtime by 10x compared to recent state-of-the-art\napproaches in both public benchmarks and realistic industrial tasks. The\ndeliverables are released at https://sites.google.com/view/chipformer/home.\n","authors":["Yao Lai","Jinxin Liu","Zhentao Tang","Bin Wang","Jianye Hao","Ping Luo"],"pdf_url":"https://arxiv.org/pdf/2306.14744v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11839v2","updated":"2023-06-26T14:45:42Z","published":"2023-06-20T18:47:50Z","title":"Should I Stop or Should I Go: Early Stopping with Heterogeneous\n  Populations","summary":"  Randomized experiments often need to be stopped prematurely due to the\ntreatment having an unintended harmful effect. Existing methods that determine\nwhen to stop an experiment early are typically applied to the data in aggregate\nand do not account for treatment effect heterogeneity. In this paper, we study\nthe early stopping of experiments for harm on heterogeneous populations. We\nfirst establish that current methods often fail to stop experiments when the\ntreatment harms a minority group of participants. We then use causal machine\nlearning to develop CLASH, the first broadly-applicable method for\nheterogeneous early stopping. We demonstrate CLASH's performance on simulated\nand real data and show that it yields effective early stopping for both\nclinical trials and A/B tests.\n","authors":["Hammaad Adam","Fan Yin","Mary Hu","Neil Tenenholtz","Lorin Crawford","Lester Mackey","Allison Koenecke"],"pdf_url":"https://arxiv.org/pdf/2306.11839v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.13492v3","updated":"2023-06-26T14:44:19Z","published":"2022-09-26T14:07:59Z","title":"Taking a Respite from Representation Learning for Molecular Property\n  Prediction","summary":"  Artificial intelligence (AI) has been widely applied in drug discovery with a\nmajor task as molecular property prediction. Despite booming techniques in\nmolecular representation learning, fundamentals underlying molecular property\nprediction haven't been carefully examined yet. In this study, we conducted a\nsystematic evaluation on a collection of representative models using various\nmolecular representations. In addition to the commonly used MoleculeNet\nbenchmark datasets, we also assembled a suite of opioids-related datasets from\nChEMBL and two additional activity datasets from literature. To interrogate the\nbasic predictive power, we also assembled a series of descriptors datasets with\nvarying sizes to evaluate the models' performance. In total, we trained 62,820\nmodels, including 50,220 models on fixed representations, 4,200 models on\nSMILES sequences and 8,400 models on molecular graphs. We first conducted\ndataset profiling and highlighted the activity-cliffs issue in the\nopioids-related datasets. We then conducted rigorous model evaluation and\naddressed key questions therein. Furthermore, we examined inter-/intra-scaffold\nchemical space generalization and found that activity cliffs significantly can\nimpact prediction performance. Based on extensive experimentation and rigorous\ncomparison, representation learning models still show limited performance in\nmolecular property prediction in most datasets. Finally, we explored into\npotential causes why representation learning models fail and highlighted the\nimportance of dataset size. By taking this respite, we reflected on the\nfundamentals underlying molecular property prediction, the awareness of which\ncan, hopefully, bring better AI techniques in this field.\n","authors":["Jianyuan Deng","Zhibo Yang","Hehe Wang","Iwao Ojima","Dimitris Samaras","Fusheng Wang"],"pdf_url":"https://arxiv.org/pdf/2209.13492v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.06201v2","updated":"2023-06-26T14:42:22Z","published":"2022-10-12T13:36:29Z","title":"Diffusion Models for Causal Discovery via Topological Ordering","summary":"  Discovering causal relations from observational data becomes possible with\nadditional assumptions such as considering the functional relations to be\nconstrained as nonlinear with additive noise (ANM). Even with strong\nassumptions, causal discovery involves an expensive search problem over the\nspace of directed acyclic graphs (DAGs). \\emph{Topological ordering} approaches\nreduce the optimisation space of causal discovery by searching over a\npermutation rather than graph space. For ANMs, the \\emph{Hessian} of the data\nlog-likelihood can be used for finding leaf nodes in a causal graph, allowing\nits topological ordering. However, existing computational methods for obtaining\nthe Hessian still do not scale as the number of variables and the number of\nsamples increase. Therefore, inspired by recent innovations in diffusion\nprobabilistic models (DPMs), we propose \\emph{DiffAN}\\footnote{Implementation\nis available at \\url{https://github.com/vios-s/DiffAN} .}, a topological\nordering algorithm that leverages DPMs for learning a Hessian function. We\nintroduce theory for updating the learned Hessian without re-training the\nneural network, and we show that computing with a subset of samples gives an\naccurate approximation of the ordering, which allows scaling to datasets with\nmore samples and variables. We show empirically that our method scales\nexceptionally well to datasets with up to $500$ nodes and up to $10^5$ samples\nwhile still performing on par over small datasets with state-of-the-art causal\ndiscovery methods. Implementation is available at\nhttps://github.com/vios-s/DiffAN .\n","authors":["Pedro Sanchez","Xiao Liu","Alison Q O'Neil","Sotirios A. Tsaftaris"],"pdf_url":"https://arxiv.org/pdf/2210.06201v2.pdf","comment":"Implementation is available at https://github.com/vios-s/DiffAN\n  Published as a conference paper at ICLR 2023\n  https://openreview.net/forum?id=Idusfje4-Wq"},{"id":"http://arxiv.org/abs/2306.14731v1","updated":"2023-06-26T14:32:46Z","published":"2023-06-26T14:32:46Z","title":"Leveraging Locality and Robustness to Achieve Massively Scalable\n  Gaussian Process Regression","summary":"  The accurate predictions and principled uncertainty measures provided by GP\nregression incur O(n^3) cost which is prohibitive for modern-day large-scale\napplications. This has motivated extensive work on computationally efficient\napproximations. We introduce a new perspective by exploring robustness\nproperties and limiting behaviour of GP nearest-neighbour (GPnn) prediction. We\ndemonstrate through theory and simulation that as the data-size n increases,\naccuracy of estimated parameters and GP model assumptions become increasingly\nirrelevant to GPnn predictive accuracy. Consequently, it is sufficient to spend\nsmall amounts of work on parameter estimation in order to achieve high MSE\naccuracy, even in the presence of gross misspecification. In contrast, as n\ntends to infinity, uncertainty calibration and NLL are shown to remain\nsensitive to just one parameter, the additive noise-variance; but we show that\nthis source of inaccuracy can be corrected for, thereby achieving both\nwell-calibrated uncertainty measures and accurate predictions at remarkably low\ncomputational cost. We exhibit a very simple GPnn regression algorithm with\nstand-out performance compared to other state-of-the-art GP approximations as\nmeasured on large UCI datasets. It operates at a small fraction of those other\nmethods' training costs, for example on a basic laptop taking about 30 seconds\nto train on a dataset of size n = 1.6 x 10^6.\n","authors":["Robert Allison","Anthony Stephenson","Samuel F","Edward Pyzer-Knapp"],"pdf_url":"https://arxiv.org/pdf/2306.14731v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14709v1","updated":"2023-06-26T13:57:05Z","published":"2023-06-26T13:57:05Z","title":"Self-supervised novel 2D view synthesis of large-scale scenes with\n  efficient multi-scale voxel carving","summary":"  The task of generating novel views of real scenes is increasingly important\nnowadays when AI models become able to create realistic new worlds. In many\npractical applications, it is important for novel view synthesis methods to\nstay grounded in the physical world as much as possible, while also being able\nto imagine it from previously unseen views. While most current methods are\ndeveloped and tested in virtual environments with small scenes and no errors in\npose and depth information, we push the boundaries to the real-world domain of\nlarge scales in the new context of UAVs. Our algorithmic contributions are two\nfolds. First, we manage to stay anchored in the real 3D world, by introducing\nan efficient multi-scale voxel carving method, which is able to accommodate\nsignificant noises in pose, depth, and illumination variations, while being\nable to reconstruct the view of the world from drastically different poses at\ntest time. Second, our final high-resolution output is efficiently self-trained\non data automatically generated by the voxel carving module, which gives it the\nflexibility to adapt efficiently to any scene. We demonstrated the\neffectiveness of our method on highly complex and large-scale scenes in real\nenvironments while outperforming the current state-of-the-art. Our code is\npublicly available: https://github.com/onorabil/MSVC.\n","authors":["Alexandra Budisteanu","Dragos Costea","Alina Marcu","Marius Leordeanu"],"pdf_url":"https://arxiv.org/pdf/2306.14709v1.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2306.14705v1","updated":"2023-06-26T13:54:52Z","published":"2023-06-26T13:54:52Z","title":"Augmenting Control over Exploration Space in Molecular Dynamics\n  Simulators to Streamline De Novo Analysis through Generative Control Policies","summary":"  This study introduces the P5 model - a foundational method that utilizes\nreinforcement learning (RL) to augment control, effectiveness, and scalability\nin molecular dynamics simulations (MD). Our innovative strategy optimizes the\nsampling of target polymer chain conformations, marking an efficiency\nimprovement of over 37.1%. The RL-induced control policies function as an\ninductive bias, modulating Brownian forces to steer the system towards the\npreferred state, thereby expanding the exploration of the configuration space\nbeyond what traditional MD allows. This broadened exploration generates a more\nvaried set of conformations and targets specific properties, a feature pivotal\nfor progress in polymer development, drug discovery, and material design. Our\ntechnique offers significant advantages when investigating new systems with\nlimited prior knowledge, opening up new methodologies for tackling complex\nsimulation problems with generative techniques.\n","authors":["Paloma Gonzalez-Rojas","Andrew Emmel","Luis Martinez","Neil Malur","Gregory Rutledge"],"pdf_url":"https://arxiv.org/pdf/2306.14705v1.pdf","comment":"ICML 2023 Workshop on Structured Probabilistic Inference (SPIGM) and\n  Generative Modeling, of the International Conference of Machine Learning\n  (ICML)"},{"id":"http://arxiv.org/abs/2306.14701v1","updated":"2023-06-26T13:47:38Z","published":"2023-06-26T13:47:38Z","title":"Hard Sample Mining Enabled Contrastive Feature Learning for Wind Turbine\n  Pitch System Fault Diagnosis","summary":"  The efficient utilization of wind power by wind turbines relies on the\nability of their pitch systems to adjust blade pitch angles in response to\nvarying wind speeds. However, the presence of multiple fault types in the pitch\nsystem poses challenges in accurately classifying these faults. This paper\nproposes a novel method based on hard sample mining-enabled contrastive feature\nlearning (HSMCFL) to address this problem. The proposed method employs cosine\nsimilarity to identify hard samples and subsequently leverages contrastive\nfeature learning to enhance representation learning through the construction of\nhard sample pairs. Furthermore, a multilayer perceptron is trained using the\nlearned discriminative representations to serve as an efficient classifier.\n  To evaluate the effectiveness of the proposed method, two real datasets\ncomprising wind turbine pitch system cog belt fracture data are utilized. The\nfault diagnosis performance of the proposed method is compared against existing\nmethods, and the results demonstrate its superior performance. The proposed\napproach exhibits significant improvements in fault diagnosis accuracy,\nproviding promising prospects for enhancing the reliability and efficiency of\nwind turbine pitch system fault diagnosis.\n","authors":["Zixuan Wang","Bo Qin","Mengxuan Li","Mark D. Butala","Haibo Wang","Peng Peng","Hongwei Wang"],"pdf_url":"https://arxiv.org/pdf/2306.14701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.03586v2","updated":"2023-06-26T13:46:52Z","published":"2020-12-07T11:02:44Z","title":"No Need to Know Physics: Resilience of Process-based Model-free Anomaly\n  Detection for Industrial Control Systems","summary":"  In recent years, a number of process-based anomaly detection schemes for\nIndustrial Control Systems were proposed. In this work, we provide the first\nsystematic analysis of such schemes, and introduce a taxonomy of properties\nthat are verified by those detection systems. We then present a novel general\nframework to generate adversarial spoofing signals that violate physical\nproperties of the system, and use the framework to analyze four anomaly\ndetectors published at top security conferences. We find that three of those\ndetectors are susceptible to a number of adversarial manipulations (e.g.,\nspoofing with precomputed patterns), which we call Synthetic Sensor Spoofing\nand one is resilient against our attacks. We investigate the root of its\nresilience and demonstrate that it comes from the properties that we\nintroduced. Our attacks reduce the Recall (True Positive Rate) of the attacked\nschemes making them not able to correctly detect anomalies. Thus, the\nvulnerabilities we discovered in the anomaly detectors show that (despite an\noriginal good detection performance), those detectors are not able to reliably\nlearn physical properties of the system. Even attacks that prior work was\nexpected to be resilient against (based on verified properties) were found to\nbe successful. We argue that our findings demonstrate the need for both more\ncomplete attacks in datasets, and more critical analysis of process-based\nanomaly detectors. We plan to release our implementation as open-source,\ntogether with an extension of two public datasets with a set of Synthetic\nSensor Spoofing attacks as generated by our framework.\n","authors":["Alessandro Erba","Nils Ole Tippenhauer"],"pdf_url":"https://arxiv.org/pdf/2012.03586v2.pdf","comment":"An updated version of the paper has been published at ACSAC'2022:\n  Assessing Model-free Anomaly Detection in Industrial Control Systems Against\n  Generic Concealment Attacks https://dl.acm.org/doi/10.1145/3564625.3564633"},{"id":"http://arxiv.org/abs/2306.14688v1","updated":"2023-06-26T13:32:11Z","published":"2023-06-26T13:32:11Z","title":"An Evolution Kernel Method for Graph Classification through Heat\n  Diffusion Dynamics","summary":"  Autonomous individuals establish a structural complex system through pairwise\nconnections and interactions. Notably, the evolution reflects the dynamic\nnature of each complex system since it recodes a series of temporal changes\nfrom the past, the present into the future. Different systems follow distinct\nevolutionary trajectories, which can serve as distinguishing traits for system\nclassification. However, modeling a complex system's evolution is challenging\nfor the graph model because the graph is typically a snapshot of the static\nstatus of a system, and thereby hard to manifest the long-term evolutionary\ntraits of a system entirely. To address this challenge, we suggest utilizing a\nheat-driven method to generate temporal graph augmentation. This approach\nincorporates the physics-based heat kernel and DropNode technique to transform\neach static graph into a sequence of temporal ones. This approach effectively\ndescribes the evolutional behaviours of the system, including the retention or\ndisappearance of elements at each time point based on the distributed heat on\neach node. Additionally, we propose a dynamic time-wrapping distance GDTW to\nquantitatively measure the distance between pairwise evolutionary systems\nthrough optimal matching. The resulting approach, called the Evolution Kernel\nmethod, has been successfully applied to classification problems in real-world\nstructural graph datasets. The results yield significant improvements in\nsupervised classification accuracy over a series of baseline methods.\n","authors":["Xue Liu","Dan Sun","Wei Wei","Zhiming Zheng"],"pdf_url":"https://arxiv.org/pdf/2306.14688v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14683v1","updated":"2023-06-26T13:27:11Z","published":"2023-06-26T13:27:11Z","title":"Multi-Agent Deep Reinforcement Learning for Dynamic Avatar Migration in\n  AIoT-enabled Vehicular Metaverses with Trajectory Prediction","summary":"  Avatars, as promising digital assistants in Vehicular Metaverses, can enable\ndrivers and passengers to immerse in 3D virtual spaces, serving as a practical\nemerging example of Artificial Intelligence of Things (AIoT) in intelligent\nvehicular environments. The immersive experience is achieved through seamless\nhuman-avatar interaction, e.g., augmented reality navigation, which requires\nintensive resources that are inefficient and impractical to process on\nintelligent vehicles locally. Fortunately, offloading avatar tasks to RoadSide\nUnits (RSUs) or cloud servers for remote execution can effectively reduce\nresource consumption. However, the high mobility of vehicles, the dynamic\nworkload of RSUs, and the heterogeneity of RSUs pose novel challenges to making\navatar migration decisions. To address these challenges, in this paper, we\npropose a dynamic migration framework for avatar tasks based on real-time\ntrajectory prediction and Multi-Agent Deep Reinforcement Learning (MADRL).\nSpecifically, we propose a model to predict the future trajectories of\nintelligent vehicles based on their historical data, indicating the future\nworkloads of RSUs.Based on the expected workloads of RSUs, we formulate the\navatar task migration problem as a long-term mixed integer programming problem.\nTo tackle this problem efficiently, the problem is transformed into a Partially\nObservable Markov Decision Process (POMDP) and solved by multiple DRL agents\nwith hybrid continuous and discrete actions in decentralized. Numerical results\ndemonstrate that our proposed algorithm can effectively reduce the latency of\nexecuting avatar tasks by around 25% without prediction and 30% with prediction\nand enhance user immersive experiences in the AIoT-enabled Vehicular Metaverse\n(AeVeM).\n","authors":["Junlong Chen","Jiawen Kang","Minrui Xu","Zehui Xiong","Dusit Niyato","Chuan Chen","Abbas Jamalipour","Shengli Xie"],"pdf_url":"https://arxiv.org/pdf/2306.14683v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14680v1","updated":"2023-06-26T13:23:52Z","published":"2023-06-26T13:23:52Z","title":"A Conditional Flow Variational Autoencoder for Controllable Synthesis of\n  Virtual Populations of Anatomy","summary":"  Generating virtual populations (VPs) of anatomy is essential for conducting\nin-silico trials of medical devices. Typically, the generated VP should capture\nsufficient variability while remaining plausible, and should reflect specific\ncharacteristics and patient demographics observed in real populations. It is\ndesirable in several applications to synthesize VPs in a \\textit{controlled}\nmanner, where relevant covariates are used to conditionally synthesise virtual\npopulations that fit specific target patient populations/characteristics. We\npropose to equip a conditional variational autoencoder (cVAE) with normalizing\nflows to boost the flexibility and complexity of the approximate posterior\nlearned, leading to enhanced flexibility for controllable synthesis of VPs of\nanatomical structures. We demonstrate the performance of our conditional-flow\nVAE using a dataset of cardiac left ventricles acquired from 2360 patients,\nwith associated demographic information and clinical measurements (used as\ncovariates/conditioning information). The obtained results indicate the\nsuperiority of the proposed method for conditional synthesis of virtual\npopulations of cardiac left ventricles relative to a cVAE. Conditional\nsynthesis performance was assessed in terms of generalisation and specificity\nerrors, and in terms of the ability to preserve clinical relevant biomarkers in\nthe synthesised VPs, I.e. left ventricular blood pool and myocardial volume,\nrelative to the observed real population.\n","authors":["Haoran Dou","Nishant Ravikumar","Alejandro F. Frangi"],"pdf_url":"https://arxiv.org/pdf/2306.14680v1.pdf","comment":"Accepted at MICCAI 2023"},{"id":"http://arxiv.org/abs/2301.01835v3","updated":"2023-06-26T13:19:07Z","published":"2023-01-04T22:04:28Z","title":"Deep Statistical Solver for Distribution System State Estimation","summary":"  Implementing accurate Distribution System State Estimation (DSSE) faces\nseveral challenges, among which the lack of observability and the high density\nof the distribution system. While data-driven alternatives based on Machine\nLearning models could be a choice, they suffer in DSSE because of the lack of\nlabeled data. In fact, measurements in the distribution system are often noisy,\ncorrupted, and unavailable. To address these issues, we propose the Deep\nStatistical Solver for Distribution System State Estimation (DSS$^2$), a deep\nlearning model based on graph neural networks (GNNs) that accounts for the\nnetwork structure of the distribution system and for the physical governing\npower flow equations. DSS$^2$ leverages hypergraphs to represent the\nheterogeneous components of the distribution systems and updates their latent\nrepresentations via a node-centric message-passing scheme. A weakly supervised\nlearning approach is put forth to train the DSS$^2$ in a learning-to-optimize\nfashion w.r.t. the Weighted Least Squares loss with noisy measurements and\npseudomeasurements. By enforcing the GNN output into the power flow equations\nand the latter into the loss function, we force the DSS$^2$ to respect the\nphysics of the distribution system. This strategy enables learning from noisy\nmeasurements, acting as an implicit denoiser, and alleviating the need for\nideal labeled data. Extensive experiments with case studies on the IEEE 14-bus,\n70-bus, and 179-bus networks showed the DSS$^2$ outperforms by a margin the\nconventional Weighted Least Squares algorithm in accuracy, convergence, and\ncomputational time, while being more robust to noisy, erroneous, and missing\nmeasurements. The DSS$^2$ achieves a competing, yet lower, performance compared\nwith the supervised models that rely on the unrealistic assumption of having\nall the true labels.\n","authors":["Benjamin Habib","Elvin Isufi","Ward van Breda","Arjen Jongepier","Jochen L. Cremer"],"pdf_url":"https://arxiv.org/pdf/2301.01835v3.pdf","comment":"12 pages, accepted at IEEE Transactions on Power Systems"},{"id":"http://arxiv.org/abs/2306.14672v1","updated":"2023-06-26T13:08:21Z","published":"2023-06-26T13:08:21Z","title":"PWSHAP: A Path-Wise Explanation Model for Targeted Variables","summary":"  Predictive black-box models can exhibit high accuracy but their opaque nature\nhinders their uptake in safety-critical deployment environments. Explanation\nmethods (XAI) can provide confidence for decision-making through increased\ntransparency. However, existing XAI methods are not tailored towards models in\nsensitive domains where one predictor is of special interest, such as a\ntreatment effect in a clinical model, or ethnicity in policy models. We\nintroduce Path-Wise Shapley effects (PWSHAP), a framework for assessing the\ntargeted effect of a binary (e.g.~treatment) variable from a complex outcome\nmodel. Our approach augments the predictive model with a user-defined directed\nacyclic graph (DAG). The method then uses the graph alongside on-manifold\nShapley values to identify effects along causal pathways whilst maintaining\nrobustness to adversarial attacks. We establish error bounds for the identified\npath-wise Shapley effects and for Shapley values. We show PWSHAP can perform\nlocal bias and mediation analyses with faithfulness to the model. Further, if\nthe targeted variable is randomised we can quantify local effect modification.\nWe demonstrate the resolution, interpretability, and true locality of our\napproach on examples and a real-world experiment.\n","authors":["Lucile Ter-Minassian","Oscar Clivio","Karla Diaz-Ordaz","Robin J. Evans","Chris Holmes"],"pdf_url":"https://arxiv.org/pdf/2306.14672v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14670v1","updated":"2023-06-26T13:06:34Z","published":"2023-06-26T13:06:34Z","title":"Improved Bayes Risk Can Yield Reduced Social Welfare Under Competition","summary":"  As the scale of machine learning models increases, trends such as scaling\nlaws anticipate consistent downstream improvements in predictive accuracy.\nHowever, these trends take the perspective of a single model-provider in\nisolation, while in reality providers often compete with each other for users.\nIn this work, we demonstrate that competition can fundamentally alter the\nbehavior of these scaling trends, even causing overall predictive accuracy\nacross users to be non-monotonic or decreasing with scale. We define a model of\ncompetition for classification tasks, and use data representations as a lens\nfor studying the impact of increases in scale. We find many settings where\nimproving data representation quality (as measured by Bayes risk) decreases the\noverall predictive accuracy across users (i.e., social welfare) for a\nmarketplace of competing model-providers. Our examples range from closed-form\nformulas in simple settings to simulations with pretrained representations on\nCIFAR-10. At a conceptual level, our work suggests that favorable scaling\ntrends for individual model-providers need not translate to downstream\nimprovements in social welfare in marketplaces with multiple model providers.\n","authors":["Meena Jagadeesan","Michael I. Jordan","Jacob Steinhardt","Nika Haghtalab"],"pdf_url":"https://arxiv.org/pdf/2306.14670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.02473v2","updated":"2023-06-26T13:04:47Z","published":"2022-03-04T18:10:24Z","title":"Interpretable Off-Policy Learning via Hyperbox Search","summary":"  Personalized treatment decisions have become an integral part of modern\nmedicine. Thereby, the aim is to make treatment decisions based on individual\npatient characteristics. Numerous methods have been developed for learning such\npolicies from observational data that achieve the best outcome across a certain\npolicy class. Yet these methods are rarely interpretable. However,\ninterpretability is often a prerequisite for policy learning in clinical\npractice. In this paper, we propose an algorithm for interpretable off-policy\nlearning via hyperbox search. In particular, our policies can be represented in\ndisjunctive normal form (i.e., OR-of-ANDs) and are thus intelligible. We prove\na universal approximation theorem that shows that our policy class is flexible\nenough to approximate any measurable function arbitrarily well. For\noptimization, we develop a tailored column generation procedure within a\nbranch-and-bound framework. Using a simulation study, we demonstrate that our\nalgorithm outperforms state-of-the-art methods from interpretable off-policy\nlearning in terms of regret. Using real-word clinical data, we perform a user\nstudy with actual clinical experts, who rate our policies as highly\ninterpretable.\n","authors":["Daniel Tschernutter","Tobias Hatt","Stefan Feuerriegel"],"pdf_url":"https://arxiv.org/pdf/2203.02473v2.pdf","comment":"ICML 2022"},{"id":"http://arxiv.org/abs/2306.14662v1","updated":"2023-06-26T12:54:28Z","published":"2023-06-26T12:54:28Z","title":"Cross Architecture Distillation for Face Recognition","summary":"  Transformers have emerged as the superior choice for face recognition tasks,\nbut their insufficient platform acceleration hinders their application on\nmobile devices. In contrast, Convolutional Neural Networks (CNNs) capitalize on\nhardware-compatible acceleration libraries. Consequently, it has become\nindispensable to preserve the distillation efficacy when transferring knowledge\nfrom a Transformer-based teacher model to a CNN-based student model, known as\nCross-Architecture Knowledge Distillation (CAKD). Despite its potential, the\ndeployment of CAKD in face recognition encounters two challenges: 1) the\nteacher and student share disparate spatial information for each pixel,\nobstructing the alignment of feature space, and 2) the teacher network is not\ntrained in the role of a teacher, lacking proficiency in handling\ndistillation-specific knowledge. To surmount these two constraints, 1) we first\nintroduce a Unified Receptive Fields Mapping module (URFM) that maps pixel\nfeatures of the teacher and student into local features with unified receptive\nfields, thereby synchronizing the pixel-wise spatial information of teacher and\nstudent. Subsequently, 2) we develop an Adaptable Prompting Teacher network\n(APT) that integrates prompts into the teacher, enabling it to manage\ndistillation-specific knowledge while preserving the model's discriminative\ncapacity. Extensive experiments on popular face benchmarks and two large-scale\nverification sets demonstrate the superiority of our method.\n","authors":["Weisong Zhao","Xiangyu Zhu","Zhixiang He","Xiao-Yu Zhang","Zhen Lei"],"pdf_url":"https://arxiv.org/pdf/2306.14662v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14658v1","updated":"2023-06-26T12:51:32Z","published":"2023-06-26T12:51:32Z","title":"Beyond AUROC & co. for evaluating out-of-distribution detection\n  performance","summary":"  While there has been a growing research interest in developing\nout-of-distribution (OOD) detection methods, there has been comparably little\ndiscussion around how these methods should be evaluated. Given their relevance\nfor safe(r) AI, it is important to examine whether the basis for comparing OOD\ndetection methods is consistent with practical needs. In this work, we take a\ncloser look at the go-to metrics for evaluating OOD detection, and question the\napproach of exclusively reducing OOD detection to a binary classification task\nwith little consideration for the detection threshold. We illustrate the\nlimitations of current metrics (AUROC & its friends) and propose a new metric -\nArea Under the Threshold Curve (AUTC), which explicitly penalizes poor\nseparation between ID and OOD samples. Scripts and data are available at\nhttps://github.com/glhr/beyond-auroc\n","authors":["Galadrielle Humblot-Renaux","Sergio Escalera","Thomas B. Moeslund"],"pdf_url":"https://arxiv.org/pdf/2306.14658v1.pdf","comment":"published in SAIAD CVPRW'23 (Safe Artificial Intelligence for All\n  Domains CVPR workshop)"},{"id":"http://arxiv.org/abs/2306.14650v1","updated":"2023-06-26T12:40:12Z","published":"2023-06-26T12:40:12Z","title":"PhD Thesis: Exploring the role of (self-)attention in cognitive and\n  computer vision architecture","summary":"  We investigate the role of attention and memory in complex reasoning tasks.\nWe analyze Transformer-based self-attention as a model and extend it with\nmemory. By studying a synthetic visual reasoning test, we refine the taxonomy\nof reasoning tasks. Incorporating self-attention with ResNet50, we enhance\nfeature maps using feature-based and spatial attention, achieving efficient\nsolving of challenging visual reasoning tasks. Our findings contribute to\nunderstanding the attentional needs of SVRT tasks. Additionally, we propose\nGAMR, a cognitive architecture combining attention and memory, inspired by\nactive vision theory. GAMR outperforms other architectures in sample\nefficiency, robustness, and compositionality, and shows zero-shot\ngeneralization on new reasoning tasks.\n","authors":["Mohit Vaishnav"],"pdf_url":"https://arxiv.org/pdf/2306.14650v1.pdf","comment":"PhD Thesis, 152 pages, 32 figures, 6 tables"},{"id":"http://arxiv.org/abs/2302.12014v2","updated":"2023-06-26T12:37:56Z","published":"2023-01-26T14:58:37Z","title":"normflows: A PyTorch Package for Normalizing Flows","summary":"  Normalizing flows model probability distributions through an expressive\ntractable density. They transform a simple base distribution, such as a\nGaussian, through a sequence of invertible functions, which are referred to as\nlayers. These layers typically use neural networks to become very expressive.\nFlows are ubiquitous in machine learning and have been applied to image\ngeneration, text modeling, variational inference, approximating Boltzmann\ndistributions, and many other problems. Here, we present normflows, a Python\npackage for normalizing flows. It allows to build normalizing flow models from\na suite of base distributions, flow layers, and neural networks. The package is\nimplemented in the popular deep learning framework PyTorch, which simplifies\nthe integration of flows in larger machine learning models or pipelines. It\nsupports most of the common normalizing flow architectures, such as Real NVP,\nGlow, Masked Autoregressive Flows, Neural Spline Flows, Residual Flows, and\nmany more. The package can be easily installed via pip and the code is publicly\navailable on GitHub.\n","authors":["Vincent Stimper","David Liu","Andrew Campbell","Vincent Berenz","Lukas Ryll","Bernhard Schölkopf","José Miguel Hernández-Lobato"],"pdf_url":"https://arxiv.org/pdf/2302.12014v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.11996v5","updated":"2023-06-26T12:36:03Z","published":"2023-02-23T13:18:12Z","title":"K-SHAP: Policy Clustering Algorithm for Anonymous Multi-Agent\n  State-Action Pairs","summary":"  Learning agent behaviors from observational data has shown to improve our\nunderstanding of their decision-making processes, advancing our ability to\nexplain their interactions with the environment and other agents. While\nmultiple learning techniques have been proposed in the literature, there is one\nparticular setting that has not been explored yet: multi agent systems where\nagent identities remain anonymous. For instance, in financial markets labeled\ndata that identifies market participant strategies is typically proprietary,\nand only the anonymous state-action pairs that result from the interaction of\nmultiple market participants are publicly available. As a result, sequences of\nagent actions are not observable, restricting the applicability of existing\nwork. In this paper, we propose a Policy Clustering algorithm, called K-SHAP,\nthat learns to group anonymous state-action pairs according to the agent\npolicies. We frame the problem as an Imitation Learning (IL) task, and we learn\na world-policy able to mimic all the agent behaviors upon different\nenvironmental states. We leverage the world-policy to explain each anonymous\nobservation through an additive feature attribution method called SHAP (SHapley\nAdditive exPlanations). Finally, by clustering the explanations we show that we\nare able to identify different agent policies and group observations\naccordingly. We evaluate our approach on simulated synthetic market data and a\nreal-world financial dataset. We show that our proposal significantly and\nconsistently outperforms the existing methods, identifying different agent\nstrategies.\n","authors":["Andrea Coletta","Svitlana Vyetrenko","Tucker Balch"],"pdf_url":"https://arxiv.org/pdf/2302.11996v5.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2306.14647v1","updated":"2023-06-26T12:33:29Z","published":"2023-06-26T12:33:29Z","title":"Mono-to-stereo through parametric stereo generation","summary":"  Generating a stereophonic presentation from a monophonic audio signal is a\nchallenging open task, especially if the goal is to obtain a realistic spatial\nimaging with a specific panning of sound elements. In this work, we propose to\nconvert mono to stereo by means of predicting parametric stereo (PS) parameters\nusing both nearest neighbor and deep network approaches. In combination with\nPS, we also propose to model the task with generative approaches, allowing to\nsynthesize multiple and equally-plausible stereo renditions from the same mono\nsignal. To achieve this, we consider both autoregressive and masked token\nmodelling approaches. We provide evidence that the proposed PS-based models\noutperform a competitive classical decorrelation baseline and that, within a PS\nprediction framework, modern generative models outshine equivalent\nnon-generative counterparts. Overall, our work positions both PS and generative\nmodelling as strong and appealing methodologies for mono-to-stereo upmixing. A\ndiscussion of the limitations of these approaches is also provided.\n","authors":["Joan Serrà","Davide Scaini","Santiago Pascual","Daniel Arteaga","Jordi Pons","Jeroen Breebaart","Giulio Cengarle"],"pdf_url":"https://arxiv.org/pdf/2306.14647v1.pdf","comment":"7 pages, 1 figure; accepted for ISMIR23"},{"id":"http://arxiv.org/abs/2210.02885v3","updated":"2023-06-26T12:17:11Z","published":"2022-10-05T12:13:04Z","title":"RankMe: Assessing the downstream performance of pretrained\n  self-supervised representations by their rank","summary":"  Joint-Embedding Self Supervised Learning (JE-SSL) has seen a rapid\ndevelopment, with the emergence of many method variations but only few\nprincipled guidelines that would help practitioners to successfully deploy\nthem. The main reason for that pitfall comes from JE-SSL's core principle of\nnot employing any input reconstruction therefore lacking visual cues of\nunsuccessful training. Adding non informative loss values to that, it becomes\ndifficult to deploy SSL on a new dataset for which no labels can help to judge\nthe quality of the learned representation. In this study, we develop a simple\nunsupervised criterion that is indicative of the quality of the learned JE-SSL\nrepresentations: their effective rank. Albeit simple and computationally\nfriendly, this method -- coined RankMe -- allows one to assess the performance\nof JE-SSL representations, even on different downstream datasets, without\nrequiring any labels. A further benefit of RankMe is that it does not have any\ntraining or hyper-parameters to tune. Through thorough empirical experiments\ninvolving hundreds of training episodes, we demonstrate how RankMe can be used\nfor hyperparameter selection with nearly no reduction in final performance\ncompared to the current selection method that involve a dataset's labels. We\nhope that RankMe will facilitate the deployment of JE-SSL towards domains that\ndo not have the opportunity to rely on labels for representations' quality\nassessment.\n","authors":["Quentin Garrido","Randall Balestriero","Laurent Najman","Yann Lecun"],"pdf_url":"https://arxiv.org/pdf/2210.02885v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.02574v3","updated":"2023-06-26T12:01:56Z","published":"2022-06-03T08:04:12Z","title":"On the duality between contrastive and non-contrastive self-supervised\n  learning","summary":"  Recent approaches in self-supervised learning of image representations can be\ncategorized into different families of methods and, in particular, can be\ndivided into contrastive and non-contrastive approaches. While differences\nbetween the two families have been thoroughly discussed to motivate new\napproaches, we focus more on the theoretical similarities between them. By\ndesigning contrastive and covariance based non-contrastive criteria that can be\nrelated algebraically and shown to be equivalent under limited assumptions, we\nshow how close those families can be. We further study popular methods and\nintroduce variations of them, allowing us to relate this theoretical result to\ncurrent practices and show the influence (or lack thereof) of design choices on\ndownstream performance. Motivated by our equivalence result, we investigate the\nlow performance of SimCLR and show how it can match VICReg's with careful\nhyperparameter tuning, improving significantly over known baselines. We also\nchallenge the popular assumption that non-contrastive methods need large output\ndimensions. Our theoretical and quantitative results suggest that the numerical\ngaps between contrastive and non-contrastive methods in certain regimes can be\nclosed given better network design choices and hyperparameter tuning. The\nevidence shows that unifying different SOTA methods is an important direction\nto build a better understanding of self-supervised learning.\n","authors":["Quentin Garrido","Yubei Chen","Adrien Bardes","Laurent Najman","Yann Lecun"],"pdf_url":"https://arxiv.org/pdf/2206.02574v3.pdf","comment":"The Eleventh International Conference on Learning Representations,\n  2023, Kigali, Rwanda"},{"id":"http://arxiv.org/abs/2301.09902v2","updated":"2023-06-26T12:01:48Z","published":"2023-01-24T10:19:24Z","title":"Investigating Labeler Bias in Face Annotation for Machine Learning","summary":"  In a world increasingly reliant on artificial intelligence, it is more\nimportant than ever to consider the ethical implications of artificial\nintelligence on humanity. One key under-explored challenge is labeler bias,\nwhich can create inherently biased datasets for training and subsequently lead\nto inaccurate or unfair decisions in healthcare, employment, education, and law\nenforcement. Hence, we conducted a study to investigate and measure the\nexistence of labeler bias using images of people from different ethnicities and\nsexes in a labeling task. Our results show that participants possess\nstereotypes that influence their decision-making process and that labeler\ndemographics impact assigned labels. We also discuss how labeler bias\ninfluences datasets and, subsequently, the models trained on them. Overall, a\nhigh degree of transparency must be maintained throughout the entire artificial\nintelligence training process to identify and correct biases in the data as\nearly as possible.\n","authors":["Luke Haliburton","Sinksar Ghebremedhin","Robin Welsch","Albrecht Schmidt","Sven Mayer"],"pdf_url":"https://arxiv.org/pdf/2301.09902v2.pdf","comment":"Pre-print currently under review"},{"id":"http://arxiv.org/abs/2206.05317v2","updated":"2023-06-26T12:00:22Z","published":"2022-06-10T18:33:15Z","title":"Intrinsic dimensionality and generalization properties of the\n  $\\mathcal{R}$-norm inductive bias","summary":"  We study the structural and statistical properties of $\\mathcal{R}$-norm\nminimizing interpolants of datasets labeled by specific target functions. The\n$\\mathcal{R}$-norm is the basis of an inductive bias for two-layer neural\nnetworks, recently introduced to capture the functional effect of controlling\nthe size of network weights, independently of the network width. We find that\nthese interpolants are intrinsically multivariate functions, even when there\nare ridge functions that fit the data, and also that the $\\mathcal{R}$-norm\ninductive bias is not sufficient for achieving statistically optimal\ngeneralization for certain learning problems. Altogether, these results shed\nnew light on an inductive bias that is connected to practical neural network\ntraining.\n","authors":["Navid Ardeshir","Daniel Hsu","Clayton Sanford"],"pdf_url":"https://arxiv.org/pdf/2206.05317v2.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2306.14626v1","updated":"2023-06-26T12:00:05Z","published":"2023-06-26T12:00:05Z","title":"Estimating player completion rate in mobile puzzle games using\n  reinforcement learning","summary":"  In this work we investigate whether it is plausible to use the performance of\na reinforcement learning (RL) agent to estimate the difficulty measured as the\nplayer completion rate of different levels in the mobile puzzle game Lily's\nGarden.For this purpose we train an RL agent and measure the number of moves\nrequired to complete a level. This is then compared to the level completion\nrate of a large sample of real players.We find that the strongest predictor of\nplayer completion rate for a level is the number of moves taken to complete a\nlevel of the ~5% best runs of the agent on a given level. A very interesting\nobservation is that, while in absolute terms, the agent is unable to reach\nhuman-level performance across all levels, the differences in terms of\nbehaviour between levels are highly correlated to the differences in human\nbehaviour. Thus, despite performing sub-par, it is still possible to use the\nperformance of the agent to estimate, and perhaps further model, player\nmetrics.\n","authors":["Jeppe Theiss Kristensen","Arturo Valdivia","Paolo Burelli"],"pdf_url":"https://arxiv.org/pdf/2306.14626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.07258v2","updated":"2023-06-26T11:59:05Z","published":"2022-02-15T09:10:01Z","title":"Accelerating Non-Negative and Bounded-Variable Linear Regression\n  Algorithms with Safe Screening","summary":"  Non-negative and bounded-variable linear regression problems arise in a\nvariety of applications in machine learning and signal processing. In this\npaper, we propose a technique to accelerate existing solvers for these problems\nby identifying saturated coordinates in the course of iterations. This is akin\nto safe screening techniques previously proposed for sparsity-regularized\nregression problems. The proposed strategy is provably safe as it provides\ntheoretical guarantees that the identified coordinates are indeed saturated in\nthe optimal solution. Experimental results on synthetic and real data show\ncompelling accelerations for both non-negative and bounded-variable problems.\n","authors":["Cassio F. Dantas","Emmanuel Soubies","Cédric Févotte"],"pdf_url":"https://arxiv.org/pdf/2202.07258v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14624v1","updated":"2023-06-26T11:56:00Z","published":"2023-06-26T11:56:00Z","title":"Insights From Insurance for Fair Machine Learning: Responsibility,\n  Performativity and Aggregates","summary":"  We argue that insurance can act as an analogon for the social situatedness of\nmachine learning systems, hence allowing machine learning scholars to take\ninsights from the rich and interdisciplinary insurance literature. Tracing the\ninteraction of uncertainty, fairness and responsibility in insurance provides a\nfresh perspective on fairness in machine learning. We link insurance fairness\nconceptions to their machine learning relatives, and use this bridge to\nproblematize fairness as calibration. In this process, we bring to the\nforefront three themes that have been largely overlooked in the machine\nlearning literature: responsibility, performativity and tensions between\naggregate and individual.\n","authors":["Christian Fröhlich","Robert C. Williamson"],"pdf_url":"https://arxiv.org/pdf/2306.14624v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14610v1","updated":"2023-06-26T11:35:22Z","published":"2023-06-26T11:35:22Z","title":"SugarCrepe: Fixing Hackable Benchmarks for Vision-Language\n  Compositionality","summary":"  In the last year alone, a surge of new benchmarks to measure compositional\nunderstanding of vision-language models have permeated the machine learning\necosystem. Given an image, these benchmarks probe a model's ability to identify\nits associated caption amongst a set of compositional distractors.\nSurprisingly, we find significant biases in all these benchmarks rendering them\nhackable. This hackability is so dire that blind models with no access to the\nimage outperform state-of-the-art vision-language models. To remedy this\nrampant vulnerability, we introduce SugarCrepe, a new benchmark for\nvision-language compositionality evaluation. We employ large language models,\ninstead of rule-based templates used in previous benchmarks, to generate fluent\nand sensical hard negatives, and utilize an adversarial refinement mechanism to\nmaximally reduce biases. We re-evaluate state-of-the-art models and recently\nproposed compositionality inducing strategies, and find that their improvements\nwere hugely overestimated, suggesting that more innovation is needed in this\nimportant direction. We release SugarCrepe and the code for evaluation at:\nhttps://github.com/RAIVNLab/sugar-crepe.\n","authors":["Cheng-Yu Hsieh","Jieyu Zhang","Zixian Ma","Aniruddha Kembhavi","Ranjay Krishna"],"pdf_url":"https://arxiv.org/pdf/2306.14610v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14609v1","updated":"2023-06-26T11:32:40Z","published":"2023-06-26T11:32:40Z","title":"The race to robustness: exploiting fragile models for urban camouflage\n  and the imperative for machine learning security","summary":"  Adversarial Machine Learning (AML) represents the ability to disrupt Machine\nLearning (ML) algorithms through a range of methods that broadly exploit the\narchitecture of deep learning optimisation. This paper presents Distributed\nAdversarial Regions (DAR), a novel method that implements distributed\ninstantiations of computer vision-based AML attack methods that may be used to\ndisguise objects from image recognition in both white and black box settings.\nWe consider the context of object detection models used in urban environments,\nand benchmark the MobileNetV2, NasNetMobile and DenseNet169 models against a\nsubset of relevant images from the ImageNet dataset. We evaluate optimal\nparameters (size, number and perturbation method), and compare to\nstate-of-the-art AML techniques that perturb the entire image. We find that\nDARs can cause a reduction in confidence of 40.4% on average, but with the\nbenefit of not requiring the entire image, or the focal object, to be\nperturbed. The DAR method is a deliberately simple approach where the intention\nis to highlight how an adversary with very little skill could attack models\nthat may already be productionised, and to emphasise the fragility of\nfoundational object detection models. We present this as a contribution to the\nfield of ML security as well as AML. This paper contributes a novel adversarial\nmethod, an original comparison between DARs and other AML methods, and frames\nit in a new context - that of urban camouflage and the necessity for ML\nsecurity and model robustness.\n","authors":["Harriet Farlow","Matthew Garratt","Gavin Mount","Tim Lynar"],"pdf_url":"https://arxiv.org/pdf/2306.14609v1.pdf","comment":"Accepted to IEEE TENSYMP 2023"},{"id":"http://arxiv.org/abs/2211.00071v3","updated":"2023-06-26T11:31:03Z","published":"2022-10-25T16:40:28Z","title":"CarbonTag: A Browser-Based Method for Approximating Energy Consumption\n  of Online Ads","summary":"  Energy is today the most critical environmental challenge. The amount of\ncarbon emissions contributing to climate change is significantly influenced by\nboth the production and consumption of energy. Measuring and reducing the\nenergy consumption of services is a crucial step toward reducing adverse\nenvironmental effects caused by carbon emissions. Millions of websites rely on\nonline advertisements to generate revenue, with most websites earning most or\nall of their revenues from ads. As a result, hundreds of billions of online ads\nare delivered daily to internet users to be rendered in their browsers. Both\nthe delivery and rendering of each ad consume energy. This study investigates\nhow much energy online ads use in the rendering process and offers a way for\npredicting it as part of rendering the ad. To the best of the authors'\nknowledge, this is the first study to calculate the energy usage of single\nadvertisements in the rendering process. Our research further introduces\ndifferent levels of consumption by which online ads can be classified based on\nenergy efficiency. This classification will allow advertisers to add energy\nefficiency metrics and optimize campaigns towards consuming less possible.\n","authors":["José González Cabañas","Patricia Callejo","Rubén Cuevas","Steffen Svatberg","Tommy Torjesen","Ángel Cuevas","Antonio Pastor","Mikko Kotila"],"pdf_url":"https://arxiv.org/pdf/2211.00071v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14606v1","updated":"2023-06-26T11:30:33Z","published":"2023-06-26T11:30:33Z","title":"Multivariate Time Series Early Classification Across Channel and Time\n  Dimensions","summary":"  Nowadays, the deployment of deep learning models on edge devices for\naddressing real-world classification problems is becoming more prevalent.\nMoreover, there is a growing popularity in the approach of early\nclassification, a technique that involves classifying the input data after\nobserving only an early portion of it, aiming to achieve reduced communication\nand computation requirements, which are crucial parameters in edge intelligence\nenvironments. While early classification in the field of time series analysis\nhas been broadly researched, existing solutions for multivariate time series\nproblems primarily focus on early classification along the temporal dimension,\ntreating the multiple input channels in a collective manner. In this study, we\npropose a more flexible early classification pipeline that offers a more\ngranular consideration of input channels and extends the early classification\nparadigm to the channel dimension. To implement this method, we utilize\nreinforcement learning techniques and introduce constraints to ensure the\nfeasibility and practicality of our objective. To validate its effectiveness,\nwe conduct experiments using synthetic data and we also evaluate its\nperformance on real datasets. The comprehensive results from our experiments\ndemonstrate that, for multiple datasets, our method can enhance the early\nclassification paradigm by achieving improved accuracy for equal input\nutilization.\n","authors":["Leonardos Pantiskas","Kees Verstoep","Mark Hoogendoorn","Henri Bal"],"pdf_url":"https://arxiv.org/pdf/2306.14606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.08883v5","updated":"2023-06-26T11:27:39Z","published":"2023-02-17T14:07:32Z","title":"Approximately Bayes-Optimal Pseudo Label Selection","summary":"  Semi-supervised learning by self-training heavily relies on pseudo-label\nselection (PLS). The selection often depends on the initial model fit on\nlabeled data. Early overfitting might thus be propagated to the final model by\nselecting instances with overconfident but erroneous predictions, often\nreferred to as confirmation bias. This paper introduces BPLS, a Bayesian\nframework for PLS that aims to mitigate this issue. At its core lies a\ncriterion for selecting instances to label: an analytical approximation of the\nposterior predictive of pseudo-samples. We derive this selection criterion by\nproving Bayes optimality of the posterior predictive of pseudo-samples. We\nfurther overcome computational hurdles by approximating the criterion\nanalytically. Its relation to the marginal likelihood allows us to come up with\nan approximation based on Laplace's method and the Gaussian integral. We\nempirically assess BPLS for parametric generalized linear and non-parametric\ngeneralized additive models on simulated and real-world data. When faced with\nhigh-dimensional data prone to overfitting, BPLS outperforms traditional PLS\nmethods.\n","authors":["Julian Rodemann","Jann Goschenhofer","Emilio Dorigatti","Thomas Nagler","Thomas Augustin"],"pdf_url":"https://arxiv.org/pdf/2302.08883v5.pdf","comment":"UAI 2023"},{"id":"http://arxiv.org/abs/2306.14601v1","updated":"2023-06-26T11:24:03Z","published":"2023-06-26T11:24:03Z","title":"Safe Navigation in Unstructured Environments by Minimizing Uncertainty\n  in Control and Perception","summary":"  Uncertainty in control and perception poses challenges for autonomous vehicle\nnavigation in unstructured environments, leading to navigation failures and\npotential vehicle damage. This paper introduces a framework that minimizes\ncontrol and perception uncertainty to ensure safe and reliable navigation. The\nframework consists of two uncertainty-aware models: a learning-based vehicle\ndynamics model and a self-supervised traversability estimation model. We train\na vehicle dynamics model that can quantify the epistemic uncertainty of the\nmodel to perform active exploration, resulting in the efficient collection of\ntraining data and effective avoidance of uncertain state-action spaces. In\naddition, we employ meta-learning to train a traversability cost prediction\nnetwork. The model can be trained with driving data from a variety of types of\nterrain, and it can online-adapt based on interaction experiences to reduce the\naleatoric uncertainty. Integrating the dynamics model and traversability cost\nprediction model with a sampling-based model predictive controller allows for\noptimizing trajectories that avoid uncertain terrains and state-action spaces.\nExperimental results demonstrate that the proposed method reduces uncertainty\nin prediction and improves stability in autonomous vehicle navigation in\nunstructured environments.\n","authors":["Junwon Seo","Jungwi Mun","Taekyung Kim"],"pdf_url":"https://arxiv.org/pdf/2306.14601v1.pdf","comment":"RSS 2023 Workshop on Inference and Decision Making for Autonomous\n  Vehicles (IDMAV)"},{"id":"http://arxiv.org/abs/2210.05247v3","updated":"2023-06-26T10:40:08Z","published":"2022-10-11T08:25:47Z","title":"Training Debiased Subnetworks with Contrastive Weight Pruning","summary":"  Neural networks are often biased to spuriously correlated features that\nprovide misleading statistical evidence that does not generalize. This raises\nan interesting question: ``Does an optimal unbiased functional subnetwork exist\nin a severely biased network? If so, how to extract such subnetwork?\" While\nempirical evidence has been accumulated about the existence of such unbiased\nsubnetworks, these observations are mainly based on the guidance of\nground-truth unbiased samples. Thus, it is unexplored how to discover the\noptimal subnetworks with biased training datasets in practice. To address this,\nhere we first present our theoretical insight that alerts potential limitations\nof existing algorithms in exploring unbiased subnetworks in the presence of\nstrong spurious correlations. We then further elucidate the importance of\nbias-conflicting samples on structure learning. Motivated by these\nobservations, we propose a Debiased Contrastive Weight Pruning (DCWP)\nalgorithm, which probes unbiased subnetworks without expensive group\nannotations. Experimental results demonstrate that our approach significantly\noutperforms state-of-the-art debiasing methods despite its considerable\nreduction in the number of parameters.\n","authors":["Geon Yeong Park","Sangmin Lee","Sang Wan Lee","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2210.05247v3.pdf","comment":"CVPR 2023, code: https://github.com/ParkGeonYeong/DCWP"},{"id":"http://arxiv.org/abs/2306.14574v1","updated":"2023-06-26T10:35:31Z","published":"2023-06-26T10:35:31Z","title":"On-Device Evaluation Toolkit for Machine Learning on Heterogeneous\n  Low-Power System-on-Chip","summary":"  Network delays, throughput bottlenecks and privacy issues push Artificial\nIntelligence of Things (AIoT) designers towards evaluating the feasibility of\nmoving model training and execution (inference) as near as possible to the\nterminals. Meanwhile, results from the TinyML community demonstrate that, in\nsome cases, it is possible to execute model inference directly on the terminals\nthemselves, even if these are small microcontroller-based devices. However, to\ndate, researchers and practitioners in the domain lack convenient all-in-one\ntoolkits to help them evaluate the feasibility of moving execution of arbitrary\nmodels to arbitrary low-power IoT hardware. To this effect, we present in this\npaper U-TOE, a universal toolkit we designed to facilitate the task of AIoT\ndesigners and researchers, by combining functionalities from a low-power\nembedded OS, a generic model transpiler and compiler, an integrated performance\nmeasurement module, and an open-access remote IoT testbed. We provide an open\nsource implementation of U-TOE and we demonstrate its use to experimentally\nevaluate the performance of a wide variety of models, on a wide variety of\nlow-power boards, based on popular microcontroller architectures (ARM Cortex-M\nand RISC-V). U-TOE thus allows easily reproducible and customisable comparative\nevaluation experiments in this domain, on a wide variety of IoT hardware\nall-at-once. The availability of a toolkit such as U-TOE is desirable to\naccelerate the field of AIoT, towards fully exploiting the potential of edge\ncomputing.\n","authors":["Zhaolan Huang","Koen Zandberg","Kaspar Schleiser","Emmanuel Baccelli"],"pdf_url":"https://arxiv.org/pdf/2306.14574v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14572v1","updated":"2023-06-26T10:33:45Z","published":"2023-06-26T10:33:45Z","title":"Feature Imitating Networks Enhance The Performance, Reliability And\n  Speed Of Deep Learning On Biomedical Image Processing Tasks","summary":"  Feature-Imitating-Networks (FINs) are neural networks with weights that are\ninitialized to approximate closed-form statistical features. In this work, we\nperform the first-ever evaluation of FINs for biomedical image processing\ntasks. We begin by training a set of FINs to imitate six common radiomics\nfeatures, and then compare the performance of networks with and without the\nFINs for three experimental tasks: COVID-19 detection from CT scans, brain\ntumor classification from MRI scans, and brain-tumor segmentation from MRI\nscans; we find that FINs provide best-in-class performance for all three tasks,\nwhile converging faster and more consistently when compared to networks with\nsimilar or greater representational power. The results of our experiments\nprovide evidence that FINs may provide state-of-the-art performance for a\nvariety of other biomedical image processing tasks.\n","authors":["Shangyang Min","Mohammad Mahdi Ghassemi","Tuka Alhanai"],"pdf_url":"https://arxiv.org/pdf/2306.14572v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.03853v3","updated":"2023-06-26T10:32:24Z","published":"2022-12-05T12:33:26Z","title":"Clustering with Neural Network and Index","summary":"  A new model called Clustering with Neural Network and Index (CNNI) is\nintroduced. CNNI uses a Neural Network to cluster data points. Training of the\nNeural Network mimics supervised learning, with an internal clustering\nevaluation index acting as the loss function. An experiment is conducted to\ntest the feasibility of the new model, and compared with results of other\nclustering models like K-means and Gaussian Mixture Model (GMM). The result\nshows CNNI can work properly for clustering data; CNNI equipped with MMJ-SC,\nachieves the first parametric (inductive) clustering model that can deal with\nnon-convex shaped (non-flat geometry) data.\n","authors":["Gangli Liu"],"pdf_url":"https://arxiv.org/pdf/2212.03853v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14568v1","updated":"2023-06-26T10:27:36Z","published":"2023-06-26T10:27:36Z","title":"Elucidating Interfacial Dynamics of Ti-Al Systems Using Molecular\n  Dynamics Simulation and Markov State Modeling","summary":"  Due to their remarkable mechanical and chemical properties, Ti-Al based\nmaterials are attracting considerable interest in numerous fields of\nengineering, such as automotive, aerospace, and defense. With their low\ndensity, high strength, and resistance to corrosion and oxidation, these\nintermetallic alloys and compound metal-metallic composites have found diverse\napplications. The present study delves into the interfacial dynamics of these\nTi-Al systems, particularly focusing on the behavior of Ti and Al atoms in the\npresence of TiAl$_3$ grain boundaries under experimental heat treatment\nconditions. Using a combination of Molecular Dynamics and Markov State Model\nanalyses, we scrutinize the kinetic processes involved in the formation of\nTiAl$_3$. The Molecular Dynamics simulation indicates that at the early stage\nof heat treatment, the predominating process is the diffusion of Al atoms\ntowards the Ti surface through the TiAl$_3$ grain boundaries. The Markov State\nModeling identifies three distinct dynamic states of Al atoms within the Ti/Al\nmixture that forms during the process, each exhibiting a unique spatial\ndistribution. Using transition timescales as a qualitative measure of the\nrapidness of the dynamics, it is observed that the Al dynamics is significantly\nless rapid near the Ti surface compared to the Al surface. Put together, the\nresults offer a comprehensive understanding of the interfacial dynamics and\nreveals a three-stage diffusion mechanism. The process initiates with the\npremelting of Al, proceeds with the prevalent diffusion of Al atoms towards the\nTi surface, and eventually ceases as the Ti concentration within the mixture\nprogressively increases. The insights gained from this study could contribute\nsignificantly to the control and optimization of manufacturing processes for\nthese high-performing Ti-Al based materials.\n","authors":["Tianjiao Li","Chenxi Tian","Atieh Moridi","Jingjie Yeo"],"pdf_url":"https://arxiv.org/pdf/2306.14568v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14563v1","updated":"2023-06-26T10:21:26Z","published":"2023-06-26T10:21:26Z","title":"Multi-output Ensembles for Multi-step Forecasting","summary":"  This paper studies the application of ensembles composed of multi-output\nmodels for multi-step ahead forecasting problems. Dynamic ensembles have been\ncommonly used for forecasting. However, these are typically designed for\none-step-ahead tasks. On the other hand, the literature regarding the\napplication of dynamic ensembles for multi-step ahead forecasting is scarce.\nMoreover, it is not clear how the combination rule is applied across the\nforecasting horizon. We carried out extensive experiments to analyze the\napplication of dynamic ensembles for multi-step forecasting. We resorted to a\ncase study with 3568 time series and an ensemble of 30 multi-output models. We\ndiscovered that dynamic ensembles based on arbitrating and windowing present\nthe best performance according to average rank. Moreover, as the horizon\nincreases, most approaches struggle to outperform a static ensemble that\nassigns equal weights to all models. The experiments are publicly available in\na repository.\n","authors":["Vitor Cerqueira","Luis Torgo"],"pdf_url":"https://arxiv.org/pdf/2306.14563v1.pdf","comment":"19 pages, github repository available"},{"id":"http://arxiv.org/abs/2305.19185v3","updated":"2023-06-26T09:46:05Z","published":"2023-05-30T16:29:52Z","title":"Compression with Bayesian Implicit Neural Representations","summary":"  Many common types of data can be represented as functions that map\ncoordinates to signal values, such as pixel locations to RGB values in the case\nof an image. Based on this view, data can be compressed by overfitting a\ncompact neural network to its functional representation and then encoding the\nnetwork weights. However, most current solutions for this are inefficient, as\nquantization to low-bit precision substantially degrades the reconstruction\nquality. To address this issue, we propose overfitting variational Bayesian\nneural networks to the data and compressing an approximate posterior weight\nsample using relative entropy coding instead of quantizing and entropy coding\nit. This strategy enables direct optimization of the rate-distortion\nperformance by minimizing the $\\beta$-ELBO, and target different\nrate-distortion trade-offs for a given network architecture by adjusting\n$\\beta$. Moreover, we introduce an iterative algorithm for learning prior\nweight distributions and employ a progressive refinement process for the\nvariational posterior that significantly enhances performance. Experiments show\nthat our method achieves strong performance on image and audio compression\nwhile retaining simplicity.\n","authors":["Zongyu Guo","Gergely Flamich","Jiajun He","Zhibo Chen","José Miguel Hernández-Lobato"],"pdf_url":"https://arxiv.org/pdf/2305.19185v3.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2211.10066v2","updated":"2023-06-26T09:44:52Z","published":"2022-11-18T07:44:27Z","title":"Hyperbolic Sliced-Wasserstein via Geodesic and Horospherical Projections","summary":"  It has been shown beneficial for many types of data which present an\nunderlying hierarchical structure to be embedded in hyperbolic spaces.\nConsequently, many tools of machine learning were extended to such spaces, but\nonly few discrepancies to compare probability distributions defined over those\nspaces exist. Among the possible candidates, optimal transport distances are\nwell defined on such Riemannian manifolds and enjoy strong theoretical\nproperties, but suffer from high computational cost. On Euclidean spaces,\nsliced-Wasserstein distances, which leverage a closed-form of the Wasserstein\ndistance in one dimension, are more computationally efficient, but are not\nreadily available on hyperbolic spaces. In this work, we propose to derive\nnovel hyperbolic sliced-Wasserstein discrepancies. These constructions use\nprojections on the underlying geodesics either along horospheres or geodesics.\nWe study and compare them on different tasks where hyperbolic representations\nare relevant, such as sampling or image classification.\n","authors":["Clément Bonet","Laetitia Chapel","Lucas Drumetz","Nicolas Courty"],"pdf_url":"https://arxiv.org/pdf/2211.10066v2.pdf","comment":"Accepted at the TAG-ML 2023 ICML Workshop"},{"id":"http://arxiv.org/abs/2206.09821v2","updated":"2023-06-26T09:39:25Z","published":"2022-06-20T14:55:17Z","title":"Exceedance Probability Forecasting via Regression for Significant Wave\n  Height Prediction","summary":"  Significant wave height forecasting is a key problem in ocean data analytics.\nPredicting the significant wave height is crucial for estimating the energy\nproduction from waves. Moreover, the timely prediction of large waves is\nimportant to ensure the safety of maritime operations, e.g. passage of vessels.\nWe frame the task of predicting extreme values of significant wave height as an\nexceedance probability forecasting problem. Accordingly, we aim at estimating\nthe probability that the significant wave height will exceed a predefined\nthreshold. This task is usually solved using a probabilistic binary\nclassification model. Instead, we propose a novel approach based on a\nforecasting model. The method leverages the forecasts for the upcoming\nobservations to estimate the exceedance probability according to the cumulative\ndistribution function. We carried out experiments using data from a buoy placed\nin the coast of Halifax, Canada. The results suggest that the proposed\nmethodology is better than state-of-the-art approaches for exceedance\nprobability forecasting.\n","authors":["Vitor Cerqueira","Luis Torgo"],"pdf_url":"https://arxiv.org/pdf/2206.09821v2.pdf","comment":"code available, 22 pages"},{"id":"http://arxiv.org/abs/2301.04388v3","updated":"2023-06-26T09:31:53Z","published":"2023-01-11T10:20:56Z","title":"Perceive and predict: self-supervised speech representation based loss\n  functions for speech enhancement","summary":"  Recent work in the domain of speech enhancement has explored the use of\nself-supervised speech representations to aid in the training of neural speech\nenhancement models. However, much of this work focuses on using the deepest or\nfinal outputs of self supervised speech representation models, rather than the\nearlier feature encodings. The use of self supervised representations in such a\nway is often not fully motivated. In this work it is shown that the distance\nbetween the feature encodings of clean and noisy speech correlate strongly with\npsychoacoustically motivated measures of speech quality and intelligibility, as\nwell as with human Mean Opinion Score (MOS) ratings. Experiments using this\ndistance as a loss function are performed and improved performance over the use\nof STFT spectrogram distance based loss as well as other common loss functions\nfrom speech enhancement literature is demonstrated using objective measures\nsuch as perceptual evaluation of speech quality (PESQ) and short-time objective\nintelligibility (STOI).\n","authors":["George Close","William Ravenscroft","Thomas Hain","Stefan Goetze"],"pdf_url":"https://arxiv.org/pdf/2301.04388v3.pdf","comment":"4 pages, accepted at ICASSP 2023"},{"id":"http://arxiv.org/abs/2306.14534v1","updated":"2023-06-26T09:18:30Z","published":"2023-06-26T09:18:30Z","title":"CEIL: Generalized Contextual Imitation Learning","summary":"  In this paper, we present \\textbf{C}ont\\textbf{E}xtual \\textbf{I}mitation\n\\textbf{L}earning~(CEIL), a general and broadly applicable algorithm for\nimitation learning (IL). Inspired by the formulation of hindsight information\nmatching, we derive CEIL by explicitly learning a hindsight embedding function\ntogether with a contextual policy using the hindsight embeddings. To achieve\nthe expert matching objective for IL, we advocate for optimizing a contextual\nvariable such that it biases the contextual policy towards mimicking expert\nbehaviors. Beyond the typical learning from demonstrations (LfD) setting, CEIL\nis a generalist that can be effectively applied to multiple settings including:\n1)~learning from observations (LfO), 2)~offline IL, 3)~cross-domain IL\n(mismatched experts), and 4) one-shot IL settings. Empirically, we evaluate\nCEIL on the popular MuJoCo tasks (online) and the D4RL dataset (offline).\nCompared to prior state-of-the-art baselines, we show that CEIL is more\nsample-efficient in most online IL tasks and achieves better or competitive\nperformances in offline tasks.\n","authors":["Jinxin Liu","Li He","Yachen Kang","Zifeng Zhuang","Donglin Wang","Huazhe Xu"],"pdf_url":"https://arxiv.org/pdf/2306.14534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.09364v2","updated":"2023-06-26T09:17:36Z","published":"2023-06-14T06:26:23Z","title":"TSMixer: Lightweight MLP-Mixer Model for Multivariate Time Series\n  Forecasting","summary":"  Transformers have gained popularity in time series forecasting for their\nability to capture long-sequence interactions. However, their high memory and\ncomputing requirements pose a critical bottleneck for long-term forecasting. To\naddress this, we propose TSMixer, a lightweight neural architecture exclusively\ncomposed of multi-layer perceptron (MLP) modules. TSMixer is designed for\nmultivariate forecasting and representation learning on patched time series,\nproviding an efficient alternative to Transformers. Our model draws inspiration\nfrom the success of MLP-Mixer models in computer vision. We demonstrate the\nchallenges involved in adapting Vision MLP-Mixer for time series and introduce\nempirically validated components to enhance accuracy. This includes a novel\ndesign paradigm of attaching online reconciliation heads to the MLP-Mixer\nbackbone, for explicitly modeling the time-series properties such as hierarchy\nand channel-correlations. We also propose a Hybrid channel modeling approach to\neffectively handle noisy channel interactions and generalization across diverse\ndatasets, a common challenge in existing patch channel-mixing methods.\nAdditionally, a simple gated attention mechanism is introduced in the backbone\nto prioritize important features. By incorporating these lightweight\ncomponents, we significantly enhance the learning capability of simple MLP\nstructures, outperforming complex Transformer models with minimal computing\nusage. Moreover, TSMixer's modular design enables compatibility with both\nsupervised and masked self-supervised learning methods, making it a promising\nbuilding block for time-series Foundation Models. TSMixer outperforms\nstate-of-the-art MLP and Transformer models in forecasting by a considerable\nmargin of 8-60%. It also outperforms the latest strong benchmarks of\nPatch-Transformer models (by 1-2%) with a significant reduction in memory and\nruntime (2-3X).\n","authors":["Vijay Ekambaram","Arindam Jati","Nam Nguyen","Phanwadee Sinthong","Jayant Kalagnanam"],"pdf_url":"https://arxiv.org/pdf/2306.09364v2.pdf","comment":"Accepted in the Proceedings of the 29th ACM SIGKDD Conference on\n  Knowledge Discovery and Data Mining (KDD '23), Research Track, August 6--10,\n  2023, Long Beach, CA, USA"},{"id":"http://arxiv.org/abs/2306.14522v1","updated":"2023-06-26T08:54:46Z","published":"2023-06-26T08:54:46Z","title":"Nonconvex Stochastic Bregman Proximal Gradient Method with Application\n  to Deep Learning","summary":"  The widely used stochastic gradient methods for minimizing nonconvex\ncomposite objective functions require the Lipschitz smoothness of the\ndifferentiable part. But the requirement does not hold true for problem classes\nincluding quadratic inverse problems and training neural networks. To address\nthis issue, we investigate a family of stochastic Bregman proximal gradient\n(SBPG) methods, which only require smooth adaptivity of the differentiable\npart. SBPG replaces the upper quadratic approximation used in SGD with the\nBregman proximity measure, resulting in a better approximation model that\ncaptures the non-Lipschitz gradients of the nonconvex objective. We formulate\nthe vanilla SBPG and establish its convergence properties under nonconvex\nsetting without finite-sum structure. Experimental results on quadratic inverse\nproblems testify the robustness of SBPG. Moreover, we propose a momentum-based\nversion of SBPG (MSBPG) and prove it has improved convergence properties. We\napply MSBPG to the training of deep neural networks with a polynomial kernel\nfunction, which ensures the smooth adaptivity of the loss function.\nExperimental results on representative benchmarks demonstrate the effectiveness\nand robustness of MSBPG in training neural networks. Since the additional\ncomputation cost of MSBPG compared with SGD is negligible in large-scale\noptimization, MSBPG can potentially be employed an universal open-source\noptimizer in the future.\n","authors":["Kuangyu Ding","Jingyang Li","Kim-Chuan Toh"],"pdf_url":"https://arxiv.org/pdf/2306.14522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09357v2","updated":"2023-06-26T08:51:58Z","published":"2023-02-18T15:02:10Z","title":"Online Instrumental Variable Regression: Regret Analysis and Bandit\n  Feedback","summary":"  Endogeneity, i.e. the dependence between noise and covariates, is a common\nphenomenon in real data due to omitted variables, strategic behaviours,\nmeasurement errors etc. In contrast, the existing analyses of stochastic online\nlinear regression with unbounded noise and linear bandits depend heavily on\nexogeneity, i.e. the independence between noise and covariates. Motivated by\nthis gap, we study the over-and just-identified Instrumental Variable (IV)\nregression for stochastic online learning. IV regression and the Two-Stage\nLeast Squares approach to it are widely deployed in economics and causal\ninference to identify the underlying model from an endogenous dataset. Thus, we\npropose to use an online variant of Two-Stage Least Squares approach, namely\nO2SLS, to tackle endogeneity in stochastic online learning. Our analysis shows\nthat O2SLS achieves $\\mathcal{O}\\left(d_x d_z \\log ^2 T\\right)$ identification\nand $\\tilde{\\mathcal{O}}\\left(\\gamma \\sqrt{d_x T}\\right)$ oracle regret after\n$T$ interactions, where $d_x$ and $d_z$ are the dimensions of covariates and\nIVs, and $\\gamma$ is the bias due to endogeneity. For $\\gamma=0$, i.e. under\nexogeneity, O2SLS achieves $\\mathcal{O}\\left(d_x^2 \\log ^2 T\\right)$ oracle\nregret, which is of the same order as that of the stochastic online ridge.\nThen, we leverage O2SLS as an oracle to design OFUL-IV, a stochastic linear\nbandit algorithm that can tackle endogeneity and achieves\n$\\widetilde{\\mathcal{O}}\\left(\\sqrt{d_x d_z T}\\right)$ regret. For different\ndatasets with endogeneity, we experimentally show efficiencies of O2SLS and\nOFUL-IV in terms of regrets.\n","authors":["Riccardo Della Vecchia","Debabrota Basu"],"pdf_url":"https://arxiv.org/pdf/2302.09357v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.01717v2","updated":"2023-06-26T08:50:40Z","published":"2022-03-03T13:55:38Z","title":"Practitioner Motives to Select Hyperparameter Optimization Methods","summary":"  Advanced programmatic hyperparameter optimization (HPO) methods, such as\nBayesian optimization, have high sample efficiency in reproducibly finding\noptimal hyperparameter values of machine learning (ML) models. Yet, ML\npractitioners often apply less sample-efficient HPO methods, such as grid\nsearch, which often results in under-optimized ML models. As a reason for this\nbehavior, we suspect practitioners choose HPO methods based on individual\nmotives, consisting of contextual factors and individual goals. However,\npractitioners' motives still need to be clarified, hindering the evaluation of\nHPO methods for achieving specific goals and the user-centered development of\nHPO tools. To understand practitioners' motives for using specific HPO methods,\nwe used a mixed-methods approach involving 20 semi-structured interviews and a\nsurvey study with 71 ML experts to gather evidence of the external validity of\nthe interview results. By presenting six main goals (e.g., improving model\nunderstanding) and 14 contextual factors affecting practitioners' selection of\nHPO methods (e.g., available computer resources), our study explains why\npractitioners use HPO methods that seem inappropriate at first glance. This\nstudy lays a foundation for designing user-centered and context-adaptive HPO\ntools and, thus, linking social and technical research on HPO.\n","authors":["Niklas Hasebrook","Felix Morsbach","Niclas Kannengießer","Marc Zöller","Jörg Franke","Marius Lindauer","Frank Hutter","Ali Sunyaev"],"pdf_url":"https://arxiv.org/pdf/2203.01717v2.pdf","comment":"submitted to JMLR; currently under review"},{"id":"http://arxiv.org/abs/2306.14511v1","updated":"2023-06-26T08:40:24Z","published":"2023-06-26T08:40:24Z","title":"TaylorPDENet: Learning PDEs from non-grid Data","summary":"  Modeling data obtained from dynamical systems has gained attention in recent\nyears as a challenging task for machine learning models. Previous approaches\nassume the measurements to be distributed on a grid. However, for real-world\napplications like weather prediction, the observations are taken from arbitrary\nlocations within the spatial domain. In this paper, we propose TaylorPDENet - a\nnovel machine learning method that is designed to overcome this challenge. Our\nalgorithm uses the multidimensional Taylor expansion of a dynamical system at\neach observation point to estimate the spatial derivatives to perform\npredictions. TaylorPDENet is able to accomplish two objectives simultaneously:\naccurately forecast the evolution of a complex dynamical system and explicitly\nreconstruct the underlying differential equation describing the system. We\nevaluate our model on a variety of advection-diffusion equations with different\nparameters and show that it performs similarly to equivalent approaches on\ngrid-structured data while being able to process unstructured data as well.\n","authors":["Paul Heinisch","Andrzej Dulny","Anna Krause","Andreas Hotho"],"pdf_url":"https://arxiv.org/pdf/2306.14511v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14510v1","updated":"2023-06-26T08:40:14Z","published":"2023-06-26T08:40:14Z","title":"Deep Bayesian Experimental Design for Quantum Many-Body Systems","summary":"  Bayesian experimental design is a technique that allows to efficiently select\nmeasurements to characterize a physical system by maximizing the expected\ninformation gain. Recent developments in deep neural networks and normalizing\nflows allow for a more efficient approximation of the posterior and thus the\nextension of this technique to complex high-dimensional situations. In this\npaper, we show how this approach holds promise for adaptive measurement\nstrategies to characterize present-day quantum technology platforms. In\nparticular, we focus on arrays of coupled cavities and qubit arrays. Both\nrepresent model systems of high relevance for modern applications, like quantum\nsimulations and computing, and both have been realized in platforms where\nmeasurement and control can be exploited to characterize and counteract\nunavoidable disorder. Thus, they represent ideal targets for applications of\nBayesian experimental design.\n","authors":["Leopoldo Sarra","Florian Marquardt"],"pdf_url":"https://arxiv.org/pdf/2306.14510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.09933v2","updated":"2023-06-26T08:37:56Z","published":"2021-12-18T13:38:48Z","title":"DegreEmbed: incorporating entity embedding into logic rule learning for\n  knowledge graph reasoning","summary":"  Knowledge graphs (KGs), as structured representations of real world facts,\nare intelligent databases incorporating human knowledge that can help machine\nimitate the way of human problem solving. However, KGs are usually huge and\nthere are inevitably missing facts in KGs, thus undermining applications such\nas question answering and recommender systems that are based on knowledge graph\nreasoning. Link prediction for knowledge graphs is the task aiming to complete\nmissing facts by reasoning based on the existing knowledge. Two main streams of\nresearch are widely studied: one learns low-dimensional embeddings for entities\nand relations that can explore latent patterns, and the other gains good\ninterpretability by mining logical rules. Unfortunately, the heterogeneity of\nmodern KGs that involve entities and relations of various types is not well\nconsidered in the previous studies. In this paper, we propose DegreEmbed, a\nmodel that combines embedding-based learning and logic rule mining for\ninferring on KGs. Specifically, we study the problem of predicting missing\nlinks in heterogeneous KGs from the perspective of the degree of nodes.\nExperimentally, we demonstrate that our DegreEmbed model outperforms the\nstate-of-the-art methods on real world datasets and the rules mined by our\nmodel are of high quality and interpretability.\n","authors":["Haotian Li","Hongri Liu","Yao Wang","Guodong Xin","Yuliang Wei"],"pdf_url":"https://arxiv.org/pdf/2112.09933v2.pdf","comment":"Accepted by Semantic Web Journal. arXiv admin note: text overlap with\n  arXiv:2112.06189"},{"id":"http://arxiv.org/abs/2210.03150v4","updated":"2023-06-26T08:18:24Z","published":"2022-10-06T18:23:10Z","title":"Towards Out-of-Distribution Adversarial Robustness","summary":"  Adversarial robustness continues to be a major challenge for deep learning. A\ncore issue is that robustness to one type of attack often fails to transfer to\nother attacks. While prior work establishes a theoretical trade-off in\nrobustness against different $L_p$ norms, we show that there is potential for\nimprovement against many commonly used attacks by adopting a domain\ngeneralisation approach. Concretely, we treat each type of attack as a domain,\nand apply the Risk Extrapolation method (REx), which promotes similar levels of\nrobustness against all training attacks. Compared to existing methods, we\nobtain similar or superior worst-case adversarial robustness on attacks seen\nduring training. Moreover, we achieve superior performance on families or\ntunings of attacks only encountered at test time. On ensembles of attacks, our\napproach improves the accuracy from 3.4% with the best existing baseline to\n25.9% on MNIST, and from 16.9% to 23.5% on CIFAR10.\n","authors":["Adam Ibrahim","Charles Guille-Escuret","Ioannis Mitliagkas","Irina Rish","David Krueger","Pouya Bashivan"],"pdf_url":"https://arxiv.org/pdf/2210.03150v4.pdf","comment":"Version of NeurIPS 2023 submission"},{"id":"http://arxiv.org/abs/2306.14498v1","updated":"2023-06-26T08:17:51Z","published":"2023-06-26T08:17:51Z","title":"Practical Privacy-Preserving Gaussian Process Regression via Secret\n  Sharing","summary":"  Gaussian process regression (GPR) is a non-parametric model that has been\nused in many real-world applications that involve sensitive personal data\n(e.g., healthcare, finance, etc.) from multiple data owners. To fully and\nsecurely exploit the value of different data sources, this paper proposes a\nprivacy-preserving GPR method based on secret sharing (SS), a secure\nmulti-party computation (SMPC) technique. In contrast to existing studies that\nprotect the data privacy of GPR via homomorphic encryption, differential\nprivacy, or federated learning, our proposed method is more practical and can\nbe used to preserve the data privacy of both the model inputs and outputs for\nvarious data-sharing scenarios (e.g., horizontally/vertically-partitioned\ndata). However, it is non-trivial to directly apply SS on the conventional GPR\nalgorithm, as it includes some operations whose accuracy and/or efficiency have\nnot been well-enhanced in the current SMPC protocol. To address this issue, we\nderive a new SS-based exponentiation operation through the idea of\n'confusion-correction' and construct an SS-based matrix inversion algorithm\nbased on Cholesky decomposition. More importantly, we theoretically analyze the\ncommunication cost and the security of the proposed SS-based operations.\nEmpirical results show that our proposed method can achieve reasonable accuracy\nand efficiency under the premise of preserving data privacy.\n","authors":["Jinglong Luo","Yehong Zhang","Jiaqi Zhang","Shuang Qin","Hui Wang","Yue Yu","Zenglin Xu"],"pdf_url":"https://arxiv.org/pdf/2306.14498v1.pdf","comment":"Accepted for the 39th Conference on Uncertainty in Artificial\n  Intelligence (UAI 2023)"},{"id":"http://arxiv.org/abs/2306.14483v1","updated":"2023-06-26T07:50:32Z","published":"2023-06-26T07:50:32Z","title":"Medical Federated Model with Mixture of Personalized and Sharing\n  Components","summary":"  Although data-driven methods usually have noticeable performance on disease\ndiagnosis and treatment, they are suspected of leakage of privacy due to\ncollecting data for model training. Recently, federated learning provides a\nsecure and trustable alternative to collaboratively train model without any\nexchange of medical data among multiple institutes. Therefore, it has draw much\nattention due to its natural merit on privacy protection. However, when\nheterogenous medical data exists between different hospitals, federated\nlearning usually has to face with degradation of performance. In the paper, we\npropose a new personalized framework of federated learning to handle the\nproblem. It successfully yields personalized models based on awareness of\nsimilarity between local data, and achieves better tradeoff between\ngeneralization and personalization than existing methods. After that, we\nfurther design a differentially sparse regularizer to improve communication\nefficiency during procedure of model training. Additionally, we propose an\neffective method to reduce the computational cost, which improves computation\nefficiency significantly. Furthermore, we collect 5 real medical datasets,\nincluding 2 public medical image datasets and 3 private multi-center clinical\ndiagnosis datasets, and evaluate its performance by conducting nodule\nclassification, tumor segmentation, and clinical risk prediction tasks.\nComparing with 13 existing related methods, the proposed method successfully\nachieves the best model performance, and meanwhile up to 60% improvement of\ncommunication efficiency. Source code is public, and can be accessed at:\nhttps://github.com/ApplicationTechnologyOfMedicalBigData/pFedNet-code.\n","authors":["Yawei Zhao","Qinghe Liu","Xinwang Liu","Kunlun He"],"pdf_url":"https://arxiv.org/pdf/2306.14483v1.pdf","comment":"Medical data, federated learning, personalized model, similarity\n  network"},{"id":"http://arxiv.org/abs/2306.14479v1","updated":"2023-06-26T07:46:04Z","published":"2023-06-26T07:46:04Z","title":"Design from Policies: Conservative Test-Time Adaptation for Offline\n  Policy Optimization","summary":"  In this work, we decouple the iterative bi-level offline RL from the offline\ntraining phase, forming a non-iterative bi-level paradigm and avoiding the\niterative error propagation over two levels. Specifically, this non-iterative\nparadigm allows us to conduct inner-level optimization in training (for OOD\nissues), while performing outer-level optimization in testing (for reward\nmaximizing). Naturally, such a paradigm raises three core questions that are\n\\textit{not} fully answered by prior non-iterative offline RL counterparts like\nreward-conditioned policy: Q1) What information should we transfer from the\ninner-level to the outer-level? Q2) What should we pay attention to when\nexploiting the transferred information in the outer-level optimization? Q3)\nWhat are the~benefits of concurrently conducting outer-level optimization\nduring testing? Motivated by model-based optimization~{(MBO)}, we propose DROP\n(\\textbf{D}esign f\\textbf{RO}m \\textbf{P}olicies), which fully answers the\nabove questions. Specifically, in the inner-level, DROP decomposes offline data\ninto multiple subsets and learns an {MBO} score model~(A1). To keep safe\nexploitation to the score model in the outer-level, we explicitly learn a\nbehavior embedding and introduce a conservative regularization (A2). During\ntesting, we show that DROP permits test-time adaptation, enabling an adaptive\ninference across states~(A3). Empirically, we find that DROP, compared to prior\nnon-iterative offline RL counterparts, gains an average improvement probability\nof more than 80\\%, and achieves comparable or better performance compared to\nprior iterative baselines.\n","authors":["Jinxin Liu","Hongyin Zhang","Zifeng Zhuang","Yachen Kang","Donglin Wang","Bin Wang"],"pdf_url":"https://arxiv.org/pdf/2306.14479v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14476v1","updated":"2023-06-26T07:37:50Z","published":"2023-06-26T07:37:50Z","title":"STEF-DHNet: Spatiotemporal External Factors Based Deep Hybrid Network\n  for Enhanced Long-Term Taxi Demand Prediction","summary":"  Accurately predicting the demand for ride-hailing services can result in\nsignificant benefits such as more effective surge pricing strategies, improved\ndriver positioning, and enhanced customer service. By understanding the demand\nfluctuations, companies can anticipate and respond to consumer requirements\nmore efficiently, leading to increased efficiency and revenue. However,\nforecasting demand in a particular region can be challenging, as it is\ninfluenced by several external factors, such as time of day, weather\nconditions, and location. Thus, understanding and evaluating these factors is\nessential for predicting consumer behavior and adapting to their needs\neffectively. Grid-based deep learning approaches have proven effective in\npredicting regional taxi demand. However, these models have limitations in\nintegrating external factors in their spatiotemporal complexity and maintaining\nhigh accuracy over extended time horizons without continuous retraining, which\nmakes them less suitable for practical and commercial applications. To address\nthese limitations, this paper introduces STEF-DHNet, a demand prediction model\nthat combines Convolutional Neural Network (CNN) and Long Short-Term Memory\n(LSTM) to integrate external features as spatiotemporal information and capture\ntheir influence on ride-hailing demand. The proposed model is evaluated using a\nlong-term performance metric called the rolling error, which assesses its\nability to maintain high accuracy over long periods without retraining. The\nresults show that STEF-DHNet outperforms existing state-of-the-art methods on\nthree diverse datasets, demonstrating its potential for practical use in\nreal-world scenarios.\n","authors":["Sheraz Hassan","Muhammad Tahir","Momin Uppal","Zubair Khalid","Ivan Gorban","Selim Turki"],"pdf_url":"https://arxiv.org/pdf/2306.14476v1.pdf","comment":"8 pages, 3 Figures"},{"id":"http://arxiv.org/abs/2306.14468v1","updated":"2023-06-26T07:20:25Z","published":"2023-06-26T07:20:25Z","title":"A General Framework for Sequential Decision-Making under Adaptivity\n  Constraints","summary":"  We take the first step in studying general sequential decision-making under\ntwo adaptivity constraints: rare policy switch and batch learning. First, we\nprovide a general class called the Eluder Condition class, which includes a\nwide range of reinforcement learning classes. Then, for the rare policy switch\nconstraint, we provide a generic algorithm to achieve a\n$\\widetilde{\\mathcal{O}}(\\log K) $ switching cost with a\n$\\widetilde{\\mathcal{O}}(\\sqrt{K})$ regret on the EC class. For the batch\nlearning constraint, we provide an algorithm that provides a\n$\\widetilde{\\mathcal{O}}(\\sqrt{K}+K/B)$ regret with the number of batches $B.$\nThis paper is the first work considering rare policy switch and batch learning\nunder general function classes, which covers nearly all the models studied in\nthe previous works such as tabular MDP (Bai et al. 2019; Zhang et al. 2020),\nlinear MDP (Wang et al. 2021; Gao et al. 2021), low eluder dimension MDP (Kong\net al. 2021; Gao et al. 2021), generalized linear function approximation (Qiao\net al. 2023), and also some new classes such as the low $D_\\Delta$-type Bellman\neluder dimension problem, linear mixture MDP, kernelized nonlinear regulator\nand undercomplete partially observed Markov decision process (POMDP).\n","authors":["Nuoya Xiong","Zhuoran Yang","Zhaoran Wang"],"pdf_url":"https://arxiv.org/pdf/2306.14468v1.pdf","comment":"48 pages"},{"id":"http://arxiv.org/abs/2212.04936v2","updated":"2023-06-26T07:17:29Z","published":"2022-12-07T08:30:23Z","title":"Deep conv-attention model for diagnosing left bundle branch block from\n  12-lead electrocardiograms","summary":"  Cardiac resynchronization therapy (CRT) is a treatment that is used to\ncompensate for irregularities in the heartbeat. Studies have shown that this\ntreatment is more effective in heart patients with left bundle branch block\n(LBBB) arrhythmia. Therefore, identifying this arrhythmia is an important\ninitial step in determining whether or not to use CRT. On the other hand,\ntraditional methods for detecting LBBB on electrocardiograms (ECG) are often\nassociated with errors. Thus, there is a need for an accurate method to\ndiagnose this arrhythmia from ECG data. Machine learning, as a new field of\nstudy, has helped to increase human systems' performance. Deep learning, as a\nnewer subfield of machine learning, has more power to analyze data and increase\nsystems accuracy. This study presents a deep learning model for the detection\nof LBBB arrhythmia from 12-lead ECG data. This model consists of 1D dilated\nconvolutional layers. Attention mechanism has also been used to identify\nimportant input data features and classify inputs more accurately. The proposed\nmodel is trained and validated on a database containing 10344 12-lead ECG\nsamples using the 10-fold cross-validation method. The final results obtained\nby the model on the 12-lead ECG data are as follows. Accuracy: 98.80+-0.08%,\nspecificity: 99.33+-0.11 %, F1 score: 73.97+-1.8%, and area under the receiver\noperating characteristics curve (AUC): 0.875+-0.0192. These results indicate\nthat the proposed model in this study can effectively diagnose LBBB with good\nefficiency and, if used in medical centers, will greatly help diagnose this\narrhythmia and early treatment.\n","authors":["Alireza Sadeghi","Alireza Rezaee","Farshid Hajati"],"pdf_url":"https://arxiv.org/pdf/2212.04936v2.pdf","comment":"The code had some kinds of error and the methodology here was changed\n  completely"},{"id":"http://arxiv.org/abs/2211.08262v3","updated":"2023-06-26T07:16:18Z","published":"2022-11-15T16:13:04Z","title":"A mixed-categorical correlation kernel for Gaussian process","summary":"  Recently, there has been a growing interest for mixed-categorical meta-models\nbased on Gaussian process (GP) surrogates. In this setting, several existing\napproaches use different strategies either by using continuous kernels (e.g.,\ncontinuous relaxation and Gower distance based GP) or by using a direct\nestimation of the correlation matrix. In this paper, we present a kernel-based\napproach that extends continuous exponential kernels to handle\nmixed-categorical variables. The proposed kernel leads to a new GP surrogate\nthat generalizes both the continuous relaxation and the Gower distance based GP\nmodels. We demonstrate, on both analytical and engineering problems, that our\nproposed GP model gives a higher likelihood and a smaller residual error than\nthe other kernel-based state-of-the-art models. Our method is available in the\nopen-source software SMT.\n","authors":["P. Saves","Y. Diouane","N. Bartoli","T. Lefebvre","J. Morlier"],"pdf_url":"https://arxiv.org/pdf/2211.08262v3.pdf","comment":"Published in Neurocomputing. 10.1016/j.neucom.2023.126472"},{"id":"http://arxiv.org/abs/2306.14462v1","updated":"2023-06-26T07:04:47Z","published":"2023-06-26T07:04:47Z","title":"Multi-task Item-attribute Graph Pre-training for Strict Cold-start Item\n  Recommendation","summary":"  Recommendation systems suffer in the strict cold-start (SCS) scenario, where\nthe user-item interactions are entirely unavailable. The ID-based approaches\ncompletely fail to work. Cold-start recommenders, on the other hand, leverage\nitem contents to map the new items to the existing ones. However, the existing\nSCS recommenders explore item contents in coarse-grained manners that introduce\nnoise or information loss. Moreover, informative data sources other than item\ncontents, such as users' purchase sequences and review texts, are ignored. We\nexplore the role of the fine-grained item attributes in bridging the gaps\nbetween the existing and the SCS items and pre-train a knowledgeable\nitem-attribute graph for SCS item recommendation. Our proposed framework,\nColdGPT, models item-attribute correlations into an item-attribute graph by\nextracting fine-grained attributes from item contents. ColdGPT then transfers\nknowledge into the item-attribute graph from various available data sources,\ni.e., item contents, historical purchase sequences, and review texts of the\nexisting items, via multi-task learning. To facilitate the positive transfer,\nColdGPT designs submodules according to the natural forms of the data sources\nand coordinates the multiple pre-training tasks via unified\nalignment-and-uniformity losses. Our pre-trained item-attribute graph acts as\nan implicit, extendable item embedding matrix, which enables the SCS item\nembeddings to be easily acquired by inserting these items and propagating their\nattributes' embeddings. We carefully process three public datasets, i.e., Yelp,\nAmazon-home, and Amazon-sports, to guarantee the SCS setting for evaluation.\nExtensive experiments show that ColdGPT consistently outperforms the existing\nSCS recommenders by large margins and even surpasses models that are\npre-trained on 75-224 times more, cross-domain data on two out of four\ndatasets.\n","authors":["Yuwei Cao","Liangwei Yang","Chen Wang","Zhiwei Liu","Hao Peng","Chenyu You","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2306.14462v1.pdf","comment":"This work has been accepted as a FULL paper in RecSys 2023"},{"id":"http://arxiv.org/abs/2201.11941v2","updated":"2023-06-26T06:21:29Z","published":"2022-01-28T05:44:27Z","title":"Unifying Pairwise Interactions in Complex Dynamics","summary":"  Scientists have developed hundreds of techniques to measure the interactions\nbetween pairs of processes in complex systems. But these computational methods,\nfrom correlation coefficients to causal inference, rely on distinct\nquantitative theories that remain largely disconnected. Here we introduce a\nlibrary of 237 statistics of pairwise interactions and assess their behavior on\n1053 multivariate time series from a wide range of real-world and\nmodel-generated systems. Our analysis highlights new commonalities between\ndifferent mathematical formulations, providing a unified picture of a rich\ninterdisciplinary literature. Using three real-world case studies, we then show\nthat simultaneously leveraging diverse methods from across science can uncover\nthose most suitable for addressing a given problem, yielding interpretable\nunderstanding of the conceptual formulations of pairwise dependence that drive\nsuccessful performance. Our framework is provided in extendable open software,\nenabling comprehensive data-driven analysis by integrating decades of\nmethodological advances.\n","authors":["Oliver M. Cliff","Annie G. Bryant","Joseph T. Lizier","Naotsugu Tsuchiya","Ben D. Fulcher"],"pdf_url":"https://arxiv.org/pdf/2201.11941v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14443v1","updated":"2023-06-26T06:14:01Z","published":"2023-06-26T06:14:01Z","title":"Federated Learning on Non-iid Data via Local and Global Distillation","summary":"  Most existing federated learning algorithms are based on the vanilla FedAvg\nscheme. However, with the increase of data complexity and the number of model\nparameters, the amount of communication traffic and the number of iteration\nrounds for training such algorithms increases significantly, especially in\nnon-independently and homogeneously distributed scenarios, where they do not\nachieve satisfactory performance. In this work, we propose FedND: federated\nlearning with noise distillation. The main idea is to use knowledge\ndistillation to optimize the model training process. In the client, we propose\na self-distillation method to train the local model. In the server, we generate\nnoisy samples for each client and use them to distill other clients. Finally,\nthe global model is obtained by the aggregation of local models. Experimental\nresults show that the algorithm achieves the best performance and is more\ncommunication-efficient than state-of-the-art methods.\n","authors":["Xiaolin Zheng","Senci Ying","Fei Zheng","Jianwei Yin","Longfei Zheng","Chaochao Chen","Fengqin Dong"],"pdf_url":"https://arxiv.org/pdf/2306.14443v1.pdf","comment":"Accpeted in IEEE ICWS 2023"},{"id":"http://arxiv.org/abs/2306.14435v1","updated":"2023-06-26T06:04:09Z","published":"2023-06-26T06:04:09Z","title":"DragDiffusion: Harnessing Diffusion Models for Interactive Point-based\n  Image Editing","summary":"  Precise and controllable image editing is a challenging task that has\nattracted significant attention. Recently, DragGAN enables an interactive\npoint-based image editing framework and achieves impressive editing results\nwith pixel-level precision. However, since this method is based on generative\nadversarial networks (GAN), its generality is upper-bounded by the capacity of\nthe pre-trained GAN models. In this work, we extend such an editing framework\nto diffusion models and propose DragDiffusion. By leveraging large-scale\npretrained diffusion models, we greatly improve the applicability of\ninteractive point-based editing in real world scenarios. While most existing\ndiffusion-based image editing methods work on text embeddings, DragDiffusion\noptimizes the diffusion latent to achieve precise spatial control. Although\ndiffusion models generate images in an iterative manner, we empirically show\nthat optimizing diffusion latent at one single step suffices to generate\ncoherent results, enabling DragDiffusion to complete high-quality editing\nefficiently. Extensive experiments across a wide range of challenging cases\n(e.g., multi-objects, diverse object categories, various styles, etc.)\ndemonstrate the versatility and generality of DragDiffusion.\n","authors":["Yujun Shi","Chuhui Xue","Jiachun Pan","Wenqing Zhang","Vincent Y. F. Tan","Song Bai"],"pdf_url":"https://arxiv.org/pdf/2306.14435v1.pdf","comment":"Preliminary version. Work in Progress"},{"id":"http://arxiv.org/abs/2306.14430v1","updated":"2023-06-26T05:58:17Z","published":"2023-06-26T05:58:17Z","title":"Enhanced multi-fidelity modelling for digital twin and uncertainty\n  quantification","summary":"  The increasing significance of digital twin technology across engineering and\nindustrial domains, such as aerospace, infrastructure, and automotive, is\nundeniable. However, the lack of detailed application-specific information\nposes challenges to its seamless implementation in practical systems.\nData-driven models play a crucial role in digital twins, enabling real-time\nupdates and predictions by leveraging data and computational models.\nNonetheless, the fidelity of available data and the scarcity of accurate sensor\ndata often hinder the efficient learning of surrogate models, which serve as\nthe connection between physical systems and digital twin models. To address\nthis challenge, we propose a novel framework that begins by developing a robust\nmulti-fidelity surrogate model, subsequently applied for tracking digital twin\nsystems. Our framework integrates polynomial correlated function expansion\n(PCFE) with the Gaussian process (GP) to create an effective surrogate model\ncalled H-PCFE. Going a step further, we introduce deep-HPCFE, a cascading\narrangement of models with different fidelities, utilizing nonlinear\nauto-regression schemes. These auto-regressive schemes effectively address the\nissue of erroneous predictions from low-fidelity models by incorporating\nspace-dependent cross-correlations among the models. To validate the efficacy\nof the multi-fidelity framework, we first assess its performance in uncertainty\nquantification using benchmark numerical examples. Subsequently, we demonstrate\nits applicability in the context of digital twin systems.\n","authors":["AS Desai","Navaneeth N","S Adhikari","S Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2306.14430v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.11242v2","updated":"2023-06-26T05:53:49Z","published":"2023-03-20T16:27:36Z","title":"Make Landscape Flatter in Differentially Private Federated Learning","summary":"  To defend the inference attacks and mitigate the sensitive information\nleakages in Federated Learning (FL), client-level Differentially Private FL\n(DPFL) is the de-facto standard for privacy protection by clipping local\nupdates and adding random noise. However, existing DPFL methods tend to make a\nsharper loss landscape and have poorer weight perturbation robustness,\nresulting in severe performance degradation. To alleviate these issues, we\npropose a novel DPFL algorithm named DP-FedSAM, which leverages gradient\nperturbation to mitigate the negative impact of DP. Specifically, DP-FedSAM\nintegrates Sharpness Aware Minimization (SAM) optimizer to generate local\nflatness models with better stability and weight perturbation robustness, which\nresults in the small norm of local updates and robustness to DP noise, thereby\nimproving the performance. From the theoretical perspective, we analyze in\ndetail how DP-FedSAM mitigates the performance degradation induced by DP.\nMeanwhile, we give rigorous privacy guarantees with R\\'enyi DP and present the\nsensitivity analysis of local updates. At last, we empirically confirm that our\nalgorithm achieves state-of-the-art (SOTA) performance compared with existing\nSOTA baselines in DPFL. Code is available at\nhttps://github.com/YMJS-Irfan/DP-FedSAM\n","authors":["Yifan Shi","Yingqi Liu","Kang Wei","Li Shen","Xueqian Wang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2303.11242v2.pdf","comment":"CVPR2023"},{"id":"http://arxiv.org/abs/2302.00491v3","updated":"2023-06-26T05:42:36Z","published":"2023-02-01T15:02:58Z","title":"Learning Prototype Classifiers for Long-Tailed Recognition","summary":"  The problem of long-tailed recognition (LTR) has received attention in recent\nyears due to the fundamental power-law distribution of objects in the\nreal-world. Most recent works in LTR use softmax classifiers that are biased in\nthat they correlate classifier norm with the amount of training data for a\ngiven class. In this work, we show that learning prototype classifiers\naddresses the biased softmax problem in LTR. Prototype classifiers can deliver\npromising results simply using Nearest-Class- Mean (NCM), a special case where\nprototypes are empirical centroids. We go one step further and propose to\njointly learn prototypes by using distances to prototypes in representation\nspace as the logit scores for classification. Further, we theoretically analyze\nthe properties of Euclidean distance based prototype classifiers that lead to\nstable gradient-based optimization which is robust to outliers. To enable\nindependent distance scales along each channel, we enhance Prototype\nclassifiers by learning channel-dependent temperature parameters. Our analysis\nshows that prototypes learned by Prototype classifiers are better separated\nthan empirical centroids. Results on four LTR benchmarks show that Prototype\nclassifier outperforms or is comparable to state-of-the-art methods. Our code\nis made available at\nhttps://github.com/saurabhsharma1993/prototype-classifier-ltr.\n","authors":["Saurabh Sharma","Yongqin Xian","Ning Yu","Ambuj Singh"],"pdf_url":"https://arxiv.org/pdf/2302.00491v3.pdf","comment":"Accepted at IJCAI-23"},{"id":"http://arxiv.org/abs/2305.18612v2","updated":"2023-06-26T04:16:48Z","published":"2023-05-29T21:11:34Z","title":"Networked Time Series Imputation via Position-aware Graph Enhanced\n  Variational Autoencoders","summary":"  Multivariate time series (MTS) imputation is a widely studied problem in\nrecent years. Existing methods can be divided into two main groups, including\n(1) deep recurrent or generative models that primarily focus on time series\nfeatures, and (2) graph neural networks (GNNs) based models that utilize the\ntopological information from the inherent graph structure of MTS as relational\ninductive bias for imputation. Nevertheless, these methods either neglect\ntopological information or assume the graph structure is fixed and accurately\nknown. Thus, they fail to fully utilize the graph dynamics for precise\nimputation in more challenging MTS data such as networked time series (NTS),\nwhere the underlying graph is constantly changing and might have missing edges.\nIn this paper, we propose a novel approach to overcome these limitations.\nFirst, we define the problem of imputation over NTS which contains missing\nvalues in both node time series features and graph structures. Then, we design\na new model named PoGeVon which leverages variational autoencoder (VAE) to\npredict missing values over both node time series features and graph\nstructures. In particular, we propose a new node position embedding based on\nrandom walk with restart (RWR) in the encoder with provable higher expressive\npower compared with message-passing based graph neural networks (GNNs). We\nfurther design a decoder with 3-stage predictions from the perspective of\nmulti-task learning to impute missing values in both time series and graph\nstructures reciprocally. Experiment results demonstrate the effectiveness of\nour model over baselines.\n","authors":["Dingsu Wang","Yuchen Yan","Ruizhong Qiu","Yada Zhu","Kaiyu Guan","Andrew J Margenot","Hanghang Tong"],"pdf_url":"https://arxiv.org/pdf/2305.18612v2.pdf","comment":"KDD 2023"},{"id":"http://arxiv.org/abs/2306.14411v1","updated":"2023-06-26T04:12:40Z","published":"2023-06-26T04:12:40Z","title":"Score-based Source Separation with Applications to Digital Communication\n  Signals","summary":"  We propose a new method for separating superimposed sources using\ndiffusion-based generative models. Our method relies only on separately trained\nstatistical priors of independent sources to establish a new objective function\nguided by maximum a posteriori estimation with an $\\alpha$-posterior, across\nmultiple levels of Gaussian smoothing. Motivated by applications in\nradio-frequency (RF) systems, we are interested in sources with underlying\ndiscrete nature and the recovery of encoded bits from a signal of interest, as\nmeasured by the bit error rate (BER). Experimental results with RF mixtures\ndemonstrate that our method results in a BER reduction of 95% over classical\nand existing learning-based methods. Our analysis demonstrates that our\nproposed method yields solutions that asymptotically approach the modes of an\nunderlying discrete distribution. Furthermore, our method can be viewed as a\nmulti-source extension to the recently proposed score distillation sampling\nscheme, shedding additional light on its use beyond conditional sampling.\n","authors":["Tejas Jayashankar","Gary C. F. Lee","Alejandro Lancho","Amir Weiss","Yury Polyanskiy","Gregory W. Wornell"],"pdf_url":"https://arxiv.org/pdf/2306.14411v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14403v1","updated":"2023-06-26T03:32:57Z","published":"2023-06-26T03:32:57Z","title":"Anomaly Detection with Score Distribution Discrimination","summary":"  Recent studies give more attention to the anomaly detection (AD) methods that\ncan leverage a handful of labeled anomalies along with abundant unlabeled data.\nThese existing anomaly-informed AD methods rely on manually predefined score\ntarget(s), e.g., prior constant or margin hyperparameter(s), to realize\ndiscrimination in anomaly scores between normal and abnormal data. However,\nsuch methods would be vulnerable to the existence of anomaly contamination in\nthe unlabeled data, and also lack adaptation to different data scenarios. In\nthis paper, we propose to optimize the anomaly scoring function from the view\nof score distribution, thus better retaining the diversity and more\nfine-grained information of input data, especially when the unlabeled data\ncontains anomaly noises in more practical AD scenarios. We design a novel loss\nfunction called Overlap loss that minimizes the overlap area between the score\ndistributions of normal and abnormal samples, which no longer depends on prior\nanomaly score targets and thus acquires adaptability to various datasets.\nOverlap loss consists of Score Distribution Estimator and Overlap Area\nCalculation, which are introduced to overcome challenges when estimating\narbitrary score distributions, and to ensure the boundness of training loss. As\na general loss component, Overlap loss can be effectively integrated into\nmultiple network architectures for constructing AD models. Extensive\nexperimental results indicate that Overlap loss based AD models significantly\noutperform their state-of-the-art counterparts, and achieve better performance\non different types of anomalies.\n","authors":["Minqi Jiang","Songqiao Han","Hailiang Huang"],"pdf_url":"https://arxiv.org/pdf/2306.14403v1.pdf","comment":"Accepted by KDD 2023. Detailed discussions can be found in\n  https://openreview.net/forum?id=P1Worw-M1Tf&referrer=[the%20profile%20of%20Minqi%20Jiang](/profile?id=~Minqi_Jiang2)"},{"id":"http://arxiv.org/abs/2304.11839v3","updated":"2023-06-26T03:27:48Z","published":"2023-04-24T06:16:09Z","title":"Local Energy Distribution Based Hyperparameter Determination for\n  Stochastic Simulated Annealing","summary":"  This paper presents a local energy distribution based hyperparameter\ndetermination for stochastic simulated annealing (SSA). SSA is capable of\nsolving combinatorial optimization problems faster than typical simulated\nannealing (SA), but requires a time-consuming hyperparameter search. The\nproposed method determines hyperparameters based on the local energy\ndistributions of spins (probabilistic bits). The spin is a basic computing\nelement of SSA and is graphically connected to other spins with its weights.\nThe distribution of the local energy can be estimated based on the central\nlimit theorem (CLT). The CLT-based normal distribution is used to determine the\nhyperparameters, which reduces the time complexity for hyperparameter search\nfrom O(n^3) of the conventional method to O(1). The performance of SSA with the\ndetermined hyperparameters is evaluated on the Gset and K2000 benchmarks for\nmaximum-cut problems. The results show that the proposed method achieves mean\ncut values of approximately 98% of the best-known cut values.\n","authors":["Naoya Onizawa","Kyo Kuroki","Duckgyu Shin","Takahiro Hanyu"],"pdf_url":"https://arxiv.org/pdf/2304.11839v3.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2306.14400v1","updated":"2023-06-26T03:23:53Z","published":"2023-06-26T03:23:53Z","title":"Contrastive Multi-view Framework for Customer Lifetime Value Prediction","summary":"  Accurate customer lifetime value (LTV) prediction can help service providers\noptimize their marketing policies in customer-centric applications. However,\nthe heavy sparsity of consumption events and the interference of data variance\nand noise obstruct LTV estimation. Many existing LTV prediction methods\ndirectly train a single-view LTV predictor on consumption samples, which may\nyield inaccurate and even biased knowledge extraction. In this paper, we\npropose a contrastive multi-view framework for LTV prediction, which is a\nplug-and-play solution compatible with various backbone models. It synthesizes\nmultiple heterogeneous LTV regressors with complementary knowledge to improve\nmodel robustness and captures sample relatedness via contrastive learning to\nmitigate the dependency on data abundance. Concretely, we use a decomposed\nscheme that converts the LTV prediction problem into a combination of\nestimating consumption probability and payment amount. To alleviate the impact\nof noisy data on model learning, we propose a multi-view framework that jointly\noptimizes multiple types of regressors with diverse characteristics and\nadvantages to encode and fuse comprehensive knowledge. To fully exploit the\npotential of limited training samples, we propose a hybrid contrastive learning\nmethod to help capture the relatedness between samples in both classification\nand regression tasks. We conduct extensive experiments on a real-world game LTV\nprediction dataset and the results validate the effectiveness of our method. We\nhave deployed our solution online in Huawei's mobile game center and achieved\n32.26% of total payment amount gains.\n","authors":["Chuhan Wu","Jingjie Li","Qinglin Jia","Hong Zhu","Yuan Fang","Ruiming Tang"],"pdf_url":"https://arxiv.org/pdf/2306.14400v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13557v2","updated":"2023-06-26T02:54:29Z","published":"2023-06-23T15:31:09Z","title":"FPGA Implementation of Convolutional Neural Network for Real-Time\n  Handwriting Recognition","summary":"  Machine Learning (ML) has recently been a skyrocketing field in Computer\nScience. As computer hardware engineers, we are enthusiastic about hardware\nimplementations of popular software ML architectures to optimize their\nperformance, reliability, and resource usage. In this project, we designed a\nhighly-configurable, real-time device for recognizing handwritten letters and\ndigits using an Altera DE1 FPGA Kit. We followed various engineering standards,\nincluding IEEE-754 32-bit Floating-Point Standard, Video Graphics Array (VGA)\ndisplay protocol, Universal Asynchronous Receiver-Transmitter (UART) protocol,\nand Inter-Integrated Circuit (I2C) protocols to achieve the project goals.\nThese significantly improved our design in compatibility, reusability, and\nsimplicity in verifications. Following these standards, we designed a 32-bit\nfloating-point (FP) instruction set architecture (ISA). We developed a 5-stage\nRISC processor in System Verilog to manage image processing, matrix\nmultiplications, ML classifications, and user interfaces. Three different ML\narchitectures were implemented and evaluated on our design: Linear\nClassification (LC), a 784-64-10 fully connected neural network (NN), and a\nLeNet-like Convolutional Neural Network (CNN) with ReLU activation layers and\n36 classes (10 for the digits and 26 for the case-insensitive letters). The\ntraining processes were done in Python scripts, and the resulting kernels and\nweights were stored in hex files and loaded into the FPGA's SRAM units.\nConvolution, pooling, data management, and various other ML features were\nguided by firmware in our custom assembly language. This paper documents the\nhigh-level design block diagrams, interfaces between each System Verilog\nmodule, implementation details of our software and firmware components, and\nfurther discussions on potential impacts.\n","authors":["Shichen Qiao","Haining Qiu","Lingkai Zhao","Qikun Liu","Eric J. Hoffman"],"pdf_url":"https://arxiv.org/pdf/2306.13557v2.pdf","comment":"27 pages, 13 figures"},{"id":"http://arxiv.org/abs/2210.03069v3","updated":"2023-06-26T02:54:09Z","published":"2022-10-06T17:22:40Z","title":"PathProx: A Proximal Gradient Algorithm for Weight Decay Regularized\n  Deep Neural Networks","summary":"  Weight decay is one of the most widely used forms of regularization in deep\nlearning, and has been shown to improve generalization and robustness. The\noptimization objective driving weight decay is a sum of losses plus a term\nproportional to the sum of squared weights. This paper argues that stochastic\ngradient descent (SGD) may be an inefficient algorithm for this objective. For\nneural networks with ReLU activations, solutions to the weight decay objective\nare equivalent to those of a different objective in which the regularization\nterm is instead a sum of products of $\\ell_2$ (not squared) norms of the input\nand output weights associated with each ReLU neuron. This alternative (and\neffectively equivalent) regularization suggests a novel proximal gradient\nalgorithm for network training. Theory and experiments support the new training\napproach, showing that it can converge much faster to the sparse solutions it\nshares with standard weight decay training.\n","authors":["Liu Yang","Jifan Zhang","Joseph Shenouda","Dimitris Papailiopoulos","Kangwook Lee","Robert D. Nowak"],"pdf_url":"https://arxiv.org/pdf/2210.03069v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.12816v2","updated":"2023-06-26T02:45:15Z","published":"2023-03-22T07:34:33Z","title":"From Wide to Deep: Dimension Lifting Network for Parameter-efficient\n  Knowledge Graph Embedding","summary":"  Knowledge graph embedding (KGE) that maps entities and relations into vector\nrepresentations is essential for downstream tasks. Conventional KGE methods\nrequire relatively high-dimensional entity representations to preserve the\nstructural information of knowledge graph, but lead to oversized model\nparameters. Recent methods reduce model parameters by adopting low-dimensional\nentity representations, while developing techniques (e.g., knowledge\ndistillation) to compensate for the reduced dimension. However, such operations\nproduce degraded model accuracy and limited reduction of model parameters.\nSpecifically, we view the concatenation of all entity representations as an\nembedding layer, and then conventional KGE methods that adopt high-dimensional\nentity representations equal to enlarging the width of the embedding layer to\ngain expressiveness. To achieve parameter efficiency without sacrificing\naccuracy, we instead increase the depth and propose a deeper embedding network\nfor entity representations, i.e., a narrow embedding layer and a multi-layer\ndimension lifting network (LiftNet). Experiments on three public datasets show\nthat the proposed method (implemented based on TransE and DistMult) with\n4-dimensional entity representations achieves more accurate link prediction\nresults than counterpart parameter-efficient KGE methods and strong KGE\nbaselines, including TransE and DistMult with 512-dimensional entity\nrepresentations.\n","authors":["Borui Cai","Yong Xiang","Longxiang Gao","Di Wu","He Zhang","Jiong Jin","Tom Luan"],"pdf_url":"https://arxiv.org/pdf/2303.12816v2.pdf","comment":"The experimental results in Table II are faulty, will withdraw and\n  resumit it when the correction is done"},{"id":"http://arxiv.org/abs/2207.12141v4","updated":"2023-06-26T02:38:27Z","published":"2022-07-25T12:45:58Z","title":"Live in the Moment: Learning Dynamics Model Adapted to Evolving Policy","summary":"  Model-based reinforcement learning (RL) often achieves higher sample\nefficiency in practice than model-free RL by learning a dynamics model to\ngenerate samples for policy learning. Previous works learn a dynamics model\nthat fits under the empirical state-action visitation distribution for all\nhistorical policies, i.e., the sample replay buffer. However, in this paper, we\nobserve that fitting the dynamics model under the distribution for \\emph{all\nhistorical policies} does not necessarily benefit model prediction for the\n\\emph{current policy} since the policy in use is constantly evolving over time.\nThe evolving policy during training will cause state-action visitation\ndistribution shifts. We theoretically analyze how this distribution shift over\nhistorical policies affects the model learning and model rollouts. We then\npropose a novel dynamics model learning method, named \\textit{Policy-adapted\nDynamics Model Learning (PDML)}. PDML dynamically adjusts the historical policy\nmixture distribution to ensure the learned model can continually adapt to the\nstate-action visitation distribution of the evolving policy. Experiments on a\nrange of continuous control environments in MuJoCo show that PDML achieves\nsignificant improvement in sample efficiency and higher asymptotic performance\ncombined with the state-of-the-art model-based RL methods.\n","authors":["Xiyao Wang","Wichayaporn Wongkamjan","Furong Huang"],"pdf_url":"https://arxiv.org/pdf/2207.12141v4.pdf","comment":"16 pages, 5 figures"},{"id":"http://arxiv.org/abs/2302.13939v3","updated":"2023-06-26T02:38:07Z","published":"2023-02-27T16:43:04Z","title":"SpikeGPT: Generative Pre-trained Language Model with Spiking Neural\n  Networks","summary":"  As the size of large language models continue to scale, so does the\ncomputational resources required to run it. Spiking Neural Networks (SNNs) have\nemerged as an energy-efficient approach to deep learning that leverage sparse\nand event-driven activations to reduce the computational overhead associated\nwith model inference. While they have become competitive with non-spiking\nmodels on many computer vision tasks, SNNs have also proven to be more\nchallenging to train. As a result, their performance lags behind modern deep\nlearning, and we are yet to see the effectiveness of SNNs in language\ngeneration. In this paper, inspired by the Receptance Weighted Key Value (RWKV)\nlanguage model, we successfully implement `SpikeGPT', a generative language\nmodel with binary, event-driven spiking activation units. We train the proposed\nmodel on two model variants: 45M and 216M parameters. To the best of our\nknowledge, SpikeGPT is the largest backpropagation-trained SNN model to date,\nrendering it suitable for both the generation and comprehension of natural\nlanguage. We achieve this by modifying the transformer block to replace\nmulti-head self attention to reduce quadratic computational complexity O(N^2)\nto linear complexity O(N) with increasing sequence length. Input tokens are\ninstead streamed in sequentially to our attention mechanism (as with typical\nSNNs). Our preliminary experiments show that SpikeGPT remains competitive with\nnon-spiking models on tested benchmarks, while maintaining 20x fewer operations\nwhen processed on neuromorphic hardware that can leverage sparse, event-driven\nactivations.\n","authors":["Rui-Jie Zhu","Qihang Zhao","Guoqi Li","Jason K. Eshraghian"],"pdf_url":"https://arxiv.org/pdf/2302.13939v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13215v2","updated":"2023-06-26T02:24:19Z","published":"2023-06-15T17:45:03Z","title":"OVLA: Neural Network Ownership Verification using Latent Watermarks","summary":"  Ownership verification for neural networks is important for protecting these\nmodels from illegal copying, free-riding, re-distribution and other\nintellectual property misuse. We present a novel methodology for neural network\nownership verification based on the notion of latent watermarks. Existing\nownership verification methods either modify or introduce constraints to the\nneural network parameters, which are accessible to an attacker in a white-box\nattack and can be harmful to the network's normal operation, or train the\nnetwork to respond to specific watermarks in the inputs similar to data\npoisoning-based backdoor attacks, which are susceptible to backdoor removal\ntechniques. In this paper, we address these problems by decoupling a network's\nnormal operation from its responses to watermarked inputs during ownership\nverification. The key idea is to train the network such that the watermarks\nremain dormant unless the owner's secret key is applied to activate it. The\nsecret key is realized as a specific perturbation only known to the owner to\nthe network's parameters. We show that our approach offers strong defense\nagainst backdoor detection, backdoor removal and surrogate model attacks.In\naddition, our method provides protection against ambiguity attacks where the\nattacker either tries to guess the secret weight key or uses fine-tuning to\nembed their own watermarks with a different key into a pre-trained neural\nnetwork. Experimental results demonstrate the advantages and effectiveness of\nour proposed approach.\n","authors":["Feisi Fu","Wenchao Li"],"pdf_url":"https://arxiv.org/pdf/2306.13215v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14381v1","updated":"2023-06-26T02:15:26Z","published":"2023-06-26T02:15:26Z","title":"Gradient Descent Converges Linearly for Logistic Regression on Separable\n  Data","summary":"  We show that running gradient descent with variable learning rate guarantees\nloss $f(x) \\leq 1.1 \\cdot f(x^*) + \\epsilon$ for the logistic regression\nobjective, where the error $\\epsilon$ decays exponentially with the number of\niterations and polynomially with the magnitude of the entries of an arbitrary\nfixed solution $x^*$. This is in contrast to the common intuition that the\nabsence of strong convexity precludes linear convergence of first-order\nmethods, and highlights the importance of variable learning rates for gradient\ndescent. We also apply our ideas to sparse logistic regression, where they lead\nto an exponential improvement of the sparsity-error tradeoff.\n","authors":["Kyriakos Axiotis","Maxim Sviridenko"],"pdf_url":"https://arxiv.org/pdf/2306.14381v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14375v1","updated":"2023-06-26T01:37:10Z","published":"2023-06-26T01:37:10Z","title":"Interpretable Sparsification of Brain Graphs: Better Practices and\n  Effective Designs for Graph Neural Networks","summary":"  Brain graphs, which model the structural and functional relationships between\nbrain regions, are crucial in neuroscientific and clinical applications\ninvolving graph classification. However, dense brain graphs pose computational\nchallenges including high runtime and memory usage and limited\ninterpretability. In this paper, we investigate effective designs in Graph\nNeural Networks (GNNs) to sparsify brain graphs by eliminating noisy edges.\nWhile prior works remove noisy edges based on explainability or task-irrelevant\nproperties, their effectiveness in enhancing performance with sparsified graphs\nis not guaranteed. Moreover, existing approaches often overlook collective edge\nremoval across multiple graphs.\n  To address these issues, we introduce an iterative framework to analyze\ndifferent sparsification models. Our findings are as follows: (i) methods\nprioritizing interpretability may not be suitable for graph sparsification as\nthey can degrade GNNs' performance in graph classification tasks; (ii)\nsimultaneously learning edge selection with GNN training is more beneficial\nthan post-training; (iii) a shared edge selection across graphs outperforms\nseparate selection for each graph; and (iv) task-relevant gradient information\naids in edge selection. Based on these insights, we propose a new model,\nInterpretable Graph Sparsification (IGS), which enhances graph classification\nperformance by up to 5.1% with 55.0% fewer edges. The retained edges identified\nby IGS provide neuroscientific interpretations and are supported by\nwell-established literature.\n","authors":["Gaotang Li","Marlena Duda","Xiang Zhang","Danai Koutra","Yujun Yan"],"pdf_url":"https://arxiv.org/pdf/2306.14375v1.pdf","comment":"To appear in Proceedings of the 29th ACM SIGKDD Conference on\n  Knowledge Discovery and Data Mining (KDD 23)"},{"id":"http://arxiv.org/abs/2301.01228v3","updated":"2023-06-26T01:23:05Z","published":"2023-01-02T09:46:53Z","title":"DMOps: Data Management Operation and Recipes","summary":"  Data-centric AI has shed light on the significance of data within the machine\nlearning (ML) pipeline. Recognizing its significance, academia, industry, and\ngovernment departments have suggested various NLP data research initiatives.\nWhile the ability to utilize existing data is essential, the ability to build a\ndataset has become more critical than ever, especially in the industry. In\nconsideration of this trend, we propose a \"Data Management Operations and\nRecipes\" to guide the industry in optimizing the building of datasets for NLP\nproducts. This paper presents the concept of DMOps which is derived from\nreal-world experiences with NLP data management and aims to streamline data\noperations by offering a baseline.\n","authors":["Eujeong Choi","Chanjun Park"],"pdf_url":"https://arxiv.org/pdf/2301.01228v3.pdf","comment":"Accepted for Data-centric Machine Learning Research (DMLR) Workshop\n  at ICML 2023"},{"id":"http://arxiv.org/abs/2208.02901v3","updated":"2023-06-26T01:05:04Z","published":"2022-08-04T22:06:25Z","title":"Nonstationary Continuum-Armed Bandit Strategies for Automated Trading in\n  a Simulated Financial Market","summary":"  We approach the problem of designing an automated trading strategy that can\nconsistently profit by adapting to changing market conditions. This challenge\ncan be framed as a Nonstationary Continuum-Armed Bandit (NCAB) problem. To\nsolve the NCAB problem, we propose PRBO, a novel trading algorithm that uses\nBayesian optimization and a ``bandit-over-bandit'' framework to dynamically\nadjust strategy parameters in response to market conditions. We use Bristol\nStock Exchange (BSE) to simulate financial markets containing heterogeneous\npopulations of automated trading agents and compare PRBO with PRSH, a reference\ntrading strategy that adapts strategy parameters through stochastic\nhill-climbing. Results show that PRBO generates significantly more profit than\nPRSH, despite having fewer hyperparameters to tune. The code for PRBO and\nperforming experiments is available online open-source\n(https://github.com/HarmoniaLeo/PRZI-Bayesian-Optimisation).\n","authors":["Bingde Liu","John Cartlidge"],"pdf_url":"https://arxiv.org/pdf/2208.02901v3.pdf","comment":"Camera ready version accepted for publication at 35th European\n  Modeling & Simulation Symposium (EMSS), Sep. 2023, Athens, Greece"},{"id":"http://arxiv.org/abs/2306.09869v2","updated":"2023-06-26T01:03:07Z","published":"2023-06-16T14:30:41Z","title":"Energy-Based Cross Attention for Bayesian Context Update in\n  Text-to-Image Diffusion Models","summary":"  Despite the remarkable performance of text-to-image diffusion models in image\ngeneration tasks, recent studies have raised the issue that generated images\nsometimes cannot capture the intended semantic contents of the text prompts,\nwhich phenomenon is often called semantic misalignment. To address this, here\nwe present a novel energy-based model (EBM) framework. Specifically, we first\nformulate EBMs of latent image representations and text embeddings in each\ncross-attention layer of the denoising autoencoder. Then, we obtain the\ngradient of the log posterior of context vectors, which can be updated and\ntransferred to the subsequent cross-attention layer, thereby implicitly\nminimizing a nested hierarchy of energy functions. Our latent EBMs further\nallow zero-shot compositional generation as a linear combination of\ncross-attention outputs from different contexts. Using extensive experiments,\nwe demonstrate that the proposed method is highly effective in handling various\nimage generation tasks, including multi-concept generation, text-guided image\ninpainting, and real and synthetic image editing.\n","authors":["Geon Yeong Park","Jeongsol Kim","Beomsu Kim","Sang Wan Lee","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2306.09869v2.pdf","comment":"Code: https://github.com/EnergyAttention/Energy-Based-CrossAttention"},{"id":"http://arxiv.org/abs/2306.14369v1","updated":"2023-06-26T00:27:48Z","published":"2023-06-26T00:27:48Z","title":"Few-Shot Continual Learning via Flat-to-Wide Approaches","summary":"  Existing approaches on continual learning call for a lot of samples in their\ntraining processes. Such approaches are impractical for many real-world\nproblems having limited samples because of the overfitting problem. This paper\nproposes a few-shot continual learning approach, termed FLat-tO-WidE AppRoach\n(FLOWER), where a flat-to-wide learning process finding the flat-wide minima is\nproposed to address the catastrophic forgetting problem. The issue of data\nscarcity is overcome with a data augmentation approach making use of a ball\ngenerator concept to restrict the sampling space into the smallest enclosing\nball. Our numerical studies demonstrate the advantage of FLOWER achieving\nsignificantly improved performances over prior arts notably in the small base\ntasks. For further study, source codes of FLOWER, competitor algorithms and\nexperimental logs are shared publicly in\n\\url{https://github.com/anwarmaxsum/FLOWER}.\n","authors":["Muhammad Anwar Ma'sum","Mahardhika Pratama","Lin Liu","Edwin Lughofer"," Habibullah","Ryszard Kowalczyk"],"pdf_url":"https://arxiv.org/pdf/2306.14369v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.12032v2","updated":"2023-06-26T23:23:09Z","published":"2023-05-19T23:12:08Z","title":"The Waymo Open Sim Agents Challenge","summary":"  Simulation with realistic, interactive agents represents a key task for\nautonomous vehicle software development. In this work, we introduce the Waymo\nOpen Sim Agents Challenge (WOSAC). WOSAC is the first public challenge to\ntackle this task and propose corresponding metrics. The goal of the challenge\nis to stimulate the design of realistic simulators that can be used to evaluate\nand train a behavior model for autonomous driving. We outline our evaluation\nmethodology, present results for a number of different baseline simulation\nagent methods, and analyze several submissions to the 2023 competition which\nran from March 16, 2023 to May 23, 2023. The WOSAC evaluation server remains\nopen for submissions and we discuss open problems for the task.\n","authors":["Nico Montali","John Lambert","Paul Mougin","Alex Kuefler","Nick Rhinehart","Michelle Li","Cole Gulino","Tristan Emrich","Zoey Yang","Shimon Whiteson","Brandyn White","Dragomir Anguelov"],"pdf_url":"https://arxiv.org/pdf/2305.12032v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.06299v3","updated":"2023-06-26T23:12:45Z","published":"2022-12-13T00:45:46Z","title":"Interpretable Diabetic Retinopathy Diagnosis based on Biomarker\n  Activation Map","summary":"  Deep learning classifiers provide the most accurate means of automatically\ndiagnosing diabetic retinopathy (DR) based on optical coherence tomography\n(OCT) and its angiography (OCTA). The power of these models is attributable in\npart to the inclusion of hidden layers that provide the complexity required to\nachieve a desired task. However, hidden layers also render algorithm outputs\ndifficult to interpret. Here we introduce a novel biomarker activation map\n(BAM) framework based on generative adversarial learning that allows clinicians\nto verify and understand classifiers decision-making. A data set including 456\nmacular scans were graded as non-referable or referable DR based on current\nclinical standards. A DR classifier that was used to evaluate our BAM was first\ntrained based on this data set. The BAM generation framework was designed by\ncombing two U-shaped generators to provide meaningful interpretability to this\nclassifier. The main generator was trained to take referable scans as input and\nproduce an output that would be classified by the classifier as non-referable.\nThe BAM is then constructed as the difference image between the output and\ninput of the main generator. To ensure that the BAM only highlights\nclassifier-utilized biomarkers an assistant generator was trained to do the\nopposite, producing scans that would be classified as referable by the\nclassifier from non-referable scans. The generated BAMs highlighted known\npathologic features including nonperfusion area and retinal fluid. A fully\ninterpretable classifier based on these highlights could help clinicians better\nutilize and verify automated DR diagnosis.\n","authors":["Pengxiao Zang","Tristan T. Hormel","Jie Wang","Yukun Guo","Steven T. Bailey","Christina J. Flaxel","David Huang","Thomas S. Hwang","Yali Jia"],"pdf_url":"https://arxiv.org/pdf/2212.06299v3.pdf","comment":"This paper has been accepted by IEEE TBME"},{"id":"http://arxiv.org/abs/2306.10045v4","updated":"2023-06-26T22:52:45Z","published":"2023-06-12T07:19:01Z","title":"Efficient Approximations of Complete Interatomic Potentials for Crystal\n  Property Prediction","summary":"  We study property prediction for crystal materials. A crystal structure\nconsists of a minimal unit cell that is repeated infinitely in 3D space. How to\naccurately represent such repetitive structures in machine learning models\nremains unresolved. Current methods construct graphs by establishing edges only\nbetween nearby nodes, thereby failing to faithfully capture infinite repeating\npatterns and distant interatomic interactions. In this work, we propose several\ninnovations to overcome these limitations. First, we propose to model\nphysics-principled interatomic potentials directly instead of only using\ndistances as in many existing methods. These potentials include the Coulomb\npotential, London dispersion potential, and Pauli repulsion potential. Second,\nwe model the complete set of potentials among all atoms, instead of only\nbetween nearby atoms as in existing methods. This is enabled by our\napproximations of infinite potential summations with provable error bounds. We\nfurther develop efficient algorithms to compute the approximations. Finally, we\npropose to incorporate our computations of complete interatomic potentials into\nmessage passing neural networks for representation learning. We perform\nexperiments on the JARVIS and Materials Project benchmarks for evaluation.\nResults show that the use of interatomic potentials and complete interatomic\npotentials leads to consistent performance improvements with reasonable\ncomputational costs. Our code is publicly available as part of the AIRS library\n(https://github.com/divelab/AIRS/tree/main/OpenMat/PotNet).\n","authors":["Yuchao Lin","Keqiang Yan","Youzhi Luo","Yi Liu","Xiaoning Qian","Shuiwang Ji"],"pdf_url":"https://arxiv.org/pdf/2306.10045v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.02317v2","updated":"2023-06-26T22:43:55Z","published":"2022-10-05T15:10:52Z","title":"Real-Time Reinforcement Learning for Vision-Based Robotics Utilizing\n  Local and Remote Computers","summary":"  Real-time learning is crucial for robotic agents adapting to ever-changing,\nnon-stationary environments. A common setup for a robotic agent is to have two\ndifferent computers simultaneously: a resource-limited local computer tethered\nto the robot and a powerful remote computer connected wirelessly. Given such a\nsetup, it is unclear to what extent the performance of a learning system can be\naffected by resource limitations and how to efficiently use the wirelessly\nconnected powerful computer to compensate for any performance loss. In this\npaper, we implement a real-time learning system called the Remote-Local\nDistributed (ReLoD) system to distribute computations of two deep reinforcement\nlearning (RL) algorithms, Soft Actor-Critic (SAC) and Proximal Policy\nOptimization (PPO), between a local and a remote computer. The performance of\nthe system is evaluated on two vision-based control tasks developed using a\nrobotic arm and a mobile robot. Our results show that SAC's performance\ndegrades heavily on a resource-limited local computer. Strikingly, when all\ncomputations of the learning system are deployed on a remote workstation, SAC\nfails to compensate for the performance loss, indicating that, without careful\nconsideration, using a powerful remote computer may not result in performance\nimprovement. However, a carefully chosen distribution of computations of SAC\nconsistently and substantially improves its performance on both tasks. On the\nother hand, the performance of PPO remains largely unaffected by the\ndistribution of computations. In addition, when all computations happen solely\non a powerful tethered computer, the performance of our system remains on par\nwith an existing system that is well-tuned for using a single machine. ReLoD is\nthe only publicly available system for real-time RL that applies to multiple\nrobots for vision-based tasks.\n","authors":["Yan Wang","Gautham Vasan","A. Rupam Mahmood"],"pdf_url":"https://arxiv.org/pdf/2210.02317v2.pdf","comment":"Appears in Proceedings of the 2023 International Conference on\n  Robotics and Automation (ICRA). Source code at\n  https://github.com/rlai-lab/relod and companion video at\n  https://youtu.be/7iZKryi1xSY"},{"id":"http://arxiv.org/abs/2306.15098v1","updated":"2023-06-26T22:31:15Z","published":"2023-06-26T22:31:15Z","title":"Off-Policy Evaluation of Ranking Policies under Diverse User Behavior","summary":"  Ranking interfaces are everywhere in online platforms. There is thus an ever\ngrowing interest in their Off-Policy Evaluation (OPE), aiming towards an\naccurate performance evaluation of ranking policies using logged data. A\nde-facto approach for OPE is Inverse Propensity Scoring (IPS), which provides\nan unbiased and consistent value estimate. However, it becomes extremely\ninaccurate in the ranking setup due to its high variance under large action\nspaces. To deal with this problem, previous studies assume either independent\nor cascade user behavior, resulting in some ranking versions of IPS. While\nthese estimators are somewhat effective in reducing the variance, all existing\nestimators apply a single universal assumption to every user, causing excessive\nbias and variance. Therefore, this work explores a far more general formulation\nwhere user behavior is diverse and can vary depending on the user context. We\nshow that the resulting estimator, which we call Adaptive IPS (AIPS), can be\nunbiased under any complex user behavior. Moreover, AIPS achieves the minimum\nvariance among all unbiased estimators based on IPS. We further develop a\nprocedure to identify the appropriate user behavior model to minimize the mean\nsquared error (MSE) of AIPS in a data-driven fashion. Extensive experiments\ndemonstrate that the empirical accuracy improvement can be significant,\nenabling effective OPE of ranking systems even under diverse user behavior.\n","authors":["Haruka Kiyohara","Masatoshi Uehara","Yusuke Narita","Nobuyuki Shimizu","Yasuo Yamamoto","Yuta Saito"],"pdf_url":"https://arxiv.org/pdf/2306.15098v1.pdf","comment":"KDD2023 Research track"},{"id":"http://arxiv.org/abs/2210.17432v2","updated":"2023-06-26T22:31:06Z","published":"2022-10-31T16:02:00Z","title":"SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for\n  Text Generation and Modular Control","summary":"  Despite the growing success of diffusion models in continuous-valued domains\n(e.g., images), similar efforts for discrete domains such as text have yet to\nmatch the performance of autoregressive language models. In this work, we\npresent SSD-LM -- a diffusion-based language model with two key design choices.\nFirst, SSD-LM is semi-autoregressive, iteratively generating blocks of text,\nallowing for flexible output length at decoding time while enabling local\nbidirectional context updates. Second, it is simplex-based, performing\ndiffusion on the natural vocabulary space rather than a learned latent space,\nallowing us to incorporate classifier guidance and modular control using\noff-the-shelf classifiers without any adaptation. We evaluate SSD-LM on\nunconstrained text generation benchmarks, and show that it matches or\noutperforms strong autoregressive GPT-2 models across standard quality and\ndiversity metrics, while vastly outperforming diffusion-based baselines. On\ncontrolled text generation, SSD-LM also outperforms competitive baselines, with\nan extra advantage in modularity.\n","authors":["Xiaochuang Han","Sachin Kumar","Yulia Tsvetkov"],"pdf_url":"https://arxiv.org/pdf/2210.17432v2.pdf","comment":"ACL 2023"}],"Multimedia":[{"id":"http://arxiv.org/abs/2306.14899v1","updated":"2023-06-26T17:59:55Z","published":"2023-06-26T17:59:55Z","title":"FunQA: Towards Surprising Video Comprehension","summary":"  Surprising videos, e.g., funny clips, creative performances, or visual\nillusions, attract significant attention. Enjoyment of these videos is not\nsimply a response to visual stimuli; rather, it hinges on the human capacity to\nunderstand (and appreciate) commonsense violations depicted in these videos. We\nintroduce FunQA, a challenging video question answering (QA) dataset\nspecifically designed to evaluate and enhance the depth of video reasoning\nbased on counter-intuitive and fun videos. Unlike most video QA benchmarks\nwhich focus on less surprising contexts, e.g., cooking or instructional videos,\nFunQA covers three previously unexplored types of surprising videos: 1)\nHumorQA, 2) CreativeQA, and 3) MagicQA. For each subset, we establish rigorous\nQA tasks designed to assess the model's capability in counter-intuitive\ntimestamp localization, detailed video description, and reasoning around\ncounter-intuitiveness. We also pose higher-level tasks, such as attributing a\nfitting and vivid title to the video, and scoring the video creativity. In\ntotal, the FunQA benchmark consists of 312K free-text QA pairs derived from\n4.3K video clips, spanning a total of 24 video hours. Extensive experiments\nwith existing VideoQA models reveal significant performance gaps for the FunQA\nvideos across spatial-temporal reasoning, visual-centered reasoning, and\nfree-text generation.\n","authors":["Binzhu Xie","Sicheng Zhang","Zitang Zhou","Bo Li","Yuanhan Zhang","Jack Hessel","Jingkang Yang","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2306.14899v1.pdf","comment":"Ask VLMs about humor, creation, and magics. Project Page:\n  https://funqa-benchmark.github.io/ Codebase:\n  https://github.com/Jingkang50/FunQA"},{"id":"http://arxiv.org/abs/2306.09382v2","updated":"2023-06-26T17:31:30Z","published":"2023-06-15T12:59:04Z","title":"Sound Demixing Challenge 2023 Music Demixing Track Technical Report:\n  TFC-TDF-UNet v3","summary":"  In this report, we present our award-winning solutions for the Music Demixing\nTrack of Sound Demixing Challenge 2023. First, we propose TFC-TDF-UNet v3, a\ntime-efficient music source separation model that achieves state-of-the-art\nresults on the MUSDB benchmark. We then give full details regarding our\nsolutions for each Leaderboard, including a loss masking approach for\nnoise-robust training. Code for reproducing model training and final\nsubmissions is available at github.com/kuielab/sdx23.\n","authors":["Minseok Kim","Jun Hyung Lee","Soonyoung Jung"],"pdf_url":"https://arxiv.org/pdf/2306.09382v2.pdf","comment":"5 pages, 4 tables"},{"id":"http://arxiv.org/abs/2306.14565v1","updated":"2023-06-26T10:26:33Z","published":"2023-06-26T10:26:33Z","title":"Aligning Large Multi-Modal Model with Robust Instruction Tuning","summary":"  Despite the promising progress in multi-modal tasks, current large\nmulti-modal models (LMM) are prone to hallucinating inconsistent descriptions\nwith respect to the associated image and human instructions. This paper\naddresses this issue by introducing the first large and diverse visual\ninstruction tuning dataset, named Large-scale Robust Visual (LRV)-Instruction.\nOur dataset consists of 120k visual instructions generated by GPT4, covering 16\nvision-and-language tasks with open-ended instructions and answers. Unlike\nexisting studies that primarily focus on positive instruction samples, we\ndesign LRV-Instruction to include both positive and negative instructions for\nmore robust visual instruction tuning. Our negative instructions are designed\nat two semantic levels: (i) Nonexistent Element Manipulation and (ii) Existent\nElement Manipulation. To efficiently measure the hallucination generated by\nLMMs, we propose GPT4-Assisted Visual Instruction Evaluation (GAVIE), a novel\napproach to evaluate visual instruction tuning without the need for\nhuman-annotated groundtruth answers and can adapt to diverse instruction\nformats. We conduct comprehensive experiments to investigate the hallucination\nof LMMs. Our results demonstrate that existing LMMs exhibit significant\nhallucination when presented with our negative instructions, particularly with\nExistent Element Manipulation instructions. Moreover, by finetuning MiniGPT4 on\nLRV-Instruction, we successfully mitigate hallucination while improving\nperformance on public datasets using less training data compared to\nstate-of-the-art methods. Additionally, we observed that a balanced ratio of\npositive and negative instances in the training data leads to a more robust\nmodel. Our project link is available at https://fuxiaoliu.github.io/LRV/.\n","authors":["Fuxiao Liu","Kevin Lin","Linjie Li","Jianfeng Wang","Yaser Yacoob","Lijuan Wang"],"pdf_url":"https://arxiv.org/pdf/2306.14565v1.pdf","comment":"35 pages, 27 figures. Under Review"},{"id":"http://arxiv.org/abs/2306.14432v1","updated":"2023-06-26T06:00:18Z","published":"2023-06-26T06:00:18Z","title":"Subjective assessment of the impact of a content adaptive optimiser for\n  compressing 4K HDR content with AV1","summary":"  Since 2015 video dimensionality has expanded to higher spatial and temporal\nresolutions and a wider colour gamut. This High Dynamic Range (HDR) content has\ngained traction in the consumer space as it delivers an enhanced quality of\nexperience. At the same time, the complexity of codecs is growing. This has\ndriven the development of tools for content-adaptive optimisation that achieve\noptimal rate-distortion performance for HDR video at 4K resolution. While\nimprovements of just a few percentage points in BD-Rate (1-5\\%) are significant\nfor the streaming media industry, the impact on subjective quality has been\nless studied especially for HDR/AV1. In this paper, we conduct a subjective\nquality assessment (42 subjects) of 4K HDR content with a per-clip optimisation\nstrategy. We correlate these subjective scores with existing popular objective\nmetrics used in standard development and show that some perceptual metrics\ncorrelate surprisingly well even though they are not tuned for HDR. We find\nthat the DSQCS protocol is too insensitive to categorically compare the methods\nbut the data allows us to make recommendations about the use of experts vs\nnon-experts in HDR studies, and explain the subjective impact of film grain in\nHDR content under compression.\n","authors":[" Vibhoothi","Angeliki Katsenou","François Pitié","Katarina Domijan","Anil Kokaram"],"pdf_url":"https://arxiv.org/pdf/2306.14432v1.pdf","comment":"Accepted Camera-ready version for the ICIP 2023 Paper"},{"id":"http://arxiv.org/abs/2306.14412v1","updated":"2023-06-26T04:19:33Z","published":"2023-06-26T04:19:33Z","title":"A Solution to CVPR'2023 AQTC Challenge: Video Alignment for Multi-Step\n  Inference","summary":"  Affordance-centric Question-driven Task Completion (AQTC) for Egocentric\nAssistant introduces a groundbreaking scenario. In this scenario, through\nlearning instructional videos, AI assistants provide users with step-by-step\nguidance on operating devices. In this paper, we present a solution for\nenhancing video alignment to improve multi-step inference. Specifically, we\nfirst utilize VideoCLIP to generate video-script alignment features.\nAfterwards, we ground the question-relevant content in instructional videos.\nThen, we reweight the multimodal context to emphasize prominent features.\nFinally, we adopt GRU to conduct multi-step inference. Through comprehensive\nexperiments, we demonstrate the effectiveness and superiority of our method,\nwhich secured the 2nd place in CVPR'2023 AQTC challenge. Our code is available\nat https://github.com/zcfinal/LOVEU-CVPR23-AQTC.\n","authors":["Chao Zhang","Shiwei Wu","Sirui Zhao","Tong Xu","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2306.14412v1.pdf","comment":"5 pages, 1 figure, technical report for track3 of CVPR 2023 LOVEU\n  challenge"}]},"2023-06-25T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2305.05352v4","updated":"2023-06-25T23:14:13Z","published":"2023-05-09T11:37:16Z","title":"A Taxonomy of Foundation Model based Systems for\n  Responsible-AI-by-Design","summary":"  The recent release of large language model (LLM) based chatbots, such as\nChatGPT, has attracted significant attention on foundation models. It is widely\nbelieved that foundation models will serve as the fundamental building blocks\nfor future AI systems. As foundation models are in their early stages, the\ndesign of foundation model based systems has not yet been systematically\nexplored. There is little understanding about the impact of introducing\nfoundation models in software architecture. Therefore, in this paper, we\npropose a taxonomy of foundation model based systems, which classifies and\ncompares the characteristics of foundation models and design options of\nfoundation model based systems. Our taxonomy comprises three categories:\nfoundation model pretraining and fine-tuning, architecture design of foundation\nmodel based systems, and responsible-AI-by-design. This taxonomy provides\nconcrete guidance for making major design decisions when designing foundation\nmodel based systems and highlights trade-offs arising from design decisions.\n","authors":["Qinghua Lu","Liming Zhu","Xiwei Xu","Zhenchang Xing","Jon Whittle"],"pdf_url":"https://arxiv.org/pdf/2305.05352v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13114v3","updated":"2023-06-25T21:38:42Z","published":"2023-02-25T16:33:53Z","title":"Sequential Query Encoding For Complex Query Answering on Knowledge\n  Graphs","summary":"  Complex Query Answering (CQA) is an important and fundamental task for\nknowledge graph (KG) reasoning. Query encoding (QE) is proposed as a fast and\nrobust solution to CQA. In the encoding process, most existing QE methods first\nparse the logical query into an executable computational direct-acyclic graph\n(DAG), then use neural networks to parameterize the operators, and finally,\nrecursively execute these neuralized operators. However, the\nparameterization-and-execution paradigm may be potentially over-complicated, as\nit can be structurally simplified by a single neural network encoder.\nMeanwhile, sequence encoders, like LSTM and Transformer, proved to be effective\nfor encoding semantic graphs in related tasks. Motivated by this, we propose\nsequential query encoding (SQE) as an alternative to encode queries for CQA.\nInstead of parameterizing and executing the computational graph, SQE first uses\na search-based algorithm to linearize the computational graph to a sequence of\ntokens and then uses a sequence encoder to compute its vector representation.\nThen this vector representation is used as a query embedding to retrieve\nanswers from the embedding space according to similarity scores. Despite its\nsimplicity, SQE demonstrates state-of-the-art neural query encoding performance\non FB15k, FB15k-237, and NELL on an extended benchmark including twenty-nine\ntypes of in-distribution queries. Further experiment shows that SQE also\ndemonstrates comparable knowledge inference capability on out-of-distribution\nqueries, whose query types are not observed during the training process.\n","authors":["Jiaxin Bai","Tianshi Zheng","Yangqiu Song"],"pdf_url":"https://arxiv.org/pdf/2302.13114v3.pdf","comment":"Accepted by TMLR"},{"id":"http://arxiv.org/abs/2306.14321v1","updated":"2023-06-25T19:23:21Z","published":"2023-06-25T19:23:21Z","title":"RobuT: A Systematic Study of Table QA Robustness Against Human-Annotated\n  Adversarial Perturbations","summary":"  Despite significant progress having been made in question answering on\ntabular data (Table QA), it's unclear whether, and to what extent existing\nTable QA models are robust to task-specific perturbations, e.g., replacing key\nquestion entities or shuffling table columns. To systematically study the\nrobustness of Table QA models, we propose a benchmark called RobuT, which\nbuilds upon existing Table QA datasets (WTQ, WikiSQL-Weak, and SQA) and\nincludes human-annotated adversarial perturbations in terms of table header,\ntable content, and question. Our results indicate that both state-of-the-art\nTable QA models and large language models (e.g., GPT-3) with few-shot learning\nfalter in these adversarial sets. We propose to address this problem by using\nlarge language models to generate adversarial examples to enhance training,\nwhich significantly improves the robustness of Table QA models. Our data and\ncode is publicly available at https://github.com/yilunzhao/RobuT.\n","authors":["Yilun Zhao","Chen Zhao","Linyong Nan","Zhenting Qi","Wenlin Zhang","Xiangru Tang","Boyu Mi","Dragomir Radev"],"pdf_url":"https://arxiv.org/pdf/2306.14321v1.pdf","comment":"Accepted at ACL 2023"},{"id":"http://arxiv.org/abs/2306.14310v1","updated":"2023-06-25T18:48:21Z","published":"2023-06-25T18:48:21Z","title":"Addressing Cold Start Problem for End-to-end Automatic Speech Scoring","summary":"  Integrating automatic speech scoring/assessment systems has become a critical\naspect of second-language speaking education. With self-supervised learning\nadvancements, end-to-end speech scoring approaches have exhibited promising\nresults. However, this study highlights the significant decrease in the\nperformance of speech scoring systems in new question contexts, thereby\nidentifying this as a cold start problem in terms of items. With the finding of\ncold-start phenomena, this paper seeks to alleviate the problem by following\nmethods: 1) prompt embeddings, 2) question context embeddings using BERT or\nCLIP models, and 3) choice of the pretrained acoustic model. Experiments are\nconducted on TOEIC speaking test datasets collected from\nEnglish-as-a-second-language (ESL) learners rated by professional TOEIC\nspeaking evaluators. The results demonstrate that the proposed framework not\nonly exhibits robustness in a cold-start environment but also outperforms the\nbaselines for known content.\n","authors":["Jungbae Park","Seungtaek Choi"],"pdf_url":"https://arxiv.org/pdf/2306.14310v1.pdf","comment":"Accepted at Interspeech 2023, 4 pages, 1 page for reference"},{"id":"http://arxiv.org/abs/2306.14308v1","updated":"2023-06-25T18:40:43Z","published":"2023-06-25T18:40:43Z","title":"Let's Do a Thought Experiment: Using Counterfactuals to Improve Moral\n  Reasoning","summary":"  Language models still struggle on moral reasoning, despite their impressive\nperformance in many other tasks. In particular, the Moral Scenarios task in\nMMLU (Multi-task Language Understanding) is among the worst performing tasks\nfor many language models, including GPT-3. In this work, we propose a new\nprompting framework, Thought Experiments, to teach language models to do better\nmoral reasoning using counterfactuals. Experiment results show that our\nframework elicits counterfactual questions and answers from the model, which in\nturn helps improve the accuracy on Moral Scenarios task by 9-16% compared to\nother zero-shot baselines. Interestingly, unlike math reasoning tasks,\nzero-shot Chain-of-Thought (CoT) reasoning doesn't work out of the box, and\neven reduces accuracy by around 4% compared to direct zero-shot. We further\nobserved that with minimal human supervision in the form of 5 few-shot\nexamples, the accuracy of the task can be improved to as much as 80%.\n","authors":["Xiao Ma","Swaroop Mishra","Ahmad Beirami","Alex Beutel","Jilin Chen"],"pdf_url":"https://arxiv.org/pdf/2306.14308v1.pdf","comment":"8 pages, ICML Neural Conversational AI workshop, thought experiments,\n  moral reasoning"},{"id":"http://arxiv.org/abs/2305.01505v2","updated":"2023-06-25T18:06:25Z","published":"2023-04-30T04:36:05Z","title":"Beyond Classification: Financial Reasoning in State-of-the-Art Language\n  Models","summary":"  Large Language Models (LLMs), consisting of 100 billion or more parameters,\nhave demonstrated remarkable ability in complex multi-step reasoning tasks.\nHowever, the application of such generic advancements has been limited to a few\nfields, such as clinical or legal, with the field of financial reasoning\nremaining largely unexplored. To the best of our knowledge, the ability of LLMs\nto solve financial reasoning problems has never been dealt with, and whether it\ncan be performed at any scale remains unknown. To address this knowledge gap,\nthis research presents a comprehensive investigation into the potential\napplication of LLMs in the financial domain. The investigation includes a\ndetailed exploration of a range of subjects, including task formulation,\nsynthetic data generation, prompting methods, and evaluation capability.\nFurthermore, the study benchmarks various GPT variants with parameter scales\nranging from 2.8B to 13B, with and without instruction tuning, on diverse\ndataset sizes. By analyzing the results, we reveal that the ability to generate\ncoherent financial reasoning first emerges at 6B parameters, and continues to\nimprove with better instruction-tuning or larger datasets. Additionally, the\nstudy provides a publicly accessible dataset named sFIOG (Synthetic-Financial\nInvestment Opinion Generation), consisting of 11,802 synthetic investment\nthesis samples, to support further research in the field of financial\nreasoning. Overall, this research seeks to contribute to the understanding of\nthe efficacy of language models in the field of finance, with a particular\nemphasis on their ability to engage in sophisticated reasoning and analysis\nwithin the context of investment decision-making.\n","authors":["Guijin Son","Hanearl Jung","Moonjeong Hahm","Keonju Na","Sol Jin"],"pdf_url":"https://arxiv.org/pdf/2305.01505v2.pdf","comment":"Accepted by FinNLP (Financial Technology and Natural Language\n  Processing) @ IJCAI2023 as long paper"},{"id":"http://arxiv.org/abs/2305.15225v2","updated":"2023-06-25T17:56:37Z","published":"2023-05-24T15:07:30Z","title":"SAIL: Search-Augmented Instruction Learning","summary":"  Large language models (LLMs) have been significantly improved by instruction\nfine-tuning, but still lack transparency and the ability to utilize up-to-date\nknowledge and information. In this work, we propose search-augmented\ninstruction learning (SAIL), which grounds the language generation and\ninstruction following abilities on complex search results generated by in-house\nand external search engines. With an instruction tuning corpus, we collect\nsearch results for each training case from different search APIs and domains,\nand construct a new search-grounded training set containing\n\\textit{(instruction, grounding information, response)} triplets. We then\nfine-tune the LLaMA-7B model on the constructed training set. Since the\ncollected results contain unrelated and disputing languages, the model needs to\nlearn to ground on trustworthy search results, filter out distracting passages,\nand generate the target response. The search result-denoising process entails\nexplicit trustworthy information selection and multi-hop reasoning, since the\nretrieved passages might be informative but not contain the\ninstruction-following answer. Experiments show that the fine-tuned SAIL-7B\nmodel has a strong instruction-following ability, and it performs significantly\nbetter on transparency-sensitive tasks, including open-ended question answering\nand fact checking.\n","authors":["Hongyin Luo","Yung-Sung Chuang","Yuan Gong","Tianhua Zhang","Yoon Kim","Xixin Wu","Danny Fox","Helen Meng","James Glass"],"pdf_url":"https://arxiv.org/pdf/2305.15225v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.09102v3","updated":"2023-06-25T16:51:52Z","published":"2022-11-16T18:42:37Z","title":"Prompting PaLM for Translation: Assessing Strategies and Performance","summary":"  Large language models (LLMs) that have been trained on multilingual but not\nparallel text exhibit a remarkable ability to translate between languages. We\nprobe this ability in an in-depth study of the pathways language model (PaLM),\nwhich has demonstrated the strongest machine translation (MT) performance among\nsimilarly-trained LLMs to date. We investigate various strategies for choosing\ntranslation examples for few-shot prompting, concluding that example quality is\nthe most important factor. Using optimized prompts, we revisit previous\nassessments of PaLM's MT capabilities with more recent test sets, modern MT\nmetrics, and human evaluation, and find that its performance, while impressive,\nstill lags that of state-of-the-art supervised systems. We conclude by\nproviding an analysis of PaLM's MT output which reveals some interesting\nproperties and prospects for future work.\n","authors":["David Vilar","Markus Freitag","Colin Cherry","Jiaming Luo","Viresh Ratnakar","George Foster"],"pdf_url":"https://arxiv.org/pdf/2211.09102v3.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2306.14264v1","updated":"2023-06-25T15:09:21Z","published":"2023-06-25T15:09:21Z","title":"Visual Question Answering in Remote Sensing with Cross-Attention and\n  Multimodal Information Bottleneck","summary":"  In this research, we deal with the problem of visual question answering (VQA)\nin remote sensing. While remotely sensed images contain information significant\nfor the task of identification and object detection, they pose a great\nchallenge in their processing because of high dimensionality, volume and\nredundancy. Furthermore, processing image information jointly with language\nfeatures adds additional constraints, such as mapping the corresponding image\nand language features. To handle this problem, we propose a cross attention\nbased approach combined with information maximization. The CNN-LSTM based\ncross-attention highlights the information in the image and language modalities\nand establishes a connection between the two, while information maximization\nlearns a low dimensional bottleneck layer, that has all the relevant\ninformation required to carry out the VQA task. We evaluate our method on two\nVQA remote sensing datasets of different resolutions. For the high resolution\ndataset, we achieve an overall accuracy of 79.11% and 73.87% for the two test\nsets while for the low resolution dataset, we achieve an overall accuracy of\n85.98%.\n","authors":["Jayesh Songara","Shivam Pande","Shabnam Choudhury","Biplab Banerjee","Rajbabu Velmurugan"],"pdf_url":"https://arxiv.org/pdf/2306.14264v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06841v3","updated":"2023-06-25T15:06:10Z","published":"2023-03-13T04:15:33Z","title":"Learning Transductions and Alignments with RNN Seq2seq Models","summary":"  The paper studies the capabilities of Recurrent-Neural-Network sequence to\nsequence (RNN seq2seq) models in learning four transduction tasks: identity,\nreversal, total reduplication, and quadratic copying. These transductions are\ntraditionally well studied under finite state transducers and attributed with\nincreasing complexity. We find that RNN seq2seq models are only able to\napproximate a mapping that fits the training or in-distribution data, instead\nof learning the underlying functions. Although attention makes learning more\nefficient and robust, it does not overcome the out-of-distribution\ngeneralization limitation. We establish a novel complexity hierarchy for\nlearning the four tasks for attention-less RNN seq2seq models, which may be\nunderstood in terms of the complexity hierarchy of formal languages, instead of\nstring transductions. RNN variants also play a role in the results. In\nparticular, we show that Simple RNN seq2seq models cannot count the input\nlength.\n","authors":["Zhengxiang Wang"],"pdf_url":"https://arxiv.org/pdf/2303.06841v3.pdf","comment":"Published as a conference paper at ICGI 2023; 27 pages; 7 figures; 11\n  tables"},{"id":"http://arxiv.org/abs/2306.11485v2","updated":"2023-06-25T13:32:14Z","published":"2023-06-20T12:16:31Z","title":"Explicit Syntactic Guidance for Neural Text Generation","summary":"  Most existing text generation models follow the sequence-to-sequence\nparadigm. Generative Grammar suggests that humans generate natural language\ntexts by learning language grammar. We propose a syntax-guided generation\nschema, which generates the sequence guided by a constituency parse tree in a\ntop-down direction. The decoding process can be decomposed into two parts: (1)\npredicting the infilling texts for each constituent in the lexicalized syntax\ncontext given the source sentence; (2) mapping and expanding each constituent\nto construct the next-level syntax context. Accordingly, we propose a\nstructural beam search method to find possible syntax structures\nhierarchically. Experiments on paraphrase generation and machine translation\nshow that the proposed method outperforms autoregressive baselines, while also\ndemonstrating effectiveness in terms of interpretability, controllability, and\ndiversity.\n","authors":["Yafu Li","Leyang Cui","Jianhao Yan","Yongjing Yin","Wei Bi","Shuming Shi","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.11485v2.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2306.03774v2","updated":"2023-06-25T12:57:37Z","published":"2023-06-06T15:32:22Z","title":"Exploring Hybrid Linguistic Features for Turkish Text Readability","summary":"  This paper presents the first comprehensive study on automatic readability\nassessment of Turkish texts. We combine state-of-the-art neural network models\nwith linguistic features at lexical, morphosyntactic, syntactic and discourse\nlevels to develop an advanced readability tool. We evaluate the effectiveness\nof traditional readability formulas compared to modern automated methods and\nidentify key linguistic features that determine the readability of Turkish\ntexts.\n","authors":["Ahmet Yavuz Uluslu","Gerold Schneider"],"pdf_url":"https://arxiv.org/pdf/2306.03774v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14222v1","updated":"2023-06-25T12:08:44Z","published":"2023-06-25T12:08:44Z","title":"Unveiling the Potential of Sentiment: Can Large Language Models Predict\n  Chinese Stock Price Movements?","summary":"  The rapid advancement of Large Language Models (LLMs) has led to extensive\ndiscourse regarding their potential to boost the return of quantitative stock\ntrading strategies. This discourse primarily revolves around harnessing the\nremarkable comprehension capabilities of LLMs to extract sentiment factors\nwhich facilitate informed and high-frequency investment portfolio adjustments.\nTo ensure successful implementations of these LLMs into the analysis of Chinese\nfinancial texts and the subsequent trading strategy development within the\nChinese stock market, we provide a rigorous and encompassing benchmark as well\nas a standardized back-testing framework aiming at objectively assessing the\nefficacy of various types of LLMs in the specialized domain of sentiment factor\nextraction from Chinese news text data. To illustrate how our benchmark works,\nwe reference three distinctive models: 1) the generative LLM (ChatGPT), 2) the\nChinese language-specific pre-trained LLM (Erlangshen-RoBERTa), and 3) the\nfinancial domain-specific fine-tuned LLM classifier(Chinese FinBERT). We apply\nthem directly to the task of sentiment factor extraction from large volumes of\nChinese news summary texts. We then proceed to building quantitative trading\nstrategies and running back-tests under realistic trading scenarios based on\nthe derived sentiment factors and evaluate their performances with our\nbenchmark. By constructing such a comparative analysis, we invoke the question\nof what constitutes the most important element for improving a LLM's\nperformance on extracting sentiment factors. And by ensuring that the LLMs are\nevaluated on the same benchmark, following the same standardized experimental\nprocedures that are designed with sufficient expertise in quantitative trading,\nwe make the first stride toward answering such a question.\n","authors":["Haohan Zhang","Fengrui Hua","Chengjin Xu","Jian Guo","Hao Kong","Ruiting Zuo"],"pdf_url":"https://arxiv.org/pdf/2306.14222v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.11716v3","updated":"2023-06-25T11:18:51Z","published":"2022-07-24T11:06:56Z","title":"A Cognitive Study on Semantic Similarity Analysis of Large Corpora: A\n  Transformer-based Approach","summary":"  Semantic similarity analysis and modeling is a fundamentally acclaimed task\nin many pioneering applications of natural language processing today. Owing to\nthe sensation of sequential pattern recognition, many neural networks like RNNs\nand LSTMs have achieved satisfactory results in semantic similarity modeling.\nHowever, these solutions are considered inefficient due to their inability to\nprocess information in a non-sequential manner, thus leading to the improper\nextraction of context. Transformers function as the state-of-the-art\narchitecture due to their advantages like non-sequential data processing and\nself-attention. In this paper, we perform semantic similarity analysis and\nmodeling on the U.S Patent Phrase to Phrase Matching Dataset using both\ntraditional and transformer-based techniques. We experiment upon four different\nvariants of the Decoding Enhanced BERT - DeBERTa and enhance its performance by\nperforming K-Fold Cross-Validation. The experimental results demonstrate our\nmethodology's enhanced performance compared to traditional techniques, with an\naverage Pearson correlation score of 0.79.\n","authors":["Praneeth Nemani","Satyanarayana Vollala"],"pdf_url":"https://arxiv.org/pdf/2207.11716v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.03358v2","updated":"2023-06-25T11:00:29Z","published":"2022-11-07T08:29:11Z","title":"Probing neural language models for understanding of words of estimative\n  probability","summary":"  Words of estimative probability (WEP) are expressions of a statement's\nplausibility (probably, maybe, likely, doubt, likely, unlikely, impossible...).\nMultiple surveys demonstrate the agreement of human evaluators when assigning\nnumerical probability levels to WEP. For example, highly likely corresponds to\na median chance of 0.90+-0.08 in Fagen-Ulmschneider (2015)'s survey. In this\nwork, we measure the ability of neural language processing models to capture\nthe consensual probability level associated to each WEP. Firstly, we use the\nUNLI dataset (Chen et al., 2020) which associates premises and hypotheses with\ntheir perceived joint probability p, to construct prompts, e.g. \"[PREMISE].\n[WEP], [HYPOTHESIS].\" and assess whether language models can predict whether\nthe WEP consensual probability level is close to p. Secondly, we construct a\ndataset of WEP-based probabilistic reasoning, to test whether language models\ncan reason with WEP compositions. When prompted \"[EVENTA] is likely. [EVENTB]\nis impossible.\", a causal language model should not express that [EVENTA&B] is\nlikely. We show that both tasks are unsolved by off-the-shelf English language\nmodels, but that fine-tuning leads to transferable improvement.\n","authors":["Damien Sileo","Marie-Francine Moens"],"pdf_url":"https://arxiv.org/pdf/2211.03358v2.pdf","comment":"Accepted at *SEM2023"},{"id":"http://arxiv.org/abs/2306.14203v1","updated":"2023-06-25T10:54:24Z","published":"2023-06-25T10:54:24Z","title":"Stance Prediction and Analysis of Twitter data : A case study of Ghana\n  2020 Presidential Elections","summary":"  On December 7, 2020, Ghanaians participated in the polls to determine their\npresident for the next four years. To gain insights from this presidential\nelection, we conducted stance analysis (which is not always equivalent to\nsentiment analysis) to understand how Twitter, a popular social media platform,\nreflected the opinions of its users regarding the two main presidential\ncandidates. We collected a total of 99,356 tweets using the Twitter API\n(Tweepy) and manually annotated 3,090 tweets into three classes: Against,\nNeutral, and Support. We then performed preprocessing on the tweets. The\nresulting dataset was evaluated using two lexicon-based approaches, VADER and\nTextBlob, as well as five supervised machine learning-based approaches: Support\nVector Machine (SVM), Logistic Regression (LR), Multinomial Na\\\"ive Bayes\n(MNB), Stochastic Gradient Descent (SGD), and Random Forest (RF), based on\nmetrics such as accuracy, precision, recall, and F1-score. The best performance\nwas achieved by Logistic Regression with an accuracy of 71.13%. We utilized\nLogistic Regression to classify all the extracted tweets and subsequently\nconducted an analysis and discussion of the results. For access to our data and\ncode, please visit:\nhttps://github.com/ShesterG/Stance-Detection-Ghana-2020-Elections.git\n","authors":["Shester Gueuwou","Rose-Mary Owusuaa Mensah Gyening"],"pdf_url":"https://arxiv.org/pdf/2306.14203v1.pdf","comment":"Project for course requirement CSM 366 at KNUST , August 2021"},{"id":"http://arxiv.org/abs/2302.05895v2","updated":"2023-06-25T10:19:00Z","published":"2023-02-12T11:26:10Z","title":"Discourse Structure Extraction from Pre-Trained and Fine-Tuned Language\n  Models in Dialogues","summary":"  Discourse processing suffers from data sparsity, especially for dialogues. As\na result, we explore approaches to build discourse structures for dialogues,\nbased on attention matrices from Pre-trained Language Models (PLMs). We\ninvestigate multiple tasks for fine-tuning and show that the dialogue-tailored\nSentence Ordering task performs best. To locate and exploit discourse\ninformation in PLMs, we propose an unsupervised and a semi-supervised method.\nOur proposals achieve encouraging results on the STAC corpus, with F1 scores of\n57.2 and 59.3 for unsupervised and semi-supervised methods, respectively. When\nrestricted to projective trees, our scores improved to 63.3 and 68.1.\n","authors":["Chuyuan Li","Patrick Huber","Wen Xiao","Maxime Amblard","Chloé Braud","Giuseppe Carenini"],"pdf_url":"https://arxiv.org/pdf/2302.05895v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14192v1","updated":"2023-06-25T10:16:49Z","published":"2023-06-25T10:16:49Z","title":"$α$-$β$-Factorization and the Binary Case of Simon's Congruence","summary":"  In 1991 H\\'ebrard introduced a factorization of words that turned out to be a\npowerful tool for the investigation of a word's scattered factors (also known\nas (scattered) subwords or subsequences). Based on this, first Karandikar and\nSchnoebelen introduced the notion of $k$-richness and later on Barker et al.\nthe notion of $k$-universality. In 2022 Fleischmann et al. presented a\ngeneralization of the arch factorization by intersecting the arch factorization\nof a word and its reverse. While the authors merely used this factorization for\nthe investigation of shortest absent scattered factors, in this work we\ninvestigate this new $\\alpha$-$\\beta$-factorization as such. We characterize\nthe famous Simon congruence of $k$-universal words in terms of $1$-universal\nwords. Moreover, we apply these results to binary words. In this special case,\nwe obtain a full characterization of the classes and calculate the index of the\ncongruence. Lastly, we start investigating the ternary case, present a full\nlist of possibilities for $\\alpha\\beta\\alpha$-factors, and characterize their\ncongruence.\n","authors":["Pamela Fleischmann","Jonas Höfer","Annika Huch","Dirk Nowotka"],"pdf_url":"https://arxiv.org/pdf/2306.14192v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14176v1","updated":"2023-06-25T09:03:56Z","published":"2023-06-25T09:03:56Z","title":"Sentence-level Event Detection without Triggers via Prompt Learning and\n  Machine Reading Comprehension","summary":"  The traditional way of sentence-level event detection involves two important\nsubtasks: trigger identification and trigger classifications, where the\nidentified event trigger words are used to classify event types from sentences.\nHowever, trigger classification highly depends on abundant annotated trigger\nwords and the accuracy of trigger identification. In a real scenario,\nannotating trigger words is time-consuming and laborious. For this reason, we\npropose a trigger-free event detection model, which transforms event detection\ninto a two-tower model based on machine reading comprehension and prompt\nlearning. Compared to existing trigger-based and trigger-free methods,\nexperimental studies on two event detection benchmark datasets (ACE2005 and\nMAVEN) have shown that the proposed approach can achieve competitive\nperformance.\n","authors":["Tongtao Ling","Lei Chen","Huangxu Sheng","Zicheng Cai","Hai-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2306.14176v1.pdf","comment":"14 pages, accepted by ADMA 2023"},{"id":"http://arxiv.org/abs/2206.12617v2","updated":"2023-06-25T08:23:04Z","published":"2022-06-25T10:39:12Z","title":"Language Models as Knowledge Embeddings","summary":"  Knowledge embeddings (KE) represent a knowledge graph (KG) by embedding\nentities and relations into continuous vector spaces. Existing methods are\nmainly structure-based or description-based. Structure-based methods learn\nrepresentations that preserve the inherent structure of KGs. They cannot well\nrepresent abundant long-tail entities in real-world KGs with limited structural\ninformation. Description-based methods leverage textual information and\nlanguage models. Prior approaches in this direction barely outperform\nstructure-based ones, and suffer from problems like expensive negative sampling\nand restrictive description demand. In this paper, we propose LMKE, which\nadopts Language Models to derive Knowledge Embeddings, aiming at both enriching\nrepresentations of long-tail entities and solving problems of prior\ndescription-based methods. We formulate description-based KE learning with a\ncontrastive learning framework to improve efficiency in training and\nevaluation. Experimental results show that LMKE achieves state-of-the-art\nperformance on KE benchmarks of link prediction and triple classification,\nespecially for long-tail entities.\n","authors":["Xintao Wang","Qianyu He","Jiaqing Liang","Yanghua Xiao"],"pdf_url":"https://arxiv.org/pdf/2206.12617v2.pdf","comment":"This revision corrects some results after fixing a data leakage issue"},{"id":"http://arxiv.org/abs/2306.14152v1","updated":"2023-06-25T07:38:43Z","published":"2023-06-25T07:38:43Z","title":"Low-Rank Prune-And-Factorize for Language Model Compression","summary":"  The components underpinning PLMs -- large weight matrices -- were shown to\nbear considerable redundancy. Matrix factorization, a well-established\ntechnique from matrix theory, has been utilized to reduce the number of\nparameters in PLM. However, it fails to retain satisfactory performance under\nmoderate to high compression rate. In this paper, we identify the\n\\textit{full-rankness} of fine-tuned PLM as the fundamental bottleneck for the\nfailure of matrix factorization and explore the use of network pruning to\nextract low-rank sparsity pattern desirable to matrix factorization. We find\nsuch low-rank sparsity pattern exclusively exists in models generated by\nfirst-order pruning, which motivates us to unite the two approaches and achieve\nmore effective model compression. We further propose two techniques:\nsparsity-aware SVD and mixed-rank fine-tuning, which improve the initialization\nand training of the compression procedure, respectively. Experiments on GLUE\nand question-answering tasks show that the proposed method has superior\ncompression-performance trade-off compared to existing approaches.\n","authors":["Siyu Ren","Kenny Q. Zhu"],"pdf_url":"https://arxiv.org/pdf/2306.14152v1.pdf","comment":"Model Compression"},{"id":"http://arxiv.org/abs/2306.14149v1","updated":"2023-06-25T07:25:14Z","published":"2023-06-25T07:25:14Z","title":"SciMRC: Multi-perspective Scientific Machine Reading Comprehension","summary":"  Scientific machine reading comprehension (SMRC) aims to understand scientific\ntexts through interactions with humans by given questions. As far as we know,\nthere is only one dataset focused on exploring full-text scientific machine\nreading comprehension. However, the dataset has ignored the fact that different\nreaders may have different levels of understanding of the text, and only\nincludes single-perspective question-answer pairs, leading to a lack of\nconsideration of different perspectives. To tackle the above problem, we\npropose a novel multi-perspective SMRC dataset, called SciMRC, which includes\nperspectives from beginners, students and experts. Our proposed SciMRC is\nconstructed from 741 scientific papers and 6,057 question-answer pairs. Each\nperspective of beginners, students and experts contains 3,306, 1,800 and 951 QA\npairs, respectively. The extensive experiments on SciMRC by utilizing\npre-trained models suggest the importance of considering perspectives of SMRC,\nand demonstrate its challenging nature for machine comprehension.\n","authors":["Xiao Zhang","Heqi Zheng","Yuxiang Nie","Heyan Huang","Xian-Ling Mao"],"pdf_url":"https://arxiv.org/pdf/2306.14149v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14145v1","updated":"2023-06-25T06:46:36Z","published":"2023-06-25T06:46:36Z","title":"DSE-TTS: Dual Speaker Embedding for Cross-Lingual Text-to-Speech","summary":"  Although high-fidelity speech can be obtained for intralingual speech\nsynthesis, cross-lingual text-to-speech (CTTS) is still far from satisfactory\nas it is difficult to accurately retain the speaker timbres(i.e. speaker\nsimilarity) and eliminate the accents from their first language(i.e.\nnativeness). In this paper, we demonstrated that vector-quantized(VQ) acoustic\nfeature contains less speaker information than mel-spectrogram. Based on this\nfinding, we propose a novel dual speaker embedding TTS (DSE-TTS) framework for\nCTTS with authentic speaking style. Here, one embedding is fed to the acoustic\nmodel to learn the linguistic speaking style, while the other one is integrated\ninto the vocoder to mimic the target speaker's timbre. Experiments show that by\ncombining both embeddings, DSE-TTS significantly outperforms the\nstate-of-the-art SANE-TTS in cross-lingual synthesis, especially in terms of\nnativeness.\n","authors":["Sen Liu","Yiwei Guo","Chenpeng Du","Xie Chen","Kai Yu"],"pdf_url":"https://arxiv.org/pdf/2306.14145v1.pdf","comment":"Accepted to Interspeech 2023"},{"id":"http://arxiv.org/abs/2306.00739v3","updated":"2023-06-25T06:44:48Z","published":"2023-05-26T21:39:05Z","title":"SQL-PaLM: Improved Large Language Model Adaptation for Text-to-SQL","summary":"  One impressive emergent capability of large language models (LLMs) is\ngeneration of code, including Structured Query Language (SQL) for databases.\nFor the task of converting natural language text to SQL queries, Text-to-SQL,\nadaptation of LLMs is of paramount importance, both in in-context learning and\nfine-tuning settings, depending on the amount of adaptation data used. In this\npaper, we propose an LLM-based Text-to-SQL model SQL-PaLM, leveraging on\nPaLM-2, that pushes the state-of-the-art in both settings. Few-shot SQL-PaLM is\nbased on an execution-based self-consistency prompting approach designed for\nText-to-SQL, and achieves 77.3% in test-suite accuracy on Spider, which to our\nbest knowledge is the first to outperform previous state-of-the-art with\nfine-tuning by a significant margin, 4%. Furthermore, we demonstrate that the\nfine-tuned SQL-PALM outperforms it further by another 1%. Towards applying\nSQL-PaLM to real-world scenarios we further evaluate its robustness on other\nchallenging variants of Spider and demonstrate the superior generalization\ncapability of SQL-PaLM. In addition, via extensive case studies, we demonstrate\nthe impressive intelligent capabilities and various success enablers of\nLLM-based Text-to-SQL.\n","authors":["Ruoxi Sun","Sercan O. Arik","Hootan Nakhost","Hanjun Dai","Rajarishi Sinha","Pengcheng Yin","Tomas Pfister"],"pdf_url":"https://arxiv.org/pdf/2306.00739v3.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2306.14135v1","updated":"2023-06-25T05:57:01Z","published":"2023-06-25T05:57:01Z","title":"Interpretable Neural Embeddings with Sparse Self-Representation","summary":"  Interpretability benefits the theoretical understanding of representations.\nExisting word embeddings are generally dense representations. Hence, the\nmeaning of latent dimensions is difficult to interpret. This makes word\nembeddings like a black-box and prevents them from being human-readable and\nfurther manipulation. Many methods employ sparse representation to learn\ninterpretable word embeddings for better interpretability. However, they also\nsuffer from the unstable issue of grouped selection in $\\ell1$ and online\ndictionary learning. Therefore, they tend to yield different results each time.\nTo alleviate this challenge, we propose a novel method to associate data\nself-representation with a shallow neural network to learn expressive,\ninterpretable word embeddings. In experiments, we report that the resulting\nword embeddings achieve comparable and even slightly better interpretability\nthan baseline embeddings. Besides, we also evaluate that our approach performs\ncompetitively well on all downstream tasks and outperforms benchmark embeddings\non a majority of them.\n","authors":["Minxue Xia","Hao Zhu"],"pdf_url":"https://arxiv.org/pdf/2306.14135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.06377v3","updated":"2023-06-25T05:53:06Z","published":"2023-04-13T10:13:00Z","title":"Emergence of Symbols in Neural Networks for Semantic Understanding and\n  Communication","summary":"  The capacity to generate meaningful symbols and effectively employ them for\nadvanced cognitive processes, such as communication, reasoning, and planning,\nconstitutes a fundamental and distinctive aspect of human intelligence.\nExisting deep neural networks still notably lag human capabilities in terms of\ngenerating symbols for higher cognitive functions. Here, we propose a solution\n(symbol emergence artificial network (SEA-net)) to endow neural networks with\nthe ability to create symbols, understand semantics, and achieve communication.\nSEA-net generates symbols that dynamically configure the network to perform\nspecific tasks. These symbols capture compositional semantic information that\nallows the system to acquire new functions purely by symbolic manipulation or\ncommunication. In addition, these self-generated symbols exhibit an intrinsic\nstructure resembling that of natural language, suggesting a common framework\nunderlying the generation and understanding of symbols in both human brains and\nartificial neural networks. We believe that the proposed framework will be\ninstrumental in producing more capable systems that can synergize the strengths\nof connectionist and symbolic approaches for artificial intelligence (AI).\n","authors":["Yang Chen","Liangxuan Guo","Shan Yu"],"pdf_url":"https://arxiv.org/pdf/2304.06377v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03763v3","updated":"2023-06-25T05:13:06Z","published":"2023-05-28T21:11:59Z","title":"ChatGPT Informed Graph Neural Network for Stock Movement Prediction","summary":"  ChatGPT has demonstrated remarkable capabilities across various natural\nlanguage processing (NLP) tasks. However, its potential for inferring dynamic\nnetwork structures from temporal textual data, specifically financial news,\nremains an unexplored frontier. In this research, we introduce a novel\nframework that leverages ChatGPT's graph inference capabilities to enhance\nGraph Neural Networks (GNN). Our framework adeptly extracts evolving network\nstructures from textual data, and incorporates these networks into graph neural\nnetworks for subsequent predictive tasks. The experimental results from stock\nmovement forecasting indicate our model has consistently outperformed the\nstate-of-the-art Deep Learning-based benchmarks. Furthermore, the portfolios\nconstructed based on our model's outputs demonstrate higher annualized\ncumulative returns, alongside reduced volatility and maximum drawdown. This\nsuperior performance highlights the potential of ChatGPT for text-based network\ninferences and underscores its promising implications for the financial sector.\n","authors":["Zihan Chen","Lei Nico Zheng","Cheng Lu","Jialu Yuan","Di Zhu"],"pdf_url":"https://arxiv.org/pdf/2306.03763v3.pdf","comment":"Accepted for the oral presentation at SIGKDD 2023 Workshop on Robust\n  NLP for Finance"},{"id":"http://arxiv.org/abs/2306.14122v1","updated":"2023-06-25T04:33:56Z","published":"2023-06-25T04:33:56Z","title":"Chain-of-Thought Prompt Distillation for Multimodal Named Entity and\n  Multimodal Relation Extraction","summary":"  Multimodal Named Entity Recognition (MNER) and Multimodal Relation Extraction\n(MRE) necessitate the fundamental reasoning capacity for intricate linguistic\nand multimodal comprehension. In this study, we explore distilling the\nreasoning ability of large language models (LLMs) into a more compact student\nmodel by generating a \\textit{chain of thought} (CoT) -- a sequence of\nintermediate reasoning steps. Specifically, we commence by exemplifying the\nelicitation of such reasoning ability from LLMs through CoT prompts covering\nmulti-grain (noun, sentence, multimodality) and data-augmentation (style,\nentity, image) dimensions. Subsequently, we present a novel conditional prompt\ndistillation method to assimilate the commonsense reasoning ability from LLMs,\nthereby enhancing the utility of the student model in addressing text-only\ninputs without the requisite addition of image and CoT knowledge. Extensive\nexperiments reveal that our approach attains state-of-the-art accuracy and\nmanifests a plethora of advantages concerning interpretability, data\nefficiency, and cross-domain generalization on MNER and MRE datasets.\n","authors":["Feng Chen","Yujian Feng"],"pdf_url":"https://arxiv.org/pdf/2306.14122v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14115v1","updated":"2023-06-25T03:34:06Z","published":"2023-06-25T03:34:06Z","title":"Towards Trustworthy Explanation: On Causal Rationalization","summary":"  With recent advances in natural language processing, rationalization becomes\nan essential self-explaining diagram to disentangle the black box by selecting\na subset of input texts to account for the major variation in prediction. Yet,\nexisting association-based approaches on rationalization cannot identify true\nrationales when two or more snippets are highly inter-correlated and thus\nprovide a similar contribution to prediction accuracy, so-called spuriousness.\nTo address this limitation, we novelly leverage two causal desiderata,\nnon-spuriousness and efficiency, into rationalization from the causal inference\nperspective. We formally define a series of probabilities of causation based on\na newly proposed structural causal model of rationalization, with its\ntheoretical identification established as the main component of learning\nnecessary and sufficient rationales. The superior performance of the proposed\ncausal rationalization is demonstrated on real-world review and medical\ndatasets with extensive experiments compared to state-of-the-art methods.\n","authors":["Wenbo Zhang","Tong Wu","Yunlong Wang","Yong Cai","Hengrui Cai"],"pdf_url":"https://arxiv.org/pdf/2306.14115v1.pdf","comment":"In Proceedings of the 40th International Conference on Machine\n  Learning (ICML) GitHub Repository:\n  https://github.com/onepounchman/Causal-Retionalization"},{"id":"http://arxiv.org/abs/2306.14096v1","updated":"2023-06-25T02:24:30Z","published":"2023-06-25T02:24:30Z","title":"Chinese Fine-Grained Financial Sentiment Analysis with Large Language\n  Models","summary":"  Entity-level fine-grained sentiment analysis in the financial domain is a\ncrucial subtask of sentiment analysis and currently faces numerous challenges.\nThe primary challenge stems from the lack of high-quality and large-scale\nannotated corpora specifically designed for financial text sentiment analysis,\nwhich in turn limits the availability of data necessary for developing\neffective text processing techniques. Recent advancements in large language\nmodels (LLMs) have yielded remarkable performance in natural language\nprocessing tasks, primarily centered around language pattern matching. In this\npaper, we propose a novel and extensive Chinese fine-grained financial\nsentiment analysis dataset, FinChina SA, for enterprise early warning. We\nthoroughly evaluate and experiment with well-known existing open-source LLMs\nusing our dataset. We firmly believe that our dataset will serve as a valuable\nresource to advance the exploration of real-world financial sentiment analysis\ntasks, which should be the focus of future research. Our dataset and all code\nto replicate the experimental results will be released.\n","authors":["Yinyu Lan","Yanru Wu","Wang Xu","Weiqiang Feng","Youhao Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.14096v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.01013v2","updated":"2023-06-25T02:23:05Z","published":"2021-10-03T14:31:46Z","title":"Counterfactual Samples Synthesizing and Training for Robust Visual\n  Question Answering","summary":"  Today's VQA models still tend to capture superficial linguistic correlations\nin the training set and fail to generalize to the test set with different QA\ndistributions. To reduce these language biases, recent VQA works introduce an\nauxiliary question-only model to regularize the training of targeted VQA model,\nand achieve dominating performance on diagnostic benchmarks for\nout-of-distribution testing. However, due to complex model design, these\nensemble-based methods are unable to equip themselves with two indispensable\ncharacteristics of an ideal VQA model: 1) Visual-explainable: The model should\nrely on the right visual regions when making decisions. 2) Question-sensitive:\nThe model should be sensitive to the linguistic variations in questions. To\nthis end, we propose a novel model-agnostic Counterfactual Samples Synthesizing\nand Training (CSST) strategy. After training with CSST, VQA models are forced\nto focus on all critical objects and words, which significantly improves both\nvisual-explainable and question-sensitive abilities. Specifically, CSST is\ncomposed of two parts: Counterfactual Samples Synthesizing (CSS) and\nCounterfactual Samples Training (CST). CSS generates counterfactual samples by\ncarefully masking critical objects in images or words in questions and\nassigning pseudo ground-truth answers. CST not only trains the VQA models with\nboth complementary samples to predict respective ground-truth answers, but also\nurges the VQA models to further distinguish the original samples and\nsuperficially similar counterfactual ones. To facilitate the CST training, we\npropose two variants of supervised contrastive loss for VQA, and design an\neffective positive and negative sample selection mechanism based on CSS.\nExtensive experiments have shown the effectiveness of CSST. Particularly, by\nbuilding on top of model LMH+SAR, we achieve record-breaking performance on all\nOOD benchmarks.\n","authors":["Long Chen","Yuhang Zheng","Yulei Niu","Hanwang Zhang","Jun Xiao"],"pdf_url":"https://arxiv.org/pdf/2110.01013v2.pdf","comment":"IEEE Transactions on Pattern Analysis and Machine Intelligence, TPAMI\n  2023. (Extension of CVPR'20 work). arXiv admin note: text overlap with\n  arXiv:2003.06576"},{"id":"http://arxiv.org/abs/2305.01437v2","updated":"2023-06-25T01:49:25Z","published":"2023-05-02T14:06:47Z","title":"Sentiment Perception Adversarial Attacks on Neural Machine Translation\n  Systems","summary":"  With the advent of deep learning methods, Neural Machine Translation (NMT)\nsystems have become increasingly powerful. However, deep learning based systems\nare susceptible to adversarial attacks, where imperceptible changes to the\ninput can cause undesirable changes at the output of the system. To date there\nhas been little work investigating adversarial attacks on sequence-to-sequence\nsystems, such as NMT models. Previous work in NMT has examined attacks with the\naim of introducing target phrases in the output sequence. In this work,\nadversarial attacks for NMT systems are explored from an output perception\nperspective. Thus the aim of an attack is to change the perception of the\noutput sequence, without altering the perception of the input sequence. For\nexample, an adversary may distort the sentiment of translated reviews to have\nan exaggerated positive sentiment. In practice it is challenging to run\nextensive human perception experiments, so a proxy deep-learning classifier\napplied to the NMT output is used to measure perception changes. Experiments\ndemonstrate that the sentiment perception of NMT systems' output sequences can\nbe changed significantly with small imperceptible changes to input sequences.\n","authors":["Vyas Raina","Mark Gales"],"pdf_url":"https://arxiv.org/pdf/2305.01437v2.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2212.05332v4","updated":"2023-06-25T22:57:54Z","published":"2022-12-10T16:27:25Z","title":"An approach to robust ICP initialization","summary":"  In this note, we propose an approach to initialize the Iterative Closest\nPoint (ICP) algorithm to match unlabelled point clouds related by rigid\ntransformations. The method is based on matching the ellipsoids defined by the\npoints' covariance matrices and then testing the various principal half-axes\nmatchings that differ by elements of a finite reflection group. We derive\nbounds on the robustness of our approach to noise and numerical experiments\nconfirm our theoretical findings.\n","authors":["Alexander Kolpakov","Michael Werman"],"pdf_url":"https://arxiv.org/pdf/2212.05332v4.pdf","comment":"9 pages, 18 figures, 1 table; GitHub repository at\n  (https://github.com/sashakolpakov/icp-init)"},{"id":"http://arxiv.org/abs/2306.14361v1","updated":"2023-06-25T22:33:21Z","published":"2023-06-25T22:33:21Z","title":"A differentiable Gaussian Prototype Layer for explainable Segmentation","summary":"  We introduce a Gaussian Prototype Layer for gradient-based prototype learning\nand demonstrate two novel network architectures for explainable segmentation\none of which relies on region proposals. Both models are evaluated on\nagricultural datasets. While Gaussian Mixture Models (GMMs) have been used to\nmodel latent distributions of neural networks before, they are typically fitted\nusing the EM algorithm. Instead, the proposed prototype layer relies on\ngradient-based optimization and hence allows for end-to-end training. This\nfacilitates development and allows to use the full potential of a trainable\ndeep feature extractor. We show that it can be used as a novel building block\nfor explainable neural networks. We employ our Gaussian Prototype Layer in (1)\na model where prototypes are detected in the latent grid and (2) a model\ninspired by Fast-RCNN with SLIC superpixels as region proposals. The earlier\nachieves a similar performance as compared to the state-of-the art while the\nlatter has the benefit of a more precise prototype localization that comes at\nthe cost of slightly lower accuracies. By introducing a gradient-based GMM\nlayer we combine the benefits of end-to-end training with the simplicity and\ntheoretical foundation of GMMs which will allow to adapt existing\nsemi-supervised learning strategies for prototypical part models in future.\n","authors":["Michael Gerstenberger","Steffen Maaß","Peter Eisert","Sebastian Bosse"],"pdf_url":"https://arxiv.org/pdf/2306.14361v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14350v1","updated":"2023-06-25T21:53:50Z","published":"2023-06-25T21:53:50Z","title":"CDiffMR: Can We Replace the Gaussian Noise with K-Space Undersampling\n  for Fast MRI?","summary":"  Deep learning has shown the capability to substantially accelerate MRI\nreconstruction while acquiring fewer measurements. Recently, diffusion models\nhave gained burgeoning interests as a novel group of deep learning-based\ngenerative methods. These methods seek to sample data points that belong to a\ntarget distribution from a Gaussian distribution, which has been successfully\nextended to MRI reconstruction. In this work, we proposed a Cold\nDiffusion-based MRI reconstruction method called CDiffMR. Different from\nconventional diffusion models, the degradation operation of our CDiffMR is\nbased on \\textit{k}-space undersampling instead of adding Gaussian noise, and\nthe restoration network is trained to harness a de-aliaseing function. We also\ndesign starting point and data consistency conditioning strategies to guide and\naccelerate the reverse process. More intriguingly, the pre-trained CDiffMR\nmodel can be reused for reconstruction tasks with different undersampling\nrates. We demonstrated, through extensive numerical and visual experiments,\nthat the proposed CDiffMR can achieve comparable or even superior\nreconstruction results than state-of-the-art models. Compared to the diffusion\nmodel-based counterpart, CDiffMR reaches readily competing results using only\n$1.6 \\sim 3.4\\%$ for inference time. The code is publicly available at\nhttps://github.com/ayanglab/CDiffMR.\n","authors":["Jiahao Huang","Angelica Aviles-Rivero","Carola-Bibiane Schönlieb","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2306.14350v1.pdf","comment":"10 pages, 4 figures, accepted by MICCAI 2023"},{"id":"http://arxiv.org/abs/2306.14313v1","updated":"2023-06-25T18:59:52Z","published":"2023-06-25T18:59:52Z","title":"A Closer Look at Geometric Temporal Dynamics for Face Anti-Spoofing","summary":"  Face anti-spoofing (FAS) is indispensable for a face recognition system. Many\ntexture-driven countermeasures were developed against presentation attacks\n(PAs), but the performance against unseen domains or unseen spoofing types is\nstill unsatisfactory. Instead of exhaustively collecting all the spoofing\nvariations and making binary decisions of live/spoof, we offer a new\nperspective on the FAS task to distinguish between normal and abnormal\nmovements of live and spoof presentations. We propose Geometry-Aware\nInteraction Network (GAIN), which exploits dense facial landmarks with\nspatio-temporal graph convolutional network (ST-GCN) to establish a more\ninterpretable and modularized FAS model. Additionally, with our cross-attention\nfeature interaction mechanism, GAIN can be easily integrated with other\nexisting methods to significantly boost performance. Our approach achieves\nstate-of-the-art performance in the standard intra- and cross-dataset\nevaluations. Moreover, our model outperforms state-of-the-art methods by a\nlarge margin in the cross-dataset cross-type protocol on CASIA-SURF 3DMask\n(+10.26% higher AUC score), exhibiting strong robustness against domain shifts\nand unseen spoofing types.\n","authors":["Chih-Jung Chang","Yaw-Chern Lee","Shih-Hsuan Yao","Min-Hung Chen","Chien-Yi Wang","Shang-Hong Lai","Trista Pei-Chun Chen"],"pdf_url":"https://arxiv.org/pdf/2306.14313v1.pdf","comment":"2023 CVPR Biometrics Workshop, Best Paper Award"},{"id":"http://arxiv.org/abs/2306.14306v1","updated":"2023-06-25T18:29:29Z","published":"2023-06-25T18:29:29Z","title":"Adaptive Sharpness-Aware Pruning for Robust Sparse Networks","summary":"  Robustness and compactness are two essential components of deep learning\nmodels that are deployed in the real world. The seemingly conflicting aims of\n(i) generalization across domains as in robustness, and (ii) specificity to one\ndomain as in compression, are why the overall design goal of achieving robust\ncompact models, despite being highly important, is still a challenging open\nproblem. We introduce Adaptive Sharpness-Aware Pruning, or AdaSAP, a method\nthat yields robust sparse networks. The central tenet of our approach is to\noptimize the loss landscape so that the model is primed for pruning via\nadaptive weight perturbation, and is also consistently regularized toward\nflatter regions for improved robustness. This unifies both goals through the\nlens of network sharpness. AdaSAP achieves strong performance in a\ncomprehensive set of experiments. For classification on ImageNet and object\ndetection on Pascal VOC datasets, AdaSAP improves the robust accuracy of pruned\nmodels by +6% on ImageNet C, +4% on ImageNet V2, and +4% on corrupted VOC\ndatasets, over a wide range of compression ratios, saliency criteria, and\nnetwork architectures, outperforming recent pruning art by large margins.\n","authors":["Anna Bair","Hongxu Yin","Maying Shen","Pavlo Molchanov","Jose Alvarez"],"pdf_url":"https://arxiv.org/pdf/2306.14306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14300v1","updated":"2023-06-25T18:02:01Z","published":"2023-06-25T18:02:01Z","title":"Screening Autism Spectrum Disorder in childrens using Deep Learning\n  Approach : Evaluating the classification model of YOLOv8 by comparing with\n  other models","summary":"  Autism spectrum disorder (ASD) is a developmental condition that presents\nsignificant challenges in social interaction, communication, and behavior.\nEarly intervention plays a pivotal role in enhancing cognitive abilities and\nreducing autistic symptoms in children with ASD. Numerous clinical studies have\nhighlighted distinctive facial characteristics that distinguish ASD children\nfrom typically developing (TD) children. In this study, we propose a practical\nsolution for ASD screening using facial images using YoloV8 model. By employing\nYoloV8, a deep learning technique, on a dataset of Kaggle, we achieved\nexceptional results. Our model achieved a remarkable 89.64% accuracy in\nclassification and an F1-score of 0.89. Our findings provide support for the\nclinical observations regarding facial feature discrepancies between children\nwith ASD. The high F1-score obtained demonstrates the potential of deep\nlearning models in screening children with ASD. We conclude that the newest\nversion of YoloV8 which is usually used for object detection can be used for\nclassification problem of Austistic and Non-autistic images.\n","authors":["Subash Gautam","Prabin Sharma","Kisan Thapa","Mala Deep Upadhaya","Dikshya Thapa","Salik Ram Khanal","Vítor Manuel de Jesus Filipe"],"pdf_url":"https://arxiv.org/pdf/2306.14300v1.pdf","comment":"17 pages,12 figures"},{"id":"http://arxiv.org/abs/2306.14293v1","updated":"2023-06-25T16:55:32Z","published":"2023-06-25T16:55:32Z","title":"Multi-Scale Cross Contrastive Learning for Semi-Supervised Medical Image\n  Segmentation","summary":"  Semi-supervised learning has demonstrated great potential in medical image\nsegmentation by utilizing knowledge from unlabeled data. However, most existing\napproaches do not explicitly capture high-level semantic relations between\ndistant regions, which limits their performance. In this paper, we focus on\nrepresentation learning for semi-supervised learning, by developing a novel\nMulti-Scale Cross Supervised Contrastive Learning (MCSC) framework, to segment\nstructures in medical images. We jointly train CNN and Transformer models,\nregularising their features to be semantically consistent across different\nscales. Our approach contrasts multi-scale features based on ground-truth and\ncross-predicted labels, in order to extract robust feature representations that\nreflect intra- and inter-slice relationships across the whole dataset. To\ntackle class imbalance, we take into account the prevalence of each class to\nguide contrastive learning and ensure that features adequately capture\ninfrequent classes. Extensive experiments on two multi-structure medical\nsegmentation datasets demonstrate the effectiveness of MCSC. It not only\noutperforms state-of-the-art semi-supervised methods by more than 3.0% in Dice,\nbut also greatly reduces the performance gap with fully supervised methods.\n","authors":["Qianying Liu","Xiao Gu","Paul Henderson","Fani Deligianni"],"pdf_url":"https://arxiv.org/pdf/2306.14293v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14291v1","updated":"2023-06-25T16:45:20Z","published":"2023-06-25T16:45:20Z","title":"Hyp-OW: Exploiting Hierarchical Structure Learning with Hyperbolic\n  Distance Enhances Open World Object Detection","summary":"  Open World Object Detection (OWOD) is a challenging and realistic task that\nextends beyond the scope of standard Object Detection task. It involves\ndetecting both known and unknown objects while integrating learned knowledge\nfor future tasks. However, the level of 'unknownness' varies significantly\ndepending on the context. For example, a tree is typically considered part of\nthe background in a self-driving scene, but it may be significant in a\nhousehold context. We argue that this external or contextual information should\nalready be embedded within the known classes. In other words, there should be a\nsemantic or latent structure relationship between the known and unknown items\nto be discovered. Motivated by this observation, we propose Hyp-OW, a method\nthat learns and models hierarchical representation of known items through a\nSuperClass Regularizer. Leveraging this learned representation allows us to\neffectively detect unknown objects using a Similarity Distance-based Relabeling\nmodule. Extensive experiments on benchmark datasets demonstrate the\neffectiveness of Hyp-OW achieving improvement in both known and unknown\ndetection (up to 6 points). These findings are particularly pronounced in our\nnewly designed benchmark, where a strong hierarchical structure exists between\nknown and unknown objects.\n","authors":["Thang Doan","Xin Li","Sima Behpour","Wenbin He","Liang Gou","Liu Ren"],"pdf_url":"https://arxiv.org/pdf/2306.14291v1.pdf","comment":"keywords: Open World Object Detection, Hyperbolic Distance, Unknown\n  Detection, Deformable Transformers"},{"id":"http://arxiv.org/abs/2306.14289v1","updated":"2023-06-25T16:37:25Z","published":"2023-06-25T16:37:25Z","title":"Faster Segment Anything: Towards Lightweight SAM for Mobile Applications","summary":"  Segment anything model (SAM) is a prompt-guided vision foundation model for\ncutting out the object of interest from its background. Since Meta research\nteam released the SA project, SAM has attracted significant attention due to\nits impressive zero-shot transfer performance and high versatility of being\ncompatible with other models for advanced vision applications like image\nediting with fine-grained control. Many of such use cases need to be run on\nresource-constraint edge devices, like mobile Apps. In this work, we aim to\nmake SAM mobile-friendly by replacing the heavyweight image encoder with a\nlightweight one. A naive way to train such a new SAM as in the original SAM\npaper leads to unsatisfactory performance, especially when limited training\nsources are available. We find that this is mainly caused by the coupled\noptimization of the image encoder and mask decoder, motivated by which we\npropose decoupled distillation. Concretely, we distill the knowledge from the\nimage encoder ViT-H in the original SAM to a lightweight image encoder, which\ncan be automatically compatible with the mask decoder in the original SAM. The\ntraining can be completed on a single GPU within less than one day, and the\nresulting lightweight SAM is termed MobileSAM which is more than 60 times\nsmaller yet performs on par with the original SAM. For inference speed,\nMobileSAM runs around 10ms per image: 8ms on the image encoder and 2ms on the\nmask decoder. With superior performance and a higher versatility, our MobileSAM\nis 7 times smaller and 4 times faster than the concurrent FastSAM, making it\nmore suitable for mobile applications. The code for MobileSAM project is\nprovided at https://github.com/ChaoningZhang/MobileSAM\n","authors":["Chaoning Zhang","Dongshen Han","Yu Qiao","Jung Uk Kim","Sung-Ho Bae","Seungkyu Lee","Choong Seon Hong"],"pdf_url":"https://arxiv.org/pdf/2306.14289v1.pdf","comment":"First work to make SAM lightweight for mobile applications"},{"id":"http://arxiv.org/abs/2306.14287v1","updated":"2023-06-25T16:29:51Z","published":"2023-06-25T16:29:51Z","title":"Efficient Contextformer: Spatio-Channel Window Attention for Fast\n  Context Modeling in Learned Image Compression","summary":"  In this work, we introduce Efficient Contextformer (eContextformer) for\ncontext modeling in lossy learned image compression, which is built upon our\nprevious work, Contextformer. The eContextformer combines the recent\nadvancements in efficient transformers and fast context models with the\nspatio-channel attention mechanism. The proposed model enables content-adaptive\nexploitation of the spatial and channel-wise latent dependencies for a high\nperformance and efficient entropy modeling. By incorporating several\ninnovations, the eContextformer features improved decoding speed, model\ncomplexity and rate-distortion performance over previous work. For instance,\ncompared to Contextformer, the eContextformer requires 145x less model\ncomplexity, 210x less decoding speed and achieves higher average bit savings on\nthe Kodak, CLIC2020 and Tecnick datasets. Compared to the standard Versatile\nVideo Coding (VVC) Test Model (VTM) 16.2, the proposed model provides up to\n17.1% bitrate savings and surpasses various learning-based models.\n","authors":["A. Burakhan Koyuncu","Panqi Jia","Atanas Boev","Elena Alshina","Eckehard Steinbach"],"pdf_url":"https://arxiv.org/pdf/2306.14287v1.pdf","comment":"11 pages, 9 figures, 5 tables"},{"id":"http://arxiv.org/abs/2301.01036v2","updated":"2023-06-25T16:19:23Z","published":"2023-01-03T10:43:22Z","title":"High-Quality Real-Time Rendering Using Subpixel Sampling Reconstruction","summary":"  Generating high-quality, realistic rendering images for real-time\napplications generally requires tracing a few samples-per-pixel (spp) and using\ndeep learning-based approaches to denoise the resulting low-spp images.\nExisting denoising methods have yet to achieve real-time performance at high\nresolutions due to the physically-based sampling and network inference time\ncosts. In this paper, we propose a novel Monte Carlo sampling strategy to\naccelerate the sampling process and a corresponding denoiser, subpixel sampling\nreconstruction (SSR), to obtain high-quality images. Extensive experiments\ndemonstrate that our method significantly outperforms previous approaches in\ndenoising quality and reduces overall time costs, enabling real-time rendering\ncapabilities at 2K resolution.\n","authors":["Boyu Zhang","Hongliang Yuan","Mingyan Zhu","Ligang Liu","Jue Wang"],"pdf_url":"https://arxiv.org/pdf/2301.01036v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.14718v3","updated":"2023-06-25T16:15:03Z","published":"2022-06-29T15:36:02Z","title":"LViT: Language meets Vision Transformer in Medical Image Segmentation","summary":"  Deep learning has been widely used in medical image segmentation and other\naspects. However, the performance of existing medical image segmentation models\nhas been limited by the challenge of obtaining sufficient high-quality labeled\ndata due to the prohibitive data annotation cost. To alleviate this limitation,\nwe propose a new text-augmented medical image segmentation model LViT (Language\nmeets Vision Transformer). In our LViT model, medical text annotation is\nincorporated to compensate for the quality deficiency in image data. In\naddition, the text information can guide to generate pseudo labels of improved\nquality in the semi-supervised learning. We also propose an Exponential Pseudo\nlabel Iteration mechanism (EPI) to help the Pixel-Level Attention Module (PLAM)\npreserve local image features in semi-supervised LViT setting. In our model, LV\n(Language-Vision) loss is designed to supervise the training of unlabeled\nimages using text information directly. For evaluation, we construct three\nmultimodal medical segmentation datasets (image + text) containing X-rays and\nCT images. Experimental results show that our proposed LViT has superior\nsegmentation performance in both fully-supervised and semi-supervised setting.\nThe code and datasets are available at https://github.com/HUANGLIZI/LViT.\n","authors":["Zihan Li","Yunxiang Li","Qingde Li","Puyang Wang","Dazhou Guo","Le Lu","Dakai Jin","You Zhang","Qingqi Hong"],"pdf_url":"https://arxiv.org/pdf/2206.14718v3.pdf","comment":"Accepted by IEEE Transactions on Medical Imaging (TMI)"},{"id":"http://arxiv.org/abs/2306.14274v1","updated":"2023-06-25T15:50:11Z","published":"2023-06-25T15:50:11Z","title":"MEPNet: A Model-Driven Equivariant Proximal Network for Joint\n  Sparse-View Reconstruction and Metal Artifact Reduction in CT Images","summary":"  Sparse-view computed tomography (CT) has been adopted as an important\ntechnique for speeding up data acquisition and decreasing radiation dose.\nHowever, due to the lack of sufficient projection data, the reconstructed CT\nimages often present severe artifacts, which will be further amplified when\npatients carry metallic implants. For this joint sparse-view reconstruction and\nmetal artifact reduction task, most of the existing methods are generally\nconfronted with two main limitations: 1) They are almost built based on common\nnetwork modules without fully embedding the physical imaging geometry\nconstraint of this specific task into the dual-domain learning; 2) Some\nimportant prior knowledge is not deeply explored and sufficiently utilized.\nAgainst these issues, we specifically construct a dual-domain reconstruction\nmodel and propose a model-driven equivariant proximal network, called MEPNet.\nThe main characteristics of MEPNet are: 1) It is optimization-inspired and has\na clear working mechanism; 2) The involved proximal operator is modeled via a\nrotation equivariant convolutional neural network, which finely represents the\ninherent rotational prior underlying the CT scanning that the same organ can be\nimaged at different angles. Extensive experiments conducted on several datasets\ncomprehensively substantiate that compared with the conventional\nconvolution-based proximal network, such a rotation equivariance mechanism\nenables our proposed method to achieve better reconstruction performance with\nfewer network parameters. We will release the code at\n\\url{https://github.com/hongwang01/MEPNet}.\n","authors":["Hong Wang","Minghao Zhou","Dong Wei","Yuexiang Li","Yefeng Zheng"],"pdf_url":"https://arxiv.org/pdf/2306.14274v1.pdf","comment":"MICCAI 2023"},{"id":"http://arxiv.org/abs/2306.14269v1","updated":"2023-06-25T15:26:06Z","published":"2023-06-25T15:26:06Z","title":"Weakly Supervised Scene Text Generation for Low-resource Languages","summary":"  A large number of annotated training images is crucial for training\nsuccessful scene text recognition models. However, collecting sufficient\ndatasets can be a labor-intensive and costly process, particularly for\nlow-resource languages. To address this challenge, auto-generating text data\nhas shown promise in alleviating the problem. Unfortunately, existing scene\ntext generation methods typically rely on a large amount of paired data, which\nis difficult to obtain for low-resource languages. In this paper, we propose a\nnovel weakly supervised scene text generation method that leverages a few\nrecognition-level labels as weak supervision. The proposed method is able to\ngenerate a large amount of scene text images with diverse backgrounds and font\nstyles through cross-language generation. Our method disentangles the content\nand style features of scene text images, with the former representing textual\ninformation and the latter representing characteristics such as font,\nalignment, and background. To preserve the complete content structure of\ngenerated images, we introduce an integrated attention module. Furthermore, to\nbridge the style gap in the style of different languages, we incorporate a\npre-trained font classifier. We evaluate our method using state-of-the-art\nscene text recognition models. Experiments demonstrate that our generated scene\ntext significantly improves the scene text recognition accuracy and help\nachieve higher accuracy when complemented with other generative methods.\n","authors":["Yangchen Xie","Xinyuan Chen","Hongjian Zhan","Palaiahankote Shivakum"],"pdf_url":"https://arxiv.org/pdf/2306.14269v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14268v1","updated":"2023-06-25T15:24:00Z","published":"2023-06-25T15:24:00Z","title":"Adaptive Window Pruning for Efficient Local Motion Deblurring","summary":"  Local motion blur commonly occurs in real-world photography due to the mixing\nbetween moving objects and stationary backgrounds during exposure. Existing\nimage deblurring methods predominantly focus on global deblurring,\ninadvertently affecting the sharpness of backgrounds in locally blurred images\nand wasting unnecessary computation on sharp pixels, especially for\nhigh-resolution images. This paper aims to adaptively and efficiently restore\nhigh-resolution locally blurred images. We propose a local motion deblurring\nvision Transformer (LMD-ViT) built on adaptive window pruning Transformer\nblocks (AdaWPT). To focus deblurring on local regions and reduce computation,\nAdaWPT prunes unnecessary windows, only allowing the active windows to be\ninvolved in the deblurring processes. The pruning operation relies on the\nblurriness confidence predicted by a confidence predictor that is trained\nend-to-end using a reconstruction loss with Gumbel-Softmax re-parameterization\nand a pruning loss guided by annotated blur masks. Our method removes local\nmotion blur effectively without distorting sharp regions, demonstrated by its\nexceptional perceptual and quantitative improvements (+0.24dB) compared to\nstate-of-the-art methods. In addition, our approach substantially reduces FLOPs\nby 66% and achieves more than a twofold increase in inference speed compared to\nTransformer-based deblurring methods. We will make our code and annotated blur\nmasks publicly available.\n","authors":["Haoying Li","Jixin Zhao","Shangchen Zhou","Huajun Feng","Chongyi Li","Chen Change Loy"],"pdf_url":"https://arxiv.org/pdf/2306.14268v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2301.13569v2","updated":"2023-06-25T15:09:48Z","published":"2023-01-31T11:44:45Z","title":"NP-Match: Towards a New Probabilistic Model for Semi-Supervised Learning","summary":"  Semi-supervised learning (SSL) has been widely explored in recent years, and\nit is an effective way of leveraging unlabeled data to reduce the reliance on\nlabeled data. In this work, we adjust neural processes (NPs) to the\nsemi-supervised image classification task, resulting in a new method named\nNP-Match. NP-Match is suited to this task for two reasons. Firstly, NP-Match\nimplicitly compares data points when making predictions, and as a result, the\nprediction of each unlabeled data point is affected by the labeled data points\nthat are similar to it, which improves the quality of pseudo-labels. Secondly,\nNP-Match is able to estimate uncertainty that can be used as a tool for\nselecting unlabeled samples with reliable pseudo-labels. Compared with\nuncertainty-based SSL methods implemented with Monte-Carlo (MC) dropout,\nNP-Match estimates uncertainty with much less computational overhead, which can\nsave time at both the training and the testing phases. We conducted extensive\nexperiments on five public datasets under three semi-supervised image\nclassification settings, namely, the standard semi-supervised image\nclassification, the imbalanced semi-supervised image classification, and the\nmulti-label semi-supervised image classification, and NP-Match outperforms\nstate-of-the-art (SOTA) approaches or achieves competitive results on them,\nwhich shows the effectiveness of NP-Match and its potential for SSL. The codes\nare at https://github.com/Jianf-Wang/NP-Match\n","authors":["Jianfeng Wang","Xiaolin Hu","Thomas Lukasiewicz"],"pdf_url":"https://arxiv.org/pdf/2301.13569v2.pdf","comment":"An extended version of our previous ICML 2022 paper arXiv:2207.01066\n  with more experiments"},{"id":"http://arxiv.org/abs/2306.14264v1","updated":"2023-06-25T15:09:21Z","published":"2023-06-25T15:09:21Z","title":"Visual Question Answering in Remote Sensing with Cross-Attention and\n  Multimodal Information Bottleneck","summary":"  In this research, we deal with the problem of visual question answering (VQA)\nin remote sensing. While remotely sensed images contain information significant\nfor the task of identification and object detection, they pose a great\nchallenge in their processing because of high dimensionality, volume and\nredundancy. Furthermore, processing image information jointly with language\nfeatures adds additional constraints, such as mapping the corresponding image\nand language features. To handle this problem, we propose a cross attention\nbased approach combined with information maximization. The CNN-LSTM based\ncross-attention highlights the information in the image and language modalities\nand establishes a connection between the two, while information maximization\nlearns a low dimensional bottleneck layer, that has all the relevant\ninformation required to carry out the VQA task. We evaluate our method on two\nVQA remote sensing datasets of different resolutions. For the high resolution\ndataset, we achieve an overall accuracy of 79.11% and 73.87% for the two test\nsets while for the low resolution dataset, we achieve an overall accuracy of\n85.98%.\n","authors":["Jayesh Songara","Shivam Pande","Shabnam Choudhury","Biplab Banerjee","Rajbabu Velmurugan"],"pdf_url":"https://arxiv.org/pdf/2306.14264v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14262v1","updated":"2023-06-25T14:47:03Z","published":"2023-06-25T14:47:03Z","title":"A Spectral Perspective towards Understanding and Improving Adversarial\n  Robustness","summary":"  Deep neural networks (DNNs) are incredibly vulnerable to crafted,\nimperceptible adversarial perturbations. While adversarial training (AT) has\nproven to be an effective defense approach, the AT mechanism for robustness\nimprovement is not fully understood. This work investigates AT from a spectral\nperspective, adding new insights to the design of effective defenses. In\nparticular, we show that AT induces the deep model to focus more on the\nlow-frequency region, which retains the shape-biased representations, to gain\nrobustness. Further, we find that the spectrum of a white-box attack is\nprimarily distributed in regions the model focuses on, and the perturbation\nattacks the spectral bands where the model is vulnerable. Based on this\nobservation, to train a model tolerant to frequency-varying perturbation, we\npropose a spectral alignment regularization (SAR) such that the spectral output\ninferred by an attacked adversarial input stays as close as possible to its\nnatural input counterpart. Experiments demonstrate that SAR and its weight\naveraging (WA) extension could significantly improve the robust accuracy by\n1.14% ~ 3.87% relative to the standard AT, across multiple datasets (CIFAR-10,\nCIFAR-100 and Tiny ImageNet), and various attacks (PGD, C&W and Autoattack),\nwithout any extra data.\n","authors":["Binxiao Huang","Rui Lin","Chaofan Tao","Ngai Wong"],"pdf_url":"https://arxiv.org/pdf/2306.14262v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14260v1","updated":"2023-06-25T14:40:26Z","published":"2023-06-25T14:40:26Z","title":"HOKEM: Human and Object Keypoint-based Extension Module for Human-Object\n  Interaction Detection","summary":"  Human-object interaction (HOI) detection for capturing relationships between\nhumans and objects is an important task in the semantic understanding of\nimages. When processing human and object keypoints extracted from an image\nusing a graph convolutional network (GCN) to detect HOI, it is crucial to\nextract appropriate object keypoints regardless of the object type and to\ndesign a GCN that accurately captures the spatial relationships between\nkeypoints. This paper presents the human and object keypoint-based extension\nmodule (HOKEM) as an easy-to-use extension module to improve the accuracy of\nthe conventional detection models. The proposed object keypoint extraction\nmethod is simple yet accurately represents the shapes of various objects.\nMoreover, the proposed human-object adaptive GCN (HO-AGCN), which introduces\nadaptive graph optimization and attention mechanism, accurately captures the\nspatial relationships between keypoints. Experiments using the HOI dataset,\nV-COCO, showed that HOKEM boosted the accuracy of an appearance-based model by\na large margin.\n","authors":["Yoshiki Ito"],"pdf_url":"https://arxiv.org/pdf/2306.14260v1.pdf","comment":"Accepted to IEEE ICIP 2023"},{"id":"http://arxiv.org/abs/2306.14259v1","updated":"2023-06-25T14:37:13Z","published":"2023-06-25T14:37:13Z","title":"Improving Reference-based Distinctive Image Captioning with Contrastive\n  Rewards","summary":"  Distinctive Image Captioning (DIC) -- generating distinctive captions that\ndescribe the unique details of a target image -- has received considerable\nattention over the last few years. A recent DIC method proposes to generate\ndistinctive captions by comparing the target image with a set of\nsemantic-similar reference images, i.e., reference-based DIC (Ref-DIC). It aims\nto force the generated captions to distinguish between the target image and the\nreference image. To ensure Ref-DIC models really perceive the unique objects\n(or attributes) in target images, we propose two new Ref-DIC benchmarks and\ndevelop a Transformer-based Ref-DIC baseline TransDIC. The model only extracts\nvisual features from the target image, but also encodes the differences between\nobjects in the target and reference images. Taking one step further, we propose\na stronger TransDIC++, which consists of an extra contrastive learning module\nto make full use of the reference images. This new module is model-agnostic,\nwhich can be easily incorporated into various Ref-DIC architectures. Finally,\nfor more trustworthy benchmarking, we propose a new evaluation metric named\nDisCIDEr for Ref-DIC, which evaluates both the accuracy and distinctiveness of\nthe generated captions. Experimental results demonstrate that our TransDIC++\ncan generate distinctive captions. Besides, it outperforms several\nstate-of-the-art models on the two new benchmarks over different metrics.\n","authors":["Yangjun Mao","Jun Xiao","Dong Zhang","Meng Cao","Jian Shao","Yueting Zhuang","Long Chen"],"pdf_url":"https://arxiv.org/pdf/2306.14259v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2207.11118"},{"id":"http://arxiv.org/abs/2306.14255v1","updated":"2023-06-25T14:28:08Z","published":"2023-06-25T14:28:08Z","title":"AttResDU-Net: Medical Image Segmentation Using Attention-based Residual\n  Double U-Net","summary":"  Manually inspecting polyps from a colonoscopy for colorectal cancer or\nperforming a biopsy on skin lesions for skin cancer are time-consuming,\nlaborious, and complex procedures. Automatic medical image segmentation aims to\nexpedite this diagnosis process. However, numerous challenges exist due to\nsignificant variations in the appearance and sizes of objects with no distinct\nboundaries. This paper proposes an attention-based residual Double U-Net\narchitecture (AttResDU-Net) that improves on the existing medical image\nsegmentation networks. Inspired by the Double U-Net, this architecture\nincorporates attention gates on the skip connections and residual connections\nin the convolutional blocks. The attention gates allow the model to retain more\nrelevant spatial information by suppressing irrelevant feature representation\nfrom the down-sampling path for which the model learns to focus on target\nregions of varying shapes and sizes. Moreover, the residual connections help to\ntrain deeper models by ensuring better gradient flow. We conducted experiments\non three datasets: CVC Clinic-DB, ISIC 2018, and the 2018 Data Science Bowl\ndatasets and achieved Dice Coefficient scores of 94.35%, 91.68% and 92.45%\nrespectively. Our results suggest that AttResDU-Net can be facilitated as a\nreliable method for automatic medical image segmentation in practice.\n","authors":["Akib Mohammed Khan","Alif Ashrafee","Fahim Shahriar Khan","Md. Bakhtiar Hasan","Md. Hasanul Kabir"],"pdf_url":"https://arxiv.org/pdf/2306.14255v1.pdf","comment":"Accepted in 2023 International Joint Conference on Neural Networks\n  (IJCNN 2023)"},{"id":"http://arxiv.org/abs/2210.10969v3","updated":"2023-06-25T14:27:22Z","published":"2022-10-20T02:35:26Z","title":"SSiT: Saliency-guided Self-supervised Image Transformer for Diabetic\n  Retinopathy Grading","summary":"  Self-supervised learning (SSL) has been widely applied to learn image\nrepresentations through exploiting unlabeled images. However, it has not been\nfully explored in the medical image analysis field. In this work, we propose\nSaliency-guided Self-Supervised image Transformer (SSiT) for diabetic\nretinopathy (DR) grading from fundus images. We novelly introduce saliency maps\ninto SSL, with a goal of guiding self-supervised pre-training with\ndomain-specific prior knowledge. Specifically, two saliency-guided learning\ntasks are employed in SSiT: (1) We conduct saliency-guided contrastive learning\nbased on the momentum contrast, wherein we utilize fundus images' saliency maps\nto remove trivial patches from the input sequences of the momentum-updated key\nencoder. And thus, the key encoder is constrained to provide target\nrepresentations focusing on salient regions, guiding the query encoder to\ncapture salient features. (2) We train the query encoder to predict the\nsaliency segmentation, encouraging preservation of fine-grained information in\nthe learned representations. Extensive experiments are conducted on four\npublicly-accessible fundus image datasets. The proposed SSiT significantly\noutperforms other representative state-of-the-art SSL methods on all datasets\nand under various evaluation settings, establishing the effectiveness of the\nlearned representations from SSiT. The source code is available at\nhttps://github.com/YijinHuang/SSiT.\n","authors":["Yijin Huang","Junyan Lyu","Pujin Cheng","Roger Tam","Xiaoying Tang"],"pdf_url":"https://arxiv.org/pdf/2210.10969v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2011.08145v2","updated":"2023-06-25T14:19:38Z","published":"2020-11-16T18:13:41Z","title":"Combining Self-Supervised and Supervised Learning with Noisy Labels","summary":"  Since convolutional neural networks (CNNs) can easily overfit noisy labels,\nwhich are ubiquitous in visual classification tasks, it has been a great\nchallenge to train CNNs against them robustly. Various methods have been\nproposed for this challenge. However, none of them pay attention to the\ndifference between representation and classifier learning of CNNs. Thus,\ninspired by the observation that classifier is more robust to noisy labels\nwhile representation is much more fragile, and by the recent advances of\nself-supervised representation learning (SSRL) technologies, we design a new\nmethod, i.e., CS$^3$NL, to obtain representation by SSRL without labels and\ntrain the classifier directly with noisy labels. Extensive experiments are\nperformed on both synthetic and real benchmark datasets. Results demonstrate\nthat the proposed method can beat the state-of-the-art ones by a large margin,\nespecially under a high noisy level.\n","authors":["Yongqi Zhang","Hui Zhang","Quanming Yao","Jun Wan"],"pdf_url":"https://arxiv.org/pdf/2011.08145v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.08992v5","updated":"2023-06-25T14:04:29Z","published":"2021-06-16T17:46:51Z","title":"On the approximation capability of GNNs in node\n  classification/regression tasks","summary":"  Graph Neural Networks (GNNs) are a broad class of connectionist models for\ngraph processing. Recent studies have shown that GNNs can approximate any\nfunction on graphs, modulo the equivalence relation on graphs defined by the\nWeisfeiler--Lehman (WL) test. However, these results suffer from some\nlimitations, both because they were derived using the Stone--Weierstrass\ntheorem -- which is existential in nature, -- and because they assume that the\ntarget function to be approximated must be continuous. Furthermore, all current\nresults are dedicated to graph classification/regression tasks, where the GNN\nmust produce a single output for the whole graph, while also node\nclassification/regression problems, in which an output is returned for each\nnode, are very common. In this paper, we propose an alternative way to\ndemonstrate the approximation capability of GNNs that overcomes these\nlimitations. Indeed, we show that GNNs are universal approximators in\nprobability for node classification/regression tasks, as they can approximate\nany measurable function that satisfies the 1--WL equivalence on nodes. The\nproposed theoretical framework allows the approximation of generic\ndiscontinuous target functions and also suggests the GNN architecture that can\nreach a desired approximation. In addition, we provide a bound on the number of\nthe GNN layers required to achieve the desired degree of approximation, namely\n$2r-1$, where $r$ is the maximum number of nodes for the graphs in the domain.\n","authors":["Giuseppe Alessio D'Inverno","Monica Bianchini","Maria Lucia Sampoli","Franco Scarselli"],"pdf_url":"https://arxiv.org/pdf/2106.08992v5.pdf","comment":"22 pages, 5 figures"},{"id":"http://arxiv.org/abs/2306.14250v1","updated":"2023-06-25T13:50:50Z","published":"2023-06-25T13:50:50Z","title":"Introducing A Novel Method For Adaptive Thresholding In Brain Tumor\n  Medical Image Segmentation","summary":"  One of the most significant challenges in the field of deep learning and\nmedical image segmentation is to determine an appropriate threshold for\nclassifying each pixel. This threshold is a value above which the model's\noutput is considered to belong to a specific class. Manual thresholding based\non personal experience is error-prone and time-consuming, particularly for\ncomplex problems such as medical images. Traditional methods for thresholding\nare not effective for determining the threshold value for such problems.\n  To tackle this challenge, automatic thresholding methods using deep learning\nhave been proposed. However, the main issue with these methods is that they\noften determine the threshold value statically without considering changes in\ninput data. Since input data can be dynamic and may change over time, threshold\ndetermination should be adaptive and consider input data and environmental\nconditions.\n","authors":["Ali Fayzi"],"pdf_url":"https://arxiv.org/pdf/2306.14250v1.pdf","comment":"5 pages , 4 figures , 3 formula"},{"id":"http://arxiv.org/abs/2305.02279v2","updated":"2023-06-25T13:38:36Z","published":"2023-05-03T17:15:58Z","title":"Learngene: Inheriting Condensed Knowledge from the Ancestry Model to\n  Descendant Models","summary":"  During the continuous evolution of one organism's ancestry, its genes\naccumulate extensive experiences and knowledge, enabling newborn descendants to\nrapidly adapt to their specific environments. Motivated by this observation, we\npropose a novel machine learning paradigm Learngene to enable learning models\nto incorporate three key characteristics of genes. (i) Accumulating: the\nknowledge is accumulated during the continuous learning of an ancestry model.\n(ii) Condensing: the extensive accumulated knowledge is condensed into a much\nmore compact information piece, i.e., learngene. (iii) Inheriting: the\ncondensed learngene is inherited to make it easier for descendant models to\nadapt to new environments. Since accumulating has been studied in\nwell-established paradigms like large-scale pre-training and lifelong learning,\nwe focus on condensing and inheriting, which induces three key issues and we\nprovide the preliminary solutions to these issues in this paper: (i) Learngene\nForm: the learngene is set to a few integral layers that can preserve\nsignificance. (ii) Learngene Condensing: we identify which layers among the\nancestry model have the most similarity as one pseudo descendant model. (iii)\nLearngene Inheriting: to construct distinct descendant models for the specific\ndownstream tasks, we stack some randomly initialized layers to the learngene\nlayers. Extensive experiments across various settings, including using\ndifferent network architectures like Vision Transformer (ViT) and Convolutional\nNeural Networks (CNNs) on different datasets, are carried out to confirm four\nadvantages of Learngene: it makes the descendant models 1) converge more\nquickly, 2) exhibit less sensitivity to hyperparameters, 3) perform better, and\n4) require fewer training samples to converge.\n","authors":["Qiufeng Wang","Xu Yang","Shuxia Lin","Jing Wang","Xin Geng"],"pdf_url":"https://arxiv.org/pdf/2305.02279v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.10402v2","updated":"2023-06-25T13:26:20Z","published":"2022-07-21T10:42:34Z","title":"Detecting Deepfake by Creating Spatio-Temporal Regularity Disruption","summary":"  Despite encouraging progress in deepfake detection, generalization to unseen\nforgery types remains a significant challenge due to the limited forgery clues\nexplored during training. In contrast, we notice a common phenomenon in\ndeepfake: fake video creation inevitably disrupts the statistical regularity in\noriginal videos. Inspired by this observation, we propose to boost the\ngeneralization of deepfake detection by distinguishing the \"regularity\ndisruption\" that does not appear in real videos. Specifically, by carefully\nexamining the spatial and temporal properties, we propose to disrupt a real\nvideo through a Pseudo-fake Generator and create a wide range of pseudo-fake\nvideos for training. Such practice allows us to achieve deepfake detection\nwithout using fake videos and improves the generalization ability in a simple\nand efficient manner. To jointly capture the spatial and temporal disruptions,\nwe propose a Spatio-Temporal Enhancement block to learn the regularity\ndisruption across space and time on our self-created videos. Through\ncomprehensive experiments, our method exhibits excellent performance on several\ndatasets.\n","authors":["Jiazhi Guan","Hang Zhou","Mingming Gong","Errui Ding","Jingdong Wang","Youjian Zhao"],"pdf_url":"https://arxiv.org/pdf/2207.10402v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14227v1","updated":"2023-06-25T12:15:44Z","published":"2023-06-25T12:15:44Z","title":"Diffusion Model Based Low-Light Image Enhancement for Space Satellite","summary":"  Space-based visible camera is an important sensor for space situation\nawareness during proximity operations. However, visible camera can be easily\naffected by the low illumination in the space environment. Recently, deep\nlearning approaches have achieved remarkable success in image enhancement of\nnatural images datasets, but seldom applied in space due to the data\nbottleneck. In this article, we propose a data-driven method for low-light\nimage enhancement (LLIE) of spin targets in space environment based on\ndiffusion model. Firstly, a dataset collection scheme is devised. To reduce the\ndomain gap and improve the diversity and quality of the dataset, we collect the\ndata with the camera on a ground-test system imitating the low lighting\nconditions and relative attitude change of satellite in space. The satellite\nmotion is controlled by a 6-DoF robot. To generate different poses, a advanced\nsampling method is combined with collision detection in physical simulation.\nThe entire process is automated. Based on our dataset, a novel diffusion model\nis proposed. The diffusion and denoising process are directly conducted on the\ngrayscale channel to save computational resources. To take advantage of the\ninner information of RGB channels, we rescale the RGB feature maps and insert\nthem into the downsampling layers to help feature extraction. The enhanced\nresults with our method have been verified to be better in image light\nenhancement and competitive in image quality compared with previous methods. To\nthe best of our knowledge, this is the first work of LLIE using diffusion\nmodel.\n","authors":["Yiman Zhu","Lu Wang","Jingyi Yuan","Yu Guo"],"pdf_url":"https://arxiv.org/pdf/2306.14227v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14221v1","updated":"2023-06-25T12:05:46Z","published":"2023-06-25T12:05:46Z","title":"Feature Adversarial Distillation for Point Cloud Classification","summary":"  Due to the point cloud's irregular and unordered geometry structure,\nconventional knowledge distillation technology lost a lot of information when\ndirectly used on point cloud tasks. In this paper, we propose Feature\nAdversarial Distillation (FAD) method, a generic adversarial loss function in\npoint cloud distillation, to reduce loss during knowledge transfer.In the\nfeature extraction stage, the features extracted by the teacher are used as the\ndiscriminator, and the students continuously generate new features in the\ntraining stage. The feature of the student is obtained by attacking the\nfeedback from the teacher and getting a score to judge whether the student has\nlearned the knowledge well or not. In experiments on standard point cloud\nclassification on ModelNet40 and ScanObjectNN datasets, our method reduced the\ninformation loss of knowledge transfer in distillation in 40x model compression\nwhile maintaining competitive performance.\n","authors":["YuXing Lee","Wei Wu"],"pdf_url":"https://arxiv.org/pdf/2306.14221v1.pdf","comment":"Accepted to ICIP2023"},{"id":"http://arxiv.org/abs/2306.14217v1","updated":"2023-06-25T11:45:08Z","published":"2023-06-25T11:45:08Z","title":"On Evaluating the Adversarial Robustness of Semantic Segmentation Models","summary":"  Achieving robustness against adversarial input perturbation is an important\nand intriguing problem in machine learning. In the area of semantic image\nsegmentation, a number of adversarial training approaches have been proposed as\na defense against adversarial perturbation, but the methodology of evaluating\nthe robustness of the models is still lacking, compared to image\nclassification. Here, we demonstrate that, just like in image classification,\nit is important to evaluate the models over several different and hard attacks.\nWe propose a set of gradient based iterative attacks and show that it is\nessential to perform a large number of iterations. We include attacks against\nthe internal representations of the models as well. We apply two types of\nattacks: maximizing the error with a bounded perturbation, and minimizing the\nperturbation for a given level of error. Using this set of attacks, we show for\nthe first time that a number of models in previous work that are claimed to be\nrobust are in fact not robust at all. We then evaluate simple adversarial\ntraining algorithms that produce reasonably robust models even under our set of\nstrong attacks. Our results indicate that a key design decision to achieve any\nrobustness is to use only adversarial examples during training. However, this\nintroduces a trade-off between robustness and accuracy.\n","authors":["Levente Halmosi","Mark Jelasity"],"pdf_url":"https://arxiv.org/pdf/2306.14217v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14209v1","updated":"2023-06-25T11:19:47Z","published":"2023-06-25T11:19:47Z","title":"Deep image prior inpainting of ancient frescoes in the Mediterranean\n  Alpine arc","summary":"  The unprecedented success of image reconstruction approaches based on deep\nneural networks has revolutionised both the processing and the analysis\nparadigms in several applied disciplines. In the field of digital humanities,\nthe task of digital reconstruction of ancient frescoes is particularly\nchallenging due to the scarce amount of available training data caused by\nageing, wear, tear and retouching over time. To overcome these difficulties, we\nconsider the Deep Image Prior (DIP) inpainting approach which computes\nappropriate reconstructions by relying on the progressive updating of an\nuntrained convolutional neural network so as to match the reliable piece of\ninformation in the image at hand while promoting regularisation elsewhere. In\ncomparison with state-of-the-art approaches (based on variational/PDEs and\npatch-based methods), DIP-based inpainting reduces artefacts and better adapts\nto contextual/non-local information, thus providing a valuable and effective\ntool for art historians. As a case study, we apply such approach to reconstruct\nmissing image contents in a dataset of highly damaged digital images of\nmedieval paintings located into several chapels in the Mediterranean Alpine Arc\nand provide a detailed description on how visible and invisible (e.g.,\ninfrared) information can be integrated for identifying and reconstructing\ndamaged image regions.\n","authors":["Fabio Merizzi","Perrine Saillard","Oceane Acquier","Elena Morotti","Elena Loli Piccolomini","Luca Calatroni","Rosa Maria Dessì"],"pdf_url":"https://arxiv.org/pdf/2306.14209v1.pdf","comment":"20 pages, 12 figures"},{"id":"http://arxiv.org/abs/2306.10484v2","updated":"2023-06-25T09:56:03Z","published":"2023-06-18T05:48:28Z","title":"The STOIC2021 COVID-19 AI challenge: applying reusable training\n  methodologies to private data","summary":"  Challenges drive the state-of-the-art of automated medical image analysis.\nThe quantity of public training data that they provide can limit the\nperformance of their solutions. Public access to the training methodology for\nthese solutions remains absent. This study implements the Type Three (T3)\nchallenge format, which allows for training solutions on private data and\nguarantees reusable training methodologies. With T3, challenge organizers train\na codebase provided by the participants on sequestered training data. T3 was\nimplemented in the STOIC2021 challenge, with the goal of predicting from a\ncomputed tomography (CT) scan whether subjects had a severe COVID-19 infection,\ndefined as intubation or death within one month. STOIC2021 consisted of a\nQualification phase, where participants developed challenge solutions using\n2000 publicly available CT scans, and a Final phase, where participants\nsubmitted their training methodologies with which solutions were trained on CT\nscans of 9724 subjects. The organizers successfully trained six of the eight\nFinal phase submissions. The submitted codebases for training and running\ninference were released publicly. The winning solution obtained an area under\nthe receiver operating characteristic curve for discerning between severe and\nnon-severe COVID-19 of 0.815. The Final phase solutions of all finalists\nimproved upon their Qualification phase solutions.HSUXJM-TNZF9CHSUXJM-TNZF9C\n","authors":["Luuk H. Boulogne","Julian Lorenz","Daniel Kienzle","Robin Schon","Katja Ludwig","Rainer Lienhart","Simon Jegou","Guang Li","Cong Chen","Qi Wang","Derik Shi","Mayug Maniparambil","Dominik Muller","Silvan Mertes","Niklas Schroter","Fabio Hellmann","Miriam Elia","Ine Dirks","Matias Nicolas Bossa","Abel Diaz Berenguer","Tanmoy Mukherjee","Jef Vandemeulebroucke","Hichem Sahli","Nikos Deligiannis","Panagiotis Gonidakis","Ngoc Dung Huynh","Imran Razzak","Reda Bouadjenek","Mario Verdicchio","Pasquale Borrelli","Marco Aiello","James A. Meakin","Alexander Lemm","Christoph Russ","Razvan Ionasec","Nikos Paragios","Bram van Ginneken","Marie-Pierre Revel Dubois"],"pdf_url":"https://arxiv.org/pdf/2306.10484v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.07392v2","updated":"2023-06-25T09:40:57Z","published":"2023-06-12T19:42:26Z","title":"Learning Any-View 6DoF Robotic Grasping in Cluttered Scenes via Neural\n  Surface Rendering","summary":"  Robotic manipulation is critical for admitting robotic agents to various\napplication domains, like intelligent assistance. A major challenge therein is\nthe effective 6DoF grasping of objects in cluttered environments from any\nviewpoint without requiring additional scene exploration. We introduce\n$\\textit{NeuGraspNet}$, a novel method for 6DoF grasp detection that leverages\nrecent advances in neural volumetric representations and surface rendering. Our\napproach learns both global (scene-level) and local (grasp-level) neural\nsurface representations, enabling effective and fully implicit 6DoF grasp\nquality prediction, even in unseen parts of the scene. Further, we reinterpret\ngrasping as a local neural surface rendering problem, allowing the model to\nencode the interaction between the robot's end-effector and the object's\nsurface geometry. NeuGraspNet operates on single viewpoints and can sample\ngrasp candidates in occluded scenes, outperforming existing implicit and\nsemi-implicit baseline methods in the literature. We demonstrate the real-world\napplicability of NeuGraspNet with a mobile manipulator robot, grasping in open\nspaces with clutter by rendering the scene, reasoning about graspable areas of\ndifferent objects, and selecting grasps likely to succeed without colliding\nwith the environment. Visit our project website:\nhttps://sites.google.com/view/neugraspnet\n","authors":["Snehal Jauhri","Ishikaa Lunawat","Georgia Chalvatzaki"],"pdf_url":"https://arxiv.org/pdf/2306.07392v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2306.14182v1","updated":"2023-06-25T09:28:40Z","published":"2023-06-25T09:28:40Z","title":"Switch-BERT: Learning to Model Multimodal Interactions by Switching\n  Attention and Input","summary":"  The ability to model intra-modal and inter-modal interactions is fundamental\nin multimodal machine learning. The current state-of-the-art models usually\nadopt deep learning models with fixed structures. They can achieve exceptional\nperformances on specific tasks, but face a particularly challenging problem of\nmodality mismatch because of diversity of input modalities and their fixed\nstructures. In this paper, we present \\textbf{Switch-BERT} for joint vision and\nlanguage representation learning to address this problem. Switch-BERT extends\nBERT architecture by introducing learnable layer-wise and cross-layer\ninteractions. It learns to optimize attention from a set of attention modes\nrepresenting these interactions. One specific property of the model is that it\nlearns to attend outputs from various depths, therefore mitigates the modality\nmismatch problem. We present extensive experiments on visual question\nanswering, image-text retrieval and referring expression comprehension\nexperiments. Results confirm that, whereas alternative architectures including\nViLBERT and UNITER may excel in particular tasks, Switch-BERT can consistently\nachieve better or comparable performances than the current state-of-the-art\nmodels in these tasks. Ablation studies indicate that the proposed model\nachieves superior performances due to its ability in learning task-specific\nmultimodal interactions.\n","authors":["Qingpei Guo","Kaisheng Yao","Wei Chu"],"pdf_url":"https://arxiv.org/pdf/2306.14182v1.pdf","comment":"Accepted by ECCV2022"},{"id":"http://arxiv.org/abs/2306.14177v1","updated":"2023-06-25T09:05:48Z","published":"2023-06-25T09:05:48Z","title":"Enhancing Mapless Trajectory Prediction through Knowledge Distillation","summary":"  Scene information plays a crucial role in trajectory forecasting systems for\nautonomous driving by providing semantic clues and constraints on potential\nfuture paths of traffic agents. Prevalent trajectory prediction techniques\noften take high-definition maps (HD maps) as part of the inputs to provide\nscene knowledge. Although HD maps offer accurate road information, they may\nsuffer from the high cost of annotation or restrictions of law that limits\ntheir widespread use. Therefore, those methods are still expected to generate\nreliable prediction results in mapless scenarios. In this paper, we tackle the\nproblem of improving the consistency of multi-modal prediction trajectories and\nthe real road topology when map information is unavailable during the test\nphase. Specifically, we achieve this by training a map-based prediction teacher\nnetwork on the annotated samples and transferring the knowledge to a student\nmapless prediction network using a two-fold knowledge distillation framework.\nOur solution is generalizable for common trajectory prediction networks and\ndoes not bring extra computation burden. Experimental results show that our\nmethod stably improves prediction performance in mapless mode on many widely\nused state-of-the-art trajectory prediction baselines, compensating for the\ngaps caused by the absence of HD maps. Qualitative visualization results\ndemonstrate that our approach helps infer unseen map information.\n","authors":["Yuning Wang","Pu Zhang","Lei Bai","Jianru Xue"],"pdf_url":"https://arxiv.org/pdf/2306.14177v1.pdf","comment":"submitted to NeurIPS 2023"},{"id":"http://arxiv.org/abs/2306.14169v1","updated":"2023-06-25T08:23:44Z","published":"2023-06-25T08:23:44Z","title":"A Web-based Mpox Skin Lesion Detection System Using State-of-the-art\n  Deep Learning Models Considering Racial Diversity","summary":"  The recent 'Mpox' outbreak, formerly known as 'Monkeypox', has become a\nsignificant public health concern and has spread to over 110 countries\nglobally. The challenge of clinically diagnosing mpox early on is due, in part,\nto its similarity to other types of rashes. Computer-aided screening tools have\nbeen proven valuable in cases where Polymerase Chain Reaction (PCR) based\ndiagnosis is not immediately available. Deep learning methods are powerful in\nlearning complex data representations, but their efficacy largely depends on\nadequate training data. To address this challenge, we present the \"Mpox Skin\nLesion Dataset Version 2.0 (MSLD v2.0)\" as a follow-up to the previously\nreleased openly accessible dataset, one of the first datasets containing mpox\nlesion images. This dataset contains images of patients with mpox and five\nother non-mpox classes (chickenpox, measles, hand-foot-mouth disease, cowpox,\nand healthy). We benchmark the performance of several state-of-the-art deep\nlearning models, including VGG16, ResNet50, DenseNet121, MobileNetV2,\nEfficientNetB3, InceptionV3, and Xception, to classify mpox and other\ninfectious skin diseases. In order to reduce the impact of racial bias, we\nutilize a color space data augmentation method to increase skin color\nvariability during training. Additionally, by leveraging transfer learning\nimplemented with pre-trained weights generated from the HAM10000 dataset, an\nextensive collection of pigmented skin lesion images, we achieved the best\noverall accuracy of $83.59\\pm2.11\\%$. Finally, the developed models are\nincorporated within a prototype web application to analyze uploaded skin images\nby a user and determine whether a subject is a suspected mpox patient.\n","authors":["Shams Nafisa Ali","Md. Tazuddin Ahmed","Tasnim Jahan","Joydip Paul","S. M. Sakeef Sani","Nawsabah Noor","Anzirun Nahar Asma","Taufiq Hasan"],"pdf_url":"https://arxiv.org/pdf/2306.14169v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14161v1","updated":"2023-06-25T08:11:43Z","published":"2023-06-25T08:11:43Z","title":"BiFF: Bi-level Future Fusion with Polyline-based Coordinate for\n  Interactive Trajectory Prediction","summary":"  Predicting future trajectories of surrounding agents is essential for\nsafety-critical autonomous driving. Most existing work focuses on predicting\nmarginal trajectories for each agent independently. However, it has rarely been\nexplored in predicting joint trajectories for interactive agents. In this work,\nwe propose Bi-level Future Fusion (BiFF) to explicitly capture future\ninteractions between interactive agents. Concretely, BiFF fuses the high-level\nfuture intentions followed by low-level future behaviors. Then the\npolyline-based coordinate is specifically designed for multi-agent prediction\nto ensure data efficiency, frame robustness, and prediction accuracy.\nExperiments show that BiFF achieves state-of-the-art performance on the\ninteractive prediction benchmark of Waymo Open Motion Dataset.\n","authors":["Yiyao Zhu","Di Luan","Shaojie Shen"],"pdf_url":"https://arxiv.org/pdf/2306.14161v1.pdf","comment":"16 pages, 10 figures"},{"id":"http://arxiv.org/abs/2209.09808v2","updated":"2023-06-25T07:42:50Z","published":"2022-09-20T15:56:52Z","title":"Thermal infrared image based vehicle detection in low-level illumination\n  conditions using multi-level GANs","summary":"  Vehicle detection accuracy is fairly accurate in good-illumination conditions\nbut susceptible to poor detection accuracy under low-light conditions. The\ncombined effect of low-light and glare from vehicle headlight or tail-light\nresults in misses in vehicle detection more likely by state-of-the-art object\ndetection models. However, thermal infrared images are robust to illumination\nchanges and are based on thermal radiation. Recently, Generative Adversarial\nNetworks (GANs) have been extensively used in image domain transfer tasks.\nState-of-the-art GAN models have attempted to improve vehicle detection\naccuracy in night-time by converting infrared images to day-time RGB images.\nHowever, these models have been found to under-perform during night-time\nconditions compared to day-time conditions, as day-time infrared images looks\ndifferent than night-time infrared images. Therefore, this study attempts to\nalleviate this shortcoming by proposing three different approaches based on\ncombination of GAN models at two different levels that try to reduce the\nfeature distribution gap between day-time and night-time infrared images.\nQuantitative analysis to compare the performance of the proposed models with\nthe state-of-the-art models has been done by testing the models using\nstate-of-the-art object detection models. Both the quantitative and qualitative\nanalyses have shown that the proposed models outperform the state-of-the-art\nGAN models for vehicle detection in night-time conditions, showing the efficacy\nof the proposed models.\n","authors":["Shivom Bhargava","Sanjita Prajapati","Pranamesh Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2209.09808v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14153v1","updated":"2023-06-25T07:40:39Z","published":"2023-06-25T07:40:39Z","title":"DomainStudio: Fine-Tuning Diffusion Models for Domain-Driven Image\n  Generation using Limited Data","summary":"  Denoising diffusion probabilistic models (DDPMs) have been proven capable of\nsynthesizing high-quality images with remarkable diversity when trained on\nlarge amounts of data. Typical diffusion models and modern large-scale\nconditional generative models like text-to-image generative models are\nvulnerable to overfitting when fine-tuned on extremely limited data. Existing\nworks have explored subject-driven generation using a reference set containing\na few images. However, few prior works explore DDPM-based domain-driven\ngeneration, which aims to learn the common features of target domains while\nmaintaining diversity. This paper proposes a novel DomainStudio approach to\nadapt DDPMs pre-trained on large-scale source datasets to target domains using\nlimited data. It is designed to keep the diversity of subjects provided by\nsource domains and get high-quality and diverse adapted samples in target\ndomains. We propose to keep the relative distances between adapted samples to\nachieve considerable generation diversity. In addition, we further enhance the\nlearning of high-frequency details for better generation quality. Our approach\nis compatible with both unconditional and conditional diffusion models. This\nwork makes the first attempt to realize unconditional few-shot image generation\nwith diffusion models, achieving better quality and greater diversity than\ncurrent state-of-the-art GAN-based approaches. Moreover, this work also\nsignificantly relieves overfitting for conditional generation and realizes\nhigh-quality domain-driven generation, further expanding the applicable\nscenarios of modern large-scale text-to-image models.\n","authors":["Jingyuan Zhu","Huimin Ma","Jiansheng Chen","Jian Yuan"],"pdf_url":"https://arxiv.org/pdf/2306.14153v1.pdf","comment":"extended from DDPM-PA (arXiv:2211.03264), 33 pages, 34 figures"},{"id":"http://arxiv.org/abs/2305.04470v2","updated":"2023-06-25T06:39:30Z","published":"2023-05-08T05:46:59Z","title":"Video Object Segmentation in Panoptic Wild Scenes","summary":"  In this paper, we introduce semi-supervised video object segmentation (VOS)\nto panoptic wild scenes and present a large-scale benchmark as well as a\nbaseline method for it. Previous benchmarks for VOS with sparse annotations are\nnot sufficient to train or evaluate a model that needs to process all possible\nobjects in real-world scenarios. Our new benchmark (VIPOSeg) contains\nexhaustive object annotations and covers various real-world object categories\nwhich are carefully divided into subsets of thing/stuff and seen/unseen classes\nfor comprehensive evaluation. Considering the challenges in panoptic VOS, we\npropose a strong baseline method named panoptic object association with\ntransformers (PAOT), which uses panoptic identification to associate objects\nwith a pyramid architecture on multiple scales. Experimental results show that\nVIPOSeg can not only boost the performance of VOS models by panoptic training\nbut also evaluate them comprehensively in panoptic scenes. Previous methods for\nclassic VOS still need to improve in performance and efficiency when dealing\nwith panoptic scenes, while our PAOT achieves SOTA performance with good\nefficiency on VIPOSeg and previous VOS benchmarks. PAOT also ranks 1st in the\nVOT2022 challenge. Our dataset is available at\nhttps://github.com/yoxu515/VIPOSeg-Benchmark.\n","authors":["Yuanyou Xu","Zongxin Yang","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2305.04470v2.pdf","comment":"Accepted to IJCAI2023"},{"id":"http://arxiv.org/abs/2306.14141v1","updated":"2023-06-25T06:28:28Z","published":"2023-06-25T06:28:28Z","title":"A Gated Cross-domain Collaborative Network for Underwater Object\n  Detection","summary":"  Underwater object detection (UOD) plays a significant role in aquaculture and\nmarine environmental protection. Considering the challenges posed by low\ncontrast and low-light conditions in underwater environments, several\nunderwater image enhancement (UIE) methods have been proposed to improve the\nquality of underwater images. However, only using the enhanced images does not\nimprove the performance of UOD, since it may unavoidably remove or alter\ncritical patterns and details of underwater objects. In contrast, we believe\nthat exploring the complementary information from the two domains is beneficial\nfor UOD. The raw image preserves the natural characteristics of the scene and\ntexture information of the objects, while the enhanced image improves the\nvisibility of underwater objects. Based on this perspective, we propose a Gated\nCross-domain Collaborative Network (GCC-Net) to address the challenges of poor\nvisibility and low contrast in underwater environments, which comprises three\ndedicated components. Firstly, a real-time UIE method is employed to generate\nenhanced images, which can improve the visibility of objects in low-contrast\nareas. Secondly, a cross-domain feature interaction module is introduced to\nfacilitate the interaction and mine complementary information between raw and\nenhanced image features. Thirdly, to prevent the contamination of unreliable\ngenerated results, a gated feature fusion module is proposed to adaptively\ncontrol the fusion ratio of cross-domain information. Our method presents a new\nUOD paradigm from the perspective of cross-domain information interaction and\nfusion. Experimental results demonstrate that the proposed GCC-Net achieves\nstate-of-the-art performance on four underwater datasets.\n","authors":["Linhui Dai","Hong Liu","Pinhao Song","Mengyuan Liu"],"pdf_url":"https://arxiv.org/pdf/2306.14141v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14136v1","updated":"2023-06-25T06:00:33Z","published":"2023-06-25T06:00:33Z","title":"Scribble-supervised Cell Segmentation Using Multiscale Contrastive\n  Regularization","summary":"  Current state-of-the-art supervised deep learning-based segmentation\napproaches have demonstrated superior performance in medical image segmentation\ntasks. However, such supervised approaches require fully annotated pixel-level\nground-truth labels, which are labor-intensive and time-consuming to acquire.\nRecently, Scribble2Label (S2L) demonstrated that using only a handful of\nscribbles with self-supervised learning can generate accurate segmentation\nresults without full annotation. However, owing to the relatively small size of\nscribbles, the model is prone to overfit and the results may be biased to the\nselection of scribbles. In this work, we address this issue by employing a\nnovel multiscale contrastive regularization term for S2L. The main idea is to\nextract features from intermediate layers of the neural network for contrastive\nloss so that structures at various scales can be effectively separated. To\nverify the efficacy of our method, we conducted ablation studies on well-known\ndatasets, such as Data Science Bowl 2018 and MoNuSeg. The results show that the\nproposed multiscale contrastive loss is effective in improving the performance\nof S2L, which is comparable to that of the supervised learning segmentation\nmethod.\n","authors":["Hyun-Jic Oh","Kanggeun Lee","Won-Ki Jeong"],"pdf_url":"https://arxiv.org/pdf/2306.14136v1.pdf","comment":"ISBI 2022 accepted"},{"id":"http://arxiv.org/abs/2306.14132v1","updated":"2023-06-25T05:31:08Z","published":"2023-06-25T05:31:08Z","title":"DiffMix: Diffusion Model-based Data Synthesis for Nuclei Segmentation\n  and Classification in Imbalanced Pathology Image Datasets","summary":"  Nuclei segmentation and classification is a significant process in pathology\nimage analysis. Deep learning-based approaches have greatly contributed to the\nhigher accuracy of this task. However, those approaches suffer from the\nimbalanced nuclei data composition, which shows lower classification\nperformance on the rare nuclei class. In this paper, we propose a realistic\ndata synthesis method using a diffusion model. We generate two types of virtual\npatches to enlarge the training data distribution, which is for balancing the\nnuclei class variance and for enlarging the chance to look at various nuclei.\nAfter that, we use a semantic-label-conditioned diffusion model to generate\nrealistic and high-quality image samples. We demonstrate the efficacy of our\nmethod by experiment results on two imbalanced nuclei datasets, improving the\nstate-of-the-art networks. The experimental results suggest that the proposed\nmethod improves the classification performance of the rare type nuclei\nclassification, while showing superior segmentation and classification\nperformance in imbalanced pathology nuclei datasets.\n","authors":["Hyun-Jic Oh","Won-Ki Jeong"],"pdf_url":"https://arxiv.org/pdf/2306.14132v1.pdf","comment":"MICCAI 2023 accepted"},{"id":"http://arxiv.org/abs/2202.10094v3","updated":"2023-06-25T05:27:57Z","published":"2022-02-21T10:21:40Z","title":"Point Cloud Denoising via Momentum Ascent in Gradient Fields","summary":"  To achieve point cloud denoising, traditional methods heavily rely on\ngeometric priors, and most learning-based approaches suffer from outliers and\nloss of details. Recently, the gradient-based method was proposed to estimate\nthe gradient fields from the noisy point clouds using neural networks, and\nrefine the position of each point according to the estimated gradient. However,\nthe predicted gradient could fluctuate, leading to perturbed and unstable\nsolutions, as well as a long inference time. To address these issues, we\ndevelop the momentum gradient ascent method that leverages the information of\nprevious iterations in determining the trajectories of the points, thus\nimproving the stability of the solution and reducing the inference time.\nExperiments demonstrate that the proposed method outperforms state-of-the-art\napproaches with a variety of point clouds, noise types, and noise levels. Code\nis available at: https://github.com/IndigoPurple/MAG\n","authors":["Yaping Zhao","Haitian Zheng","Zhongrui Wang","Jiebo Luo","Edmund Y. Lam"],"pdf_url":"https://arxiv.org/pdf/2202.10094v3.pdf","comment":"5 pages, 6 figures"},{"id":"http://arxiv.org/abs/2306.14129v1","updated":"2023-06-25T05:11:41Z","published":"2023-06-25T05:11:41Z","title":"Masked conditional variational autoencoders for chromosome straightening","summary":"  Karyotyping is of importance for detecting chromosomal aberrations in human\ndisease. However, chromosomes easily appear curved in microscopic images, which\nprevents cytogeneticists from analyzing chromosome types. To address this\nissue, we propose a framework for chromosome straightening, which comprises a\npreliminary processing algorithm and a generative model called masked\nconditional variational autoencoders (MC-VAE). The processing method utilizes\npatch rearrangement to address the difficulty in erasing low degrees of\ncurvature, providing reasonable preliminary results for the MC-VAE. The MC-VAE\nfurther straightens the results by leveraging chromosome patches conditioned on\ntheir curvatures to learn the mapping between banding patterns and conditions.\nDuring model training, we apply a masking strategy with a high masking ratio to\ntrain the MC-VAE with eliminated redundancy. This yields a non-trivial\nreconstruction task, allowing the model to effectively preserve chromosome\nbanding patterns and structure details in the reconstructed results. Extensive\nexperiments on three public datasets with two stain styles show that our\nframework surpasses the performance of state-of-the-art methods in retaining\nbanding patterns and structure details. Compared to using real-world bent\nchromosomes, the use of high-quality straightened chromosomes generated by our\nproposed method can improve the performance of various deep learning models for\nchromosome classification by a large margin. Such a straightening approach has\nthe potential to be combined with other karyotyping systems to assist\ncytogeneticists in chromosome analysis.\n","authors":["Jingxiong Li","Sunyi Zheng","Zhongyi Shui","Shichuan Zhang","Linyi Yang","Yuxuan Sun","Yunlong Zhang","Honglin Li","Yuanxin Ye","Peter M. A. van Ooijen","Kang Li","Lin Yang"],"pdf_url":"https://arxiv.org/pdf/2306.14129v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2306.14314v1","updated":"2023-06-25T19:02:31Z","published":"2023-06-25T19:02:31Z","title":"G-STO: Sequential Main Shopping Intention Detection via\n  Graph-Regularized Stochastic Transformer","summary":"  Sequential recommendation requires understanding the dynamic patterns of\nusers' behaviors, contexts, and preferences from their historical interactions.\nMost existing works focus on modeling user-item interactions only from the item\nlevel, ignoring that they are driven by latent shopping intentions (e.g.,\nballpoint pens, miniatures, etc). The detection of the underlying shopping\nintentions of users based on their historical interactions is a crucial aspect\nfor e-commerce platforms, such as Amazon, to enhance the convenience and\nefficiency of their customers' shopping experiences. Despite its significance,\nthe area of main shopping intention detection remains under-investigated in the\nacademic literature. To fill this gap, we propose a graph-regularized\nstochastic Transformer method, G-STO. By considering intentions as sets of\nproducts and user preferences as compositions of intentions, we model both of\nthem as stochastic Gaussian embeddings in the latent representation space.\nInstead of training the stochastic representations from scratch, we develop a\nglobal intention relational graph as prior knowledge for regularization,\nallowing relevant shopping intentions to be distributionally close. Finally, we\nfeed the newly regularized stochastic embeddings into Transformer-based models\nto encode sequential information from the intention transitions. We evaluate\nour main shopping intention identification model on three different real-world\ndatasets, where G-STO achieves significantly superior performances to the\nbaselines by 18.08% in Hit@1, 7.01% in Hit@10, and 6.11% in NDCG@10 on average.\n","authors":["Yuchen Zhuang","Xin Shen","Yan Zhao","Chaosheng Dong","Ming Wang","Jin Li","Chao Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.14314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14292v1","updated":"2023-06-25T16:52:37Z","published":"2023-06-25T16:52:37Z","title":"RecBaselines2023: a new dataset for choosing baselines for recommender\n  models","summary":"  The number of proposed recommender algorithms continues to grow. The authors\npropose new approaches and compare them with existing models, called baselines.\nDue to the large number of recommender models, it is difficult to estimate\nwhich algorithms to choose in the article. To solve this problem, we have\ncollected and published a dataset containing information about the recommender\nmodels used in 903 papers, both as baselines and as proposed approaches. This\ndataset can be seen as a typical dataset with interactions between papers and\npreviously proposed models. In addition, we provide a descriptive analysis of\nthe dataset and highlight possible challenges to be investigated with the data.\nFurthermore, we have conducted extensive experiments using a well-established\nmethodology to build a good recommender algorithm under the dataset. Our\nexperiments show that the selection of the best baselines for proposing new\nrecommender approaches can be considered and successfully solved by existing\nstate-of-the-art collaborative filtering models. Finally, we discuss\nlimitations and future work.\n","authors":["Veronika Ivanova","Oleg Lashinin","Marina Ananyeva","Sergey Kolesnikov"],"pdf_url":"https://arxiv.org/pdf/2306.14292v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14179v1","updated":"2023-06-25T09:09:11Z","published":"2023-06-25T09:09:11Z","title":"Mining Stable Preferences: Adaptive Modality Decorrelation for\n  Multimedia Recommendation","summary":"  Multimedia content is of predominance in the modern Web era. In real\nscenarios, multiple modalities reveal different aspects of item attributes and\nusually possess different importance to user purchase decisions. However, it is\ndifficult for models to figure out users' true preference towards different\nmodalities since there exists strong statistical correlation between\nmodalities. Even worse, the strong statistical correlation might mislead models\nto learn the spurious preference towards inconsequential modalities. As a\nresult, when data (modal features) distribution shifts, the learned spurious\npreference might not guarantee to be as effective on the inference set as on\nthe training set. We propose a novel MOdality DEcorrelating STable learning\nframework, MODEST for brevity, to learn users' stable preference. Inspired by\nsample re-weighting techniques, the proposed method aims to estimate a weight\nfor each item, such that the features from different modalities in the weighted\ndistribution are decorrelated. We adopt Hilbert Schmidt Independence Criterion\n(HSIC) as independence testing measure which is a kernel-based method capable\nof evaluating the correlation degree between two multi-dimensional and\nnon-linear variables. Our method could be served as a play-and-plug module for\nexisting multimedia recommendation backbones. Extensive experiments on four\npublic datasets and four state-of-the-art multimedia recommendation backbones\nunequivocally show that our proposed method can improve the performances by a\nlarge margin.\n","authors":["Jinghao Zhang","Qiang Liu","Shu Wu","Liang Wang"],"pdf_url":"https://arxiv.org/pdf/2306.14179v1.pdf","comment":"Accepted to SIGIR 2023"},{"id":"http://arxiv.org/abs/2306.10933v2","updated":"2023-06-25T07:05:30Z","published":"2023-06-19T13:44:48Z","title":"Towards Open-World Recommendation with Knowledge Augmentation from Large\n  Language Models","summary":"  Recommender systems play a vital role in various online services. However,\nthe insulated nature of training and deploying separately within a specific\ndomain limits their access to open-world knowledge. Recently, the emergence of\nlarge language models (LLMs) has shown promise in bridging this gap by encoding\nextensive world knowledge and demonstrating reasoning capability. Nevertheless,\nprevious attempts to directly use LLMs as recommenders have not achieved\nsatisfactory results. In this work, we propose an Open-World Knowledge\nAugmented Recommendation Framework with Large Language Models, dubbed KAR, to\nacquire two types of external knowledge from LLMs -- the reasoning knowledge on\nuser preferences and the factual knowledge on items. We introduce factorization\nprompting to elicit accurate reasoning on user preferences. The generated\nreasoning and factual knowledge are effectively transformed and condensed into\naugmented vectors by a hybrid-expert adaptor in order to be compatible with the\nrecommendation task. The obtained vectors can then be directly used to enhance\nthe performance of any recommendation model. We also ensure efficient inference\nby preprocessing and prestoring the knowledge from the LLM. Extensive\nexperiments show that KAR significantly outperforms the state-of-the-art\nbaselines and is compatible with a wide range of recommendation algorithms.\n","authors":["Yunjia Xi","Weiwen Liu","Jianghao Lin","Jieming Zhu","Bo Chen","Ruiming Tang","Weinan Zhang","Rui Zhang","Yong Yu"],"pdf_url":"https://arxiv.org/pdf/2306.10933v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11963v2","updated":"2023-06-25T06:25:49Z","published":"2023-06-21T01:22:43Z","title":"Multimodality Fusion for Smart Healthcare: a Journey from Data,\n  Information, Knowledge to Wisdom","summary":"  Multimodal medical data fusion has emerged as a transformative approach in\nsmart healthcare, enabling a comprehensive understanding of patient health and\npersonalized treatment plans. In this paper, a journey from data, information,\nand knowledge to wisdom (DIKW) is explored through multimodal fusion for smart\nhealthcare. A comprehensive review of multimodal medical data fusion focuses on\nthe integration of various data modalities are presented. It explores different\napproaches such as Feature selection, Rule-based systems, Machine learning,\nDeep learning, and Natural Language Processing for fusing and analyzing\nmultimodal data. The paper also highlights the challenges associated with\nmultimodal fusion in healthcare. By synthesizing the reviewed frameworks and\ninsights, a generic framework for multimodal medical data fusion is proposed\nwhile aligning with the DIKW mechanism. Moreover, it discusses future\ndirections aligned with the four pillars of healthcare: Predictive, Preventive,\nPersonalized, and Participatory approaches based on the DIKW and the generic\nframework. The components from this comprehensive survey form the foundation\nfor the successful implementation of multimodal fusion in smart healthcare. The\nfindings of this survey can guide researchers and practitioners in leveraging\nthe power of multimodal fusion with the approaches to revolutionize healthcare\nand improve patient outcomes.\n","authors":["Thanveer Shaik","Xiaohui Tao","Lin Li","Haoran Xie","Juan D. Velásquez"],"pdf_url":"https://arxiv.org/pdf/2306.11963v2.pdf","comment":"This work has been submitted to the ELSEVIER for possible\n  publication. Copyright may be transferred without notice, after which this\n  version may no longer be accessible"},{"id":"http://arxiv.org/abs/2306.14112v1","updated":"2023-06-25T03:28:24Z","published":"2023-06-25T03:28:24Z","title":"Enhancing Dynamic Image Advertising with Vision-Language Pre-training","summary":"  In the multimedia era, image is an effective medium in search advertising.\nDynamic Image Advertising (DIA), a system that matches queries with ad images\nand generates multimodal ads, is introduced to improve user experience and ad\nrevenue. The core of DIA is a query-image matching module performing ad image\nretrieval and relevance modeling. Current query-image matching suffers from\nlimited and inconsistent data, and insufficient cross-modal interaction. Also,\nthe separate optimization of retrieval and relevance models affects overall\nperformance. To address this issue, we propose a vision-language framework\nconsisting of two parts. First, we train a base model on large-scale image-text\npairs to learn general multimodal representation. Then, we fine-tune the base\nmodel on advertising business data, unifying relevance modeling and retrieval\nthrough multi-objective learning. Our framework has been implemented in Baidu\nsearch advertising system \"Phoneix Nest\". Online evaluation shows that it\nimproves cost per mille (CPM) and click-through rate (CTR) by 1.04% and 1.865%.\n","authors":["Zhoufutu Wen","Xinyu Zhao","Zhipeng Jin","Yi Yang","Wei Jia","Xiaodong Chen","Shuanglong Li","Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2306.14112v1.pdf","comment":"6 pages, 3 figures, accepted to SIRIP 2023"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2301.12383v2","updated":"2023-06-25T23:54:34Z","published":"2023-01-29T07:36:49Z","title":"On Heterogeneous Treatment Effects in Heterogeneous Causal Graphs","summary":"  Heterogeneity and comorbidity are two interwoven challenges associated with\nvarious healthcare problems that greatly hampered research on developing\neffective treatment and understanding of the underlying neurobiological\nmechanism. Very few studies have been conducted to investigate heterogeneous\ncausal effects (HCEs) in graphical contexts due to the lack of statistical\nmethods. To characterize this heterogeneity, we first conceptualize\nheterogeneous causal graphs (HCGs) by generalizing the causal graphical model\nwith confounder-based interactions and multiple mediators. Such confounders\nwith an interaction with the treatment are known as moderators. This allows us\nto flexibly produce HCGs given different moderators and explicitly characterize\nHCEs from the treatment or potential mediators on the outcome. We establish the\ntheoretical forms of HCEs and derive their properties at the individual level\nin both linear and nonlinear models. An interactive structural learning is\ndeveloped to estimate the complex HCGs and HCEs with confidence intervals\nprovided. Our method is empirically justified by extensive simulations and its\npractical usefulness is illustrated by exploring causality among psychiatric\ndisorders for trauma survivors.\n","authors":["Richard A Watson","Hengrui Cai","Xinming An","Samuel McLean","Rui Song"],"pdf_url":"https://arxiv.org/pdf/2301.12383v2.pdf","comment":"In Proceedings of the 40th International Conference on Machine\n  Learning (ICML) Code implementing the proposed algorithm is open-source and\n  publicly available at: https://github.com/richard-watson/ISL"},{"id":"http://arxiv.org/abs/2304.14621v2","updated":"2023-06-25T23:42:44Z","published":"2023-04-28T04:25:57Z","title":"MUDiff: Unified Diffusion for Complete Molecule Generation","summary":"  Molecule generation is a very important practical problem, with uses in drug\ndiscovery and material design, and AI methods promise to provide useful\nsolutions. However, existing methods for molecule generation focus either on 2D\ngraph structure or on 3D geometric structure, which is not sufficient to\nrepresent a complete molecule as 2D graph captures mainly topology while 3D\ngeometry captures mainly spatial atom arrangements. Combining these\nrepresentations is essential to better represent a molecule. In this paper, we\npresent a new model for generating a comprehensive representation of molecules,\nincluding atom features, 2D discrete molecule structures, and 3D continuous\nmolecule coordinates, by combining discrete and continuous diffusion processes.\nThe use of diffusion processes allows for capturing the probabilistic nature of\nmolecular processes and exploring the effect of different factors on molecular\nstructures. Additionally, we propose a novel graph transformer architecture to\ndenoise the diffusion process. The transformer adheres to 3D roto-translation\nequivariance constraints, allowing it to learn invariant atom and edge\nrepresentations while preserving the equivariance of atom coordinates. This\ntransformer can be used to learn molecular representations robust to geometric\ntransformations. We evaluate the performance of our model through experiments\nand comparisons with existing methods, showing its ability to generate more\nstable and valid molecules. Our model is a promising approach for designing\nstable and diverse molecules and can be applied to a wide range of tasks in\nmolecular modeling.\n","authors":["Chenqing Hua","Sitao Luan","Minkai Xu","Rex Ying","Jie Fu","Stefano Ermon","Doina Precup"],"pdf_url":"https://arxiv.org/pdf/2304.14621v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11666v2","updated":"2023-06-25T23:14:55Z","published":"2023-06-20T16:37:57Z","title":"Neural Astrophysical Wind Models","summary":"  The bulk kinematics and thermodynamics of hot supernovae-driven galactic\nwinds is critically dependent on both the amount of swept up cool clouds and\nnon-spherical collimated flow geometry. However, accurately parameterizing\nthese physics is difficult because their functional forms are often unknown,\nand because the coupled non-linear flow equations contain singularities. We\nshow that deep neural networks embedded as individual terms in the governing\ncoupled ordinary differential equations (ODEs) can robustly discover both of\nthese physics, without any prior knowledge of the true function structure, as a\nsupervised learning task. We optimize a loss function based on the Mach number,\nrather than the explicitly solved-for 3 conserved variables, and apply a\npenalty term towards near-diverging solutions. The same neural network\narchitecture is used for learning both the hidden mass-loading and surface area\nexpansion rates. This work further highlights the feasibility of neural ODEs as\na promising discovery tool with mechanistic interpretability for non-linear\ninverse problems.\n","authors":["Dustin D. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2306.11666v2.pdf","comment":"7 Pages, 4 Figures, Accepted at the ICML 2023 Workshop on Machine\n  Learning for Astrophysics; v2) fixed typos"},{"id":"http://arxiv.org/abs/2306.14357v1","updated":"2023-06-25T22:17:25Z","published":"2023-06-25T22:17:25Z","title":"PolicyClusterGCN: Identifying Efficient Clusters for Training Graph\n  Convolutional Networks","summary":"  Graph convolutional networks (GCNs) have achieved huge success in several\nmachine learning (ML) tasks on graph-structured data. Recently, several\nsampling techniques have been proposed for the efficient training of GCNs and\nto improve the performance of GCNs on ML tasks. Specifically, the\nsubgraph-based sampling approaches such as ClusterGCN and GraphSAINT have\nachieved state-of-the-art performance on the node classification tasks. These\nsubgraph-based sampling approaches rely on heuristics -- such as graph\npartitioning via edge cuts -- to identify clusters that are then treated as\nminibatches during GCN training. In this work, we hypothesize that rather than\nrelying on such heuristics, one can learn a reinforcement learning (RL) policy\nto compute efficient clusters that lead to effective GCN performance. To that\nend, we propose PolicyClusterGCN, an online RL framework that can identify good\nclusters for GCN training. We develop a novel Markov Decision Process (MDP)\nformulation that allows the policy network to predict ``importance\" weights on\nthe edges which are then utilized by a clustering algorithm (Graclus) to\ncompute the clusters. We train the policy network using a standard policy\ngradient algorithm where the rewards are computed from the classification\naccuracies while training GCN using clusters given by the policy. Experiments\non six real-world datasets and several synthetic datasets show that\nPolicyClusterGCN outperforms existing state-of-the-art models on node\nclassification task.\n","authors":["Saket Gurukar","Shaileshh Bojja Venkatakrishnan","Balaraman Ravindran","Srinivasan Parthasarathy"],"pdf_url":"https://arxiv.org/pdf/2306.14357v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.06262v2","updated":"2023-06-25T21:58:50Z","published":"2023-04-13T04:45:25Z","title":"Canonical and Noncanonical Hamiltonian Operator Inference","summary":"  A method for the nonintrusive and structure-preserving model reduction of\ncanonical and noncanonical Hamiltonian systems is presented. Based on the idea\nof operator inference, this technique is provably convergent and reduces to a\nstraightforward linear solve given snapshot data and gray-box knowledge of the\nsystem Hamiltonian. Examples involving several hyperbolic partial differential\nequations show that the proposed method yields reduced models which, in\naddition to being accurate and stable with respect to the addition of basis\nmodes, preserve conserved quantities well outside the range of their training\ndata.\n","authors":["Anthony Gruber","Irina Tezaur"],"pdf_url":"https://arxiv.org/pdf/2304.06262v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14351v1","updated":"2023-06-25T21:57:20Z","published":"2023-06-25T21:57:20Z","title":"Comparing Causal Frameworks: Potential Outcomes, Structural Models,\n  Graphs, and Abstractions","summary":"  The aim of this paper is to make clear and precise the relationship between\nthe Rubin causal model (RCM) and structural causal model (SCM) frameworks for\ncausal inference. Adopting a neutral logical perspective, and drawing on\nprevious work, we show what is required for an RCM to be representable by an\nSCM. A key result then shows that every RCM -- including those that violate\nalgebraic principles implied by the SCM framework -- emerges as an abstraction\nof some representable RCM. Finally, we illustrate the power of this\nameliorative perspective by pinpointing an important role for SCM principles in\nclassic applications of RCMs; conversely, we offer a characterization of the\nalgebraic constraints implied by a graph, helping to substantiate further\ncomparisons between the two frameworks.\n","authors":["Duligur Ibeling","Thomas Icard"],"pdf_url":"https://arxiv.org/pdf/2306.14351v1.pdf","comment":"Submitted to NeurIPS 2023"},{"id":"http://arxiv.org/abs/2306.14350v1","updated":"2023-06-25T21:53:50Z","published":"2023-06-25T21:53:50Z","title":"CDiffMR: Can We Replace the Gaussian Noise with K-Space Undersampling\n  for Fast MRI?","summary":"  Deep learning has shown the capability to substantially accelerate MRI\nreconstruction while acquiring fewer measurements. Recently, diffusion models\nhave gained burgeoning interests as a novel group of deep learning-based\ngenerative methods. These methods seek to sample data points that belong to a\ntarget distribution from a Gaussian distribution, which has been successfully\nextended to MRI reconstruction. In this work, we proposed a Cold\nDiffusion-based MRI reconstruction method called CDiffMR. Different from\nconventional diffusion models, the degradation operation of our CDiffMR is\nbased on \\textit{k}-space undersampling instead of adding Gaussian noise, and\nthe restoration network is trained to harness a de-aliaseing function. We also\ndesign starting point and data consistency conditioning strategies to guide and\naccelerate the reverse process. More intriguingly, the pre-trained CDiffMR\nmodel can be reused for reconstruction tasks with different undersampling\nrates. We demonstrated, through extensive numerical and visual experiments,\nthat the proposed CDiffMR can achieve comparable or even superior\nreconstruction results than state-of-the-art models. Compared to the diffusion\nmodel-based counterpart, CDiffMR reaches readily competing results using only\n$1.6 \\sim 3.4\\%$ for inference time. The code is publicly available at\nhttps://github.com/ayanglab/CDiffMR.\n","authors":["Jiahao Huang","Angelica Aviles-Rivero","Carola-Bibiane Schönlieb","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2306.14350v1.pdf","comment":"10 pages, 4 figures, accepted by MICCAI 2023"},{"id":"http://arxiv.org/abs/2306.14348v1","updated":"2023-06-25T21:43:05Z","published":"2023-06-25T21:43:05Z","title":"Collaborative and Distributed Bayesian Optimization via Consensus:\n  Showcasing the Power of Collaboration for Optimal Design","summary":"  Optimal design is a critical yet challenging task within many applications.\nThis challenge arises from the need for extensive trial and error, often done\nthrough simulations or running field experiments. Fortunately, sequential\noptimal design, also referred to as Bayesian optimization when using surrogates\nwith a Bayesian flavor, has played a key role in accelerating the design\nprocess through efficient sequential sampling strategies. However, a key\nopportunity exists nowadays. The increased connectivity of edge devices sets\nforth a new collaborative paradigm for Bayesian optimization. A paradigm\nwhereby different clients collaboratively borrow strength from each other by\neffectively distributing their experimentation efforts to improve and\nfast-track their optimal design process. To this end, we bring the notion of\nconsensus to Bayesian optimization, where clients agree (i.e., reach a\nconsensus) on their next-to-sample designs. Our approach provides a generic and\nflexible framework that can incorporate different collaboration mechanisms. In\nlieu of this, we propose transitional collaborative mechanisms where clients\ninitially rely more on each other to maneuver through the early stages with\nscant data, then, at the late stages, focus on their own objectives to get\nclient-specific solutions. Theoretically, we show the sub-linear growth in\nregret for our proposed framework. Empirically, through simulated datasets and\na real-world collaborative material discovery experiment, we show that our\nframework can effectively accelerate and improve the optimal design process and\nbenefit all participants.\n","authors":["Xubo Yue","Raed Al Kontar","Albert S. Berahas","Yang Liu","Zhenghao Zai","Kevin Edgar","Blake N. Johnson"],"pdf_url":"https://arxiv.org/pdf/2306.14348v1.pdf","comment":"43 pages"},{"id":"http://arxiv.org/abs/2306.14347v1","updated":"2023-06-25T21:31:46Z","published":"2023-06-25T21:31:46Z","title":"Fast Classification with Sequential Feature Selection in Test Phase","summary":"  This paper introduces a novel approach to active feature acquisition for\nclassification, which is the task of sequentially selecting the most\ninformative subset of features to achieve optimal prediction performance during\ntesting while minimizing cost. The proposed approach involves a new lazy model\nthat is significantly faster and more efficient compared to existing methods,\nwhile still producing comparable accuracy results. During the test phase, the\nproposed approach utilizes Fisher scores for feature ranking to identify the\nmost important feature at each step. In the next step the training dataset is\nfiltered based on the observed value of the selected feature and then we\ncontinue this process to reach to acceptable accuracy or limit of the budget\nfor feature acquisition. The performance of the proposed approach was evaluated\non synthetic and real datasets, including our new synthetic dataset, CUBE\ndataset and also real dataset Forest. The experimental results demonstrate that\nour approach achieves competitive accuracy results compared to existing\nmethods, while significantly outperforming them in terms of speed. The source\ncode of the algorithm is released at github with this link:\nhttps://github.com/alimirzaei/FCwSFS.\n","authors":["Ali Mirzaei","Vahid Pourahmadi","Hamid Sheikhzadeh","Alireza Abdollahpourrostam"],"pdf_url":"https://arxiv.org/pdf/2306.14347v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14346v1","updated":"2023-06-25T21:22:21Z","published":"2023-06-25T21:22:21Z","title":"Evolution of $K$-means solution landscapes with the addition of dataset\n  outliers and a robust clustering comparison measure for their analysis","summary":"  The $K$-means algorithm remains one of the most widely-used clustering\nmethods due to its simplicity and general utility. The performance of $K$-means\ndepends upon location of minima low in cost function, amongst a potentially\nvast number of solutions. Here, we use the energy landscape approach to map the\nchange in $K$-means solution space as a result of increasing dataset outliers\nand show that the cost function surface becomes more funnelled. Kinetic\nanalysis reveals that in all cases the overall funnel is composed of shallow\nlocally-funnelled regions, each of which are separated by areas that do not\nsupport any clustering solutions. These shallow regions correspond to different\ntypes of clustering solution and their increasing number with outliers leads to\nlonger pathways within the funnel and a reduced correlation between accuracy\nand cost function. Finally, we propose that the rates obtained from kinetic\nanalysis provide a novel measure of clustering similarity that incorporates\ninformation about the paths between them. This measure is robust to outliers\nand we illustrate the application to datasets containing multiple outliers.\n","authors":["Luke Dicks","David J. Wales"],"pdf_url":"https://arxiv.org/pdf/2306.14346v1.pdf","comment":"27 pages, 9 figures"},{"id":"http://arxiv.org/abs/2306.14343v1","updated":"2023-06-25T21:12:43Z","published":"2023-06-25T21:12:43Z","title":"TCE: A Test-Based Approach to Measuring Calibration Error","summary":"  This paper proposes a new metric to measure the calibration error of\nprobabilistic binary classifiers, called test-based calibration error (TCE).\nTCE incorporates a novel loss function based on a statistical test to examine\nthe extent to which model predictions differ from probabilities estimated from\ndata. It offers (i) a clear interpretation, (ii) a consistent scale that is\nunaffected by class imbalance, and (iii) an enhanced visual representation with\nrepect to the standard reliability diagram. In addition, we introduce an\noptimality criterion for the binning procedure of calibration error metrics\nbased on a minimal estimation error of the empirical probabilities. We provide\na novel computational algorithm for optimal bins under bin-size constraints. We\ndemonstrate properties of TCE through a range of experiments, including\nmultiple real-world imbalanced datasets and ImageNet 1000.\n","authors":["Takuo Matsubara","Niek Tax","Richard Mudd","Ido Guy"],"pdf_url":"https://arxiv.org/pdf/2306.14343v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14340v1","updated":"2023-06-25T20:57:35Z","published":"2023-06-25T20:57:35Z","title":"GPatcher: A Simple and Adaptive MLP Model for Alleviating Graph\n  Heterophily","summary":"  While graph heterophily has been extensively studied in recent years, a\nfundamental research question largely remains nascent: How and to what extent\nwill graph heterophily affect the prediction performance of graph neural\nnetworks (GNNs)? In this paper, we aim to demystify the impact of graph\nheterophily on GNN spectral filters. Our theoretical results show that it is\nessential to design adaptive polynomial filters that adapts different degrees\nof graph heterophily to guarantee the generalization performance of GNNs.\nInspired by our theoretical findings, we propose a simple yet powerful GNN\nnamed GPatcher by leveraging the MLP-Mixer architectures. Our approach\ncomprises two main components: (1) an adaptive patch extractor function that\nautomatically transforms each node's non-Euclidean graph representations to\nEuclidean patch representations given different degrees of heterophily, and (2)\nan efficient patch mixer function that learns salient node representation from\nboth the local context information and the global positional information.\nThrough extensive experiments, the GPatcher model demonstrates outstanding\nperformance on node classification compared with popular homophily GNNs and\nstate-of-the-art heterophily GNNs.\n","authors":["Shuaicheng Zhang","Haohui Wang","Si Zhang","Dawei Zhou"],"pdf_url":"https://arxiv.org/pdf/2306.14340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14326v1","updated":"2023-06-25T19:41:14Z","published":"2023-06-25T19:41:14Z","title":"Computational Asymmetries in Robust Classification","summary":"  In the context of adversarial robustness, we make three strongly related\ncontributions. First, we prove that while attacking ReLU classifiers is\n$\\mathit{NP}$-hard, ensuring their robustness at training time is\n$\\Sigma^2_P$-hard (even on a single example). This asymmetry provides a\nrationale for the fact that robust classifications approaches are frequently\nfooled in the literature. Second, we show that inference-time robustness\ncertificates are not affected by this asymmetry, by introducing a\nproof-of-concept approach named Counter-Attack (CA). Indeed, CA displays a\nreversed asymmetry: running the defense is $\\mathit{NP}$-hard, while attacking\nit is $\\Sigma_2^P$-hard. Finally, motivated by our previous result, we argue\nthat adversarial attacks can be used in the context of robustness\ncertification, and provide an empirical evaluation of their effectiveness. As a\nbyproduct of this process, we also release UG100, a benchmark dataset for\nadversarial attacks.\n","authors":["Samuele Marro","Michele Lombardi"],"pdf_url":"https://arxiv.org/pdf/2306.14326v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14325v1","updated":"2023-06-25T19:38:01Z","published":"2023-06-25T19:38:01Z","title":"The Neuro-Symbolic Inverse Planning Engine (NIPE): Modeling\n  Probabilistic Social Inferences from Linguistic Inputs","summary":"  Human beings are social creatures. We routinely reason about other agents,\nand a crucial component of this social reasoning is inferring people's goals as\nwe learn about their actions. In many settings, we can perform intuitive but\nreliable goal inference from language descriptions of agents, actions, and the\nbackground environments. In this paper, we study this process of language\ndriving and influencing social reasoning in a probabilistic goal inference\ndomain. We propose a neuro-symbolic model that carries out goal inference from\nlinguistic inputs of agent scenarios. The \"neuro\" part is a large language\nmodel (LLM) that translates language descriptions to code representations, and\nthe \"symbolic\" part is a Bayesian inverse planning engine. To test our model,\nwe design and run a human experiment on a linguistic goal inference task. Our\nmodel closely matches human response patterns and better predicts human\njudgements than using an LLM alone.\n","authors":["Lance Ying","Katherine M. Collins","Megan Wei","Cedegao E. Zhang","Tan Zhi-Xuan","Adrian Weller","Joshua B. Tenenbaum","Lionel Wong"],"pdf_url":"https://arxiv.org/pdf/2306.14325v1.pdf","comment":"To appear at ICML Workshop on Theory of Mind in Communicating Agents"},{"id":"http://arxiv.org/abs/2306.14320v1","updated":"2023-06-25T19:21:10Z","published":"2023-06-25T19:21:10Z","title":"Im2win: Memory Efficient Convolution On SIMD Architectures","summary":"  Convolution is the most expensive operation among neural network operations,\nthus its performance is critical to the overall performance of neural networks.\nCommonly used convolution approaches, including general matrix multiplication\n(GEMM)-based convolution and direct convolution, rely on im2col for data\ntransformation or do not use data transformation at all, respectively. However,\nthe im2col data transformation can lead to at least 2$\\times$ memory footprint\ncompared to not using data transformation at all, thus limiting the size of\nneural network models running on memory-limited systems. Meanwhile, not using\ndata transformation usually performs poorly due to nonconsecutive memory access\nalthough it consumes less memory. To solve those problems, we propose a new\nmemory-efficient data transformation algorithm, called im2win. This algorithm\nrefactorizes a row of square or rectangle dot product windows of the input\nimage and flattens unique elements within these windows into a row in the\noutput tensor, which enables consecutive memory access and data reuse, and thus\ngreatly reduces the memory overhead. Furthermore, we propose a high-performance\nim2win-based convolution algorithm with various optimizations, including\nvectorization, loop reordering, etc. Our experimental results show that our\nalgorithm reduces the memory overhead by average to 41.6% compared to the\nPyTorch's convolution implementation based on im2col, and achieves average to\n3.6$\\times$ and 5.3$\\times$ speedup in performance compared to the im2col-based\nconvolution and not using data transformation, respectively.\n","authors":["Shuai Lu","Jun Chu","Xu T. Liu"],"pdf_url":"https://arxiv.org/pdf/2306.14320v1.pdf","comment":"Published at \"2022 IEEE High Performance Extreme Computing Conference\n  (HPEC)\""},{"id":"http://arxiv.org/abs/2306.14316v1","updated":"2023-06-25T19:09:56Z","published":"2023-06-25T19:09:56Z","title":"Im2win: An Efficient Convolution Paradigm on GPU","summary":"  Convolution is the most time-consuming operation in deep neural network\noperations, so its performance is critical to the overall performance of the\nneural network. The commonly used methods for convolution on GPU include the\ngeneral matrix multiplication (GEMM)-based convolution and the direct\nconvolution. GEMM-based convolution relies on the im2col algorithm, which\nresults in a large memory footprint and reduced performance. Direct convolution\ndoes not have the large memory footprint problem, but the performance is not on\npar with GEMM-based approach because of the discontinuous memory access. This\npaper proposes a window-order-based convolution paradigm on GPU, called im2win,\nwhich not only reduces memory footprint but also offers continuous memory\naccesses, resulting in improved performance. Furthermore, we apply a range of\noptimization techniques on the convolution CUDA kernel, including shared\nmemory, tiling, micro-kernel, double buffer, and prefetching. We compare our\nimplementation with the direct convolution, and PyTorch's GEMM-based\nconvolution with cuBLAS and six cuDNN-based convolution implementations, with\ntwelve state-of-the-art DNN benchmarks. The experimental results show that our\nimplementation 1) uses less memory footprint by 23.1% and achieves 3.5$\\times$\nTFLOPS compared with cuBLAS, 2) uses less memory footprint by 32.8% and\nachieves up to 1.8$\\times$ TFLOPS compared with the best performant\nconvolutions in cuDNN, and 3) achieves up to 155$\\times$ TFLOPS compared with\nthe direct convolution. We further perform an ablation study on the applied\noptimization techniques and find that the micro-kernel has the greatest\npositive impact on performance.\n","authors":["Shuai Lu","Jun Chu","Luanzheng Guo","Xu T. Liu"],"pdf_url":"https://arxiv.org/pdf/2306.14316v1.pdf","comment":"Accepted at \"29th International European conference on parallel and\n  distributed computing (Euro-Par'2023)\""},{"id":"http://arxiv.org/abs/2306.14314v1","updated":"2023-06-25T19:02:31Z","published":"2023-06-25T19:02:31Z","title":"G-STO: Sequential Main Shopping Intention Detection via\n  Graph-Regularized Stochastic Transformer","summary":"  Sequential recommendation requires understanding the dynamic patterns of\nusers' behaviors, contexts, and preferences from their historical interactions.\nMost existing works focus on modeling user-item interactions only from the item\nlevel, ignoring that they are driven by latent shopping intentions (e.g.,\nballpoint pens, miniatures, etc). The detection of the underlying shopping\nintentions of users based on their historical interactions is a crucial aspect\nfor e-commerce platforms, such as Amazon, to enhance the convenience and\nefficiency of their customers' shopping experiences. Despite its significance,\nthe area of main shopping intention detection remains under-investigated in the\nacademic literature. To fill this gap, we propose a graph-regularized\nstochastic Transformer method, G-STO. By considering intentions as sets of\nproducts and user preferences as compositions of intentions, we model both of\nthem as stochastic Gaussian embeddings in the latent representation space.\nInstead of training the stochastic representations from scratch, we develop a\nglobal intention relational graph as prior knowledge for regularization,\nallowing relevant shopping intentions to be distributionally close. Finally, we\nfeed the newly regularized stochastic embeddings into Transformer-based models\nto encode sequential information from the intention transitions. We evaluate\nour main shopping intention identification model on three different real-world\ndatasets, where G-STO achieves significantly superior performances to the\nbaselines by 18.08% in Hit@1, 7.01% in Hit@10, and 6.11% in NDCG@10 on average.\n","authors":["Yuchen Zhuang","Xin Shen","Yan Zhao","Chaosheng Dong","Ming Wang","Jin Li","Chao Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.14314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14313v1","updated":"2023-06-25T18:59:52Z","published":"2023-06-25T18:59:52Z","title":"A Closer Look at Geometric Temporal Dynamics for Face Anti-Spoofing","summary":"  Face anti-spoofing (FAS) is indispensable for a face recognition system. Many\ntexture-driven countermeasures were developed against presentation attacks\n(PAs), but the performance against unseen domains or unseen spoofing types is\nstill unsatisfactory. Instead of exhaustively collecting all the spoofing\nvariations and making binary decisions of live/spoof, we offer a new\nperspective on the FAS task to distinguish between normal and abnormal\nmovements of live and spoof presentations. We propose Geometry-Aware\nInteraction Network (GAIN), which exploits dense facial landmarks with\nspatio-temporal graph convolutional network (ST-GCN) to establish a more\ninterpretable and modularized FAS model. Additionally, with our cross-attention\nfeature interaction mechanism, GAIN can be easily integrated with other\nexisting methods to significantly boost performance. Our approach achieves\nstate-of-the-art performance in the standard intra- and cross-dataset\nevaluations. Moreover, our model outperforms state-of-the-art methods by a\nlarge margin in the cross-dataset cross-type protocol on CASIA-SURF 3DMask\n(+10.26% higher AUC score), exhibiting strong robustness against domain shifts\nand unseen spoofing types.\n","authors":["Chih-Jung Chang","Yaw-Chern Lee","Shih-Hsuan Yao","Min-Hung Chen","Chien-Yi Wang","Shang-Hong Lai","Trista Pei-Chun Chen"],"pdf_url":"https://arxiv.org/pdf/2306.14313v1.pdf","comment":"2023 CVPR Biometrics Workshop, Best Paper Award"},{"id":"http://arxiv.org/abs/2305.14699v2","updated":"2023-06-25T18:38:38Z","published":"2023-05-24T04:08:37Z","title":"Can Transformers Learn to Solve Problems Recursively?","summary":"  Neural networks have in recent years shown promise for helping software\nengineers write programs and even formally verify them. While semantic\ninformation plays a crucial part in these processes, it remains unclear to what\ndegree popular neural architectures like transformers are capable of modeling\nthat information. This paper examines the behavior of neural networks learning\nalgorithms relevant to programs and formal verification proofs through the lens\nof mechanistic interpretability, focusing in particular on structural\nrecursion. Structural recursion is at the heart of tasks on which symbolic\ntools currently outperform neural models, like inferring semantic relations\nbetween datatypes and emulating program behavior. We evaluate the ability of\ntransformer models to learn to emulate the behavior of structurally recursive\nfunctions from input-output examples. Our evaluation includes empirical and\nconceptual analyses of the limitations and capabilities of transformer models\nin approximating these functions, as well as reconstructions of the ``shortcut\"\nalgorithms the model learns. By reconstructing these algorithms, we are able to\ncorrectly predict 91 percent of failure cases for one of the approximated\nfunctions. Our work provides a new foundation for understanding the behavior of\nneural networks that fail to solve the very tasks they are trained for.\n","authors":["Shizhuo Dylan Zhang","Curt Tigges","Stella Biderman","Maxim Raginsky","Talia Ringer"],"pdf_url":"https://arxiv.org/pdf/2305.14699v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14306v1","updated":"2023-06-25T18:29:29Z","published":"2023-06-25T18:29:29Z","title":"Adaptive Sharpness-Aware Pruning for Robust Sparse Networks","summary":"  Robustness and compactness are two essential components of deep learning\nmodels that are deployed in the real world. The seemingly conflicting aims of\n(i) generalization across domains as in robustness, and (ii) specificity to one\ndomain as in compression, are why the overall design goal of achieving robust\ncompact models, despite being highly important, is still a challenging open\nproblem. We introduce Adaptive Sharpness-Aware Pruning, or AdaSAP, a method\nthat yields robust sparse networks. The central tenet of our approach is to\noptimize the loss landscape so that the model is primed for pruning via\nadaptive weight perturbation, and is also consistently regularized toward\nflatter regions for improved robustness. This unifies both goals through the\nlens of network sharpness. AdaSAP achieves strong performance in a\ncomprehensive set of experiments. For classification on ImageNet and object\ndetection on Pascal VOC datasets, AdaSAP improves the robust accuracy of pruned\nmodels by +6% on ImageNet C, +4% on ImageNet V2, and +4% on corrupted VOC\ndatasets, over a wide range of compression ratios, saliency criteria, and\nnetwork architectures, outperforming recent pruning art by large margins.\n","authors":["Anna Bair","Hongxu Yin","Maying Shen","Pavlo Molchanov","Jose Alvarez"],"pdf_url":"https://arxiv.org/pdf/2306.14306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.06735v3","updated":"2023-06-25T17:49:27Z","published":"2022-03-13T19:17:15Z","title":"Private Non-Convex Federated Learning Without a Trusted Server","summary":"  We study federated learning (FL) -- especially cross-silo FL -- with\nnon-convex loss functions and data from people who do not trust the server or\nother silos. In this setting, each silo (e.g. hospital) must protect the\nprivacy of each person's data (e.g. patient's medical record), even if the\nserver or other silos act as adversarial eavesdroppers. To that end, we\nconsider inter-silo record-level (ISRL) differential privacy (DP), which\nrequires silo~$i$'s communications to satisfy record/item-level DP. We propose\nnovel ISRL-DP algorithms for FL with heterogeneous (non-i.i.d.) silo data and\ntwo classes of Lipschitz continuous loss functions: First, we consider losses\nsatisfying the Proximal Polyak-Lojasiewicz (PL) inequality, which is an\nextension of the classical PL condition to the constrained setting. In contrast\nto our result, prior works only considered unconstrained private optimization\nwith Lipschitz PL loss, which rules out most interesting PL losses such as\nstrongly convex problems and linear/logistic regression. Our algorithms nearly\nattain the optimal strongly convex, homogeneous (i.i.d.) rate for ISRL-DP FL\nwithout assuming convexity or i.i.d. data. Second, we give the first private\nalgorithms for non-convex non-smooth loss functions. Our utility bounds even\nimprove on the state-of-the-art bounds for smooth losses. We complement our\nupper bounds with lower bounds. Additionally, we provide shuffle DP (SDP)\nalgorithms that improve over the state-of-the-art central DP algorithms under\nmore practical trust assumptions. Numerical experiments show that our algorithm\nhas better accuracy than baselines for most privacy levels. All the codes are\npublicly available at:\nhttps://github.com/ghafeleb/Private-NonConvex-Federated-Learning-Without-a-Trusted-Server.\n","authors":["Andrew Lowy","Ali Ghafelebashi","Meisam Razaviyayn"],"pdf_url":"https://arxiv.org/pdf/2203.06735v3.pdf","comment":"AISTATS 2023"},{"id":"http://arxiv.org/abs/2306.14297v1","updated":"2023-06-25T17:14:45Z","published":"2023-06-25T17:14:45Z","title":"Inference for relative sparsity","summary":"  In healthcare, there is much interest in estimating policies, or mappings\nfrom covariates to treatment decisions. Recently, there is also interest in\nconstraining these estimated policies to the standard of care, which generated\nthe observed data. A relative sparsity penalty was proposed to derive policies\nthat have sparse, explainable differences from the standard of care,\nfacilitating justification of the new policy. However, the developers of this\npenalty only considered estimation, not inference. Here, we develop inference\nfor the relative sparsity objective function, because characterizing\nuncertainty is crucial to applications in medicine. Further, in the relative\nsparsity work, the authors only considered the single-stage decision case;\nhere, we consider the more general, multi-stage case. Inference is difficult,\nbecause the relative sparsity objective depends on the unpenalized value\nfunction, which is unstable and has infinite estimands in the binary action\ncase. Further, one must deal with a non-differentiable penalty. To tackle these\nissues, we nest a weighted Trust Region Policy Optimization function within a\nrelative sparsity objective, implement an adaptive relative sparsity penalty,\nand propose a sample-splitting framework for post-selection inference. We study\nthe asymptotic behavior of our proposed approaches, perform extensive\nsimulations, and analyze a real, electronic health record dataset.\n","authors":["Samuel J. Weisenthal","Sally W. Thurston","Ashkan Ertefaie"],"pdf_url":"https://arxiv.org/pdf/2306.14297v1.pdf","comment":"66 pages, 3 figures"},{"id":"http://arxiv.org/abs/2306.14291v1","updated":"2023-06-25T16:45:20Z","published":"2023-06-25T16:45:20Z","title":"Hyp-OW: Exploiting Hierarchical Structure Learning with Hyperbolic\n  Distance Enhances Open World Object Detection","summary":"  Open World Object Detection (OWOD) is a challenging and realistic task that\nextends beyond the scope of standard Object Detection task. It involves\ndetecting both known and unknown objects while integrating learned knowledge\nfor future tasks. However, the level of 'unknownness' varies significantly\ndepending on the context. For example, a tree is typically considered part of\nthe background in a self-driving scene, but it may be significant in a\nhousehold context. We argue that this external or contextual information should\nalready be embedded within the known classes. In other words, there should be a\nsemantic or latent structure relationship between the known and unknown items\nto be discovered. Motivated by this observation, we propose Hyp-OW, a method\nthat learns and models hierarchical representation of known items through a\nSuperClass Regularizer. Leveraging this learned representation allows us to\neffectively detect unknown objects using a Similarity Distance-based Relabeling\nmodule. Extensive experiments on benchmark datasets demonstrate the\neffectiveness of Hyp-OW achieving improvement in both known and unknown\ndetection (up to 6 points). These findings are particularly pronounced in our\nnewly designed benchmark, where a strong hierarchical structure exists between\nknown and unknown objects.\n","authors":["Thang Doan","Xin Li","Sima Behpour","Wenbin He","Liang Gou","Liu Ren"],"pdf_url":"https://arxiv.org/pdf/2306.14291v1.pdf","comment":"keywords: Open World Object Detection, Hyperbolic Distance, Unknown\n  Detection, Deformable Transformers"}],"Multimedia":[{"id":"http://arxiv.org/abs/2306.14170v1","updated":"2023-06-25T08:31:12Z","published":"2023-06-25T08:31:12Z","title":"AV-SepFormer: Cross-Attention SepFormer for Audio-Visual Target Speaker\n  Extraction","summary":"  Visual information can serve as an effective cue for target speaker\nextraction (TSE) and is vital to improving extraction performance. In this\npaper, we propose AV-SepFormer, a SepFormer-based attention dual-scale model\nthat utilizes cross- and self-attention to fuse and model features from audio\nand visual. AV-SepFormer splits the audio feature into a number of chunks,\nequivalent to the length of the visual feature. Then self- and cross-attention\nare employed to model and fuse the multi-modal features. Furthermore, we use a\nnovel 2D positional encoding, that introduces the positional information\nbetween and within chunks and provides significant gains over the traditional\npositional encoding. Our model has two key advantages: the time granularity of\naudio chunked feature is synchronized to the visual feature, which alleviates\nthe harm caused by the inconsistency of audio and video sampling rate; by\ncombining self- and cross-attention, feature fusion and speech extraction\nprocesses are unified within an attention paradigm. The experimental results\nshow that AV-SepFormer significantly outperforms other existing methods.\n","authors":["Jiuxin Lin","Xinyu Cai","Heinrich Dinkel","Jun Chen","Zhiyong Yan","Yongqing Wang","Junbo Zhang","Zhiyong Wu","Yujun Wang","Helen Meng"],"pdf_url":"https://arxiv.org/pdf/2306.14170v1.pdf","comment":"Accepted by ICASSP2023"},{"id":"http://arxiv.org/abs/2110.01013v2","updated":"2023-06-25T02:23:05Z","published":"2021-10-03T14:31:46Z","title":"Counterfactual Samples Synthesizing and Training for Robust Visual\n  Question Answering","summary":"  Today's VQA models still tend to capture superficial linguistic correlations\nin the training set and fail to generalize to the test set with different QA\ndistributions. To reduce these language biases, recent VQA works introduce an\nauxiliary question-only model to regularize the training of targeted VQA model,\nand achieve dominating performance on diagnostic benchmarks for\nout-of-distribution testing. However, due to complex model design, these\nensemble-based methods are unable to equip themselves with two indispensable\ncharacteristics of an ideal VQA model: 1) Visual-explainable: The model should\nrely on the right visual regions when making decisions. 2) Question-sensitive:\nThe model should be sensitive to the linguistic variations in questions. To\nthis end, we propose a novel model-agnostic Counterfactual Samples Synthesizing\nand Training (CSST) strategy. After training with CSST, VQA models are forced\nto focus on all critical objects and words, which significantly improves both\nvisual-explainable and question-sensitive abilities. Specifically, CSST is\ncomposed of two parts: Counterfactual Samples Synthesizing (CSS) and\nCounterfactual Samples Training (CST). CSS generates counterfactual samples by\ncarefully masking critical objects in images or words in questions and\nassigning pseudo ground-truth answers. CST not only trains the VQA models with\nboth complementary samples to predict respective ground-truth answers, but also\nurges the VQA models to further distinguish the original samples and\nsuperficially similar counterfactual ones. To facilitate the CST training, we\npropose two variants of supervised contrastive loss for VQA, and design an\neffective positive and negative sample selection mechanism based on CSS.\nExtensive experiments have shown the effectiveness of CSST. Particularly, by\nbuilding on top of model LMH+SAR, we achieve record-breaking performance on all\nOOD benchmarks.\n","authors":["Long Chen","Yuhang Zheng","Yulei Niu","Hanwang Zhang","Jun Xiao"],"pdf_url":"https://arxiv.org/pdf/2110.01013v2.pdf","comment":"IEEE Transactions on Pattern Analysis and Machine Intelligence, TPAMI\n  2023. (Extension of CVPR'20 work). arXiv admin note: text overlap with\n  arXiv:2003.06576"}]},"2023-06-24T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2306.14067v1","updated":"2023-06-24T22:00:06Z","published":"2023-06-24T22:00:06Z","title":"UAlberta at SemEval-2023 Task 1: Context Augmentation and Translation\n  for Multilingual Visual Word Sense Disambiguation","summary":"  We describe the systems of the University of Alberta team for the\nSemEval-2023 Visual Word Sense Disambiguation (V-WSD) Task. We present a novel\nalgorithm that leverages glosses retrieved from BabelNet, in combination with\ntext and image encoders. Furthermore, we compare language-specific encoders\nagainst the application of English encoders to translated texts. As the\ncontexts given in the task datasets are extremely short, we also experiment\nwith augmenting these contexts with descriptions generated by a language model.\nThis yields substantial improvements in accuracy. We describe and evaluate\nadditional V-WSD methods which use image generation and text-conditioned image\nsegmentation. Overall, the results of our official submission rank us 18 out of\n56 teams. Some of our unofficial results are even better than the official\nones. Our code is publicly available at https://github.com/UAlberta-NLP/v-wsd.\n","authors":["Michael Ogezi","Bradley Hauer","Talgat Omarov","Ning Shi","Grzegorz Kondrak"],"pdf_url":"https://arxiv.org/pdf/2306.14067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14060v1","updated":"2023-06-24T21:05:02Z","published":"2023-06-24T21:05:02Z","title":"DesCo: Learning Object Recognition with Rich Language Descriptions","summary":"  Recent development in vision-language approaches has instigated a paradigm\nshift in learning visual recognition models from language supervision. These\napproaches align objects with language queries (e.g. \"a photo of a cat\") and\nimprove the models' adaptability to identify novel objects and domains.\nRecently, several studies have attempted to query these models with complex\nlanguage expressions that include specifications of fine-grained semantic\ndetails, such as attributes, shapes, textures, and relations. However, simply\nincorporating language descriptions as queries does not guarantee accurate\ninterpretation by the models. In fact, our experiments show that GLIP, the\nstate-of-the-art vision-language model for object detection, often disregards\ncontextual information in the language descriptions and instead relies heavily\non detecting objects solely by their names. To tackle the challenges, we\npropose a new description-conditioned (DesCo) paradigm of learning object\nrecognition models with rich language descriptions consisting of two major\ninnovations: 1) we employ a large language model as a commonsense knowledge\nengine to generate rich language descriptions of objects based on object names\nand the raw image-text caption; 2) we design context-sensitive queries to\nimprove the model's ability in deciphering intricate nuances embedded within\ndescriptions and enforce the model to focus on context rather than object names\nalone. On two novel object detection benchmarks, LVIS and OminiLabel, under the\nzero-shot detection setting, our approach achieves 34.8 APr minival (+9.1) and\n29.3 AP (+3.6), respectively, surpassing the prior state-of-the-art models,\nGLIP and FIBER, by a large margin.\n","authors":["Liunian Harold Li","Zi-Yi Dou","Nanyun Peng","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2306.14060v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14050v1","updated":"2023-06-24T20:15:07Z","published":"2023-06-24T20:15:07Z","title":"Symbolic Chain-of-Thought Distillation: Small Models Can Also \"Think\"\n  Step-by-Step","summary":"  Chain-of-thought prompting (e.g., \"Let's think step-by-step\") primes large\nlanguage models to verbalize rationalization for their predictions. While\nchain-of-thought can lead to dramatic performance gains, benefits appear to\nemerge only for sufficiently large models (beyond 50B parameters). We show that\norders-of-magnitude smaller models (125M -- 1.3B parameters) can still benefit\nfrom chain-of-thought prompting. To achieve this, we introduce Symbolic\nChain-of-Thought Distillation (SCoTD), a method to train a smaller student\nmodel on rationalizations sampled from a significantly larger teacher model.\nExperiments across several commonsense benchmarks show that: 1) SCoTD enhances\nthe performance of the student model in both supervised and few-shot settings,\nand especially for challenge sets; 2) sampling many reasoning chains per\ninstance from the teacher is paramount; and 3) after distillation, student\nchain-of-thoughts are judged by humans as comparable to the teacher, despite\norders of magnitude fewer parameters. We test several hypotheses regarding what\nproperties of chain-of-thought samples are important, e.g., diversity vs.\nteacher likelihood vs. open-endedness. We release our corpus of\nchain-of-thought samples and code.\n","authors":["Liunian Harold Li","Jack Hessel","Youngjae Yu","Xiang Ren","Kai-Wei Chang","Yejin Choi"],"pdf_url":"https://arxiv.org/pdf/2306.14050v1.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2304.08453v3","updated":"2023-06-24T19:23:11Z","published":"2023-04-17T17:25:48Z","title":"Improving Autoregressive NLP Tasks via Modular Linearized Attention","summary":"  Various natural language processing (NLP) tasks necessitate models that are\nefficient and small based on their ultimate application at the edge or in other\nresource-constrained environments. While prior research has reduced the size of\nthese models, increasing computational efficiency without considerable\nperformance impacts remains difficult, especially for autoregressive tasks.\nThis paper proposes modular linearized attention (MLA), which combines multiple\nefficient attention mechanisms, including cosFormer, to maximize inference\nquality while achieving notable speedups. We validate this approach on several\nautoregressive NLP tasks, including speech-to-text neural machine translation\n(S2T NMT), speech-to-text simultaneous translation (SimulST), and\nautoregressive text-to-spectrogram, noting efficiency gains on TTS and\ncompetitive performance for NMT and SimulST during training and inference.\n","authors":["Victor Agostinelli","Lizhong Chen"],"pdf_url":"https://arxiv.org/pdf/2304.08453v3.pdf","comment":"Submitted and accepted at ECML PKDD 2023"},{"id":"http://arxiv.org/abs/2306.14040v1","updated":"2023-06-24T19:16:56Z","published":"2023-06-24T19:16:56Z","title":"Weighted Automata Extraction and Explanation of Recurrent Neural\n  Networks for Natural Language Tasks","summary":"  Recurrent Neural Networks (RNNs) have achieved tremendous success in\nprocessing sequential data, yet understanding and analyzing their behaviours\nremains a significant challenge. To this end, many efforts have been made to\nextract finite automata from RNNs, which are more amenable for analysis and\nexplanation. However, existing approaches like exact learning and compositional\napproaches for model extraction have limitations in either scalability or\nprecision. In this paper, we propose a novel framework of Weighted Finite\nAutomata (WFA) extraction and explanation to tackle the limitations for natural\nlanguage tasks. First, to address the transition sparsity and context loss\nproblems we identified in WFA extraction for natural language tasks, we propose\nan empirical method to complement missing rules in the transition diagram, and\nadjust transition matrices to enhance the context-awareness of the WFA. We also\npropose two data augmentation tactics to track more dynamic behaviours of RNN,\nwhich further allows us to improve the extraction precision. Based on the\nextracted model, we propose an explanation method for RNNs including a word\nembedding method -- Transition Matrix Embeddings (TME) and TME-based task\noriented explanation for the target RNN. Our evaluation demonstrates the\nadvantage of our method in extraction precision than existing approaches, and\nthe effectiveness of TME-based explanation method in applications to\npretraining and adversarial example generation.\n","authors":["Zeming Wei","Xiyue Zhang","Yihao Zhang","Meng Sun"],"pdf_url":"https://arxiv.org/pdf/2306.14040v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.07952v2","updated":"2023-06-24T19:16:28Z","published":"2023-06-13T17:51:18Z","title":"MOFI: Learning Image Representations from Noisy Entity Annotated Images","summary":"  We present MOFI, a new vision foundation model designed to learn image\nrepresentations from noisy entity annotated images. MOFI differs from previous\nwork in two key aspects: ($i$) pre-training data, and ($ii$) training recipe.\nRegarding data, we introduce a new approach to automatically assign entity\nlabels to images from noisy image-text pairs. Our approach involves employing a\nnamed entity recognition model to extract entities from the alt-text, and then\nusing a CLIP model to select the correct entities as labels of the paired\nimage. The approach is simple, does not require costly human annotation, and\ncan be readily scaled up to billions of image-text pairs mined from the web.\nThrough this method, we have created Image-to-Entities (I2E), a new large-scale\ndataset with 1 billion images and 2 million distinct entities, covering rich\nvisual concepts in the wild. Building upon the I2E dataset, we study different\ntraining recipes, including supervised pre-training, contrastive pre-training,\nand multi-task learning. For constrastive pre-training, we treat entity names\nas free-form text, and further enrich them with entity descriptions.\nExperiments show that supervised pre-training with large-scale fine-grained\nentity labels is highly effective for image retrieval tasks, and multi-task\ntraining further improves the performance. The final MOFI model achieves 86.66%\nmAP on the challenging GPR1200 dataset, surpassing the previous\nstate-of-the-art performance of 72.19% from OpenAI's CLIP model. Further\nexperiments on zero-shot and linear probe image classification also show that\nMOFI outperforms a CLIP model trained on the original image-text data,\ndemonstrating the effectiveness of the I2E dataset in learning strong image\nrepresentations.\n","authors":["Wentao Wu","Aleksei Timofeev","Chen Chen","Bowen Zhang","Kun Duan","Shuangning Liu","Yantao Zheng","Jon Shlens","Xianzhi Du","Zhe Gan","Yinfei Yang"],"pdf_url":"https://arxiv.org/pdf/2306.07952v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14030v1","updated":"2023-06-24T18:17:38Z","published":"2023-06-24T18:17:38Z","title":"My Boli: Code-mixed Marathi-English Corpora, Pretrained Language Models\n  and Evaluation Benchmarks","summary":"  The research on code-mixed data is limited due to the unavailability of\ndedicated code-mixed datasets and pre-trained language models. In this work, we\nfocus on the low-resource Indian language Marathi which lacks any prior work in\ncode-mixing. We present L3Cube-MeCorpus, a large code-mixed Marathi-English\n(Mr-En) corpus with 5 million tweets for pretraining. We also release\nL3Cube-MeBERT and MeRoBERTa, code-mixed BERT-based transformer models\npre-trained on MeCorpus. Furthermore, for benchmarking, we present three\nsupervised datasets MeHate, MeSent, and MeLID for downstream tasks like\ncode-mixed Mr-En hate speech detection, sentiment analysis, and language\nidentification respectively. These evaluation datasets individually consist of\nmanually annotated \\url{~}12,000 Marathi-English code-mixed tweets. Ablations\nshow that the models trained on this novel corpus significantly outperform the\nexisting state-of-the-art BERT models. This is the first work that presents\nartifacts for code-mixed Marathi research. All datasets and models are publicly\nreleased at https://github.com/l3cube-pune/MarathiNLP .\n","authors":["Tanmay Chavan","Omkar Gokhale","Aditya Kane","Shantanu Patankar","Raviraj Joshi"],"pdf_url":"https://arxiv.org/pdf/2306.14030v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11260v2","updated":"2023-06-24T16:24:27Z","published":"2023-06-20T03:25:51Z","title":"A novel Counterfactual method for aspect-based sentiment analysis","summary":"  Aspect-based-sentiment-analysis (ABSA) is a fine-grained sentiment evaluation\ntask, which analyze the emotional polarity of the evaluation aspects. However,\nprevious works only focus on the identification of opinion expressions, forget\nthat the diversity of opinion expressions also has great impacts on the ABSA\ntask. To mitigate this problem, we propose a novel counterfactual data\naugmentation method to generate opinion expression with reversed sentiment\npolarity. Specially, the integrated gradients are calculated to identify and\nmask the opinion expression. Then, a prompt with the reverse label is combined\nto the original text, and a pre-trained language model (PLM), T5, is finally\nemployed to retrieve the masks. The experimental results show the proposed\ncounterfactual data augmentation method perform better than current\naugmentation methods on three ABSA datasets, i.e. Laptop, Restaurant and MAMS.\n","authors":["Dongming Wu","Lulu Wen","Chao Chen","Zhaoshu Shi"],"pdf_url":"https://arxiv.org/pdf/2306.11260v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.06800v3","updated":"2023-06-24T15:49:31Z","published":"2022-12-13T18:34:15Z","title":"Diverse Demonstrations Improve In-context Compositional Generalization","summary":"  In-context learning has shown great success in i.i.d semantic parsing splits,\nwhere the training and test sets are drawn from the same distribution. In this\nsetup, models are typically prompted with demonstrations that are similar to\nthe input utterance. However, in the setup of compositional generalization,\nwhere models are tested on outputs with structures that are absent from the\ntraining set, selecting similar demonstrations is insufficient, as often no\nexample will be similar enough to the input. In this work, we propose a method\nto select diverse demonstrations that aims to collectively cover all of the\nstructures required in the output program, in order to encourage the model to\ngeneralize to new structures from these demonstrations. We empirically show\nthat combining diverse demonstrations with in-context learning substantially\nimproves performance across three compositional generalization semantic parsing\ndatasets in the pure in-context learning setup and when combined with\nfinetuning.\n","authors":["Itay Levy","Ben Bogin","Jonathan Berant"],"pdf_url":"https://arxiv.org/pdf/2212.06800v3.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2306.14003v1","updated":"2023-06-24T15:27:55Z","published":"2023-06-24T15:27:55Z","title":"Weakly Supervised Multi-Label Classification of Full-Text Scientific\n  Papers","summary":"  Instead of relying on human-annotated training samples to build a classifier,\nweakly supervised scientific paper classification aims to classify papers only\nusing category descriptions (e.g., category names, category-indicative\nkeywords). Existing studies on weakly supervised paper classification are less\nconcerned with two challenges: (1) Papers should be classified into not only\ncoarse-grained research topics but also fine-grained themes, and potentially\ninto multiple themes, given a large and fine-grained label space; and (2) full\ntext should be utilized to complement the paper title and abstract for\nclassification. Moreover, instead of viewing the entire paper as a long linear\nsequence, one should exploit the structural information such as citation links\nacross papers and the hierarchy of sections and paragraphs in each paper. To\ntackle these challenges, in this study, we propose FUTEX, a framework that uses\nthe cross-paper network structure and the in-paper hierarchy structure to\nclassify full-text scientific papers under weak supervision. A network-aware\ncontrastive fine-tuning module and a hierarchy-aware aggregation module are\ndesigned to leverage the two types of structural signals, respectively.\nExperiments on two benchmark datasets demonstrate that FUTEX significantly\noutperforms competitive baselines and is on par with fully supervised\nclassifiers that use 1,000 to 60,000 ground-truth training samples.\n","authors":["Yu Zhang","Bowen Jin","Xiusi Chen","Yanzhen Shen","Yunyi Zhang","Yu Meng","Jiawei Han"],"pdf_url":"https://arxiv.org/pdf/2306.14003v1.pdf","comment":"12 pages; Accepted to KDD 2023 (Code:\n  https://github.com/yuzhimanhua/FUTEX)"},{"id":"http://arxiv.org/abs/2303.14070v5","updated":"2023-06-24T15:26:44Z","published":"2023-03-24T15:29:16Z","title":"ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model\n  Meta-AI (LLaMA) Using Medical Domain Knowledge","summary":"  The primary aim of this research was to address the limitations observed in\nthe medical knowledge of prevalent large language models (LLMs) such as\nChatGPT, by creating a specialized language model with enhanced accuracy in\nmedical advice. We achieved this by adapting and refining the large language\nmodel meta-AI (LLaMA) using a large dataset of 100,000 patient-doctor dialogues\nsourced from a widely used online medical consultation platform. These\nconversations were cleaned and anonymized to respect privacy concerns. In\naddition to the model refinement, we incorporated a self-directed information\nretrieval mechanism, allowing the model to access and utilize real-time\ninformation from online sources like Wikipedia and data from curated offline\nmedical databases. The fine-tuning of the model with real-world patient-doctor\ninteractions significantly improved the model's ability to understand patient\nneeds and provide informed advice. By equipping the model with self-directed\ninformation retrieval from reliable online and offline sources, we observed\nsubstantial improvements in the accuracy of its responses. Our proposed\nChatDoctor, represents a significant advancement in medical LLMs, demonstrating\na significant improvement in understanding patient inquiries and providing\naccurate advice. Given the high stakes and low error tolerance in the medical\nfield, such enhancements in providing accurate and reliable information are not\nonly beneficial but essential.\n","authors":["Yunxiang Li","Zihan Li","Kai Zhang","Ruilong Dan","Steve Jiang","You Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.14070v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13986v1","updated":"2023-06-24T14:42:43Z","published":"2023-06-24T14:42:43Z","title":"Large Language Models as Sous Chefs: Revising Recipes with GPT-3","summary":"  With their remarkably improved text generation and prompting capabilities,\nlarge language models can adapt existing written information into forms that\nare easier to use and understand. In our work, we focus on recipes as an\nexample of complex, diverse, and widely used instructions. We develop a prompt\ngrounded in the original recipe and ingredients list that breaks recipes down\ninto simpler steps. We apply this prompt to recipes from various world\ncuisines, and experiment with several large language models (LLMs), finding\nbest results with GPT-3.5. We also contribute an Amazon Mechanical Turk task\nthat is carefully designed to reduce fatigue while collecting human judgment of\nthe quality of recipe revisions. We find that annotators usually prefer the\nrevision over the original, demonstrating a promising application of LLMs in\nserving as digital sous chefs for recipes and beyond. We release our prompt,\ncode, and MTurk template for public use.\n","authors":["Alyssa Hwang","Bryan Li","Zhaoyi Hou","Dan Roth"],"pdf_url":"https://arxiv.org/pdf/2306.13986v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13971v1","updated":"2023-06-24T13:57:32Z","published":"2023-06-24T13:57:32Z","title":"Towards Robust Aspect-based Sentiment Analysis through\n  Non-counterfactual Augmentations","summary":"  While state-of-the-art NLP models have demonstrated excellent performance for\naspect based sentiment analysis (ABSA), substantial evidence has been presented\non their lack of robustness. This is especially manifested as significant\ndegradation in performance when faced with out-of-distribution data. Recent\nsolutions that rely on counterfactually augmented datasets show promising\nresults, but they are inherently limited because of the lack of access to\nexplicit causal structure. In this paper, we present an alternative approach\nthat relies on non-counterfactual data augmentation. Our proposal instead\nrelies on using noisy, cost-efficient data augmentations that preserve\nsemantics associated with the target aspect. Our approach then relies on\nmodelling invariances between different versions of the data to improve\nrobustness. A comprehensive suite of experiments shows that our proposal\nsignificantly improves upon strong pre-trained baselines on both standard and\nrobustness-specific datasets. Our approach further establishes a new\nstate-of-the-art on the ABSA robustness benchmark and transfers well across\ndomains.\n","authors":["Xinyu Liu","Yan Ding","Kaikai An","Chunyang Xiao","Pranava Madhyastha","Tong Xiao","Jingbo Zhu"],"pdf_url":"https://arxiv.org/pdf/2306.13971v1.pdf","comment":"10pages,1 figure,10 tables"},{"id":"http://arxiv.org/abs/2306.13968v1","updated":"2023-06-24T13:51:42Z","published":"2023-06-24T13:51:42Z","title":"Fusing Multimodal Signals on Hyper-complex Space for Extreme Abstractive\n  Text Summarization (TL;DR) of Scientific Contents","summary":"  The realm of scientific text summarization has experienced remarkable\nprogress due to the availability of annotated brief summaries and ample data.\nHowever, the utilization of multiple input modalities, such as videos and\naudio, has yet to be thoroughly explored. At present, scientific\nmultimodal-input-based text summarization systems tend to employ longer target\nsummaries like abstracts, leading to an underwhelming performance in the task\nof text summarization.\n  In this paper, we deal with a novel task of extreme abstractive text\nsummarization (aka TL;DR generation) by leveraging multiple input modalities.\nTo this end, we introduce mTLDR, a first-of-its-kind dataset for the\naforementioned task, comprising videos, audio, and text, along with both\nauthor-composed summaries and expert-annotated summaries. The mTLDR dataset\naccompanies a total of 4,182 instances collected from various academic\nconference proceedings, such as ICLR, ACL, and CVPR. Subsequently, we present\nmTLDRgen, an encoder-decoder-based model that employs a novel dual-fused\nhyper-complex Transformer combined with a Wasserstein Riemannian Encoder\nTransformer, to dexterously capture the intricacies between different\nmodalities in a hyper-complex latent geometric space. The hyper-complex\nTransformer captures the intrinsic properties between the modalities, while the\nWasserstein Riemannian Encoder Transformer captures the latent structure of the\nmodalities in the latent space geometry, thereby enabling the model to produce\ndiverse sentences. mTLDRgen outperforms 20 baselines on mTLDR as well as\nanother non-scientific dataset (How2) across three Rouge-based evaluation\nmeasures. Furthermore, based on the qualitative metrics, BERTScore and FEQA,\nand human evaluations, we demonstrate that the summaries generated by mTLDRgen\nare fluent and congruent to the original source material.\n","authors":["Yash Kumar Atri","Vikram Goyal","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2306.13968v1.pdf","comment":"Accepted to ADS-SIGKDD2023"},{"id":"http://arxiv.org/abs/2306.13959v1","updated":"2023-06-24T13:22:02Z","published":"2023-06-24T13:22:02Z","title":"Emotion Flip Reasoning in Multiparty Conversations","summary":"  In a conversational dialogue, speakers may have different emotional states\nand their dynamics play an important role in understanding dialogue's emotional\ndiscourse. However, simply detecting emotions is not sufficient to entirely\ncomprehend the speaker-specific changes in emotion that occur during a\nconversation. To understand the emotional dynamics of speakers in an efficient\nmanner, it is imperative to identify the rationale or instigator behind any\nchanges or flips in emotion expressed by the speaker. In this paper, we explore\nthe task called Instigator based Emotion Flip Reasoning (EFR), which aims to\nidentify the instigator behind a speaker's emotion flip within a conversation.\nFor example, an emotion flip from joy to anger could be caused by an instigator\nlike threat. To facilitate this task, we present MELD-I, a dataset that\nincludes ground-truth EFR instigator labels, which are in line with emotional\npsychology. To evaluate the dataset, we propose a novel neural architecture\ncalled TGIF, which leverages Transformer encoders and stacked GRUs to capture\nthe dialogue context, speaker dynamics, and emotion sequence in a conversation.\nOur evaluation demonstrates state-of-the-art performance (+4-12% increase in\nF1-score) against five baselines used for the task. Further, we establish the\ngeneralizability of TGIF on an unseen dataset in a zero-shot setting.\nAdditionally, we provide a detailed analysis of the competing models,\nhighlighting the advantages and limitations of our neural architecture.\n","authors":["Shivani Kumar","Shubham Dudeja","Md Shad Akhtar","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2306.13959v1.pdf","comment":"Paper accepted in IEEE Transaction on AI. 12 pages, 5 figures, 11\n  tables"},{"id":"http://arxiv.org/abs/2306.13954v1","updated":"2023-06-24T12:56:56Z","published":"2023-06-24T12:56:56Z","title":"Characterizing the Emotion Carriers of COVID-19 Misinformation and Their\n  Impact on Vaccination Outcomes in India and the United States","summary":"  The COVID-19 Infodemic had an unprecedented impact on health behaviors and\noutcomes at a global scale. While many studies have focused on a qualitative\nand quantitative understanding of misinformation, including sentiment analysis,\nthere is a gap in understanding the emotion-carriers of misinformation and\ntheir differences across geographies. In this study, we characterized emotion\ncarriers and their impact on vaccination rates in India and the United States.\nA manually labelled dataset was created from 2.3 million tweets and collated\nwith three publicly available datasets (CoAID, AntiVax, CMU) to train deep\nlearning models for misinformation classification. Misinformation labelled\ntweets were further analyzed for behavioral aspects by leveraging Plutchik\nTransformers to determine the emotion for each tweet. Time series analysis was\nconducted to study the impact of misinformation on spatial and temporal\ncharacteristics. Further, categorical classification was performed using\ntransformer models to assign categories for the misinformation tweets.\nWord2Vec+BiLSTM was the best model for misinformation classification, with an\nF1-score of 0.92. The US had the highest proportion of misinformation tweets\n(58.02%), followed by the UK (10.38%) and India (7.33%). Disgust, anticipation,\nand anger were associated with an increased prevalence of misinformation\ntweets. Disgust was the predominant emotion associated with misinformation\ntweets in the US, while anticipation was the predominant emotion in India. For\nIndia, the misinformation rate exhibited a lead relationship with vaccination,\nwhile in the US it lagged behind vaccination. Our study deciphered that\nemotions acted as differential carriers of misinformation across geography and\ntime. These carriers can be monitored to develop strategic interventions for\ncountering misinformation, leading to improved public health.\n","authors":["Ridam Pal","Sanjana S","Deepak Mahto","Kriti Agrawal","Gopal Mengi","Sargun Nagpal","Akshaya Devadiga","Tavpritesh Sethi"],"pdf_url":"https://arxiv.org/pdf/2306.13954v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.08997v2","updated":"2023-06-24T12:39:06Z","published":"2023-06-15T09:48:14Z","title":"Exploring the MIT Mathematics and EECS Curriculum Using Large Language\n  Models","summary":"  We curate a comprehensive dataset of 4,550 questions and solutions from\nproblem sets, midterm exams, and final exams across all MIT Mathematics and\nElectrical Engineering and Computer Science (EECS) courses required for\nobtaining a degree. We evaluate the ability of large language models to fulfill\nthe graduation requirements for any MIT major in Mathematics and EECS. Our\nresults demonstrate that GPT-3.5 successfully solves a third of the entire MIT\ncurriculum, while GPT-4, with prompt engineering, achieves a perfect solve rate\non a test set excluding questions based on images. We fine-tune an open-source\nlarge language model on this dataset. We employ GPT-4 to automatically grade\nmodel responses, providing a detailed performance breakdown by course,\nquestion, and answer type. By embedding questions in a low-dimensional space,\nwe explore the relationships between questions, topics, and classes and\ndiscover which questions and classes are required for solving other questions\nand classes through few-shot learning. Our analysis offers valuable insights\ninto course prerequisites and curriculum design, highlighting language models'\npotential for learning and improving Mathematics and EECS education.\n","authors":["Sarah J. Zhang","Samuel Florin","Ariel N. Lee","Eamon Niknafs","Andrei Marginean","Annie Wang","Keith Tyser","Zad Chin","Yann Hicke","Nikhil Singh","Madeleine Udell","Yoon Kim","Tonio Buonassisi","Armando Solar-Lezama","Iddo Drori"],"pdf_url":"https://arxiv.org/pdf/2306.08997v2.pdf","comment":"Did not receive permission to release the data or model fine-tuned on\n  the data"},{"id":"http://arxiv.org/abs/2306.13947v1","updated":"2023-06-24T12:09:43Z","published":"2023-06-24T12:09:43Z","title":"Comparison of Pre-trained Language Models for Turkish Address Parsing","summary":"  Transformer based pre-trained models such as BERT and its variants, which are\ntrained on large corpora, have demonstrated tremendous success for natural\nlanguage processing (NLP) tasks. Most of academic works are based on the\nEnglish language; however, the number of multilingual and language specific\nstudies increase steadily. Furthermore, several studies claimed that language\nspecific models outperform multilingual models in various tasks. Therefore, the\ncommunity tends to train or fine-tune the models for the language of their case\nstudy, specifically. In this paper, we focus on Turkish maps data and\nthoroughly evaluate both multilingual and Turkish based BERT, DistilBERT,\nELECTRA and RoBERTa. Besides, we also propose a MultiLayer Perceptron (MLP) for\nfine-tuning BERT in addition to the standard approach of one-layer fine-tuning.\nFor the dataset, a mid-sized Address Parsing corpus taken with a relatively\nhigh quality is constructed. Conducted experiments on this dataset indicate\nthat Turkish language specific models with MLP fine-tuning yields slightly\nbetter results when compared to the multilingual fine-tuned models. Moreover,\nvisualization of address tokens' representations further indicates the\neffectiveness of BERT variants for classifying a variety of addresses.\n","authors":["Muhammed Cihat Ünal","Betül Aygün","Aydın Gerek"],"pdf_url":"https://arxiv.org/pdf/2306.13947v1.pdf","comment":"published in 16th UYMS (2023)\n  https://ekitap.atauni.edu.tr/index.php/product/16-ulusal-yazilim-muhendisligi-sempozyumu-bildiri-kitabi/"},{"id":"http://arxiv.org/abs/2207.01079v3","updated":"2023-06-24T11:55:56Z","published":"2022-07-03T17:11:17Z","title":"DiSCoMaT: Distantly Supervised Composition Extraction from Tables in\n  Materials Science Articles","summary":"  A crucial component in the curation of KB for a scientific domain is\ninformation extraction from tables in the domain's published articles -- tables\ncarry important information (often numeric), which must be adequately extracted\nfor a comprehensive machine understanding of an article. Existing table\nextractors assume prior knowledge of table structure and format, which may not\nbe known in scientific tables. We study a specific and challenging table\nextraction problem: extracting compositions of materials (e.g., glasses,\nalloys). We first observe that materials science researchers organize similar\ncompositions in a wide variety of table styles, necessitating an intelligent\nmodel for table understanding and composition extraction. Consequently, we\ndefine this novel task as a challenge for the ML community and create a\ntraining dataset comprising 4,408 distantly supervised tables, along with 1,475\nmanually annotated dev and test tables. We also present DiSCoMaT, a strong\nbaseline geared towards this specific task, which combines multiple graph\nneural networks with several task-specific regular expressions, features, and\nconstraints. We show that DiSCoMaT outperforms recent table processing\narchitectures by significant margins.\n","authors":["Tanishq Gupta","Mohd Zaki","N. M. Anoop Krishnan"," Mausam"],"pdf_url":"https://arxiv.org/pdf/2207.01079v3.pdf","comment":"Accepted long paper at ACL 2023\n  (https://2023.aclweb.org/program/accepted_main_conference/)"},{"id":"http://arxiv.org/abs/2212.10189v2","updated":"2023-06-24T11:06:55Z","published":"2022-12-20T12:00:26Z","title":"Do I have the Knowledge to Answer? Investigating Answerability of\n  Knowledge Base Questions","summary":"  When answering natural language questions over knowledge bases, missing\nfacts, incomplete schema and limited scope naturally lead to many questions\nbeing unanswerable. While answerability has been explored in other QA settings,\nit has not been studied for QA over knowledge bases (KBQA). We create\nGrailQAbility, a new benchmark KBQA dataset with unanswerability, by first\nidentifying various forms of KB incompleteness that make questions\nunanswerable, and then systematically adapting GrailQA (a popular KBQA dataset\nwith only answerable questions). Experimenting with three state-of-the-art KBQA\nmodels, we find that all three models suffer a drop in performance even after\nsuitable adaptation for unanswerable questions. In addition, these often detect\nunanswerability for wrong reasons and find specific forms of unanswerability\nparticularly difficult to handle. This underscores the need for further\nresearch in making KBQA systems robust to unanswerability\n","authors":["Mayur Patidar","Prayushi Faldu","Avinash Singh","Lovekesh Vig","Indrajit Bhattacharya"," Mausam"],"pdf_url":"https://arxiv.org/pdf/2212.10189v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13922v1","updated":"2023-06-24T10:07:01Z","published":"2023-06-24T10:07:01Z","title":"Unsupervised Mapping of Arguments of Deverbal Nouns to Their\n  Corresponding Verbal Labels","summary":"  Deverbal nouns are nominal forms of verbs commonly used in written English\ntexts to describe events or actions, as well as their arguments. However, many\nNLP systems, and in particular pattern-based ones, neglect to handle such\nnominalized constructions. The solutions that do exist for handling arguments\nof nominalized constructions are based on semantic annotation and require\nsemantic ontologies, making their applications restricted to a small set of\nnouns. We propose to adopt instead a more syntactic approach, which maps the\narguments of deverbal nouns to the universal-dependency relations of the\ncorresponding verbal construction. We present an unsupervised mechanism --\nbased on contextualized word representations -- which allows to enrich\nuniversal-dependency trees with dependency arcs denoting arguments of deverbal\nnouns, using the same labels as the corresponding verbal cases. By sharing the\nsame label set as in the verbal case, patterns that were developed for verbs\ncan be applied without modification but with high accuracy also to the nominal\nconstructions.\n","authors":["Aviv Weinstein","Yoav Goldberg"],"pdf_url":"https://arxiv.org/pdf/2306.13922v1.pdf","comment":"Accepted to Findings of ACL 2023"},{"id":"http://arxiv.org/abs/2209.13335v3","updated":"2023-06-24T10:04:14Z","published":"2022-09-27T12:40:29Z","title":"PROD: Progressive Distillation for Dense Retrieval","summary":"  Knowledge distillation is an effective way to transfer knowledge from a\nstrong teacher to an efficient student model. Ideally, we expect the better the\nteacher is, the better the student. However, this expectation does not always\ncome true. It is common that a better teacher model results in a bad student\nvia distillation due to the nonnegligible gap between teacher and student. To\nbridge the gap, we propose PROD, a PROgressive Distillation method, for dense\nretrieval. PROD consists of a teacher progressive distillation and a data\nprogressive distillation to gradually improve the student. We conduct extensive\nexperiments on five widely-used benchmarks, MS MARCO Passage, TREC Passage 19,\nTREC Document 19, MS MARCO Document and Natural Questions, where PROD achieves\nthe state-of-the-art within the distillation methods for dense retrieval. The\ncode and models will be released.\n","authors":["Zhenghao Lin","Yeyun Gong","Xiao Liu","Hang Zhang","Chen Lin","Anlei Dong","Jian Jiao","Jingwen Lu","Daxin Jiang","Rangan Majumder","Nan Duan"],"pdf_url":"https://arxiv.org/pdf/2209.13335v3.pdf","comment":"Accepted by WWW2023"},{"id":"http://arxiv.org/abs/2305.13599v3","updated":"2023-06-24T08:54:12Z","published":"2023-05-23T02:01:13Z","title":"Decoupled Rationalization with Asymmetric Learning Rates: A Flexible\n  Lipschitz Restraint","summary":"  A self-explaining rationalization model is generally constructed by a\ncooperative game where a generator selects the most human-intelligible pieces\nfrom the input text as rationales, followed by a predictor that makes\npredictions based on the selected rationales. However, such a cooperative game\nmay incur the degeneration problem where the predictor overfits to the\nuninformative pieces generated by a not yet well-trained generator and in turn,\nleads the generator to converge to a sub-optimal model that tends to select\nsenseless pieces. In this paper, we theoretically bridge degeneration with the\npredictor's Lipschitz continuity. Then, we empirically propose a simple but\neffective method named DR, which can naturally and flexibly restrain the\nLipschitz constant of the predictor, to address the problem of degeneration.\nThe main idea of DR is to decouple the generator and predictor to allocate them\nwith asymmetric learning rates. A series of experiments conducted on two widely\nused benchmarks have verified the effectiveness of the proposed method. Codes:\n\\href{https://github.com/jugechengzi/Rationalization-DR}{https://github.com/jugechengzi/Rationalization-DR}.\n","authors":["Wei Liu","Jun Wang","Haozhao Wang","Ruixuan Li","Yang Qiu","YuanKai Zhang","Jie Han","Yixiong Zou"],"pdf_url":"https://arxiv.org/pdf/2305.13599v3.pdf","comment":"KDD 2023 research track"},{"id":"http://arxiv.org/abs/2306.13906v1","updated":"2023-06-24T08:48:24Z","published":"2023-06-24T08:48:24Z","title":"Can GPT-4 Support Analysis of Textual Data in Tasks Requiring Highly\n  Specialized Domain Expertise?","summary":"  We evaluated the capability of generative pre-trained transformers~(GPT-4) in\nanalysis of textual data in tasks that require highly specialized domain\nexpertise. Specifically, we focused on the task of analyzing court opinions to\ninterpret legal concepts. We found that GPT-4, prompted with annotation\nguidelines, performs on par with well-trained law student annotators. We\nobserved that, with a relatively minor decrease in performance, GPT-4 can\nperform batch predictions leading to significant cost reductions. However,\nemploying chain-of-thought prompting did not lead to noticeably improved\nperformance on this task. Further, we demonstrated how to analyze GPT-4's\npredictions to identify and mitigate deficiencies in annotation guidelines, and\nsubsequently improve the performance of the model. Finally, we observed that\nthe model is quite brittle, as small formatting related changes in the prompt\nhad a high impact on the predictions. These findings can be leveraged by\nresearchers and practitioners who engage in semantic/pragmatic annotations of\ntexts in the context of the tasks requiring highly specialized domain\nexpertise.\n","authors":["Jaromir Savelka","Kevin D. Ashley","Morgan A Gray","Hannes Westermann","Huihui Xu"],"pdf_url":"https://arxiv.org/pdf/2306.13906v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13905v1","updated":"2023-06-24T08:45:47Z","published":"2023-06-24T08:45:47Z","title":"Spatio-temporal Storytelling? Leveraging Generative Models for Semantic\n  Trajectory Analysis","summary":"  In this paper, we lay out a vision for analysing semantic trajectory traces\nand generating synthetic semantic trajectory data (SSTs) using generative\nlanguage model. Leveraging the advancements in deep learning, as evident by\nprogress in the field of natural language processing (NLP), computer vision,\netc. we intend to create intelligent models that can study the semantic\ntrajectories in various contexts, predicting future trends, increasing machine\nunderstanding of the movement of animals, humans, goods, etc. enhancing\nhuman-computer interactions, and contributing to an array of applications\nranging from urban-planning to personalized recommendation engines and business\nstrategy.\n","authors":["Shreya Ghosh","Saptarshi Sengupta","Prasenjit Mitra"],"pdf_url":"https://arxiv.org/pdf/2306.13905v1.pdf","comment":"8 pages, 1 figure, Submitted for peer review"},{"id":"http://arxiv.org/abs/2306.13899v1","updated":"2023-06-24T08:27:39Z","published":"2023-06-24T08:27:39Z","title":"Math Word Problem Solving by Generating Linguistic Variants of Problem\n  Statements","summary":"  The art of mathematical reasoning stands as a fundamental pillar of\nintellectual progress and is a central catalyst in cultivating human ingenuity.\nResearchers have recently published a plethora of works centered around the\ntask of solving Math Word Problems (MWP) $-$ a crucial stride towards general\nAI. These existing models are susceptible to dependency on shallow heuristics\nand spurious correlations to derive the solution expressions. In order to\nameliorate this issue, in this paper, we propose a framework for MWP solvers\nbased on the generation of linguistic variants of the problem text. The\napproach involves solving each of the variant problems and electing the\npredicted expression with the majority of the votes. We use DeBERTa\n(Decoding-enhanced BERT with disentangled attention) as the encoder to leverage\nits rich textual representations and enhanced mask decoder to construct the\nsolution expressions. Furthermore, we introduce a challenging dataset,\n$\\mathrm{P\\small{ARA}\\normalsize{MAWPS}}$, consisting of paraphrased,\nadversarial, and inverse variants of selectively sampled MWPs from the\nbenchmark $\\mathrm{M\\small{AWPS}}$ dataset. We extensively experiment on this\ndataset along with other benchmark datasets using some baseline MWP solver\nmodels. We show that training on linguistic variants of problem statements and\nvoting on candidate predictions improve the mathematical reasoning and\nrobustness of the model. We make our code and data publicly available.\n","authors":["Syed Rifat Raiyan","Md. Nafis Faiyaz","Shah Md. Jawad Kabir","Mohsinul Kabir","Hasan Mahmud","Md Kamrul Hasan"],"pdf_url":"https://arxiv.org/pdf/2306.13899v1.pdf","comment":"Accepted in Proceedings of the 61st Annual Meeting of the Association\n  for Computational Linguistics: Student Research Workshop (ACL-SRW 2023), 17\n  pages, 2 figures, 7 tables"},{"id":"http://arxiv.org/abs/2306.13891v1","updated":"2023-06-24T07:45:38Z","published":"2023-06-24T07:45:38Z","title":"Estimating the Causal Effect of Early ArXiving on Paper Acceptance","summary":"  What is the effect of releasing a preprint of a paper before it is submitted\nfor peer review? No randomized controlled trial has been conducted, so we turn\nto observational data to answer this question. We use data from the ICLR\nconference (2018--2022) and apply methods from causal inference to estimate the\neffect of arXiving a paper before the reviewing period (early arXiving) on its\nacceptance to the conference. Adjusting for 18 confounders such as topic,\nauthors, and quality, we may estimate the causal effect. However, since quality\nis a challenging construct to estimate, we use the negative outcome control\nmethod, using paper citation count as a control variable to debias the quality\nconfounding effect. Our results suggest that early arXiving may have a small\neffect on a paper's chances of acceptance. However, this effect (when existing)\ndoes not differ significantly across different groups of authors, as grouped by\nauthor citation count and institute rank. This suggests that early arXiving\ndoes not provide an advantage to any particular group.\n","authors":["Yanai Elazar","Jiayao Zhang","David Wadden","Bo Zhang","Noah A. Smith"],"pdf_url":"https://arxiv.org/pdf/2306.13891v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.05940v3","updated":"2023-06-24T07:43:35Z","published":"2023-05-10T07:24:36Z","title":"Multilingual LLMs are Better Cross-lingual In-context Learners with\n  Alignment","summary":"  In-context learning (ICL) unfolds as large language models become capable of\ninferring test labels conditioned on a few labeled samples without any gradient\nupdate. ICL-enabled large language models provide a promising step forward\ntoward bypassing recurrent annotation costs in a low-resource setting. Yet,\nonly a handful of past studies have explored ICL in a cross-lingual setting, in\nwhich the need for transferring label-knowledge from a high-resource language\nto a low-resource one is immensely crucial. To bridge the gap, we provide the\nfirst in-depth analysis of ICL for cross-lingual text classification. We find\nthat the prevalent mode of selecting random input-label pairs to construct the\nprompt-context is severely limited in the case of cross-lingual ICL, primarily\ndue to the lack of alignment in the input as well as the output spaces. To\nmitigate this, we propose a novel prompt construction strategy -- Cross-lingual\nIn-context Source-Target Alignment (X-InSTA). With an injected coherence in the\nsemantics of the input examples and a task-based alignment across the source\nand target languages, X-InSTA is able to outperform random prompt selection by\na large margin across three different tasks using 44 different cross-lingual\npairs.\n","authors":["Eshaan Tanwar","Subhabrata Dutta","Manish Borthakur","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2305.05940v3.pdf","comment":"Accepted in ACL 2023. Code available at\n  https://github.com/EshaanT/X-InSTA"},{"id":"http://arxiv.org/abs/2306.13888v1","updated":"2023-06-24T07:27:53Z","published":"2023-06-24T07:27:53Z","title":"L3Cube-MahaSent-MD: A Multi-domain Marathi Sentiment Analysis Dataset\n  and Transformer Models","summary":"  The exploration of sentiment analysis in low-resource languages, such as\nMarathi, has been limited due to the availability of suitable datasets. In this\nwork, we present L3Cube-MahaSent-MD, a multi-domain Marathi sentiment analysis\ndataset, with four different domains - movie reviews, general tweets, TV show\nsubtitles, and political tweets. The dataset consists of around 60,000 manually\ntagged samples covering 3 distinct sentiments - positive, negative, and\nneutral. We create a sub-dataset for each domain comprising 15k samples. The\nMahaSent-MD is the first comprehensive multi-domain sentiment analysis dataset\nwithin the Indic sentiment landscape. We fine-tune different monolingual and\nmultilingual BERT models on these datasets and report the best accuracy with\nthe MahaBERT model. We also present an extensive in-domain and cross-domain\nanalysis thus highlighting the need for low-resource multi-domain datasets. The\ndata and models are available at https://github.com/l3cube-pune/MarathiNLP .\n","authors":["Aabha Pingle","Aditya Vyawahare","Isha Joshi","Rahul Tangsali","Raviraj Joshi"],"pdf_url":"https://arxiv.org/pdf/2306.13888v1.pdf","comment":"Accepted at DMLR Workshop @ ICML 2023"},{"id":"http://arxiv.org/abs/2306.00013v2","updated":"2023-06-24T07:12:20Z","published":"2023-05-30T07:36:12Z","title":"Machine Learning Approach for Cancer Entities Association and\n  Classification","summary":"  According to the World Health Organization (WHO), cancer is the second\nleading cause of death globally. Scientific research on different types of\ncancers grows at an ever-increasing rate, publishing large volumes of research\narticles every year. The insight information and the knowledge of the drug,\ndiagnostics, risk, symptoms, treatments, etc., related to genes are significant\nfactors that help explore and advance the cancer research progression. Manual\nscreening of such a large volume of articles is very laborious and\ntime-consuming to formulate any hypothesis. The study uses the two most\nnon-trivial NLP, Natural Language Processing functions, Entity Recognition, and\ntext classification to discover knowledge from biomedical literature. Named\nEntity Recognition (NER) recognizes and extracts the predefined entities\nrelated to cancer from unstructured text with the support of a user-friendly\ninterface and built-in dictionaries. Text classification helps to explore the\ninsights into the text and simplifies data categorization, querying, and\narticle screening. Machine learning classifiers are also used to build the\nclassification model and Structured Query Languages (SQL) is used to identify\nthe hidden relations that may lead to significant predictions.\n","authors":["G. Jeyakodi","Arkadeep Pal","Debapratim Gupta","K. Sarukeswari","V. Amouda"],"pdf_url":"https://arxiv.org/pdf/2306.00013v2.pdf","comment":"This paper got accepted for paper presentation at the International\n  Conference on Knowledge Discoveries on Statistical Innovations and Recent\n  Advances in Optimization (ICON-KSRAO) on 29th and 30th December 2022"},{"id":"http://arxiv.org/abs/2304.01295v2","updated":"2023-06-24T06:18:33Z","published":"2023-04-03T18:46:01Z","title":"Efficiently Aligned Cross-Lingual Transfer Learning for Conversational\n  Tasks using Prompt-Tuning","summary":"  Cross-lingual transfer of language models trained on high-resource languages\nlike English has been widely studied for many NLP tasks, but focus on\nconversational tasks has been rather limited. This is partly due to the high\ncost of obtaining non-English conversational data, which results in limited\ncoverage. In this work, we introduce XSGD, a parallel and large-scale\nmultilingual conversation dataset that we created by translating the\nEnglish-only Schema-Guided Dialogue (SGD) dataset (Rastogi et al., 2020) into\n105 other languages. XSGD contains approximately 330k utterances per language.\nTo facilitate aligned cross-lingual representations, we develop an efficient\nprompt-tuning-based method for learning alignment prompts. We also investigate\ntwo different classifiers: NLI-based and vanilla classifiers, and test\ncross-lingual capability enabled by the aligned prompts. We evaluate our\nmodel's cross-lingual generalization capabilities on two conversation tasks:\nslot-filling and intent classification. Our results demonstrate the strong and\nefficient modeling ability of NLI-based classifiers and the large cross-lingual\ntransfer improvements achieved by our aligned prompts, particularly in few-shot\nsettings. In addition, we highlight the nice results of our approach compared\nto LLMs such as text-davinci-003 and ChatGPT in both zero-shot and few-shot\nsettings. While LLMs exhibit impressive performance in English, their\ncross-lingual capabilities in other languages, particularly low-resource\nlanguages, are limited.\n","authors":["Lifu Tu","Jin Qu","Semih Yavuz","Shafiq Joty","Wenhao Liu","Caiming Xiong","Yingbo Zhou"],"pdf_url":"https://arxiv.org/pdf/2304.01295v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13865v1","updated":"2023-06-24T05:02:34Z","published":"2023-06-24T05:02:34Z","title":"IERL: Interpretable Ensemble Representation Learning -- Combining\n  CrowdSourced Knowledge and Distributed Semantic Representations","summary":"  Large Language Models (LLMs) encode meanings of words in the form of\ndistributed semantics. Distributed semantics capture common statistical\npatterns among language tokens (words, phrases, and sentences) from large\namounts of data. LLMs perform exceedingly well across General Language\nUnderstanding Evaluation (GLUE) tasks designed to test a model's understanding\nof the meanings of the input tokens. However, recent studies have shown that\nLLMs tend to generate unintended, inconsistent, or wrong texts as outputs when\nprocessing inputs that were seen rarely during training, or inputs that are\nassociated with diverse contexts (e.g., well-known hallucination phenomenon in\nlanguage generation tasks). Crowdsourced and expert-curated knowledge graphs\nsuch as ConceptNet are designed to capture the meaning of words from a compact\nset of well-defined contexts. Thus LLMs may benefit from leveraging such\nknowledge contexts to reduce inconsistencies in outputs. We propose a novel\nensemble learning method, Interpretable Ensemble Representation Learning\n(IERL), that systematically combines LLM and crowdsourced knowledge\nrepresentations of input tokens. IERL has the distinct advantage of being\ninterpretable by design (when was the LLM context used vs. when was the\nknowledge context used?) over state-of-the-art (SOTA) methods, allowing\nscrutiny of the inputs in conjunction with the parameters of the model,\nfacilitating the analysis of models' inconsistent or irrelevant outputs.\nAlthough IERL is agnostic to the choice of LLM and crowdsourced knowledge, we\ndemonstrate our approach using BERT and ConceptNet. We report improved or\ncompetitive results with IERL across GLUE tasks over current SOTA methods and\nsignificantly enhanced model interpretability.\n","authors":["Yuxin Zi","Kaushik Roy","Vignesh Narayanan","Manas Gaur","Amit Sheth"],"pdf_url":"https://arxiv.org/pdf/2306.13865v1.pdf","comment":"Accepted for publication at the KDD workshop on Knowledge-infused\n  Machine Learning, 2023"},{"id":"http://arxiv.org/abs/2210.04307v2","updated":"2023-06-24T04:33:03Z","published":"2022-10-09T17:23:49Z","title":"KSAT: Knowledge-infused Self Attention Transformer -- Integrating\n  Multiple Domain-Specific Contexts","summary":"  Domain-specific language understanding requires integrating multiple pieces\nof relevant contextual information. For example, we see both suicide and\ndepression-related behavior (multiple contexts) in the text ``I have a gun and\nfeel pretty bad about my life, and it wouldn't be the worst thing if I didn't\nwake up tomorrow''. Domain specificity in self-attention architectures is\nhandled by fine-tuning on excerpts from relevant domain specific resources\n(datasets and external knowledge - medical textbook chapters on mental health\ndiagnosis related to suicide and depression). We propose a modified\nself-attention architecture Knowledge-infused Self Attention Transformer (KSAT)\nthat achieves the integration of multiple domain-specific contexts through the\nuse of external knowledge sources. KSAT introduces knowledge-guided biases in\ndedicated self-attention layers for each knowledge source to accomplish this.\nIn addition, KSAT provides mechanics for controlling the trade-off between\nlearning from data and learning from knowledge. Our quantitative and\nqualitative evaluations show that (1) the KSAT architecture provides novel\nhuman-understandable ways to precisely measure and visualize the contributions\nof the infused domain contexts, and (2) KSAT performs competitively with other\nknowledge-infused baselines and significantly outperforms baselines that use\nfine-tuning for domain-specific tasks.\n","authors":["Kaushik Roy","Yuxin Zi","Vignesh Narayanan","Manas Gaur","Amit Sheth"],"pdf_url":"https://arxiv.org/pdf/2210.04307v2.pdf","comment":"Preprint version of paper accepted for publication at KDD workshop on\n  Knowledge Augmented Methods for NLP, 2023"},{"id":"http://arxiv.org/abs/2306.13841v1","updated":"2023-06-24T02:26:45Z","published":"2023-06-24T02:26:45Z","title":"Is Pre-training Truly Better Than Meta-Learning?","summary":"  In the context of few-shot learning, it is currently believed that a fixed\npre-trained (PT) model, along with fine-tuning the final layer during\nevaluation, outperforms standard meta-learning algorithms. We re-evaluate these\nclaims under an in-depth empirical examination of an extensive set of formally\ndiverse datasets and compare PT to Model Agnostic Meta-Learning (MAML). Unlike\nprevious work, we emphasize a fair comparison by using: the same architecture,\nthe same optimizer, and all models trained to convergence. Crucially, we use a\nmore rigorous statistical tool -- the effect size (Cohen's d) -- to determine\nthe practical significance of the difference between a model trained with PT\nvs. a MAML. We then use a previously proposed metric -- the diversity\ncoefficient -- to compute the average formal diversity of a dataset. Using this\nanalysis, we demonstrate the following: 1. when the formal diversity of a data\nset is low, PT beats MAML on average and 2. when the formal diversity is high,\nMAML beats PT on average. The caveat is that the magnitude of the average\ndifference between a PT vs. MAML using the effect size is low (according to\nclassical statistical thresholds) -- less than 0.2. Nevertheless, this\nobservation is contrary to the currently held belief that a pre-trained model\nis always better than a meta-learning model. Our extensive experiments consider\n21 few-shot learning benchmarks, including the large-scale few-shot learning\ndataset Meta-Data set. We also show no significant difference between a MAML\nmodel vs. a PT model with GPT-2 on Openwebtext. We, therefore, conclude that a\npre-trained model does not always beat a meta-learned model and that the formal\ndiversity of a dataset is a driving factor.\n","authors":["Brando Miranda","Patrick Yu","Saumya Goyal","Yu-Xiong Wang","Sanmi Koyejo"],"pdf_url":"https://arxiv.org/pdf/2306.13841v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13840v1","updated":"2023-06-24T02:25:56Z","published":"2023-06-24T02:25:56Z","title":"Beyond Scale: the Diversity Coefficient as a Data Quality Metric\n  Demonstrates LLMs are Pre-trained on Formally Diverse Data","summary":"  Current trends to pre-train capable Large Language Models (LLMs) mostly focus\non scaling of model and dataset size. However, the quality of pre-training data\nis an important factor for training powerful LLMs, yet it is a nebulous concept\nthat has not been fully characterized. Therefore, we use the recently proposed\nTask2Vec diversity coefficient to ground and understand formal aspects of data\nquality, to go beyond scale alone. Specifically, we measure the diversity\ncoefficient of publicly available pre-training datasets to demonstrate that\ntheir formal diversity is high when compared to theoretical lower and upper\nbounds. In addition, to build confidence in the diversity coefficient, we\nconduct interpretability experiments and find that the coefficient aligns with\nintuitive properties of diversity, e.g., it increases as the number of latent\nconcepts increases. We conclude the diversity coefficient is reliable, show\nit's high for publicly available LLM datasets, and conjecture it can be used to\nbuild useful diverse datasets for LLMs.\n","authors":["Alycia Lee","Brando Miranda","Sanmi Koyejo"],"pdf_url":"https://arxiv.org/pdf/2306.13840v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.01772v2","updated":"2023-06-24T00:16:51Z","published":"2022-07-05T02:18:49Z","title":"Vision-and-Language Pretraining","summary":"  With the burgeoning amount of data of image-text pairs and diversity of\nVision-and-Language (V\\&L) tasks, scholars have introduced an abundance of deep\nlearning models in this research domain. Furthermore, in recent years, transfer\nlearning has also shown tremendous success in Computer Vision for tasks such as\nImage Classification, Object Detection, etc., and in Natural Language\nProcessing for Question Answering, Machine Translation, etc. Inheriting the\nspirit of Transfer Learning, research works in V\\&L have devised multiple\npretraining techniques on large-scale datasets in order to enhance the\nperformance of downstream tasks. The aim of this article is to provide a\ncomprehensive revision of contemporary V\\&L pretraining models. In particular,\nwe categorize and delineate pretraining approaches, along with the summary of\nstate-of-the-art vision-and-language pretrained models. Moreover, a list of\ntraining datasets and downstream tasks is supplied to further polish the\nperspective into V\\&L pretraining. Lastly, we decided to take a further step to\ndiscuss numerous directions for future research.\n","authors":["Thong Nguyen","Cong-Duy Nguyen","Xiaobao Wu","See-Kiong Ng","Anh Tuan Luu"],"pdf_url":"https://arxiv.org/pdf/2207.01772v2.pdf","comment":"46 pages, 2 figures"},{"id":"http://arxiv.org/abs/2004.02913v3","updated":"2023-06-24T22:04:37Z","published":"2020-04-06T18:03:06Z","title":"Speaker-change Aware CRF for Dialogue Act Classification","summary":"  Recent work in Dialogue Act (DA) classification approaches the task as a\nsequence labeling problem, using neural network models coupled with a\nConditional Random Field (CRF) as the last layer. CRF models the conditional\nprobability of the target DA label sequence given the input utterance sequence.\nHowever, the task involves another important input sequence, that of speakers,\nwhich is ignored by previous work. To address this limitation, this paper\nproposes a simple modification of the CRF layer that takes speaker-change into\naccount. Experiments on the SwDA corpus show that our modified CRF layer\noutperforms the original one, with very wide margins for some DA labels.\nFurther, visualizations demonstrate that our CRF layer can learn meaningful,\nsophisticated transition patterns between DA label pairs conditioned on\nspeaker-change in an end-to-end way. Code is publicly available.\n","authors":["Guokan Shang","Antoine Jean-Pierre Tixier","Michalis Vazirgiannis","Jean-Pierre Lorré"],"pdf_url":"https://arxiv.org/pdf/2004.02913v3.pdf","comment":"typo fix: argmin -> argmax"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2304.11029v3","updated":"2023-06-24T15:04:28Z","published":"2023-04-21T15:23:00Z","title":"CLaMP: Contrastive Language-Music Pre-training for Cross-Modal Symbolic\n  Music Information Retrieval","summary":"  We introduce CLaMP: Contrastive Language-Music Pre-training, which learns\ncross-modal representations between natural language and symbolic music using a\nmusic encoder and a text encoder trained jointly with a contrastive loss. To\npre-train CLaMP, we collected a large dataset of 1.4 million music-text pairs.\nIt employed text dropout as a data augmentation technique and bar patching to\nefficiently represent music data which reduces sequence length to less than\n10%. In addition, we developed a masked music model pre-training objective to\nenhance the music encoder's comprehension of musical context and structure.\nCLaMP integrates textual information to enable semantic search and zero-shot\nclassification for symbolic music, surpassing the capabilities of previous\nmodels. To support the evaluation of semantic search and music classification,\nwe publicly release WikiMusicText (WikiMT), a dataset of 1010 lead sheets in\nABC notation, each accompanied by a title, artist, genre, and description. In\ncomparison to state-of-the-art models that require fine-tuning, zero-shot CLaMP\ndemonstrated comparable or superior performance on score-oriented datasets. Our\nmodels and code are available at\nhttps://github.com/microsoft/muzic/tree/main/clamp.\n","authors":["Shangda Wu","Dingyao Yu","Xu Tan","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2304.11029v3.pdf","comment":"11 pages, 5 figures, 5 tables, accepted by ISMIR 2023"},{"id":"http://arxiv.org/abs/2207.01079v3","updated":"2023-06-24T11:55:56Z","published":"2022-07-03T17:11:17Z","title":"DiSCoMaT: Distantly Supervised Composition Extraction from Tables in\n  Materials Science Articles","summary":"  A crucial component in the curation of KB for a scientific domain is\ninformation extraction from tables in the domain's published articles -- tables\ncarry important information (often numeric), which must be adequately extracted\nfor a comprehensive machine understanding of an article. Existing table\nextractors assume prior knowledge of table structure and format, which may not\nbe known in scientific tables. We study a specific and challenging table\nextraction problem: extracting compositions of materials (e.g., glasses,\nalloys). We first observe that materials science researchers organize similar\ncompositions in a wide variety of table styles, necessitating an intelligent\nmodel for table understanding and composition extraction. Consequently, we\ndefine this novel task as a challenge for the ML community and create a\ntraining dataset comprising 4,408 distantly supervised tables, along with 1,475\nmanually annotated dev and test tables. We also present DiSCoMaT, a strong\nbaseline geared towards this specific task, which combines multiple graph\nneural networks with several task-specific regular expressions, features, and\nconstraints. We show that DiSCoMaT outperforms recent table processing\narchitectures by significant margins.\n","authors":["Tanishq Gupta","Mohd Zaki","N. M. Anoop Krishnan"," Mausam"],"pdf_url":"https://arxiv.org/pdf/2207.01079v3.pdf","comment":"Accepted long paper at ACL 2023\n  (https://2023.aclweb.org/program/accepted_main_conference/)"},{"id":"http://arxiv.org/abs/2209.13335v3","updated":"2023-06-24T10:04:14Z","published":"2022-09-27T12:40:29Z","title":"PROD: Progressive Distillation for Dense Retrieval","summary":"  Knowledge distillation is an effective way to transfer knowledge from a\nstrong teacher to an efficient student model. Ideally, we expect the better the\nteacher is, the better the student. However, this expectation does not always\ncome true. It is common that a better teacher model results in a bad student\nvia distillation due to the nonnegligible gap between teacher and student. To\nbridge the gap, we propose PROD, a PROgressive Distillation method, for dense\nretrieval. PROD consists of a teacher progressive distillation and a data\nprogressive distillation to gradually improve the student. We conduct extensive\nexperiments on five widely-used benchmarks, MS MARCO Passage, TREC Passage 19,\nTREC Document 19, MS MARCO Document and Natural Questions, where PROD achieves\nthe state-of-the-art within the distillation methods for dense retrieval. The\ncode and models will be released.\n","authors":["Zhenghao Lin","Yeyun Gong","Xiao Liu","Hang Zhang","Chen Lin","Anlei Dong","Jian Jiao","Jingwen Lu","Daxin Jiang","Rangan Majumder","Nan Duan"],"pdf_url":"https://arxiv.org/pdf/2209.13335v3.pdf","comment":"Accepted by WWW2023"},{"id":"http://arxiv.org/abs/2306.13887v1","updated":"2023-06-24T07:27:43Z","published":"2023-06-24T07:27:43Z","title":"Cross-domain Recommender Systems via Multimodal Domain Adaptation","summary":"  Collaborative Filtering (CF) has emerged as one of the most prominent\nimplementation strategies for building recommender systems. The key idea is to\nexploit the usage patterns of individuals to generate personalized\nrecommendations. CF techniques, especially for newly launched platforms, often\nface a critical issue known as the data sparsity problem, which greatly limits\ntheir performance. Several approaches have been proposed in the literature to\ntackle the problem of data sparsity, among which cross-domain collaborative\nfiltering (CDCF) has gained significant attention in the recent past. In order\nto compensate for the scarcity of available feedback in a target domain, the\nCDCF approach makes use of information available in other auxiliary domains.\nMost of the traditional CDCF approach aim is to find a common set of entities\n(users or items) across the domains and then use them as a bridge for knowledge\ntransfer. However, most real-world datasets are collected from different\ndomains, so they often lack information about anchor points or reference\ninformation for entity alignment. In this paper, we propose a domain adaptation\ntechnique to align the embeddings of users and items across the two domains.\nOur approach first exploits the available textual and visual information to\nindependently learn a multi-view latent representation for each user and item\nin the auxiliary and target domains. The different representations of a user or\nitem are then fused to generate the corresponding unified representation. A\ndomain classifier is then trained to learn the embedding for the domain\nalignment by fixing the unified features as the anchor points. Experiments on\ntwo publicly benchmark datasets indicate the effectiveness of our proposed\napproach.\n","authors":["Ramya Kamani","Vikas Kumar","Venkateswara Rao Kagita"],"pdf_url":"https://arxiv.org/pdf/2306.13887v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2306.13837v1","updated":"2023-06-24T01:54:49Z","published":"2023-06-24T01:54:49Z","title":"DEKGCI: A double-sided recommendation model for integrating knowledge\n  graph and user-item interaction graph","summary":"  Both knowledge graphs and user-item interaction graphs are frequently used in\nrecommender systems due to their ability to provide rich information for\nmodeling users and items. However, existing studies often focused on one of\nthese sources (either the knowledge graph or the user-item interaction graph),\nresulting in underutilization of the benefits that can be obtained by\nintegrating both sources of information. In this paper, we propose DEKGCI, a\nnovel double-sided recommendation model. In DEKGCI, we use the high-order\ncollaborative signals from the user-item interaction graph to enrich the user\nrepresentations on the user side. Additionally, we utilize the high-order\nstructural and semantic information from the knowledge graph to enrich the item\nrepresentations on the item side. DEKGCI simultaneously learns the user and\nitem representations to effectively capture the joint interactions between\nusers and items. Three real-world datasets are adopted in the experiments to\nevaluate DEKGCI's performance, and experimental results demonstrate its high\neffectiveness compared to seven state-of-the-art baselines in terms of AUC and\nACC.\n","authors":["Yajing Yang","Zeyu Zeng","Mao Chen","Ruirui Shang"],"pdf_url":"https://arxiv.org/pdf/2306.13837v1.pdf","comment":"24 pages, 6 figures,6 tables"}]},"2023-06-23T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2306.13817v1","updated":"2023-06-23T23:53:49Z","published":"2023-06-23T23:53:49Z","title":"The Double Helix inside the NLP Transformer","summary":"  We introduce a framework for analyzing various types of information in an NLP\nTransformer. In this approach, we distinguish four layers of information:\npositional, syntactic, semantic, and contextual. We also argue that the common\npractice of adding positional information to semantic embedding is sub-optimal\nand propose instead a Linear-and-Add approach. Our analysis reveals an\nautogenetic separation of positional information through the deep layers. We\nshow that the distilled positional components of the embedding vectors follow\nthe path of a helix, both on the encoder side and on the decoder side. We\nadditionally show that on the encoder side, the conceptual dimensions generate\nPart-of-Speech (PoS) clusters. On the decoder side, we show that a di-gram\napproach helps to reveal the PoS clusters of the next token. Our approach paves\na way to elucidate the processing of information through the deep layers of an\nNLP Transformer.\n","authors":["Jason H. J. Lu","Qingzhen Guo"],"pdf_url":"https://arxiv.org/pdf/2306.13817v1.pdf","comment":"Submitted to IEEE Transactions on Neural Networks and Learning\n  Systems 21-Jun-2023. 12 pages, 14 figures"},{"id":"http://arxiv.org/abs/2306.13804v1","updated":"2023-06-23T22:38:32Z","published":"2023-06-23T22:38:32Z","title":"Cross-Language Speech Emotion Recognition Using Multimodal Dual\n  Attention Transformers","summary":"  Despite the recent progress in speech emotion recognition (SER),\nstate-of-the-art systems are unable to achieve improved performance in\ncross-language settings. In this paper, we propose a Multimodal Dual Attention\nTransformer (MDAT) model to improve cross-language SER. Our model utilises\npre-trained models for multimodal feature extraction and is equipped with a\ndual attention mechanism including graph attention and co-attention to capture\ncomplex dependencies across different modalities and achieve improved\ncross-language SER results using minimal target language data. In addition, our\nmodel also exploits a transformer encoder layer for high-level feature\nrepresentation to improve emotion classification accuracy. In this way, MDAT\nperforms refinement of feature representation at various stages and provides\nemotional salient features to the classification layer. This novel approach\nalso ensures the preservation of modality-specific emotional information while\nenhancing cross-modality and cross-language interactions. We assess our model's\nperformance on four publicly available SER datasets and establish its superior\neffectiveness compared to recent approaches and baseline models.\n","authors":["Syed Aun Muhammad Zaidi","Siddique Latif","Junaid Qadi"],"pdf_url":"https://arxiv.org/pdf/2306.13804v1.pdf","comment":"Under Review IEEE TMM"},{"id":"http://arxiv.org/abs/2306.13797v1","updated":"2023-06-23T22:10:05Z","published":"2023-06-23T22:10:05Z","title":"An analysis of vaccine-related sentiments from development to deployment\n  of COVID-19 vaccines","summary":"  Anti-vaccine sentiments have been well-known and reported throughout the\nhistory of viral outbreaks and vaccination programmes. The COVID-19 pandemic\nhad fear and uncertainty about vaccines which has been well expressed on social\nmedia platforms such as Twitter. We analyse Twitter sentiments from the\nbeginning of the COVID-19 pandemic and study the public behaviour during the\nplanning, development and deployment of vaccines expressed in tweets worldwide\nusing a sentiment analysis framework via deep learning models. In this way, we\nprovide visualisation and analysis of anti-vaccine sentiments over the course\nof the COVID-19 pandemic. Our results show a link between the number of tweets,\nthe number of cases, and the change in sentiment polarity scores during major\nwaves of COVID-19 cases. We also found that the first half of the pandemic had\ndrastic changes in the sentiment polarity scores that later stabilised which\nimplies that the vaccine rollout had an impact on the nature of discussions on\nsocial media.\n","authors":["Rohitash Chandra","Jayesh Sonawane","Janhavi Lande","Cathy Yu"],"pdf_url":"https://arxiv.org/pdf/2306.13797v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01006v2","updated":"2023-06-23T22:03:54Z","published":"2023-05-31T17:54:07Z","title":"Scaling Evidence-based Instructional Design Expertise through Large\n  Language Models","summary":"  This paper presents a comprehensive exploration of leveraging Large Language\nModels (LLMs), specifically GPT-4, in the field of instructional design. With a\nfocus on scaling evidence-based instructional design expertise, our research\naims to bridge the gap between theoretical educational studies and practical\nimplementation. We discuss the benefits and limitations of AI-driven content\ngeneration, emphasizing the necessity of human oversight in ensuring the\nquality of educational materials. This work is elucidated through two detailed\ncase studies where we applied GPT-4 in creating complex higher-order\nassessments and active learning components for different courses. From our\nexperiences, we provide best practices for effectively using LLMs in\ninstructional design tasks, such as utilizing templates, fine-tuning, handling\nunexpected output, implementing LLM chains, citing references, evaluating\noutput, creating rubrics, grading, and generating distractors. We also share\nour vision of a future recommendation system, where a customized GPT-4 extracts\ninstructional design principles from educational studies and creates\npersonalized, evidence-supported strategies for users' unique educational\ncontexts. Our research contributes to understanding and optimally harnessing\nthe potential of AI-driven language models in enhancing educational outcomes.\n","authors":["Gautam Yadav"],"pdf_url":"https://arxiv.org/pdf/2306.01006v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13789v1","updated":"2023-06-23T21:25:38Z","published":"2023-06-23T21:25:38Z","title":"Deconstructing Classifiers: Towards A Data Reconstruction Attack Against\n  Text Classification Models","summary":"  Natural language processing (NLP) models have become increasingly popular in\nreal-world applications, such as text classification. However, they are\nvulnerable to privacy attacks, including data reconstruction attacks that aim\nto extract the data used to train the model. Most previous studies on data\nreconstruction attacks have focused on LLM, while classification models were\nassumed to be more secure. In this work, we propose a new targeted data\nreconstruction attack called the Mix And Match attack, which takes advantage of\nthe fact that most classification models are based on LLM. The Mix And Match\nattack uses the base model of the target model to generate candidate tokens and\nthen prunes them using the classification head. We extensively demonstrate the\neffectiveness of the attack using both random and organic canaries. This work\nhighlights the importance of considering the privacy risks associated with data\nreconstruction attacks in classification models and offers insights into\npossible leakages.\n","authors":["Adel Elmahdy","Ahmed Salem"],"pdf_url":"https://arxiv.org/pdf/2306.13789v1.pdf","comment":"17 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2306.13775v1","updated":"2023-06-23T20:14:07Z","published":"2023-06-23T20:14:07Z","title":"Resume Information Extraction via Post-OCR Text Processing","summary":"  Information extraction (IE), one of the main tasks of natural language\nprocessing (NLP), has recently increased importance in the use of resumes. In\nstudies on the text to extract information from the CV, sentence classification\nwas generally made using NLP models. In this study, it is aimed to extract\ninformation by classifying all of the text groups after pre-processing such as\nOptical Character Recognition (OCT) and object recognition with the YOLOv8\nmodel of the resumes. The text dataset consists of 286 resumes collected for 5\ndifferent (education, experience, talent, personal and language) job\ndescriptions in the IT industry. The dataset created for object recognition\nconsists of 1198 resumes, which were collected from the open-source internet\nand labeled as sets of text. BERT, BERT-t, DistilBERT, RoBERTa and XLNet were\nused as models. F1 score variances were used to compare the model results. In\naddition, the YOLOv8 model has also been reported comparatively in itself. As a\nresult of the comparison, DistilBERT was showed better results despite having a\nlower number of parameters than other models.\n","authors":["Selahattin Serdar Helli","Senem Tanberk","Sena Nur Cavsak"],"pdf_url":"https://arxiv.org/pdf/2306.13775v1.pdf","comment":"in Turkish language"},{"id":"http://arxiv.org/abs/2306.13734v1","updated":"2023-06-23T18:49:20Z","published":"2023-06-23T18:49:20Z","title":"The CHiME-7 DASR Challenge: Distant Meeting Transcription with Multiple\n  Devices in Diverse Scenarios","summary":"  The CHiME challenges have played a significant role in the development and\nevaluation of robust speech recognition (ASR) systems. We introduce the CHiME-7\ndistant ASR (DASR) task, within the 7th CHiME challenge. This task comprises\njoint ASR and diarization in far-field settings with multiple, and possibly\nheterogeneous, recording devices. Different from previous challenges, we\nevaluate systems on 3 diverse scenarios: CHiME-6, DiPCo, and Mixer 6. The goal\nis for participants to devise a single system that can generalize across\ndifferent array geometries and use cases with no a-priori information. Another\ndeparture from earlier CHiME iterations is that participants are allowed to use\nopen-source pre-trained models and datasets. In this paper, we describe the\nchallenge design, motivation, and fundamental research questions in detail. We\nalso present the baseline system, which is fully array-topology agnostic and\nfeatures multi-channel diarization, channel selection, guided source separation\nand a robust ASR model that leverages self-supervised speech representations\n(SSLR).\n","authors":["Samuele Cornell","Matthew Wiesner","Shinji Watanabe","Desh Raj","Xuankai Chang","Paola Garcia","Yoshiki Masuyama","Zhong-Qiu Wang","Stefano Squartini","Sanjeev Khudanpur"],"pdf_url":"https://arxiv.org/pdf/2306.13734v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13651v1","updated":"2023-06-23T17:59:09Z","published":"2023-06-23T17:59:09Z","title":"Bring Your Own Data! Self-Supervised Evaluation for Large Language\n  Models","summary":"  With the rise of Large Language Models (LLMs) and their ubiquitous deployment\nin diverse domains, measuring language model behavior on realistic data is\nimperative. For example, a company deploying a client-facing chatbot must\nensure that the model will not respond to client requests with profanity.\nCurrent evaluations approach this problem using small, domain-specific datasets\nwith human-curated labels. These evaluation sets are often sampled from a\nnarrow and simplified distribution, and data sources can unknowingly be leaked\ninto the training set which can lead to misleading evaluations. To bypass these\ndrawbacks, we propose a framework for self-supervised evaluation of LLMs by\nanalyzing their sensitivity or invariance to transformations on the input text.\nSelf-supervised evaluation can directly monitor LLM behavior on datasets\ncollected in the wild or streamed during live model deployment. We demonstrate\nself-supervised evaluation strategies for measuring closed-book knowledge,\ntoxicity, and long-range context dependence, in addition to sensitivity to\ngrammatical structure and tokenization errors. When comparisons to similar\nhuman-labeled benchmarks are available, we find strong correlations between\nself-supervised and human-supervised evaluations. The self-supervised paradigm\ncomplements current evaluation strategies that rely on labeled data.\n","authors":["Neel Jain","Khalid Saifullah","Yuxin Wen","John Kirchenbauer","Manli Shu","Aniruddha Saha","Micah Goldblum","Jonas Geiping","Tom Goldstein"],"pdf_url":"https://arxiv.org/pdf/2306.13651v1.pdf","comment":"Code is available at https://github.com/neelsjain/BYOD. First two\n  authors contributed equally. 21 pages, 22 figures"},{"id":"http://arxiv.org/abs/2306.13649v1","updated":"2023-06-23T17:56:26Z","published":"2023-06-23T17:56:26Z","title":"GKD: Generalized Knowledge Distillation for Auto-regressive Sequence\n  Models","summary":"  Knowledge distillation is commonly used for compressing neural networks to\nreduce their inference cost and memory footprint. However, current distillation\nmethods for auto-regressive models, such as generative language models (LMs),\nsuffer from two key issues: (1) distribution mismatch between output sequences\nduring training and the sequences generated by the student during its\ndeployment, and (2) model under-specification, where the student model may not\nbe expressive enough to fit the teacher's distribution. To address these\nissues, we propose Generalized Knowledge Distillation (GKD). GKD mitigates\ndistribution mismatch by sampling output sequences from the student during\ntraining. Furthermore, GKD handles model under-specification by optimizing\nalternative divergences, such as reverse KL, that focus on generating samples\nfrom the student that are likely under the teacher's distribution. We\ndemonstrate that GKD outperforms commonly-used approaches for distilling LLMs\non summarization, machine translation, and arithmetic reasoning tasks.\n","authors":["Rishabh Agarwal","Nino Vieillard","Piotr Stanczyk","Sabela Ramos","Matthieu Geist","Olivier Bachem"],"pdf_url":"https://arxiv.org/pdf/2306.13649v1.pdf","comment":"First two authors contributed equally"},{"id":"http://arxiv.org/abs/2306.13596v1","updated":"2023-06-23T16:35:46Z","published":"2023-06-23T16:35:46Z","title":"Margin Maximization in Attention Mechanism","summary":"  Attention mechanism is a central component of the transformer architecture\nwhich led to the phenomenal success of large language models. However, the\ntheoretical principles underlying the attention mechanism are poorly\nunderstood, especially its nonconvex optimization dynamics. In this work, we\nexplore the seminal softmax-attention model $f(\\boldsymbol{X})=\\langle\n\\boldsymbol{Xv}, \\texttt{softmax}(\\boldsymbol{XWp})\\rangle$, where,\n$\\boldsymbol{X}$ is the token sequence and\n$(\\boldsymbol{v},\\boldsymbol{W},\\boldsymbol{p})$ are tunable parameters. We\nprove that running gradient descent on $\\boldsymbol{p}$, or equivalently\n$\\boldsymbol{W}$, converges in direction to a max-margin solution that\nseparates $\\textit{locally-optimal}$ tokens from non-optimal ones. This clearly\nformalizes attention as a token separation mechanism. Remarkably, our results\nare applicable to general data and precisely characterize $\\textit{optimality}$\nof tokens in terms of the value embeddings $\\boldsymbol{Xv}$ and problem\ngeometry. We also provide a broader regularization path analysis that\nestablishes the margin maximizing nature of attention even for nonlinear\nprediction heads. When optimizing $\\boldsymbol{v}$ and $\\boldsymbol{p}$\nsimultaneously with logistic loss, we identify conditions under which the\nregularization paths directionally converge to their respective hard-margin SVM\nsolutions where $\\boldsymbol{v}$ separates the input features based on their\nlabels. Interestingly, the SVM formulation of $\\boldsymbol{p}$ is influenced by\nthe support vector geometry of $\\boldsymbol{v}$. Finally, we verify our\ntheoretical findings via numerical experiments and provide insights.\n","authors":["Davoud Ataee Tarzanagh","Yingcong Li","Xuechen Zhang","Samet Oymak"],"pdf_url":"https://arxiv.org/pdf/2306.13596v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06077v2","updated":"2023-06-23T16:29:51Z","published":"2023-06-05T17:22:54Z","title":"Visually-Grounded Descriptions Improve Zero-Shot Image Classification","summary":"  Language-vision models like CLIP have made significant progress in zero-shot\nvision tasks, such as zero-shot image classification (ZSIC). However,\ngenerating specific and expressive class descriptions remains a major\nchallenge. Existing approaches suffer from granularity and label ambiguity\nissues. To tackle these challenges, we propose V-GLOSS: Visual Glosses, a novel\nmethod leveraging modern language models and semantic knowledge bases to\nproduce visually-grounded class descriptions. We demonstrate V-GLOSS's\neffectiveness by achieving state-of-the-art results on benchmark ZSIC datasets\nincluding ImageNet and STL-10. In addition, we introduce a silver dataset with\nclass descriptions generated by V-GLOSS, and show its usefulness for vision\ntasks. We make available our code and dataset.\n","authors":["Michael Ogezi","Bradley Hauer","Grzegorz Kondrak"],"pdf_url":"https://arxiv.org/pdf/2306.06077v2.pdf","comment":"We're withdrawing this paper due to an inadvertent breach of a\n  conference's anonymity policy. It was uploaded to arXiv after the\n  conference's anonymity period began, potentially compromising the review\n  process. The withdrawal doesn't reflect any content issues. We aim to respect\n  the conference rules and apologize for any confusion caused"},{"id":"http://arxiv.org/abs/2306.13588v1","updated":"2023-06-23T16:21:40Z","published":"2023-06-23T16:21:40Z","title":"System-Level Natural Language Feedback","summary":"  Natural language (NL) feedback contains rich information about the user\nexperience. Existing studies focus on an instance-level approach, where\nfeedback is used to refine specific examples, disregarding its system-wide\napplication. This paper proposes a general framework for unlocking the\nsystem-level use of NL feedback. We show how to use feedback to formalize\nsystem-level design decisions in a human-in-the-loop-process -- in order to\nproduce better models. In particular this is done through: (i) metric design\nfor tasks; and (ii) language model prompt design for refining model responses.\nWe conduct two case studies of this approach for improving search query\ngeneration and dialog response generation, demonstrating the effectiveness of\nthe use of system-level feedback. We show the combination of system-level\nfeedback and instance-level feedback brings further gains, and that human\nwritten instance-level feedback results in more grounded refinements than\nGPT-3.5 written ones, underlying the importance of human feedback for building\nsystems.\n","authors":["Weizhe Yuan","Kyunghyun Cho","Jason Weston"],"pdf_url":"https://arxiv.org/pdf/2306.13588v1.pdf","comment":"12 pages, 13 tables, 2 figures"},{"id":"http://arxiv.org/abs/2306.13549v1","updated":"2023-06-23T15:21:52Z","published":"2023-06-23T15:21:52Z","title":"A Survey on Multimodal Large Language Models","summary":"  Multimodal Large Language Model (MLLM) recently has been a new rising\nresearch hotspot, which uses powerful Large Language Models (LLMs) as a brain\nto perform multimodal tasks. The surprising emergent capabilities of MLLM, such\nas writing stories based on images and OCR-free math reasoning, are rare in\ntraditional methods, suggesting a potential path to artificial general\nintelligence. In this paper, we aim to trace and summarize the recent progress\nof MLLM. First of all, we present the formulation of MLLM and delineate its\nrelated concepts. Then, we discuss the key techniques and applications,\nincluding Multimodal Instruction Tuning (M-IT), Multimodal In-Context Learning\n(M-ICL), Multimodal Chain of Thought (M-CoT), and LLM-Aided Visual Reasoning\n(LAVR). Finally, we discuss existing challenges and point out promising\nresearch directions. In light of the fact that the era of MLLM has only just\nbegun, we will keep updating this survey and hope it can inspire more research.\nAn associated GitHub link collecting the latest papers is available at\nhttps://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models.\n","authors":["Shukang Yin","Chaoyou Fu","Sirui Zhao","Ke Li","Xing Sun","Tong Xu","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2306.13549v1.pdf","comment":"Project\n  page:https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models"},{"id":"http://arxiv.org/abs/2110.05367v2","updated":"2023-06-23T15:03:49Z","published":"2021-10-11T15:52:16Z","title":"Improving Gender Fairness of Pre-Trained Language Models without\n  Catastrophic Forgetting","summary":"  Existing studies addressing gender bias of pre-trained language models,\nusually build a small gender-neutral data set and conduct a second phase\npre-training on the model with such data. However, given the limited size and\nconcentrated focus of the gender-neutral data, catastrophic forgetting would\noccur during second-phase pre-training. Forgetting information in the original\ntraining data may damage the model's downstream performance by a large margin.\nIn this work, we empirically show that catastrophic forgetting occurs in such\nmethods by evaluating them with general NLP tasks in GLUE. Then, we propose a\nnew method, GEnder Equality Prompt (GEEP), to improve gender fairness of\npre-trained models with less forgetting. GEEP freezes the pre-trained model and\nlearns gender-related prompts with gender-neutral data. Empirical results show\nthat GEEP not only achieves SOTA performances on gender fairness tasks, but\nalso forgets less and performs better on GLUE by a large margin.\n","authors":["Zahra Fatemi","Chen Xing","Wenhao Liu","Caiming Xiong"],"pdf_url":"https://arxiv.org/pdf/2110.05367v2.pdf","comment":"This paper has been accepted at the 61st Annual Meeting of the\n  Association for Computational Linguistics (ACL 2023)"},{"id":"http://arxiv.org/abs/2303.04715v2","updated":"2023-06-23T14:54:03Z","published":"2023-03-08T16:53:19Z","title":"Extending the Pre-Training of BLOOM for Improved Support of Traditional\n  Chinese: Models, Methods and Results","summary":"  In this paper we present the multilingual language model BLOOM-zh that\nfeatures enhanced support for Traditional Chinese. BLOOM-zh has its origins in\nthe open-source BLOOM models presented by BigScience in 2022. Starting from\nreleased models, we extended the pre-training of BLOOM by additional 7.4\nbillion tokens in Traditional Chinese and English covering a variety of domains\nsuch as news articles, books, encyclopedias, educational materials as well as\nspoken language. In order to show the properties of BLOOM-zh, both existing and\nnewly created benchmark scenarios are used for evaluating the performance.\nBLOOM-zh outperforms its predecessor on most Traditional Chinese benchmarks\nwhile maintaining its English capability. We release all our models to the\nresearch community.\n","authors":["Philipp Ennen","Po-Chun Hsu","Chan-Jan Hsu","Chang-Le Liu","Yen-Chen Wu","Yin-Hsiang Liao","Chin-Tung Lin","Da-Shan Shiu","Wei-Yun Ma"],"pdf_url":"https://arxiv.org/pdf/2303.04715v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13501v1","updated":"2023-06-23T13:55:01Z","published":"2023-06-23T13:55:01Z","title":"Knowledge-Infused Self Attention Transformers","summary":"  Transformer-based language models have achieved impressive success in various\nnatural language processing tasks due to their ability to capture complex\ndependencies and contextual information using self-attention mechanisms.\nHowever, they are not without limitations. These limitations include\nhallucinations, where they produce incorrect outputs with high confidence, and\nalignment issues, where they generate unhelpful and unsafe outputs for human\nusers. These limitations stem from the absence of implicit and missing context\nin the data alone. To address this, researchers have explored augmenting these\nmodels with external knowledge from knowledge graphs to provide the necessary\nadditional context. However, the ad-hoc nature of existing methods makes it\ndifficult to properly analyze the effects of knowledge infusion on the many\nmoving parts or components of a transformer. This paper introduces a systematic\nmethod for infusing knowledge into different components of a transformer-based\nmodel. A modular framework is proposed to identify specific components within\nthe transformer architecture, such as the self-attention mechanism, encoder\nlayers, or the input embedding layer, where knowledge infusion can be applied.\nAdditionally, extensive experiments are conducted on the General Language\nUnderstanding Evaluation (GLUE) benchmark tasks, and the findings are reported.\nThis systematic approach aims to facilitate more principled approaches to\nincorporating knowledge into language model architectures.\n","authors":["Kaushik Roy","Yuxin Zi","Vignesh Narayanan","Manas Gaur","Amit Sheth"],"pdf_url":"https://arxiv.org/pdf/2306.13501v1.pdf","comment":"Accepted for publication at the Second Workshop on Knowledge\n  Augmented Methods for NLP, colocated with KDD 2023"},{"id":"http://arxiv.org/abs/2305.19928v4","updated":"2023-06-23T13:47:17Z","published":"2023-05-31T15:05:25Z","title":"Supplementary Features of BiLSTM for Enhanced Sequence Labeling","summary":"  Sequence labeling tasks require the computation of sentence representations\nfor each word within a given sentence. A prevalent method incorporates a\nBi-directional Long Short-Term Memory (BiLSTM) layer to enhance the sequence\nstructure information. However, empirical evidence Li (2020) suggests that the\ncapacity of BiLSTM to produce sentence representations for sequence labeling\ntasks is inherently limited. This limitation primarily results from the\nintegration of fragments from past and future sentence representations to\nformulate a complete sentence representation. In this study, we observed that\nthe entire sentence representation, found in both the first and last cells of\nBiLSTM, can supplement each the individual sentence representation of each\ncell. Accordingly, we devised a global context mechanism to integrate entire\nfuture and past sentence representations into each cell's sentence\nrepresentation within the BiLSTM framework. By incorporating the BERT model\nwithin BiLSTM as a demonstration, and conducting exhaustive experiments on nine\ndatasets for sequence labeling tasks, including named entity recognition (NER),\npart of speech (POS) tagging, and End-to-End Aspect-Based sentiment analysis\n(E2E-ABSA). We noted significant improvements in F1 scores and accuracy across\nall examined datasets.\n","authors":["Conglei Xu","Kun Shen","Hongguang Sun"],"pdf_url":"https://arxiv.org/pdf/2305.19928v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13467v1","updated":"2023-06-23T12:12:08Z","published":"2023-06-23T12:12:08Z","title":"Incorporating Graph Information in Transformer-based AMR Parsing","summary":"  Abstract Meaning Representation (AMR) is a Semantic Parsing formalism that\naims at providing a semantic graph abstraction representing a given text.\nCurrent approaches are based on autoregressive language models such as BART or\nT5, fine-tuned through Teacher Forcing to obtain a linearized version of the\nAMR graph from a sentence. In this paper, we present LeakDistill, a model and\nmethod that explores a modification to the Transformer architecture, using\nstructural adapters to explicitly incorporate graph information into the\nlearned representations and improve AMR parsing performance. Our experiments\nshow how, by employing word-to-node alignment to embed graph structural\ninformation into the encoder at training time, we can obtain state-of-the-art\nAMR parsing through self-knowledge distillation, even without the use of\nadditional data. We release the code at\n\\url{http://www.github.com/sapienzanlp/LeakDistill}.\n","authors":["Pavlo Vasylenko","Pere-Lluís Huguet Cabot","Abelardo Carlos Martínez Lorenzo","Roberto Navigli"],"pdf_url":"https://arxiv.org/pdf/2306.13467v1.pdf","comment":"ACL 2023. Please cite authors correctly using both lastnames\n  (\"Mart\\'inez Lorenzo\", \"Huguet Cabot\")"},{"id":"http://arxiv.org/abs/2306.13460v1","updated":"2023-06-23T12:03:07Z","published":"2023-06-23T12:03:07Z","title":"Learning Descriptive Image Captioning via Semipermeable Maximum\n  Likelihood Estimation","summary":"  Image captioning aims to describe visual content in natural language. As 'a\npicture is worth a thousand words', there could be various correct descriptions\nfor an image. However, with maximum likelihood estimation as the training\nobjective, the captioning model is penalized whenever its prediction mismatches\nwith the label. For instance, when the model predicts a word expressing richer\nsemantics than the label, it will be penalized and optimized to prefer more\nconcise expressions, referred to as conciseness optimization. In contrast,\npredictions that are more concise than labels lead to richness optimization.\nSuch conflicting optimization directions could eventually result in the model\ngenerating general descriptions. In this work, we introduce Semipermeable\nMaxImum Likelihood Estimation (SMILE), which allows richness optimization while\nblocking conciseness optimization, thus encouraging the model to generate\nlonger captions with more details. Extensive experiments on two mainstream\nimage captioning datasets MSCOCO and Flickr30K demonstrate that SMILE\nsignificantly enhances the descriptiveness of generated captions. We further\nprovide in-depth investigations to facilitate a better understanding of how\nSMILE works.\n","authors":["Zihao Yue","Anwen Hu","Liang Zhang","Qin Jin"],"pdf_url":"https://arxiv.org/pdf/2306.13460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09209v3","updated":"2023-06-23T10:43:14Z","published":"2023-01-22T21:30:12Z","title":"Summarize the Past to Predict the Future: Natural Language Descriptions\n  of Context Boost Multimodal Object Interaction","summary":"  We study object interaction anticipation in egocentric videos. This task\nrequires an understanding of the spatiotemporal context formed by past actions\non objects, coined action context. We propose TransFusion, a multimodal\ntransformer-based architecture. It exploits the representational power of\nlanguage by summarising the action context. TransFusion leverages pre-trained\nimage captioning and vision-language models to extract the action context from\npast video frames. This action context together with the next video frame is\nprocessed by the multimodal fusion module to forecast the next object\ninteraction. Our model enables more efficient end-to-end learning. The large\npre-trained language models add common sense and a generalisation capability.\nExperiments on Ego4D and EPIC-KITCHENS-100 show the effectiveness of our\nmultimodal fusion model. They also highlight the benefits of using\nlanguage-based context summaries in a task where vision seems to suffice. Our\nmethod outperforms state-of-the-art approaches by 40.4% in relative terms in\noverall mAP on the Ego4D test set. We validate the effectiveness of TransFusion\nvia experiments on EPIC-KITCHENS-100. Video and code are available at\nhttps://eth-ait.github.io/transfusion-proj/.\n","authors":["Razvan-George Pasca","Alexey Gavryushin","Yen-Ling Kuo","Luc Van Gool","Otmar Hilliges","Xi Wang"],"pdf_url":"https://arxiv.org/pdf/2301.09209v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13421v1","updated":"2023-06-23T10:18:02Z","published":"2023-06-23T10:18:02Z","title":"Long-range Language Modeling with Self-retrieval","summary":"  Retrieval-augmented language models (LMs) have received much attention\nrecently. However, typically the retriever is not trained jointly as a native\ncomponent of the LM, but added to an already-pretrained LM, which limits the\nability of the LM and the retriever to adapt to one another. In this work, we\npropose the Retrieval-Pretrained Transformer (RPT), an architecture and\ntraining procedure for jointly training a retrieval-augmented LM from scratch\nfor the task of modeling long texts. Given a recently generated text chunk in a\nlong document, the LM computes query representations, which are then used to\nretrieve earlier chunks in the document, located potentially tens of thousands\nof tokens before. Information from retrieved chunks is fused into the LM\nrepresentations to predict the next target chunk. We train the retriever\ncomponent with a semantic objective, where the goal is to retrieve chunks that\nincrease the probability of the next chunk, according to a reference LM. We\nevaluate RPT on four long-range language modeling tasks, spanning books, code,\nand mathematical writing, and demonstrate that RPT improves retrieval quality\nand subsequently perplexity across the board compared to strong baselines.\n","authors":["Ohad Rubin","Jonathan Berant"],"pdf_url":"https://arxiv.org/pdf/2306.13421v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13379v1","updated":"2023-06-23T09:01:56Z","published":"2023-06-23T09:01:56Z","title":"Stress Testing BERT Anaphora Resolution Models for Reaction Extraction\n  in Chemical Patents","summary":"  The high volume of published chemical patents and the importance of a timely\nacquisition of their information gives rise to automating information\nextraction from chemical patents. Anaphora resolution is an important component\nof comprehensive information extraction, and is critical for extracting\nreactions. In chemical patents, there are five anaphoric relations of interest:\nco-reference, transformed, reaction associated, work up, and contained. Our\ngoal is to investigate how the performance of anaphora resolution models for\nreaction texts in chemical patents differs in a noise-free and noisy\nenvironment and to what extent we can improve the robustness against noise of\nthe model.\n","authors":["Chieling Yueh","Evangelos Kanoulas","Bruno Martins","Camilo Thorne","Saber Akhondi"],"pdf_url":"https://arxiv.org/pdf/2306.13379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13315v1","updated":"2023-06-23T06:33:20Z","published":"2023-06-23T06:33:20Z","title":"Abstractive Text Summarization for Resumes With Cutting Edge NLP\n  Transformers and LSTM","summary":"  Text summarization is a fundamental task in natural language processing that\naims to condense large amounts of textual information into concise and coherent\nsummaries. With the exponential growth of content and the need to extract key\ninformation efficiently, text summarization has gained significant attention in\nrecent years. In this study, LSTM and pre-trained T5, Pegasus, BART and\nBART-Large model performances were evaluated on the open source dataset (Xsum,\nCNN/Daily Mail, Amazon Fine Food Review and News Summary) and the prepared\nresume dataset. This resume dataset consists of many information such as\nlanguage, education, experience, personal information, skills, and this data\nincludes 75 resumes. The primary objective of this research was to classify\nresume text. Various techniques such as LSTM, pre-trained models, and\nfine-tuned models were assessed using a dataset of resumes. The BART-Large\nmodel fine-tuned with the resume dataset gave the best performance.\n","authors":["Öykü Berfin Mercan","Sena Nur Cavsak","Aysu Deliahmetoglu","Senem Tanberk"],"pdf_url":"https://arxiv.org/pdf/2306.13315v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13089v2","updated":"2023-06-23T06:26:11Z","published":"2023-05-28T18:27:59Z","title":"GIMLET: A Unified Graph-Text Model for Instruction-Based Molecule\n  Zero-Shot Learning","summary":"  Molecule property prediction has gained significant attention in recent\nyears. The main bottleneck is the label insufficiency caused by expensive lab\nexperiments. In order to alleviate this issue and to better leverage textual\nknowledge for tasks, this study investigates the feasibility of employing\nnatural language instructions to accomplish molecule-related tasks in a\nzero-shot setting. We discover that existing molecule-text models perform\npoorly in this setting due to inadequate treatment of instructions and limited\ncapacity for graphs. To overcome these issues, we propose GIMLET, which unifies\nlanguage models for both graph and text data. By adopting generalized position\nembedding, our model is extended to encode both graph structures and\ninstruction text without additional graph encoding modules. GIMLET also\ndecouples encoding of the graph from tasks instructions in the attention\nmechanism, enhancing the generalization of graph features across novel tasks.\nWe construct a dataset consisting of more than two thousand molecule tasks with\ncorresponding instructions derived from task descriptions. We pretrain GIMLET\non the molecule tasks along with instructions, enabling the model to transfer\neffectively to a broad range of tasks. Experimental results demonstrate that\nGIMLET significantly outperforms molecule-text baselines in instruction-based\nzero-shot learning, even achieving closed results to supervised GNN models on\ntasks such as toxcast and muv.\n","authors":["Haiteng Zhao","Shengchao Liu","Chang Ma","Hannan Xu","Jie Fu","Zhi-Hong Deng","Lingpeng Kong","Qi Liu"],"pdf_url":"https://arxiv.org/pdf/2306.13089v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13310v1","updated":"2023-06-23T06:15:54Z","published":"2023-06-23T06:15:54Z","title":"Mutually Guided Few-shot Learning for Relational Triple Extraction","summary":"  Knowledge graphs (KGs), containing many entity-relation-entity triples,\nprovide rich information for downstream applications. Although extracting\ntriples from unstructured texts has been widely explored, most of them require\na large number of labeled instances. The performance will drop dramatically\nwhen only few labeled data are available. To tackle this problem, we propose\nthe Mutually Guided Few-shot learning framework for Relational Triple\nExtraction (MG-FTE). Specifically, our method consists of an entity-guided\nrelation proto-decoder to classify the relations firstly and a relation-guided\nentity proto-decoder to extract entities based on the classified relations. To\ndraw the connection between entity and relation, we design a proto-level fusion\nmodule to boost the performance of both entity extraction and relation\nclassification. Moreover, a new cross-domain few-shot triple extraction task is\nintroduced. Extensive experiments show that our method outperforms many\nstate-of-the-art methods by 12.6 F1 score on FewRel 1.0 (single-domain) and\n20.5 F1 score on FewRel 2.0 (cross-domain).\n","authors":["Chengmei Yang","Shuai Jiang","Bowei He","Chen Ma","Lianghua He"],"pdf_url":"https://arxiv.org/pdf/2306.13310v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2306.12672v2","updated":"2023-06-23T06:05:31Z","published":"2023-06-22T05:14:00Z","title":"From Word Models to World Models: Translating from Natural Language to\n  the Probabilistic Language of Thought","summary":"  How does language inform our downstream thinking? In particular, how do\nhumans make meaning from language--and how can we leverage a theory of\nlinguistic meaning to build machines that think in more human-like ways? In\nthis paper, we propose rational meaning construction, a computational framework\nfor language-informed thinking that combines neural language models with\nprobabilistic models for rational inference. We frame linguistic meaning as a\ncontext-sensitive mapping from natural language into a probabilistic language\nof thought (PLoT)--a general-purpose symbolic substrate for generative world\nmodeling. Our architecture integrates two computational tools that have not\npreviously come together: we model thinking with probabilistic programs, an\nexpressive representation for commonsense reasoning; and we model meaning\nconstruction with large language models (LLMs), which support broad-coverage\ntranslation from natural language utterances to code expressions in a\nprobabilistic programming language. We illustrate our framework through\nexamples covering four core domains from cognitive science: probabilistic\nreasoning, logical and relational reasoning, visual and physical reasoning, and\nsocial reasoning. In each, we show that LLMs can generate context-sensitive\ntranslations that capture pragmatically-appropriate linguistic meanings, while\nBayesian inference with the generated programs supports coherent and robust\ncommonsense reasoning. We extend our framework to integrate\ncognitively-motivated symbolic modules (physics simulators, graphics engines,\nand planning algorithms) to provide a unified commonsense thinking interface\nfrom language. Finally, we explore how language can drive the construction of\nworld models themselves. We hope this work will provide a roadmap towards\ncognitive models and AI systems that synthesize the insights of both modern and\nclassical computational perspectives.\n","authors":["Lionel Wong","Gabriel Grand","Alexander K. Lew","Noah D. Goodman","Vikash K. Mansinghka","Jacob Andreas","Joshua B. Tenenbaum"],"pdf_url":"https://arxiv.org/pdf/2306.12672v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09686v2","updated":"2023-06-23T05:59:16Z","published":"2022-12-19T18:14:36Z","title":"A Natural Bias for Language Generation Models","summary":"  After just a few hundred training updates, a standard probabilistic model for\nlanguage generation has likely not yet learnt many semantic or syntactic rules\nof natural language, making it difficult to estimate the probability\ndistribution over next tokens. Yet around this point, these models have\nidentified a simple, loss-minimising behaviour: to output the unigram\ndistribution of the target training corpus. The use of such a heuristic raises\nthe question: Can we initialise our models with this behaviour and save\nprecious compute resources and model capacity? Here we show that we can\neffectively endow standard neural language generation models with a separate\nmodule that reflects unigram frequency statistics as prior knowledge, simply by\ninitialising the bias term in a model's final linear layer with the log-unigram\ndistribution. We use neural machine translation as a test bed for this simple\ntechnique and observe that it: (i) improves learning efficiency; (ii) achieves\nbetter overall performance; and perhaps most importantly (iii) appears to\ndisentangle strong frequency effects by encouraging the model to specialise in\nnon-frequency-related aspects of language.\n","authors":["Clara Meister","Wojciech Stokowiec","Tiago Pimentel","Lei Yu","Laura Rimell","Adhiguna Kuncoro"],"pdf_url":"https://arxiv.org/pdf/2212.09686v2.pdf","comment":"Main conference paper at ACL 2023"},{"id":"http://arxiv.org/abs/2306.07932v2","updated":"2023-06-23T05:56:51Z","published":"2023-06-10T04:31:57Z","title":"Human-in-the-Loop through Chain-of-Thought","summary":"  While the emergence of powerful language models along with Chain-of-thought\nprompting has made automation more and more omnipresent, it sometimes\ndemonstrates its weakness in long-term or multi-step logical reasoning. For\nexample, users don't always get desirable answers for complex mathematical\nproblems without human involvement. Against this background, we present the\nManual Correction System (MCS) -- a human-in-the-loop system enhanced by\nChain-of-Thought prompting, which explores how manual correction of sub-logics\nin rationales can improve LLM's reasoning performance. Moving one step forward,\nconsidering a system with human-in-the-loop involves more than having humans\nimprove performance but also controlling the cost. Therefore, we post a\nCost-utility Analysis Model for Human-in-the-Loop systems (CAMLOP) based on\nclassical economics theory to analyze, quantify and balance the utility and the\ncorresponding cost. We conduct experiments of MCS and CAMLOP with twelve\ndatasets. A significant advantage w.r.t cost and utility proves its superiority\nover strong baselines.\n","authors":["Zefan Cai","Baobao Chang","Wenjuan Han"],"pdf_url":"https://arxiv.org/pdf/2306.07932v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.07400v4","updated":"2023-06-23T05:52:22Z","published":"2021-06-14T13:01:46Z","title":"Determinantal Beam Search","summary":"  Beam search is a go-to strategy for decoding neural sequence models. The\nalgorithm can naturally be viewed as a subset optimization problem, albeit one\nwhere the corresponding set function does not reflect interactions between\ncandidates. Empirically, this leads to sets often exhibiting high overlap,\ne.g., strings may differ by only a single word. Yet in use-cases that call for\nmultiple solutions, a diverse or representative set is often desired. To\naddress this issue, we propose a reformulation of beam search, which we call\ndeterminantal beam search. Determinantal beam search has a natural relationship\nto determinantal point processes (DPPs), models over sets that inherently\nencode intra-set interactions. By posing iterations in beam search as a series\nof subdeterminant maximization problems, we can turn the algorithm into a\ndiverse subset selection process. In a case study, we use the string\nsubsequence kernel to explicitly encourage n-gram coverage in text generated\nfrom a sequence model. We observe that our algorithm offers competitive\nperformance against other diverse set generation strategies in the context of\nlanguage generation, while providing a more general approach to optimizing for\ndiversity.\n","authors":["Clara Meister","Martina Forster","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2106.07400v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13304v1","updated":"2023-06-23T05:43:28Z","published":"2023-06-23T05:43:28Z","title":"ToolQA: A Dataset for LLM Question Answering with External Tools","summary":"  Large Language Models (LLMs) have demonstrated impressive performance in\nvarious NLP tasks, but they still suffer from challenges such as hallucination\nand weak numerical reasoning. To overcome these challenges, external tools can\nbe used to enhance LLMs' question-answering abilities. However, current\nevaluation methods do not distinguish between questions that can be answered\nusing LLMs' internal knowledge and those that require external information\nthrough tool use. To address this issue, we introduce a new dataset called\nToolQA, which is designed to faithfully evaluate LLMs' ability to use external\ntools for question answering. Our development of ToolQA involved a scalable,\nautomated process for dataset curation, along with 13 specialized tools\ndesigned for interaction with external knowledge in order to answer questions.\nImportantly, we strive to minimize the overlap between our benchmark data and\nLLMs' pre-training data, enabling a more precise evaluation of LLMs' tool-use\nreasoning abilities. We conducted an in-depth diagnosis of existing tool-use\nLLMs to highlight their strengths, weaknesses, and potential improvements. Our\nfindings set a new benchmark for evaluating LLMs and suggest new directions for\nfuture advancements. Our data and code are freely available to the broader\nscientific community on GitHub.\n","authors":["Yuchen Zhuang","Yue Yu","Kuan Wang","Haotian Sun","Chao Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.13304v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10509v2","updated":"2023-06-23T00:59:13Z","published":"2022-12-20T18:26:34Z","title":"Interleaving Retrieval with Chain-of-Thought Reasoning for\n  Knowledge-Intensive Multi-Step Questions","summary":"  Prompting-based large language models (LLMs) are surprisingly powerful at\ngenerating natural language reasoning steps or Chains-of-Thoughts (CoT) for\nmulti-step question answering (QA). They struggle, however, when the necessary\nknowledge is either unavailable to the LLM or not up-to-date within its\nparameters. While using the question to retrieve relevant text from an external\nknowledge source helps LLMs, we observe that this one-step retrieve-and-read\napproach is insufficient for multi-step QA. Here, \\textit{what to retrieve}\ndepends on \\textit{what has already been derived}, which in turn may depend on\n\\textit{what was previously retrieved}. To address this, we propose IRCoT, a\nnew approach for multi-step QA that interleaves retrieval with steps\n(sentences) in a CoT, guiding the retrieval with CoT and in turn using\nretrieved results to improve CoT. Using IRCoT with GPT3 substantially improves\nretrieval (up to 21 points) as well as downstream QA (up to 15 points) on four\ndatasets: HotpotQA, 2WikiMultihopQA, MuSiQue, and IIRC. We observe similar\nsubstantial gains in out-of-distribution (OOD) settings as well as with much\nsmaller models such as Flan-T5-large without additional training. IRCoT reduces\nmodel hallucination, resulting in factually more accurate CoT reasoning. Code,\ndata, and prompts are available at \\url{https://github.com/stonybrooknlp/ircot}\n","authors":["Harsh Trivedi","Niranjan Balasubramanian","Tushar Khot","Ashish Sabharwal"],"pdf_url":"https://arxiv.org/pdf/2212.10509v2.pdf","comment":"ACL'23 Camera Ready"},{"id":"http://arxiv.org/abs/2306.03819v2","updated":"2023-06-23T00:16:46Z","published":"2023-06-06T16:07:24Z","title":"LEACE: Perfect linear concept erasure in closed form","summary":"  Concept erasure aims to remove specified features from a representation. It\ncan improve fairness (e.g. preventing a classifier from using gender or race)\nand interpretability (e.g. removing a concept to observe changes in model\nbehavior). We introduce LEAst-squares Concept Erasure (LEACE), a closed-form\nmethod which provably prevents all linear classifiers from detecting a concept\nwhile changing the representation as little as possible, as measured by a broad\nclass of norms. We apply LEACE to large language models with a novel procedure\ncalled \"concept scrubbing,\" which erases target concept information from every\nlayer in the network. We demonstrate our method on two tasks: measuring the\nreliance of language models on part-of-speech information, and reducing gender\nbias in BERT embeddings. Code is available at\nhttps://github.com/EleutherAI/concept-erasure.\n","authors":["Nora Belrose","David Schneider-Joseph","Shauli Ravfogel","Ryan Cotterell","Edward Raff","Stella Biderman"],"pdf_url":"https://arxiv.org/pdf/2306.03819v2.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2306.13781v1","updated":"2023-06-23T20:45:29Z","published":"2023-06-23T20:45:29Z","title":"Retrieving Supporting Evidence for LLMs Generated Answers","summary":"  Current large language models (LLMs) can exhibit near-human levels of\nperformance on many natural language tasks, including open-domain question\nanswering. Unfortunately, they also convincingly hallucinate incorrect answers,\nso that responses to questions must be verified against external sources before\nthey can be accepted at face value. In this paper, we report a simple\nexperiment to automatically verify generated answers against a corpus. After\npresenting a question to an LLM and receiving a generated answer, we query the\ncorpus with the combination of the question + generated answer. We then present\nthe LLM with the combination of the question + generated answer + retrieved\nanswer, prompting it to indicate if the generated answer can be supported by\nthe retrieved answer. We base our experiment on questions and passages from the\nMS MARCO (V1) test collection, exploring three retrieval approaches ranging\nfrom standard BM25 to a full question answering stack, including a reader based\non the LLM. For a large fraction of questions, we find that an LLM is capable\nof verifying its generated answer if appropriate supporting material is\nprovided. However, with an accuracy of 70-80%, this approach cannot be fully\nrelied upon to detect hallucinations.\n","authors":["Siqing Huo","Negar Arabzadeh","Charles L. A. Clarke"],"pdf_url":"https://arxiv.org/pdf/2306.13781v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13548v1","updated":"2023-06-23T15:20:49Z","published":"2023-06-23T15:20:49Z","title":"Fuzzification-based Feature Selection for Enhanced Website Content\n  Encryption","summary":"  We propose a novel approach that utilizes fuzzification theory to perform\nfeature selection on website content for encryption purposes. Our objective is\nto identify and select the most relevant features from the website by\nharnessing the principles of fuzzy logic. Fuzzification allows us to transform\nthe crisp website content into fuzzy representations, enabling a more nuanced\nanalysis of their characteristics. By considering the degree of membership of\neach feature in different fuzzy categories, we can evaluate their importance\nand relevance for encryption. This approach enables us to prioritize and focus\non the features that exhibit higher membership degrees, indicating their\nsignificance in the encryption process. By employing fuzzification-based\nfeature selection, we aim to enhance the effectiveness and efficiency of\nwebsite content encryption, ultimately improving the overall internet security.\n","authors":["Mike Nkongolo"],"pdf_url":"https://arxiv.org/pdf/2306.13548v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12235v2","updated":"2023-06-23T13:48:14Z","published":"2023-06-21T12:53:31Z","title":"CompMix: A Benchmark for Heterogeneous Question Answering","summary":"  Fact-centric question answering (QA) often requires access to multiple,\nheterogeneous, information sources. By jointly considering several sources like\na knowledge base (KB), a text collection, and tables from the web, QA systems\ncan enhance their answer coverage and confidence. However, existing QA\nbenchmarks are mostly constructed with a single source of knowledge in mind.\nThis limits capabilities of these benchmarks to fairly evaluate QA systems that\ncan tap into more than one information repository. To bridge this gap, we\nrelease CompMix, a crowdsourced QA benchmark which naturally demands the\nintegration of a mixture of input sources. CompMix has a total of 9,410\nquestions, and features several complex intents like joins and temporal\nconditions. Evaluation of a range of QA systems on CompMix highlights the need\nfor further research on leveraging information from heterogeneous sources.\n","authors":["Philipp Christmann","Rishiraj Saha Roy","Gerhard Weikum"],"pdf_url":"https://arxiv.org/pdf/2306.12235v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06601v3","updated":"2023-06-23T13:38:33Z","published":"2023-01-16T20:37:29Z","title":"A Dataset of Coordinated Cryptocurrency-Related Social Media Campaigns","summary":"  The rise in adoption of cryptoassets has brought many new and inexperienced\ninvestors in the cryptocurrency space. These investors can be disproportionally\ninfluenced by information they receive online, and particularly from social\nmedia. This paper presents a dataset of crypto-related bounty events and the\nusers that participate in them. These events coordinate social media campaigns\nto create artificial \"hype\" around a crypto project in order to influence the\nprice of its token. The dataset consists of information about 15.8K cross-media\nbounty events, 185K participants, 10M forum comments and 82M social media URLs\ncollected from the Bounties(Altcoins) subforum of the BitcoinTalk online forum\nfrom May 2014 to December 2022. We describe the data collection and the data\nprocessing methods employed and we present a basic characterization of the\ndataset. Furthermore, we discuss potential research opportunities afforded by\nthe dataset across many disciplines and we highlight potential novel insights\ninto how the cryptocurrency industry operates and how it interacts with its\naudience.\n","authors":["Karolis Zilius","Tasos Spiliotopoulos","Aad van Moorsel"],"pdf_url":"https://arxiv.org/pdf/2301.06601v3.pdf","comment":"Camera-ready version for the ICWSM 2023 Conference. This paper\n  describes the dataset available at https://zenodo.org/record/7813450"},{"id":"http://arxiv.org/abs/2306.13382v1","updated":"2023-06-23T09:04:07Z","published":"2023-06-23T09:04:07Z","title":"OptMSM: Optimizing Multi-Scenario Modeling for Click-Through Rate\n  Prediction","summary":"  A large-scale industrial recommendation platform typically consists of\nmultiple associated scenarios, requiring a unified click-through rate (CTR)\nprediction model to serve them simultaneously. Existing approaches for\nmulti-scenario CTR prediction generally consist of two main modules: i) a\nscenario-aware learning module that learns a set of multi-functional\nrepresentations with scenario-shared and scenario-specific information from\ninput features, and ii) a scenario-specific prediction module that serves each\nscenario based on these representations. However, most of these approaches\nprimarily focus on improving the former module and neglect the latter module.\nThis can result in challenges such as increased model parameter size, training\ndifficulty, and performance bottlenecks for each scenario. To address these\nissues, we propose a novel framework called OptMSM (\\textbf{Opt}imizing\n\\textbf{M}ulti-\\textbf{S}cenario \\textbf{M}odeling). First, we introduce a\nsimplified yet effective scenario-enhanced learning module to alleviate the\naforementioned challenges. Specifically, we partition the input features into\nscenario-specific and scenario-shared features, which are mapped to specific\ninformation embedding encodings and a set of shared information embeddings,\nrespectively. By imposing an orthogonality constraint on the shared information\nembeddings to facilitate the disentanglement of shared information\ncorresponding to each scenario, we combine them with the specific information\nembeddings to obtain multi-functional representations. Second, we introduce a\nscenario-specific hypernetwork in the scenario-specific prediction module to\ncapture interactions within each scenario more effectively, thereby alleviating\nthe performance bottlenecks. Finally, we conduct extensive offline experiments\nand an online A/B test to demonstrate the effectiveness of OptMSM.\n","authors":["Xing Tang","Yang Qiao","Yuwen Fu","Fuyuan Lyu","Dugang Liu","Xiuqiang He"],"pdf_url":"https://arxiv.org/pdf/2306.13382v1.pdf","comment":"Accepted by ECML-PKDD 2023 Applied Data Science Track"},{"id":"http://arxiv.org/abs/2306.13374v1","updated":"2023-06-23T08:53:41Z","published":"2023-06-23T08:53:41Z","title":"Human Activity Behavioural Pattern Recognition in Smarthome with\n  Long-hour Data Collection","summary":"  The research on human activity recognition has provided novel solutions to\nmany applications like healthcare, sports, and user profiling. Considering the\ncomplex nature of human activities, it is still challenging even after\neffective and efficient sensors are available. The existing works on human\nactivity recognition using smartphone sensors focus on recognizing basic human\nactivities like sitting, sleeping, standing, stair up and down and running.\nHowever, more than these basic activities is needed to analyze human\nbehavioural pattern. The proposed framework recognizes basic human activities\nusing deep learning models. Also, ambient sensors like PIR, pressure sensors,\nand smartphone-based sensors like accelerometers and gyroscopes are combined to\nmake it hybrid-sensor-based human activity recognition. The hybrid approach\nhelped derive more activities than the basic ones, which also helped derive\nhuman activity patterns or user profiling. User profiling provides sufficient\ninformation to identify daily living activity patterns and predict whether any\nanomaly exists. The framework provides the base for applications such as\nelderly monitoring when they are alone at home. The GRU model's accuracy of\n95\\% is observed to recognize the basic activities. Finally, Human activity\npatterns over time are recognized based on the duration and frequency of the\nactivities. It is observed that human activity pattern, like, morning walking\nduration, varies depending on the day of the week.\n","authors":["Ranjit Kolkar","Geetha V"],"pdf_url":"https://arxiv.org/pdf/2306.13374v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14921v1","updated":"2023-06-23T09:30:01Z","published":"2023-06-23T09:30:01Z","title":"Product Information Extraction using ChatGPT","summary":"  Structured product data in the form of attribute/value pairs is the\nfoundation of many e-commerce applications such as faceted product search,\nproduct comparison, and product recommendation. Product offers often only\ncontain textual descriptions of the product attributes in the form of titles or\nfree text. Hence, extracting attribute/value pairs from textual product\ndescriptions is an essential enabler for e-commerce applications. In order to\nexcel, state-of-the-art product information extraction methods require large\nquantities of task-specific training data. The methods also struggle with\ngeneralizing to out-of-distribution attributes and attribute values that were\nnot a part of the training data. Due to being pre-trained on huge amounts of\ntext as well as due to emergent effects resulting from the model size, Large\nLanguage Models like ChatGPT have the potential to address both of these\nshortcomings. This paper explores the potential of ChatGPT for extracting\nattribute/value pairs from product descriptions. We experiment with different\nzero-shot and few-shot prompt designs. Our results show that ChatGPT achieves a\nperformance similar to a pre-trained language model but requires much smaller\namounts of training data and computation for fine-tuning.\n","authors":["Alexander Brinkmann","Roee Shraga","Reng Chiz Der","Christian Bizer"],"pdf_url":"https://arxiv.org/pdf/2306.14921v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2306.13592v1","updated":"2023-06-23T16:28:12Z","published":"2023-06-23T16:28:12Z","title":"TACOformer:Token-channel compounded Cross Attention for Multimodal\n  Emotion Recognition","summary":"  Recently, emotion recognition based on physiological signals has emerged as a\nfield with intensive research. The utilization of multi-modal, multi-channel\nphysiological signals has significantly improved the performance of emotion\nrecognition systems, due to their complementarity. However, effectively\nintegrating emotion-related semantic information from different modalities and\ncapturing inter-modal dependencies remains a challenging issue. Many existing\nmultimodal fusion methods ignore either token-to-token or channel-to-channel\ncorrelations of multichannel signals from different modalities, which limits\nthe classification capability of the models to some extent. In this paper, we\npropose a comprehensive perspective of multimodal fusion that integrates\nchannel-level and token-level cross-modal interactions. Specifically, we\nintroduce a unified cross attention module called Token-chAnnel COmpound (TACO)\nCross Attention to perform multimodal fusion, which simultaneously models\nchannel-level and token-level dependencies between modalities. Additionally, we\npropose a 2D position encoding method to preserve information about the spatial\ndistribution of EEG signal channels, then we use two transformer encoders ahead\nof the fusion module to capture long-term temporal dependencies from the EEG\nsignal and the peripheral physiological signal, respectively.\nSubject-independent experiments on emotional dataset DEAP and Dreamer\ndemonstrate that the proposed model achieves state-of-the-art performance.\n","authors":["Xinda Li"],"pdf_url":"https://arxiv.org/pdf/2306.13592v1.pdf","comment":"Accepted by IJCAI 2023- AI4TS workshop"},{"id":"http://arxiv.org/abs/2305.01233v3","updated":"2023-06-23T13:45:01Z","published":"2023-05-02T07:15:10Z","title":"On Uni-Modal Feature Learning in Supervised Multi-Modal Learning","summary":"  We abstract the features (i.e. learned representations) of multi-modal data\ninto 1) uni-modal features, which can be learned from uni-modal training, and\n2) paired features, which can only be learned from cross-modal interactions.\nMulti-modal models are expected to benefit from cross-modal interactions on the\nbasis of ensuring uni-modal feature learning. However, recent supervised\nmulti-modal late-fusion training approaches still suffer from insufficient\nlearning of uni-modal features on each modality. We prove that this phenomenon\ndoes hurt the model's generalization ability. To this end, we propose to choose\na targeted late-fusion learning method for the given supervised multi-modal\ntask from Uni-Modal Ensemble(UME) and the proposed Uni-Modal Teacher(UMT),\naccording to the distribution of uni-modal and paired features. We demonstrate\nthat, under a simple guiding strategy, we can achieve comparable results to\nother complex late-fusion or intermediate-fusion methods on various multi-modal\ndatasets, including VGG-Sound, Kinetics-400, UCF101, and ModelNet40.\n","authors":["Chenzhuang Du","Jiaye Teng","Tingle Li","Yichen Liu","Tianyuan Yuan","Yue Wang","Yang Yuan","Hang Zhao"],"pdf_url":"https://arxiv.org/pdf/2305.01233v3.pdf","comment":null}]},"2023-06-27T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2306.15656v1","updated":"2023-06-27T17:50:26Z","published":"2023-06-27T17:50:26Z","title":"SparseOptimizer: Sparsify Language Models through Moreau-Yosida\n  Regularization and Accelerate through Compiler Co-design","summary":"  This paper introduces SparseOptimizer, a novel deep learning optimizer that\nexploits Moreau-Yosida regularization to naturally induce sparsity in large\nlanguage models such as BERT, ALBERT and GPT. Key to the design of\nSparseOptimizer is an embedded shrinkage operator, which imparts sparsity\ndirectly within the optimization process. This operator, backed by a sound\ntheoretical framework, includes an analytical solution, thereby reinforcing the\noptimizer's robustness and efficacy. Crucially, SparseOptimizer's plug-and-play\nfunctionality eradicates the need for code modifications, making it a\nuniversally adaptable tool for a wide array of large language models. Empirical\nevaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2\nconfirm that SparseBERT and SparseALBERT, when sparsified using\nSparseOptimizer, achieve performance comparable to their dense counterparts,\nBERT and ALBERT, while significantly reducing their parameter count. Further,\nthis work proposes an innovative optimizer-compiler co-design strategy,\ndemonstrating the potential of inference acceleration (\\textbf{3.37x},\n\\textbf{6.30x}, and \\textbf{7.15x} in comparison with Pytorch, TensorFlow, and\nLLVM generic compile, respectively) in SparseBERT when paired with an\nappropriately designed compiler. This study represents a significant step\nforward in the evolution of efficient, scalable, and high-performing large\nlanguage models, setting a precedent for future exploration and optimization in\nthis domain. The SparseOptimizer code and SparseALBERT model will be made\navailable upon paper acceptance.\n","authors":["Fu-Ming Guo"],"pdf_url":"https://arxiv.org/pdf/2306.15656v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15644v1","updated":"2023-06-27T17:37:53Z","published":"2023-06-27T17:37:53Z","title":"Style-transfer based Speech and Audio-visual Scene Understanding for\n  Robot Action Sequence Acquisition from Videos","summary":"  To realize human-robot collaboration, robots need to execute actions for new\ntasks according to human instructions given finite prior knowledge. Human\nexperts can share their knowledge of how to perform a task with a robot through\nmulti-modal instructions in their demonstrations, showing a sequence of\nshort-horizon steps to achieve a long-horizon goal. This paper introduces a\nmethod for robot action sequence generation from instruction videos using (1)\nan audio-visual Transformer that converts audio-visual features and instruction\nspeech to a sequence of robot actions called dynamic movement primitives (DMPs)\nand (2) style-transfer-based training that employs multi-task learning with\nvideo captioning and weakly-supervised learning with a semantic classifier to\nexploit unpaired video-action data. We built a system that accomplishes various\ncooking actions, where an arm robot executes a DMP sequence acquired from a\ncooking video using the audio-visual Transformer. Experiments with\nEpic-Kitchen-100, YouCookII, QuerYD, and in-house instruction video datasets\nshow that the proposed method improves the quality of DMP sequences by 2.3\ntimes the METEOR score obtained with a baseline video-to-action Transformer.\nThe model achieved 32% of the task success rate with the task knowledge of the\nobject.\n","authors":["Chiori Hori","Puyuan Peng","David Harwath","Xinyu Liu","Kei Ota","Siddarth Jain","Radu Corcodel","Devesh Jha","Diego Romeres","Jonathan Le Roux"],"pdf_url":"https://arxiv.org/pdf/2306.15644v1.pdf","comment":"Accepted to Interspeech2023"},{"id":"http://arxiv.org/abs/2306.15634v1","updated":"2023-06-27T17:21:00Z","published":"2023-06-27T17:21:00Z","title":"Automatic Annotation of Direct Speech in Written French Narratives","summary":"  The automatic annotation of direct speech (AADS) in written text has been\noften used in computational narrative understanding. Methods based on either\nrules or deep neural networks have been explored, in particular for English or\nGerman languages. Yet, for French, our target language, not many works exist.\nOur goal is to create a unified framework to design and evaluate AADS models in\nFrench. For this, we consolidated the largest-to-date French narrative dataset\nannotated with DS per word; we adapted various baselines for sequence labelling\nor from AADS in other languages; and we designed and conducted an extensive\nevaluation focused on generalisation. Results show that the task still requires\nsubstantial efforts and emphasise characteristics of each baseline. Although\nthis framework could be improved, it is a step further to encourage more\nresearch on the topic.\n","authors":["Noé Durandard","Viet-Anh Tan","Gaspard Michel","Elena V. Epure"],"pdf_url":"https://arxiv.org/pdf/2306.15634v1.pdf","comment":"9 pages, ACL 2023"},{"id":"http://arxiv.org/abs/2109.07446v2","updated":"2023-06-27T17:10:50Z","published":"2021-09-15T17:29:30Z","title":"When Does Translation Require Context? A Data-driven, Multilingual\n  Exploration","summary":"  Although proper handling of discourse significantly contributes to the\nquality of machine translation (MT), these improvements are not adequately\nmeasured in common translation quality metrics. Recent works in context-aware\nMT attempt to target a small set of discourse phenomena during evaluation,\nhowever not in a fully systematic way. In this paper, we develop the\nMultilingual Discourse-Aware (MuDA) benchmark, a series of taggers that\nidentify and evaluate model performance on discourse phenomena in any given\ndataset. The choice of phenomena is inspired by a novel methodology to\nsystematically identify translations requiring context. We confirm the\ndifficulty of previously studied phenomena while uncovering others that were\npreviously unaddressed. We find that common context-aware MT models make only\nmarginal improvements over context-agnostic models, which suggests these models\ndo not handle these ambiguities effectively. We release code and data for 14\nlanguage pairs to encourage the MT community to focus on accurately capturing\ndiscourse phenomena.\n","authors":["Patrick Fernandes","Kayo Yin","Emmy Liu","André F. T. Martins","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2109.07446v2.pdf","comment":"Accepted at ACL2023"},{"id":"http://arxiv.org/abs/2306.15604v1","updated":"2023-06-27T16:42:36Z","published":"2023-06-27T16:42:36Z","title":"Constructing Multilingual Code Search Dataset Using Neural Machine\n  Translation","summary":"  Code search is a task to find programming codes that semantically match the\ngiven natural language queries. Even though some of the existing datasets for\nthis task are multilingual on the programming language side, their query data\nare only in English. In this research, we create a multilingual code search\ndataset in four natural and four programming languages using a neural machine\ntranslation model. Using our dataset, we pre-train and fine-tune the\nTransformer-based models and then evaluate them on multiple code search test\nsets. Our results show that the model pre-trained with all natural and\nprogramming language data has performed best in most cases. By applying\nback-translation data filtering to our dataset, we demonstrate that the\ntranslation quality affects the model's performance to a certain extent, but\nthe data size matters more.\n","authors":["Ryo Sekizawa","Nan Duan","Shuai Lu","Hitomi Yanaka"],"pdf_url":"https://arxiv.org/pdf/2306.15604v1.pdf","comment":"To appear in the Proceedings of the ACL2023 Student Research Workshop\n  (SRW)"},{"id":"http://arxiv.org/abs/2306.15595v1","updated":"2023-06-27T16:26:26Z","published":"2023-06-27T16:26:26Z","title":"Extending Context Window of Large Language Models via Positional\n  Interpolation","summary":"  We present Position Interpolation (PI) that extends the context window sizes\nof RoPE-based pretrained LLMs such as LLaMA models to up to 32768 with minimal\nfine-tuning (within 1000 steps), while demonstrating strong empirical results\non various tasks that require long context, including passkey retrieval,\nlanguage modeling, and long document summarization from LLaMA 7B to 65B.\nMeanwhile, the extended model by Position Interpolation preserve quality\nrelatively well on tasks within its original context window. To achieve this\ngoal, Position Interpolation linearly down-scales the input position indices to\nmatch the original context window size, rather than extrapolating beyond the\ntrained context length which may lead to catastrophically high attention scores\nthat completely ruin the self-attention mechanism. Our theoretical study shows\nthat the upper bound of interpolation is at least $\\sim 600 \\times$ smaller\nthan that of extrapolation, further demonstrating its stability. Models\nextended via Position Interpolation retain its original architecture and can\nreuse most pre-existing optimization and infrastructure.\n","authors":["Shouyuan Chen","Sherman Wong","Liangjian Chen","Yuandong Tian"],"pdf_url":"https://arxiv.org/pdf/2306.15595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.11543v2","updated":"2023-06-27T15:45:46Z","published":"2023-05-19T09:26:02Z","title":"Constructing Word-Context-Coupled Space Aligned with Associative\n  Knowledge Relations for Interpretable Language Modeling","summary":"  As the foundation of current natural language processing methods, pre-trained\nlanguage model has achieved excellent performance. However, the black-box\nstructure of the deep neural network in pre-trained language models seriously\nlimits the interpretability of the language modeling process. After revisiting\nthe coupled requirement of deep neural representation and semantics logic of\nlanguage modeling, a Word-Context-Coupled Space (W2CSpace) is proposed by\nintroducing the alignment processing between uninterpretable neural\nrepresentation and interpretable statistical logic. Moreover, a clustering\nprocess is also designed to connect the word- and context-level semantics.\nSpecifically, an associative knowledge network (AKN), considered interpretable\nstatistical logic, is introduced in the alignment process for word-level\nsemantics. Furthermore, the context-relative distance is employed as the\nsemantic feature for the downstream classifier, which is greatly different from\nthe current uninterpretable semantic representations of pre-trained models. Our\nexperiments for performance evaluation and interpretable analysis are executed\non several types of datasets, including SIGHAN, Weibo, and ChnSenti. Wherein a\nnovel evaluation strategy for the interpretability of machine learning models\nis first proposed. According to the experimental results, our language model\ncan achieve better performance and highly credible interpretable ability\ncompared to related state-of-the-art methods.\n","authors":["Fanyu Wang","Zhenping Xie"],"pdf_url":"https://arxiv.org/pdf/2305.11543v2.pdf","comment":"Accepted at ACL 2023, Findings"},{"id":"http://arxiv.org/abs/2306.15551v1","updated":"2023-06-27T15:23:42Z","published":"2023-06-27T15:23:42Z","title":"CrunchGPT: A chatGPT assisted framework for scientific machine learning","summary":"  Scientific Machine Learning (SciML) has advanced recently across many\ndifferent areas in computational science and engineering. The objective is to\nintegrate data and physics seamlessly without the need of employing elaborate\nand computationally taxing data assimilation schemes. However, preprocessing,\nproblem formulation, code generation, postprocessing and analysis are still\ntime consuming and may prevent SciML from wide applicability in industrial\napplications and in digital twin frameworks. Here, we integrate the various\nstages of SciML under the umbrella of ChatGPT, to formulate CrunchGPT, which\nplays the role of a conductor orchestrating the entire workflow of SciML based\non simple prompts by the user. Specifically, we present two examples that\ndemonstrate the potential use of CrunchGPT in optimizing airfoils in\naerodynamics, and in obtaining flow fields in various geometries in interactive\nmode, with emphasis on the validation stage. To demonstrate the flow of the\nCrunchGPT, and create an infrastructure that can facilitate a broader vision,\nwe built a webapp based guided user interface, that includes options for a\ncomprehensive summary report. The overall objective is to extend CrunchGPT to\nhandle diverse problems in computational mechanics, design, optimization and\ncontrols, and general scientific computing tasks involved in SciML, hence using\nit as a research assistant tool but also as an educational tool. While here the\nexamples focus in fluid mechanics, future versions will target solid mechanics\nand materials science, geophysics, systems biology and bioinformatics.\n","authors":["Varun Kumar","Leonard Gleyzer","Adar Kahana","Khemraj Shukla","George Em Karniadakis"],"pdf_url":"https://arxiv.org/pdf/2306.15551v1.pdf","comment":"20 pages, 26 figures"},{"id":"http://arxiv.org/abs/2306.15550v1","updated":"2023-06-27T15:23:14Z","published":"2023-06-27T15:23:14Z","title":"CamemBERT-bio: a Tasty French Language Model Better for your Health","summary":"  Clinical data in hospitals are increasingly accessible for research through\nclinical data warehouses, however these documents are unstructured. It is\ntherefore necessary to extract information from medical reports to conduct\nclinical studies. Transfer learning with BERT-like models such as CamemBERT has\nallowed major advances, especially for named entity recognition. However, these\nmodels are trained for plain language and are less efficient on biomedical\ndata. This is why we propose a new French public biomedical dataset on which we\nhave continued the pre-training of CamemBERT. Thus, we introduce a first\nversion of CamemBERT-bio, a specialized public model for the French biomedical\ndomain that shows 2.54 points of F1 score improvement on average on different\nbiomedical named entity recognition tasks.\n","authors":["Rian Touchent","Laurent Romary","Eric de la Clergerie"],"pdf_url":"https://arxiv.org/pdf/2306.15550v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15541v1","updated":"2023-06-27T15:10:57Z","published":"2023-06-27T15:10:57Z","title":"Unleashing the Power of User Reviews: Exploring Airline Choices at\n  Catania Airport, Italy","summary":"  This study aims to investigate the possible relationship between the\nmechanisms of social influence and the choice of airline, through the use of\nnew tools, with the aim of understanding whether they can contribute to a\nbetter understanding of the factors influencing the decisions of consumers in\nthe aviation sector. We have chosen to extract user reviews from well-known\nplatforms: Trustpilot, Google, and Twitter. By combining web scraping\ntechniques, we have been able to collect a comprehensive dataset comprising a\nwide range of user opinions, feedback, and ratings. We then refined the BERT\nmodel to focus on insightful sentiment in the context of airline reviews.\nThrough our analysis, we observed an intriguing trend of average negative\nsentiment scores across various airlines, giving us deeper insight into the\ndynamics between airlines and helping us identify key partnerships, popular\nroutes, and airlines that play a central role in the aeronautical ecosystem of\nCatania airport during the specified period. Our investigation led us to find\nthat, despite an airline having received prestigious awards as a low-cost\nleader in Europe for two consecutive years 2021 and 2022, the \"Catanese\" user\ntends to suffer the dominant position of other companies. Understanding the\nimpact of positive reviews and leveraging sentiment analysis can help airlines\nimprove their reputation, attract more customers, and ultimately gain a\ncompetitive edge in the marketplace.\n","authors":["Vincenzo Miracula","Antonio Picone"],"pdf_url":"https://arxiv.org/pdf/2306.15541v1.pdf","comment":"arXiv admin note: text overlap with arXiv:1311.3475 by other authors"},{"id":"http://arxiv.org/abs/2306.15518v1","updated":"2023-06-27T14:46:47Z","published":"2023-06-27T14:46:47Z","title":"Paradigm Shift in Sustainability Disclosure Analysis: Empowering\n  Stakeholders with CHATREPORT, a Language Model-Based Tool","summary":"  This paper introduces a novel approach to enhance Large Language Models\n(LLMs) with expert knowledge to automate the analysis of corporate\nsustainability reports by benchmarking them against the Task Force for\nClimate-Related Financial Disclosures (TCFD) recommendations. Corporate\nsustainability reports are crucial in assessing organizations' environmental\nand social risks and impacts. However, analyzing these reports' vast amounts of\ninformation makes human analysis often too costly. As a result, only a few\nentities worldwide have the resources to analyze these reports, which could\nlead to a lack of transparency. While AI-powered tools can automatically\nanalyze the data, they are prone to inaccuracies as they lack domain-specific\nexpertise. This paper introduces a novel approach to enhance LLMs with expert\nknowledge to automate the analysis of corporate sustainability reports. We\nchristen our tool CHATREPORT, and apply it in a first use case to assess\ncorporate climate risk disclosures following the TCFD recommendations.\nCHATREPORT results from collaborating with experts in climate science, finance,\neconomic policy, and computer science, demonstrating how domain experts can be\ninvolved in developing AI tools. We make our prompt templates, generated data,\nand scores available to the public to encourage transparency.\n","authors":["Jingwei Ni","Julia Bingler","Chiara Colesanti-Senni","Mathias Kraus","Glen Gostlow","Tobias Schimanski","Dominik Stammbach","Saeid Ashraf Vaghefi","Qian Wang","Nicolas Webersinke","Tobias Wekhof","Tingyu Yu","Markus Leippold"],"pdf_url":"https://arxiv.org/pdf/2306.15518v1.pdf","comment":"This is a working paper"},{"id":"http://arxiv.org/abs/2306.15498v1","updated":"2023-06-27T14:19:12Z","published":"2023-06-27T14:19:12Z","title":"Using Large Language Models to Provide Explanatory Feedback to Human\n  Tutors","summary":"  Research demonstrates learners engaging in the process of producing\nexplanations to support their reasoning, can have a positive impact on\nlearning. However, providing learners real-time explanatory feedback often\npresents challenges related to classification accuracy, particularly in\ndomain-specific environments, containing situationally complex and nuanced\nresponses. We present two approaches for supplying tutors real-time feedback\nwithin an online lesson on how to give students effective praise. This\nwork-in-progress demonstrates considerable accuracy in binary classification\nfor corrective feedback of effective, or effort-based (F1 score = 0.811), and\nineffective, or outcome-based (F1 score = 0.350), praise responses. More\nnotably, we introduce progress towards an enhanced approach of providing\nexplanatory feedback using large language model-facilitated named entity\nrecognition, which can provide tutors feedback, not only while engaging in\nlessons, but can potentially suggest real-time tutor moves. Future work\ninvolves leveraging large language models for data augmentation to improve\naccuracy, while also developing an explanatory feedback interface.\n","authors":["Jionghao Lin","Danielle R. Thomas","Feifei Han","Shivang Gupta","Wei Tan","Ngoc Dang Nguyen","Kenneth R. Koedinger"],"pdf_url":"https://arxiv.org/pdf/2306.15498v1.pdf","comment":"12 pages Workshop paper, The 24th International Conference on\n  Artificial Intelligence in Education, AIED 2023 Educational Dialogue Act\n  Classification, Large Language Models, Named Entity Recognition, Tutor\n  Training, Explanatory Feedback, Natural Language Processing"},{"id":"http://arxiv.org/abs/2305.13108v3","updated":"2023-06-27T13:19:19Z","published":"2023-05-22T15:09:27Z","title":"Debiased Automatic Speech Recognition for Dysarthric Speech via Sample\n  Reweighting with Sample Affinity Test","summary":"  Automatic speech recognition systems based on deep learning are mainly\ntrained under empirical risk minimization (ERM). Since ERM utilizes the\naveraged performance on the data samples regardless of a group such as healthy\nor dysarthric speakers, ASR systems are unaware of the performance disparities\nacross the groups. This results in biased ASR systems whose performance\ndifferences among groups are severe. In this study, we aim to improve the ASR\nsystem in terms of group robustness for dysarthric speakers. To achieve our\ngoal, we present a novel approach, sample reweighting with sample affinity test\n(Re-SAT). Re-SAT systematically measures the debiasing helpfulness of the given\ndata sample and then mitigates the bias by debiasing helpfulness-based sample\nreweighting. Experimental results demonstrate that Re-SAT contributes to\nimproved ASR performance on dysarthric speech without performance degradation\non healthy speech.\n","authors":["Eungbeom Kim","Yunkee Chae","Jaeheon Sim","Kyogu Lee"],"pdf_url":"https://arxiv.org/pdf/2305.13108v3.pdf","comment":"Accepted by Interspeech 2023"},{"id":"http://arxiv.org/abs/2305.17760v3","updated":"2023-06-27T13:16:42Z","published":"2023-05-28T16:04:48Z","title":"Language Models are Bounded Pragmatic Speakers","summary":"  How do language models \"think\"? This paper formulates a probabilistic\ncognitive model called the bounded pragmatic speaker, which can characterize\nthe operation of different variations of language models. Specifically, we\ndemonstrate that large language models fine-tuned with reinforcement learning\nfrom human feedback (Ouyang et al., 2022) embody a model of thought that\nconceptually resembles a fast-and-slow model (Kahneman, 2011), which\npsychologists have attributed to humans. We discuss the limitations of\nreinforcement learning from human feedback as a fast-and-slow model of thought\nand propose avenues for expanding this framework. In essence, our research\nhighlights the value of adopting a cognitive probabilistic modeling approach to\ngain insights into the comprehension, evaluation, and advancement of language\nmodels.\n","authors":["Khanh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2305.17760v3.pdf","comment":"Proceedings of the First Workshop on Theory of Mind in Communicating\n  Agents at (TOM @ ICML 2023)"},{"id":"http://arxiv.org/abs/2306.15430v1","updated":"2023-06-27T12:38:49Z","published":"2023-06-27T12:38:49Z","title":"KnowPrefix-Tuning: A Two-Stage Prefix-Tuning Framework for\n  Knowledge-Grounded Dialogue Generation","summary":"  Existing knowledge-grounded conversation systems generate responses typically\nin a retrieve-then-generate manner. They require a large knowledge base and a\nstrong knowledge retrieval component, which is time- and resource-consuming. In\nthis paper, we address the challenge by leveraging the inherent knowledge\nencoded in the pre-trained language models (PLMs). We propose Knowledgeable\nPrefix Tuning (KnowPrefix-Tuning), a two-stage tuning framework, bypassing the\nretrieval process in a knowledge-grounded conversation system by injecting\nprior knowledge into the lightweight knowledge prefix. The knowledge prefix is\na sequence of continuous knowledge-specific vectors that can be learned during\ntraining. In addition, we propose a novel interactive re-parameterization\nmechanism that allows the prefix to interact fully with the PLM during the\noptimization of response generation. Experimental results demonstrate that\nKnowPrefix-Tuning outperforms fine-tuning and other lightweight tuning\napproaches, and performs comparably with strong retrieval-based baselines while\nbeing $3\\times$ faster during inference.\n","authors":["Jiaqi Bai","Zhao Yan","Jian Yang","Xinnian Liang","Hongcheng Guo","Zhoujun Li"],"pdf_url":"https://arxiv.org/pdf/2306.15430v1.pdf","comment":"Accepted by ECML-PKDD 2023 (Research Track)"},{"id":"http://arxiv.org/abs/2306.15425v1","updated":"2023-06-27T12:37:21Z","published":"2023-06-27T12:37:21Z","title":"Phase Space Analysis of Cardiac Spectra","summary":"  Cardiac diseases are one of the main reasons of mortality in modern,\nindustrialized societies, and they cause high expenses in public health\nsystems. Therefore, it is important to develop analytical methods to improve\ncardiac diagnostics. Electric activity of heart was first modeled by using a\nset of nonlinear differential equations. Latter, variations of cardiac spectra\noriginated from deterministic dynamics are investigated. Analyzing the power\nspectra of a normal human heart presents His-Purkinje network, possessing a\nfractal like structure. Phase space trajectories are extracted from the time\nseries graph of ECG. Lower values of fractal dimension, D indicate dynamics\nthat are more coherent. If D has non-integer values greater than two when the\nsystem becomes chaotic or strange attractor. Recently, the development of a\nfast and robust method, which can be applied to multichannel physiologic\nsignals, was reported. This manuscript investigates two different ECG systems\nproduced from normal and abnormal human hearts to introduce an auxiliary phase\nspace method in conjunction with ECG signals for diagnoses of heart diseases.\nHere, the data for each person includes two signals based on V_4 and modified\nlead III (MLIII) respectively. Fractal analysis method is employed on the\ntrajectories constructed in phase space, from which the fractal dimension D is\nobtained using the box counting method. It is observed that, MLIII signals have\nlarger D values than the first signals (V_4), predicting more randomness yet\nmore information. The lowest value of D (1.708) indicates the perfect\noscillation of the normal heart and the highest value of D (1.863) presents the\nrandomness of the abnormal heart. Our significant finding is that the phase\nspace picture presents the distribution of the peak heights from the ECG\nspectra, giving valuable information about heart activities in conjunction with\nECG.\n","authors":["Onder Pekcan","Taner Arsan"],"pdf_url":"https://arxiv.org/pdf/2306.15425v1.pdf","comment":"10 pages, 8 figures, 1 table. arXiv admin note: text overlap with\n  arXiv:2305.10450"},{"id":"http://arxiv.org/abs/2306.15399v1","updated":"2023-06-27T11:52:28Z","published":"2023-06-27T11:52:28Z","title":"Quality Estimation of Machine Translated Texts based on Direct Evidence\n  from Training Data","summary":"  Current Machine Translation systems achieve very good results on a growing\nvariety of language pairs and data sets. However, it is now well known that\nthey produce fluent translation outputs that often can contain important\nmeaning errors. Quality Estimation task deals with the estimation of quality of\ntranslations produced by a Machine Translation system without depending on\nReference Translations. A number of approaches have been suggested over the\nyears. In this paper we show that the parallel corpus used as training data for\ntraining the MT system holds direct clues for estimating the quality of\ntranslations produced by the MT system. Our experiments show that this simple\nand direct method holds promise for quality estimation of translations produced\nby any purely data driven machine translation system.\n","authors":["Vibhuti Kumari","Narayana Murthy Kavi"],"pdf_url":"https://arxiv.org/pdf/2306.15399v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13460v2","updated":"2023-06-27T11:38:30Z","published":"2023-06-23T12:03:07Z","title":"Learning Descriptive Image Captioning via Semipermeable Maximum\n  Likelihood Estimation","summary":"  Image captioning aims to describe visual content in natural language. As 'a\npicture is worth a thousand words', there could be various correct descriptions\nfor an image. However, with maximum likelihood estimation as the training\nobjective, the captioning model is penalized whenever its prediction mismatches\nwith the label. For instance, when the model predicts a word expressing richer\nsemantics than the label, it will be penalized and optimized to prefer more\nconcise expressions, referred to as conciseness optimization. In contrast,\npredictions that are more concise than labels lead to richness optimization.\nSuch conflicting optimization directions could eventually result in the model\ngenerating general descriptions. In this work, we introduce Semipermeable\nMaxImum Likelihood Estimation (SMILE), which allows richness optimization while\nblocking conciseness optimization, thus encouraging the model to generate\nlonger captions with more details. Extensive experiments on two mainstream\nimage captioning datasets MSCOCO and Flickr30K demonstrate that SMILE\nsignificantly enhances the descriptiveness of generated captions. We further\nprovide in-depth investigations to facilitate a better understanding of how\nSMILE works.\n","authors":["Zihao Yue","Anwen Hu","Liang Zhang","Qin Jin"],"pdf_url":"https://arxiv.org/pdf/2306.13460v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15376v1","updated":"2023-06-27T10:51:02Z","published":"2023-06-27T10:51:02Z","title":"Exploiting Pseudo Future Contexts for Emotion Recognition in\n  Conversations","summary":"  With the extensive accumulation of conversational data on the Internet,\nemotion recognition in conversations (ERC) has received increasing attention.\nPrevious efforts of this task mainly focus on leveraging contextual and\nspeaker-specific features, or integrating heterogeneous external commonsense\nknowledge. Among them, some heavily rely on future contexts, which, however,\nare not always available in real-life scenarios. This fact inspires us to\ngenerate pseudo future contexts to improve ERC. Specifically, for an utterance,\nwe generate its future context with pre-trained language models, potentially\ncontaining extra beneficial knowledge in a conversational form homogeneous with\nthe historical ones. These characteristics make pseudo future contexts easily\nfused with historical contexts and historical speaker-specific contexts,\nyielding a conceptually simple framework systematically integrating\nmulti-contexts. Experimental results on four ERC datasets demonstrate our\nmethod's superiority. Further in-depth analyses reveal that pseudo future\ncontexts can rival real ones to some extent, especially in relatively\ncontext-independent conversations.\n","authors":["Yinyi Wei","Shuaipeng Liu","Hailei Yan","Wei Ye","Tong Mo","Guanglu Wan"],"pdf_url":"https://arxiv.org/pdf/2306.15376v1.pdf","comment":"15 pages, accepted by ADMA 2023"},{"id":"http://arxiv.org/abs/2306.15364v1","updated":"2023-06-27T10:25:22Z","published":"2023-06-27T10:25:22Z","title":"The Architecture of a Biologically Plausible Language Organ","summary":"  We present a simulated biologically plausible language organ, made up of\nstylized but realistic neurons, synapses, brain areas, plasticity, and a\nsimplified model of sensory perception. We show through experiments that this\nmodel succeeds in an important early step in language acquisition: the learning\nof nouns, verbs, and their meanings, from the grounded input of only a modest\nnumber of sentences. Learning in this system is achieved through Hebbian\nplasticity, and without backpropagation. Our model goes beyond a parser\npreviously designed in a similar environment, with the critical addition of a\nbiologically plausible account for how language can be acquired in the infant's\nbrain, not just processed by a mature brain.\n","authors":["Daniel Mitropolsky","Christos H. Papadimitriou"],"pdf_url":"https://arxiv.org/pdf/2306.15364v1.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2306.15354v1","updated":"2023-06-27T10:09:43Z","published":"2023-06-27T10:09:43Z","title":"3D-Speaker: A Large-Scale Multi-Device, Multi-Distance, and\n  Multi-Dialect Corpus for Speech Representation Disentanglement","summary":"  Disentangling uncorrelated information in speech utterances is a crucial\nresearch topic within speech community. Different speech-related tasks focus on\nextracting distinct speech representations while minimizing the affects of\nother uncorrelated information. We present a large-scale speech corpus to\nfacilitate the research of speech representation disentanglement. 3D-Speaker\ncontains over 10,000 speakers, each of whom are simultaneously recorded by\nmultiple Devices, locating at different Distances, and some speakers are\nspeaking multiple Dialects. The controlled combinations of multi-dimensional\naudio data yield a matrix of a diverse blend of speech representation\nentanglement, thereby motivating intriguing methods to untangle them. The\nmulti-domain nature of 3D-Speaker also makes it a suitable resource to evaluate\nlarge universal speech models and experiment methods of out-of-domain learning\nand self-supervised learning. https://3dspeaker.github.io/\n","authors":["Siqi Zheng","Luyao Cheng","Yafeng Chen","Hui Wang","Qian Chen"],"pdf_url":"https://arxiv.org/pdf/2306.15354v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.05100v4","updated":"2023-06-27T09:57:58Z","published":"2022-11-09T18:48:09Z","title":"BLOOM: A 176B-Parameter Open-Access Multilingual Language Model","summary":"  Large language models (LLMs) have been shown to be able to perform new tasks\nbased on a few demonstrations or natural language instructions. While these\ncapabilities have led to widespread adoption, most LLMs are developed by\nresource-rich organizations and are frequently kept from the public. As a step\ntowards democratizing this powerful technology, we present BLOOM, a\n176B-parameter open-access language model designed and built thanks to a\ncollaboration of hundreds of researchers. BLOOM is a decoder-only Transformer\nlanguage model that was trained on the ROOTS corpus, a dataset comprising\nhundreds of sources in 46 natural and 13 programming languages (59 in total).\nWe find that BLOOM achieves competitive performance on a wide variety of\nbenchmarks, with stronger results after undergoing multitask prompted\nfinetuning. To facilitate future research and applications using LLMs, we\npublicly release our models and code under the Responsible AI License.\n","authors":["BigScience Workshop"," :","Teven Le Scao","Angela Fan","Christopher Akiki","Ellie Pavlick","Suzana Ilić","Daniel Hesslow","Roman Castagné","Alexandra Sasha Luccioni","François Yvon","Matthias Gallé","Jonathan Tow","Alexander M. Rush","Stella Biderman","Albert Webson","Pawan Sasanka Ammanamanchi","Thomas Wang","Benoît Sagot","Niklas Muennighoff","Albert Villanova del Moral","Olatunji Ruwase","Rachel Bawden","Stas Bekman","Angelina McMillan-Major","Iz Beltagy","Huu Nguyen","Lucile Saulnier","Samson Tan","Pedro Ortiz Suarez","Victor Sanh","Hugo Laurençon","Yacine Jernite","Julien Launay","Margaret Mitchell","Colin Raffel","Aaron Gokaslan","Adi Simhi","Aitor Soroa","Alham Fikri Aji","Amit Alfassy","Anna Rogers","Ariel Kreisberg Nitzav","Canwen Xu","Chenghao Mou","Chris Emezue","Christopher Klamm","Colin Leong","Daniel van Strien","David Ifeoluwa Adelani","Dragomir Radev","Eduardo González Ponferrada","Efrat Levkovizh","Ethan Kim","Eyal Bar Natan","Francesco De Toni","Gérard Dupont","Germán Kruszewski","Giada Pistilli","Hady Elsahar","Hamza Benyamina","Hieu Tran","Ian Yu","Idris Abdulmumin","Isaac Johnson","Itziar Gonzalez-Dios","Javier de la Rosa","Jenny Chim","Jesse Dodge","Jian Zhu","Jonathan Chang","Jörg Frohberg","Joseph Tobing","Joydeep Bhattacharjee","Khalid Almubarak","Kimbo Chen","Kyle Lo","Leandro Von Werra","Leon Weber","Long Phan","Loubna Ben allal","Ludovic Tanguy","Manan Dey","Manuel Romero Muñoz","Maraim Masoud","María Grandury","Mario Šaško","Max Huang","Maximin Coavoux","Mayank Singh","Mike Tian-Jian Jiang","Minh Chien Vu","Mohammad A. Jauhar","Mustafa Ghaleb","Nishant Subramani","Nora Kassner","Nurulaqilla Khamis","Olivier Nguyen","Omar Espejel","Ona de Gibert","Paulo Villegas","Peter Henderson","Pierre Colombo","Priscilla Amuok","Quentin Lhoest","Rheza Harliman","Rishi Bommasani","Roberto Luis López","Rui Ribeiro","Salomey Osei","Sampo Pyysalo","Sebastian Nagel","Shamik Bose","Shamsuddeen Hassan Muhammad","Shanya Sharma","Shayne Longpre","Somaieh Nikpoor","Stanislav Silberberg","Suhas Pai","Sydney Zink","Tiago Timponi Torrent","Timo Schick","Tristan Thrush","Valentin Danchev","Vassilina Nikoulina","Veronika Laippala","Violette Lepercq","Vrinda Prabhu","Zaid Alyafeai","Zeerak Talat","Arun Raja","Benjamin Heinzerling","Chenglei Si","Davut Emre Taşar","Elizabeth Salesky","Sabrina J. Mielke","Wilson Y. Lee","Abheesht Sharma","Andrea Santilli","Antoine Chaffin","Arnaud Stiegler","Debajyoti Datta","Eliza Szczechla","Gunjan Chhablani","Han Wang","Harshit Pandey","Hendrik Strobelt","Jason Alan Fries","Jos Rozen","Leo Gao","Lintang Sutawika","M Saiful Bari","Maged S. Al-shaibani","Matteo Manica","Nihal Nayak","Ryan Teehan","Samuel Albanie","Sheng Shen","Srulik Ben-David","Stephen H. Bach","Taewoon Kim","Tali Bers","Thibault Fevry","Trishala Neeraj","Urmish Thakker","Vikas Raunak","Xiangru Tang","Zheng-Xin Yong","Zhiqing Sun","Shaked Brody","Yallow Uri","Hadar Tojarieh","Adam Roberts","Hyung Won Chung","Jaesung Tae","Jason Phang","Ofir Press","Conglong Li","Deepak Narayanan","Hatim Bourfoune","Jared Casper","Jeff Rasley","Max Ryabinin","Mayank Mishra","Minjia Zhang","Mohammad Shoeybi","Myriam Peyrounette","Nicolas Patry","Nouamane Tazi","Omar Sanseviero","Patrick von Platen","Pierre Cornette","Pierre François Lavallée","Rémi Lacroix","Samyam Rajbhandari","Sanchit Gandhi","Shaden Smith","Stéphane Requena","Suraj Patil","Tim Dettmers","Ahmed Baruwa","Amanpreet Singh","Anastasia Cheveleva","Anne-Laure Ligozat","Arjun Subramonian","Aurélie Névéol","Charles Lovering","Dan Garrette","Deepak Tunuguntla","Ehud Reiter","Ekaterina Taktasheva","Ekaterina Voloshina","Eli Bogdanov","Genta Indra Winata","Hailey Schoelkopf","Jan-Christoph Kalo","Jekaterina Novikova","Jessica Zosa Forde","Jordan Clive","Jungo Kasai","Ken Kawamura","Liam Hazan","Marine Carpuat","Miruna Clinciu","Najoung Kim","Newton Cheng","Oleg Serikov","Omer Antverg","Oskar van der Wal","Rui Zhang","Ruochen Zhang","Sebastian Gehrmann","Shachar Mirkin","Shani Pais","Tatiana Shavrina","Thomas Scialom","Tian Yun","Tomasz Limisiewicz","Verena Rieser","Vitaly Protasov","Vladislav Mikhailov","Yada Pruksachatkun","Yonatan Belinkov","Zachary Bamberger","Zdeněk Kasner","Alice Rueda","Amanda Pestana","Amir Feizpour","Ammar Khan","Amy Faranak","Ana Santos","Anthony Hevia","Antigona Unldreaj","Arash Aghagol","Arezoo Abdollahi","Aycha Tammour","Azadeh HajiHosseini","Bahareh Behroozi","Benjamin Ajibade","Bharat Saxena","Carlos Muñoz Ferrandis","Daniel McDuff","Danish Contractor","David Lansky","Davis David","Douwe Kiela","Duong A. Nguyen","Edward Tan","Emi Baylor","Ezinwanne Ozoani","Fatima Mirza","Frankline Ononiwu","Habib Rezanejad","Hessie Jones","Indrani Bhattacharya","Irene Solaiman","Irina Sedenko","Isar Nejadgholi","Jesse Passmore","Josh Seltzer","Julio Bonis Sanz","Livia Dutra","Mairon Samagaio","Maraim Elbadri","Margot Mieskes","Marissa Gerchick","Martha Akinlolu","Michael McKenna","Mike Qiu","Muhammed Ghauri","Mykola Burynok","Nafis Abrar","Nazneen Rajani","Nour Elkott","Nour Fahmy","Olanrewaju Samuel","Ran An","Rasmus Kromann","Ryan Hao","Samira Alizadeh","Sarmad Shubber","Silas Wang","Sourav Roy","Sylvain Viguier","Thanh Le","Tobi Oyebade","Trieu Le","Yoyo Yang","Zach Nguyen","Abhinav Ramesh Kashyap","Alfredo Palasciano","Alison Callahan","Anima Shukla","Antonio Miranda-Escalada","Ayush Singh","Benjamin Beilharz","Bo Wang","Caio Brito","Chenxi Zhou","Chirag Jain","Chuxin Xu","Clémentine Fourrier","Daniel León Periñán","Daniel Molano","Dian Yu","Enrique Manjavacas","Fabio Barth","Florian Fuhrimann","Gabriel Altay","Giyaseddin Bayrak","Gully Burns","Helena U. Vrabec","Imane Bello","Ishani Dash","Jihyun Kang","John Giorgi","Jonas Golde","Jose David Posada","Karthik Rangasai Sivaraman","Lokesh Bulchandani","Lu Liu","Luisa Shinzato","Madeleine Hahn de Bykhovetz","Maiko Takeuchi","Marc Pàmies","Maria A Castillo","Marianna Nezhurina","Mario Sänger","Matthias Samwald","Michael Cullan","Michael Weinberg","Michiel De Wolf","Mina Mihaljcic","Minna Liu","Moritz Freidank","Myungsun Kang","Natasha Seelam","Nathan Dahlberg","Nicholas Michio Broad","Nikolaus Muellner","Pascale Fung","Patrick Haller","Ramya Chandrasekhar","Renata Eisenberg","Robert Martin","Rodrigo Canalli","Rosaline Su","Ruisi Su","Samuel Cahyawijaya","Samuele Garda","Shlok S Deshmukh","Shubhanshu Mishra","Sid Kiblawi","Simon Ott","Sinee Sang-aroonsiri","Srishti Kumar","Stefan Schweter","Sushil Bharati","Tanmay Laud","Théo Gigant","Tomoya Kainuma","Wojciech Kusa","Yanis Labrak","Yash Shailesh Bajaj","Yash Venkatraman","Yifan Xu","Yingxin Xu","Yu Xu","Zhe Tan","Zhongli Xie","Zifan Ye","Mathilde Bras","Younes Belkada","Thomas Wolf"],"pdf_url":"https://arxiv.org/pdf/2211.05100v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15334v1","updated":"2023-06-27T09:39:54Z","published":"2023-06-27T09:39:54Z","title":"Understanding Client Reactions in Online Mental Health Counseling","summary":"  Communication success relies heavily on reading participants' reactions. Such\nfeedback is especially important for mental health counselors, who must\ncarefully consider the client's progress and adjust their approach accordingly.\nHowever, previous NLP research on counseling has mainly focused on studying\ncounselors' intervention strategies rather than their clients' reactions to the\nintervention. This work aims to fill this gap by developing a theoretically\ngrounded annotation framework that encompasses counselors' strategies and\nclient reaction behaviors. The framework has been tested against a large-scale,\nhigh-quality text-based counseling dataset we collected over the past two years\nfrom an online welfare counseling platform. Our study shows how clients react\nto counselors' strategies, how such reactions affect the final counseling\noutcomes, and how counselors can adjust their strategies in response to these\nreactions. We also demonstrate that this study can help counselors\nautomatically predict their clients' states.\n","authors":["Anqi Li","Lizhi Ma","Yaling Mei","Hongliang He","Shuai Zhang","Huachuan Qiu","Zhenzhong Lan"],"pdf_url":"https://arxiv.org/pdf/2306.15334v1.pdf","comment":"Accept to ACL 2023, oral. For code and data, see\n  https://github.com/dll-wu/Client-React"},{"id":"http://arxiv.org/abs/2205.10828v4","updated":"2023-06-27T09:34:34Z","published":"2022-05-22T13:54:44Z","title":"What Do Compressed Multilingual Machine Translation Models Forget?","summary":"  Recently, very large pre-trained models achieve state-of-the-art results in\nvarious natural language processing (NLP) tasks, but their size makes it more\nchallenging to apply them in resource-constrained environments. Compression\ntechniques allow to drastically reduce the size of the models and therefore\ntheir inference time with negligible impact on top-tier metrics. However, the\ngeneral performance averaged across multiple tasks and/or languages may hide a\ndrastic performance drop on under-represented features, which could result in\nthe amplification of biases encoded by the models. In this work, we assess the\nimpact of compression methods on Multilingual Neural Machine Translation models\n(MNMT) for various language groups, gender, and semantic biases by extensive\nanalysis of compressed models on different machine translation benchmarks, i.e.\nFLORES-101, MT-Gender, and DiBiMT. We show that the performance of\nunder-represented languages drops significantly, while the average BLEU metric\nonly slightly decreases. Interestingly, the removal of noisy memorization with\ncompression leads to a significant improvement for some medium-resource\nlanguages. Finally, we demonstrate that compression amplifies intrinsic gender\nand semantic biases, even in high-resource languages. Code:\nhttps://github.com/alirezamshi/bias-compressedMT\n","authors":["Alireza Mohammadshahi","Vassilina Nikoulina","Alexandre Berard","Caroline Brun","James Henderson","Laurent Besacier"],"pdf_url":"https://arxiv.org/pdf/2205.10828v4.pdf","comment":"Accepted to Findings of EMNLP 2022, presented at WMT 2022"},{"id":"http://arxiv.org/abs/2306.14824v2","updated":"2023-06-27T09:11:34Z","published":"2023-06-26T16:32:47Z","title":"Kosmos-2: Grounding Multimodal Large Language Models to the World","summary":"  We introduce Kosmos-2, a Multimodal Large Language Model (MLLM), enabling new\ncapabilities of perceiving object descriptions (e.g., bounding boxes) and\ngrounding text to the visual world. Specifically, we represent refer\nexpressions as links in Markdown, i.e., ``[text span](bounding boxes)'', where\nobject descriptions are sequences of location tokens. Together with multimodal\ncorpora, we construct large-scale data of grounded image-text pairs (called\nGrIT) to train the model. In addition to the existing capabilities of MLLMs\n(e.g., perceiving general modalities, following instructions, and performing\nin-context learning), Kosmos-2 integrates the grounding capability into\ndownstream applications. We evaluate Kosmos-2 on a wide range of tasks,\nincluding (i) multimodal grounding, such as referring expression comprehension,\nand phrase grounding, (ii) multimodal referring, such as referring expression\ngeneration, (iii) perception-language tasks, and (iv) language understanding\nand generation. This work lays out the foundation for the development of\nEmbodiment AI and sheds light on the big convergence of language, multimodal\nperception, action, and world modeling, which is a key step toward artificial\ngeneral intelligence. Data, demo, and pretrained models are available at\nhttps://aka.ms/kosmos-2.\n","authors":["Zhiliang Peng","Wenhui Wang","Li Dong","Yaru Hao","Shaohan Huang","Shuming Ma","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2306.14824v2.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2303.09901v2","updated":"2023-06-27T08:52:50Z","published":"2023-03-17T11:33:06Z","title":"mCPT at SemEval-2023 Task 3: Multilingual Label-Aware Contrastive\n  Pre-Training of Transformers for Few- and Zero-shot Framing Detection","summary":"  This paper presents the winning system for the zero-shot Spanish framing\ndetection task, which also achieves competitive places in eight additional\nlanguages. The challenge of the framing detection task lies in identifying a\nset of 14 frames when only a few or zero samples are available, i.e., a\nmultilingual multi-label few- or zero-shot setting. Our developed solution\nemploys a pre-training procedure based on multilingual Transformers using a\nlabel-aware contrastive loss function. In addition to describing the system, we\nperform an embedding space analysis and ablation study to demonstrate how our\npre-training procedure supports framing detection to advance computational\nframing analysis.\n","authors":["Markus Reiter-Haas","Alexander Ertl","Kevin Innerhofer","Elisabeth Lex"],"pdf_url":"https://arxiv.org/pdf/2303.09901v2.pdf","comment":"Accepted for publication at SemEval'23"},{"id":"http://arxiv.org/abs/2306.15298v1","updated":"2023-06-27T08:36:35Z","published":"2023-06-27T08:36:35Z","title":"Gender Bias in BERT -- Measuring and Analysing Biases through Sentiment\n  Rating in a Realistic Downstream Classification Task","summary":"  Pretrained language models are publicly available and constantly finetuned\nfor various real-life applications. As they become capable of grasping complex\ncontextual information, harmful biases are likely increasingly intertwined with\nthose models. This paper analyses gender bias in BERT models with two main\ncontributions: First, a novel bias measure is introduced, defining biases as\nthe difference in sentiment valuation of female and male sample versions.\nSecond, we comprehensively analyse BERT's biases on the example of a realistic\nIMDB movie classifier. By systematically varying elements of the training\npipeline, we can conclude regarding their impact on the final model bias. Seven\ndifferent public BERT models in nine training conditions, i.e. 63 models in\ntotal, are compared. Almost all conditions yield significant gender biases.\nResults indicate that reflected biases stem from public BERT models rather than\ntask-specific data, emphasising the weight of responsible usage.\n","authors":["Sophie Jentzsch","Cigdem Turan"],"pdf_url":"https://arxiv.org/pdf/2306.15298v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13596v2","updated":"2023-06-27T08:28:40Z","published":"2023-06-23T16:35:46Z","title":"Max-Margin Token Selection in Attention Mechanism","summary":"  Attention mechanism is a central component of the transformer architecture\nwhich led to the phenomenal success of large language models. However, the\ntheoretical principles underlying the attention mechanism are poorly\nunderstood, especially its nonconvex optimization dynamics. In this work, we\nexplore the seminal softmax-attention model $f(\\boldsymbol{X})=\\langle\n\\boldsymbol{Xv}, \\texttt{softmax}(\\boldsymbol{XWp})\\rangle$, where\n$\\boldsymbol{X}$ is the token sequence and\n$(\\boldsymbol{v},\\boldsymbol{W},\\boldsymbol{p})$ are trainable parameters. We\nprove that running gradient descent on $\\boldsymbol{p}$, or equivalently\n$\\boldsymbol{W}$, converges in direction to a max-margin solution that\nseparates $\\textit{locally-optimal}$ tokens from non-optimal ones. This clearly\nformalizes attention as an optimal token selection mechanism. Remarkably, our\nresults are applicable to general data and precisely characterize\n$\\textit{optimality}$ of tokens in terms of the value embeddings\n$\\boldsymbol{Xv}$ and problem geometry. We also provide a broader\nregularization path analysis that establishes the margin maximizing nature of\nattention even for nonlinear prediction heads. When optimizing $\\boldsymbol{v}$\nand $\\boldsymbol{p}$ simultaneously with logistic loss, we identify conditions\nunder which the regularization paths directionally converge to their respective\nhard-margin SVM solutions where $\\boldsymbol{v}$ separates the input features\nbased on their labels. Interestingly, the SVM formulation of $\\boldsymbol{p}$\nis influenced by the support vector geometry of $\\boldsymbol{v}$. Finally, we\nverify our theoretical findings via numerical experiments and provide insights.\n","authors":["Davoud Ataee Tarzanagh","Yingcong Li","Xuechen Zhang","Samet Oymak"],"pdf_url":"https://arxiv.org/pdf/2306.13596v2.pdf","comment":"minor edits and title change"},{"id":"http://arxiv.org/abs/2306.15273v1","updated":"2023-06-27T07:57:42Z","published":"2023-06-27T07:57:42Z","title":"IDOL: Indicator-oriented Logic Pre-training for Logical Reasoning","summary":"  In the field of machine reading comprehension (MRC), existing systems have\nsurpassed the average performance of human beings in many tasks like SQuAD.\nHowever, there is still a long way to go when it comes to logical reasoning.\nAlthough some methods for it have been put forward, they either are designed in\na quite complicated way or rely too much on external structures. In this paper,\nwe proposed IDOL (InDicator-Oriented Logic Pre-training), an easy-to-understand\nbut highly effective further pre-training task which logically strengthens the\npre-trained models with the help of 6 types of logical indicators and a\nlogically rich dataset LGP (LoGic Pre-training). IDOL achieves state-of-the-art\nperformance on ReClor and LogiQA, the two most representative benchmarks in\nlogical reasoning MRC, and is proven to be capable of generalizing to different\npre-trained models and other types of MRC benchmarks like RACE and SQuAD 2.0\nwhile keeping competitive general language understanding ability through\ntesting on tasks in GLUE. Besides, at the beginning of the era of large\nlanguage models, we take several of them like ChatGPT into comparison and find\nthat IDOL still shows its advantage.\n","authors":["Zihang Xu","Ziqing Yang","Yiming Cui","Shijin Wang"],"pdf_url":"https://arxiv.org/pdf/2306.15273v1.pdf","comment":"Accepted to the Findings of ACL 2023"},{"id":"http://arxiv.org/abs/2306.15268v1","updated":"2023-06-27T07:51:01Z","published":"2023-06-27T07:51:01Z","title":"Can Pretrained Language Models Derive Correct Semantics from Corrupt\n  Subwords under Noise?","summary":"  For Pretrained Language Models (PLMs), their susceptibility to noise has\nrecently been linked to subword segmentation. However, it is unclear which\naspects of segmentation affect their understanding. This study assesses the\nrobustness of PLMs against various disrupted segmentation caused by noise. An\nevaluation framework for subword segmentation, named Contrastive Lexical\nSemantic (CoLeS) probe, is proposed. It provides a systematic categorization of\nsegmentation corruption under noise and evaluation protocols by generating\ncontrastive datasets with canonical-noisy word pairs. Experimental results\nindicate that PLMs are unable to accurately compute word meanings if the noise\nintroduces completely different subwords, small subword fragments, or a large\nnumber of additional subwords, particularly when they are inserted within other\nsubwords.\n","authors":["Xinzhe Li","Ming Liu","Shang Gao"],"pdf_url":"https://arxiv.org/pdf/2306.15268v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15261v1","updated":"2023-06-27T07:44:25Z","published":"2023-06-27T07:44:25Z","title":"A Survey on Out-of-Distribution Evaluation of Neural NLP Models","summary":"  Adversarial robustness, domain generalization and dataset biases are three\nactive lines of research contributing to out-of-distribution (OOD) evaluation\non neural NLP models. However, a comprehensive, integrated discussion of the\nthree research lines is still lacking in the literature. In this survey, we 1)\ncompare the three lines of research under a unifying definition; 2) summarize\nthe data-generating processes and evaluation protocols for each line of\nresearch; and 3) emphasize the challenges and opportunities for future work.\n","authors":["Xinzhe Li","Ming Liu","Shang Gao","Wray Buntine"],"pdf_url":"https://arxiv.org/pdf/2306.15261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.08500v2","updated":"2023-06-27T07:40:15Z","published":"2023-02-16T18:55:21Z","title":"Auditing large language models: a three-layered approach","summary":"  Large language models (LLMs) represent a major advance in artificial\nintelligence (AI) research. However, the widespread use of LLMs is also coupled\nwith significant ethical and social challenges. Previous research has pointed\ntowards auditing as a promising governance mechanism to help ensure that AI\nsystems are designed and deployed in ways that are ethical, legal, and\ntechnically robust. However, existing auditing procedures fail to address the\ngovernance challenges posed by LLMs, which display emergent capabilities and\nare adaptable to a wide range of downstream tasks. In this article, we address\nthat gap by outlining a novel blueprint for how to audit LLMs. Specifically, we\npropose a three-layered approach, whereby governance audits (of technology\nproviders that design and disseminate LLMs), model audits (of LLMs after\npre-training but prior to their release), and application audits (of\napplications based on LLMs) complement and inform each other. We show how\naudits, when conducted in a structured and coordinated manner on all three\nlevels, can be a feasible and effective mechanism for identifying and managing\nsome of the ethical and social risks posed by LLMs. However, it is important to\nremain realistic about what auditing can reasonably be expected to achieve.\nTherefore, we discuss the limitations not only of our three-layered approach\nbut also of the prospect of auditing LLMs at all. Ultimately, this article\nseeks to expand the methodological toolkit available to technology providers\nand policymakers who wish to analyse and evaluate LLMs from technical, ethical,\nand legal perspectives.\n","authors":["Jakob Mökander","Jonas Schuett","Hannah Rose Kirk","Luciano Floridi"],"pdf_url":"https://arxiv.org/pdf/2302.08500v2.pdf","comment":"22 pages, 2 figures. AI Ethics (2023)"},{"id":"http://arxiv.org/abs/2306.15255v1","updated":"2023-06-27T07:27:52Z","published":"2023-06-27T07:27:52Z","title":"GroundNLQ @ Ego4D Natural Language Queries Challenge 2023","summary":"  In this report, we present our champion solution for Ego4D Natural Language\nQueries (NLQ) Challenge in CVPR 2023. Essentially, to accurately ground in a\nvideo, an effective egocentric feature extractor and a powerful grounding model\nare required. Motivated by this, we leverage a two-stage pre-training strategy\nto train egocentric feature extractors and the grounding model on video\nnarrations, and further fine-tune the model on annotated data. In addition, we\nintroduce a novel grounding model GroundNLQ, which employs a multi-modal\nmulti-scale grounding module for effective video and text fusion and various\ntemporal intervals, especially for long videos. On the blind test set,\nGroundNLQ achieves 25.67 and 18.18 for R1@IoU=0.3 and R1@IoU=0.5, respectively,\nand surpasses all other teams by a noticeable margin. Our code will be released\nat\\url{https://github.com/houzhijian/GroundNLQ}.\n","authors":["Zhijian Hou","Lei Ji","Difei Gao","Wanjun Zhong","Kun Yan","Chao Li","Wing-Kwong Chan","Chong-Wah Ngo","Nan Duan","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2306.15255v1.pdf","comment":"5 pages, 2 figures, 4 tables, the champion solution for Ego4D Natural\n  Language Queries Challenge in CVPR 2023"},{"id":"http://arxiv.org/abs/2306.15253v1","updated":"2023-06-27T07:24:32Z","published":"2023-06-27T07:24:32Z","title":"MindDial: Belief Dynamics Tracking with Theory-of-Mind Modeling for\n  Situated Neural Dialogue Generation","summary":"  Humans talk in free-form while negotiating the expressed meanings or common\nground. Despite the impressive conversational abilities of the large generative\nlanguage models, they do not consider the individual differences in contextual\nunderstanding in a shared situated environment. In this work, we propose\nMindDial, a novel conversational framework that can generate situated free-form\nresponses to negotiate common ground. We design an explicit mind module that\ncan track three-level beliefs -- the speaker's belief, the speaker's prediction\nof the listener's belief, and the common belief based on the gap between the\nfirst two. Then the speaking act classification head will decide to continue to\ntalk, end this turn, or take task-related action. We augment a common ground\nalignment dataset MutualFriend with belief dynamics annotation, of which the\ngoal is to find a single mutual friend based on the free chat between two\nagents. Experiments show that our model with mental state modeling can resemble\nhuman responses when aligning common ground meanwhile mimic the natural human\nconversation flow. The ablation study further validates the third-level common\nbelief can aggregate information of the first and second-order beliefs and\nalign common ground more efficiently.\n","authors":["Shuwen Qiu","Song-Chun Zhu","Zilong Zheng"],"pdf_url":"https://arxiv.org/pdf/2306.15253v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05352v2","updated":"2023-06-27T06:59:50Z","published":"2023-03-07T17:54:53Z","title":"Extracting Accurate Materials Data from Research Papers with\n  Conversational Language Models and Prompt Engineering","summary":"  There has been a growing effort to replace hand extraction of data from\nresearch papers with automated data extraction based on natural language\nprocessing, language models, and recently, large language models (LLMs).\nAlthough these methods enable efficient extraction of data from large sets of\nresearch papers, they require a significant amount of up-front effort,\nexpertise, and coding. In this work we propose the ChatExtract method that can\nfully automate very accurate data extraction with minimal initial effort and\nbackground, using an advanced conversational LLM. ChatExtract consists of a set\nof engineered prompts applied to a conversational LLM that both identify\nsentences with data, extract that data, and assure the data's correctness\nthrough a series of follow-up questions. These follow-up questions largely\novercome known issues with LLMs providing factually inaccurate responses.\nChatExtract can be applied with any conversational LLMs and yields very high\nquality data extraction. In tests on materials data we find precision and\nrecall both close to 90% from the best conversational LLMs, like ChatGPT-4. We\ndemonstrate that the exceptional performance is enabled by the information\nretention in a conversational model combined with purposeful redundancy and\nintroducing uncertainty through follow-up prompts. These results suggest that\napproaches similar to ChatExtract, due to their simplicity, transferability,\nand accuracy are likely to become powerful tools for data extraction in the\nnear future. Finally, databases for critical cooling rates of metallic glasses\nand yield strengths of high entropy alloys are developed using ChatExtract.\n","authors":["Maciej P. Polak","Dane Morgan"],"pdf_url":"https://arxiv.org/pdf/2303.05352v2.pdf","comment":"7 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2306.14514v2","updated":"2023-06-27T06:59:28Z","published":"2023-06-26T08:45:47Z","title":"Data-Driven Approach for Formality-Sensitive Machine Translation:\n  Language-Specific Handling and Synthetic Data Generation","summary":"  In this paper, we introduce a data-driven approach for Formality-Sensitive\nMachine Translation (FSMT) that caters to the unique linguistic properties of\nfour target languages. Our methodology centers on two core strategies: 1)\nlanguage-specific data handling, and 2) synthetic data generation using\nlarge-scale language models and empirical prompt engineering. This approach\ndemonstrates a considerable improvement over the baseline, highlighting the\neffectiveness of data-centric techniques. Our prompt engineering strategy\nfurther improves performance by producing superior synthetic translation\nexamples.\n","authors":["Seugnjun Lee","Hyeonseok Moon","Chanjun Park","Heuiseok Lim"],"pdf_url":"https://arxiv.org/pdf/2306.14514v2.pdf","comment":"Accepted for Data-centric Machine Learning Research (DMLR) Workshop\n  at ICML 2023"},{"id":"http://arxiv.org/abs/2306.15245v1","updated":"2023-06-27T06:58:03Z","published":"2023-06-27T06:58:03Z","title":"C-PMI: Conditional Pointwise Mutual Information for Turn-level Dialogue\n  Evaluation","summary":"  Existing reference-free turn-level evaluation metrics for chatbots\ninadequately capture the interaction between the user and the system.\nConsequently, they often correlate poorly with human evaluations. To address\nthis issue, we propose a novel model-agnostic approach that leverages\nConditional Pointwise Mutual Information (C-PMI) to measure the turn-level\ninteraction between the system and the user based on a given evaluation\ndimension. Experimental results on the widely used FED dialogue evaluation\ndataset demonstrate that our approach significantly improves the correlation\nwith human judgment compared with existing evaluation systems. By replacing the\nnegative log-likelihood-based scorer with our proposed C-PMI scorer, we achieve\na relative 60.5% higher Spearman correlation on average for the FED evaluation\nmetric. Our code is publicly available at https://github.com/renll/C-PMI.\n","authors":["Liliang Ren","Mankeerat Sidhu","Qi Zeng","Revanth Gangi Reddy","Heng Ji","ChengXiang Zhai"],"pdf_url":"https://arxiv.org/pdf/2306.15245v1.pdf","comment":"Presented at ACL2023 DiaDoc Workshop"},{"id":"http://arxiv.org/abs/2306.15231v1","updated":"2023-06-27T06:14:24Z","published":"2023-06-27T06:14:24Z","title":"Emulating Reader Behaviors for Fake News Detection","summary":"  The wide dissemination of fake news has affected our lives in many aspects,\nmaking fake news detection important and attracting increasing attention.\nExisting approaches make substantial contributions in this field by modeling\nnews from a single-modal or multi-modal perspective. However, these modal-based\nmethods can result in sub-optimal outcomes as they ignore reader behaviors in\nnews consumption and authenticity verification. For instance, they haven't\ntaken into consideration the component-by-component reading process: from the\nheadline, images, comments, to the body, which is essential for modeling news\nwith more granularity. To this end, we propose an approach of Emulating the\nbehaviors of readers (Ember) for fake news detection on social media,\nincorporating readers' reading and verificating process to model news from the\ncomponent perspective thoroughly. Specifically, we first construct\nintra-component feature extractors to emulate the behaviors of semantic\nanalyzing on each component. Then, we design a module that comprises\ninter-component feature extractors and a sequence-based aggregator. This module\nmimics the process of verifying the correlation between components and the\noverall reading and verification sequence. Thus, Ember can handle the news with\nvarious components by emulating corresponding sequences. We conduct extensive\nexperiments on nine real-world datasets, and the results demonstrate the\nsuperiority of Ember.\n","authors":["Junwei Yin","Min Gao","Kai Shu","Zehua Zhao","Yinqiu Huang","Jia Wang"],"pdf_url":"https://arxiv.org/pdf/2306.15231v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2305.13583v2","updated":"2023-06-27T05:48:46Z","published":"2023-05-23T01:24:15Z","title":"Cross-Attention is Not Enough: Incongruity-Aware Hierarchical Multimodal\n  Sentiment Analysis and Emotion Recognition","summary":"  Fusing multiple modalities for affective computing tasks has proven effective\nfor performance improvement. However, how multimodal fusion works is not well\nunderstood, and its use in the real world usually results in large model sizes.\nIn this work, on sentiment and emotion analysis, we first analyze how the\nsalient affective information in one modality can be affected by the other in\ncrossmodal attention. We find that inter-modal incongruity exists at the latent\nlevel due to crossmodal attention. Based on this finding, we propose a\nlightweight model via Hierarchical Crossmodal Transformer with Modality Gating\n(HCT-MG), which determines a primary modality according to its contribution to\nthe target task and then hierarchically incorporates auxiliary modalities to\nalleviate inter-modal incongruity and reduce information redundancy. The\nexperimental evaluation on three benchmark datasets: CMU-MOSI, CMU-MOSEI, and\nIEMOCAP verifies the efficacy of our approach, showing that it: 1) achieves\nbetter performance than prior work as well as manual selection of the primary\nmodality; 2) can recognize hard samples whose emotions are hard to tell; 3)\nmitigates the inter-modal incongruity at the latent level when modalities have\nmismatched affective tendencies; 4) reduces model size to less than 1M\nparameters while outperforming existing models of similar sizes.\n","authors":["Yaoting Wang","Yuanchao Li","Peter Bell","Catherine Lai"],"pdf_url":"https://arxiv.org/pdf/2305.13583v2.pdf","comment":"*Equal contribution"},{"id":"http://arxiv.org/abs/2306.15222v1","updated":"2023-06-27T05:48:14Z","published":"2023-06-27T05:48:14Z","title":"Learning to Rank in Generative Retrieval","summary":"  Generative retrieval is a promising new paradigm in text retrieval that\ngenerates identifier strings of relevant passages as the retrieval target. This\nparadigm leverages powerful generation models and represents a new paradigm\ndistinct from traditional learning-to-rank methods. However, despite its rapid\ndevelopment, current generative retrieval methods are still limited. They\ntypically rely on a heuristic function to transform predicted identifiers into\na passage rank list, which creates a gap between the learning objective of\ngenerative retrieval and the desired passage ranking target. Moreover, the\ninherent exposure bias problem of text generation also persists in generative\nretrieval. To address these issues, we propose a novel framework, called LTRGR,\nthat combines generative retrieval with the classical learning-to-rank\nparadigm. Our approach involves training an autoregressive model using a\npassage rank loss, which directly optimizes the autoregressive model toward the\noptimal passage ranking. This framework only requires an additional training\nstep to enhance current generative retrieval systems and does not add any\nburden to the inference stage. We conducted experiments on three public\ndatasets, and our results demonstrate that LTRGR achieves state-of-the-art\nperformance among generative retrieval methods, indicating its effectiveness\nand robustness.\n","authors":["Yongqi Li","Nan Yang","Liang Wang","Furu Wei","Wenjie Li"],"pdf_url":"https://arxiv.org/pdf/2306.15222v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.08952v2","updated":"2023-06-27T05:39:25Z","published":"2023-06-15T08:44:41Z","title":"Towards Benchmarking and Improving the Temporal Reasoning Capability of\n  Large Language Models","summary":"  Reasoning about time is of fundamental importance. Many facts are\ntime-dependent. For example, athletes change teams from time to time, and\ndifferent government officials are elected periodically. Previous\ntime-dependent question answering (QA) datasets tend to be biased in either\ntheir coverage of time spans or question types. In this paper, we introduce a\ncomprehensive probing dataset \\tempreason to evaluate the temporal reasoning\ncapability of large language models. Our dataset includes questions of three\ntemporal reasoning levels. In addition, we also propose a novel learning\nframework to improve the temporal reasoning capability of large language\nmodels, based on temporal span extraction and time-sensitive reinforcement\nlearning. We conducted experiments in closed book QA, open book QA, and\nreasoning QA settings and demonstrated the effectiveness of our approach. Our\ncode and data are released on https://github.com/DAMO-NLP-SG/TempReason.\n","authors":["Qingyu Tan","Hwee Tou Ng","Lidong Bing"],"pdf_url":"https://arxiv.org/pdf/2306.08952v2.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2006.10909v2","updated":"2023-06-27T05:32:12Z","published":"2020-06-19T00:43:23Z","title":"Neural Topic Modeling with Continual Lifelong Learning","summary":"  Lifelong learning has recently attracted attention in building machine\nlearning systems that continually accumulate and transfer knowledge to help\nfuture learning. Unsupervised topic modeling has been popularly used to\ndiscover topics from document collections. However, the application of topic\nmodeling is challenging due to data sparsity, e.g., in a small collection of\n(short) documents and thus, generate incoherent topics and sub-optimal document\nrepresentations. To address the problem, we propose a lifelong learning\nframework for neural topic modeling that can continuously process streams of\ndocument collections, accumulate topics and guide future topic modeling tasks\nby knowledge transfer from several sources to better deal with the sparse data.\nIn the lifelong process, we particularly investigate jointly: (1) sharing\ngenerative homologies (latent topics) over lifetime to transfer prior\nknowledge, and (2) minimizing catastrophic forgetting to retain the past\nlearning via novel selective data augmentation, co-training and topic\nregularization approaches. Given a stream of document collections, we apply the\nproposed Lifelong Neural Topic Modeling (LNTM) framework in modeling three\nsparse document collections as future tasks and demonstrate improved\nperformance quantified by perplexity, topic coherence and information retrieval\ntask.\n","authors":["Pankaj Gupta","Yatin Chaudhary","Thomas Runkler","Hinrich Schütze"],"pdf_url":"https://arxiv.org/pdf/2006.10909v2.pdf","comment":"Accepted at ICML2020 (13 pages, 11 figures, 9 tables)"},{"id":"http://arxiv.org/abs/2006.10632v3","updated":"2023-06-27T05:07:42Z","published":"2020-06-18T15:53:58Z","title":"Explainable and Discourse Topic-aware Neural Language Understanding","summary":"  Marrying topic models and language models exposes language understanding to a\nbroader source of document-level context beyond sentences via topics. While\nintroducing topical semantics in language models, existing approaches\nincorporate latent document topic proportions and ignore topical discourse in\nsentences of the document. This work extends the line of research by\nadditionally introducing an explainable topic representation in language\nunderstanding, obtained from a set of key terms correspondingly for each latent\ntopic of the proportion. Moreover, we retain sentence-topic associations along\nwith document-topic association by modeling topical discourse for every\nsentence in the document. We present a novel neural composite language model\nthat exploits both the latent and explainable topics along with topical\ndiscourse at sentence-level in a joint learning framework of topic and language\nmodels. Experiments over a range of tasks such as language modeling, word sense\ndisambiguation, document classification, retrieval and text generation\ndemonstrate ability of the proposed model in improving language understanding.\n","authors":["Yatin Chaudhary","Hinrich Schütze","Pankaj Gupta"],"pdf_url":"https://arxiv.org/pdf/2006.10632v3.pdf","comment":"Accepted at ICML2020 (13 pages, 2 figures)"},{"id":"http://arxiv.org/abs/2306.13804v2","updated":"2023-06-27T03:45:08Z","published":"2023-06-23T22:38:32Z","title":"Cross-Language Speech Emotion Recognition Using Multimodal Dual\n  Attention Transformers","summary":"  Despite the recent progress in speech emotion recognition (SER),\nstate-of-the-art systems are unable to achieve improved performance in\ncross-language settings. In this paper, we propose a Multimodal Dual Attention\nTransformer (MDAT) model to improve cross-language SER. Our model utilises\npre-trained models for multimodal feature extraction and is equipped with a\ndual attention mechanism including graph attention and co-attention to capture\ncomplex dependencies across different modalities and achieve improved\ncross-language SER results using minimal target language data. In addition, our\nmodel also exploits a transformer encoder layer for high-level feature\nrepresentation to improve emotion classification accuracy. In this way, MDAT\nperforms refinement of feature representation at various stages and provides\nemotional salient features to the classification layer. This novel approach\nalso ensures the preservation of modality-specific emotional information while\nenhancing cross-modality and cross-language interactions. We assess our model's\nperformance on four publicly available SER datasets and establish its superior\neffectiveness compared to recent approaches and baseline models.\n","authors":["Syed Aun Muhammad Zaidi","Siddique Latif","Junaid Qadir"],"pdf_url":"https://arxiv.org/pdf/2306.13804v2.pdf","comment":"Under Review IEEE TMM"},{"id":"http://arxiv.org/abs/2306.15171v1","updated":"2023-06-27T03:11:21Z","published":"2023-06-27T03:11:21Z","title":"Reducing the gap between streaming and non-streaming Transducer-based\n  ASR by adaptive two-stage knowledge distillation","summary":"  Transducer is one of the mainstream frameworks for streaming speech\nrecognition. There is a performance gap between the streaming and non-streaming\ntransducer models due to limited context. To reduce this gap, an effective way\nis to ensure that their hidden and output distributions are consistent, which\ncan be achieved by hierarchical knowledge distillation. However, it is\ndifficult to ensure the distribution consistency simultaneously because the\nlearning of the output distribution depends on the hidden one. In this paper,\nwe propose an adaptive two-stage knowledge distillation method consisting of\nhidden layer learning and output layer learning. In the former stage, we learn\nhidden representation with full context by applying mean square error loss\nfunction. In the latter stage, we design a power transformation based adaptive\nsmoothness method to learn stable output distribution. It achieved 19\\%\nrelative reduction in word error rate, and a faster response for the first\ntoken compared with the original streaming model in LibriSpeech corpus.\n","authors":["Haitao Tang","Yu Fu","Lei Sun","Jiabin Xue","Dan Liu","Yongchao Li","Zhiqiang Ma","Minghui Wu","Jia Pan","Genshun Wan","Ming'en Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.15171v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13939v4","updated":"2023-06-27T02:55:23Z","published":"2023-02-27T16:43:04Z","title":"SpikeGPT: Generative Pre-trained Language Model with Spiking Neural\n  Networks","summary":"  As the size of large language models continue to scale, so does the\ncomputational resources required to run it. Spiking Neural Networks (SNNs) have\nemerged as an energy-efficient approach to deep learning that leverage sparse\nand event-driven activations to reduce the computational overhead associated\nwith model inference. While they have become competitive with non-spiking\nmodels on many computer vision tasks, SNNs have also proven to be more\nchallenging to train. As a result, their performance lags behind modern deep\nlearning, and we are yet to see the effectiveness of SNNs in language\ngeneration. In this paper, inspired by the Receptance Weighted Key Value (RWKV)\nlanguage model, we successfully implement `SpikeGPT', a generative language\nmodel with binary, event-driven spiking activation units. We train the proposed\nmodel on two model variants: 45M and 216M parameters. To the best of our\nknowledge, SpikeGPT is the largest backpropagation-trained SNN model to date,\nrendering it suitable for both the generation and comprehension of natural\nlanguage. We achieve this by modifying the transformer block to replace\nmulti-head self attention to reduce quadratic computational complexity O(N^2)\nto linear complexity O(N) with increasing sequence length. Input tokens are\ninstead streamed in sequentially to our attention mechanism (as with typical\nSNNs). Our preliminary experiments show that SpikeGPT remains competitive with\nnon-spiking models on tested benchmarks, while maintaining 20x fewer operations\nwhen processed on neuromorphic hardware that can leverage sparse, event-driven\nactivations.\n","authors":["Rui-Jie Zhu","Qihang Zhao","Guoqi Li","Jason K. Eshraghian"],"pdf_url":"https://arxiv.org/pdf/2302.13939v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15164v1","updated":"2023-06-27T02:46:08Z","published":"2023-06-27T02:46:08Z","title":"DSRM: Boost Textual Adversarial Training with Distribution Shift Risk\n  Minimization","summary":"  Adversarial training is one of the best-performing methods in improving the\nrobustness of deep language models. However, robust models come at the cost of\nhigh time consumption, as they require multi-step gradient ascents or word\nsubstitutions to obtain adversarial samples. In addition, these generated\nsamples are deficient in grammatical quality and semantic consistency, which\nimpairs the effectiveness of adversarial training. To address these problems,\nwe introduce a novel, effective procedure for instead adversarial training with\nonly clean data. Our procedure, distribution shift risk minimization (DSRM),\nestimates the adversarial loss by perturbing the input data's probability\ndistribution rather than their embeddings. This formulation results in a robust\nmodel that minimizes the expected global loss under adversarial attacks. Our\napproach requires zero adversarial samples for training and reduces time\nconsumption by up to 70\\% compared to current best-performing adversarial\ntraining methods. Experiments demonstrate that DSRM considerably improves\nBERT's resistance to textual adversarial attacks and achieves state-of-the-art\nrobust accuracy on various benchmarks.\n","authors":["Songyang Gao","Shihan Dou","Yan Liu","Xiao Wang","Qi Zhang","Zhongyu Wei","Jin Ma","Ying Shan"],"pdf_url":"https://arxiv.org/pdf/2306.15164v1.pdf","comment":"Accepted by ACL2023"},{"id":"http://arxiv.org/abs/2306.15162v1","updated":"2023-06-27T02:44:07Z","published":"2023-06-27T02:44:07Z","title":"YouTube-ASL: A Large-Scale, Open-Domain American Sign Language-English\n  Parallel Corpus","summary":"  Machine learning for sign languages is bottlenecked by data. In this paper,\nwe present YouTube-ASL, a large-scale, open-domain corpus of American Sign\nLanguage (ASL) videos and accompanying English captions drawn from YouTube.\nWith ~1000 hours of videos and >2500 unique signers, YouTube-ASL is ~3x as\nlarge and has ~10x as many unique signers as the largest prior ASL dataset. We\ntrain baseline models for ASL to English translation on YouTube-ASL and\nevaluate them on How2Sign, where we achieve a new finetuned state of the art of\n12.39 BLEU and, for the first time, report zero-shot results.\n","authors":["David Uthus","Garrett Tanzer","Manfred Georg"],"pdf_url":"https://arxiv.org/pdf/2306.15162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09359v2","updated":"2023-06-27T02:15:24Z","published":"2022-12-19T10:49:35Z","title":"WACO: Word-Aligned Contrastive Learning for Speech Translation","summary":"  End-to-end Speech Translation (E2E ST) aims to directly translate source\nspeech into target text. Existing ST methods perform poorly when only extremely\nsmall speech-text data are available for training. We observe that an ST\nmodel's performance closely correlates with its embedding similarity between\nspeech and source transcript. In this paper, we propose Word-Aligned\nCOntrastive learning (WACO), a simple and effective method for extremely\nlow-resource speech-to-text translation. Our key idea is bridging word-level\nrepresentations for both speech and text modalities via contrastive learning.\nWe evaluate WACO and other methods on the MuST-C dataset, a widely used ST\nbenchmark, and on a low-resource direction Maltese-English from IWSLT 2023. Our\nexperiments demonstrate that WACO outperforms the best baseline by 9+ BLEU\npoints with only 1-hour parallel ST data. Code is available at\nhttps://github.com/owaski/WACO.\n","authors":["Siqi Ouyang","Rong Ye","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2212.09359v2.pdf","comment":"ACL 2023 Poster"},{"id":"http://arxiv.org/abs/2306.08158v2","updated":"2023-06-27T02:06:24Z","published":"2023-06-13T22:07:54Z","title":"Survey on Sociodemographic Bias in Natural Language Processing","summary":"  Deep neural networks often learn unintended biases during training, which\nmight have harmful effects when deployed in real-world settings. This paper\nsurveys 209 papers on bias in NLP models, most of which address\nsociodemographic bias. To better understand the distinction between bias and\nreal-world harm, we turn to ideas from psychology and behavioral economics to\npropose a definition for sociodemographic bias. We identify three main\ncategories of NLP bias research: types of bias, quantifying bias, and\ndebiasing. We conclude that current approaches on quantifying bias face\nreliability issues, that many of the bias metrics do not relate to real-world\nbiases, and that current debiasing techniques are superficial and hide bias\nrather than removing it. Finally, we provide recommendations for future work.\n","authors":["Vipul Gupta","Pranav Narayanan Venkit","Shomir Wilson","Rebecca J. Passonneau"],"pdf_url":"https://arxiv.org/pdf/2306.08158v2.pdf","comment":"23 pages, 1 figure"},{"id":"http://arxiv.org/abs/2306.14898v2","updated":"2023-06-27T01:51:57Z","published":"2023-06-26T17:59:50Z","title":"InterCode: Standardizing and Benchmarking Interactive Coding with\n  Execution Feedback","summary":"  Humans write code in a fundamentally interactive manner and rely on constant\nexecution feedback to correct errors, resolve ambiguities, and decompose tasks.\nWhile LLMs have recently exhibited promising coding capabilities, current\ncoding benchmarks mostly consider a static instruction-to-code sequence\ntransduction process, which has the potential for error propagation and a\ndisconnect between the generated code and its final execution environment. To\naddress this gap, we introduce InterCode, a lightweight, flexible, and\neasy-to-use framework of interactive coding as a standard reinforcement\nlearning (RL) environment, with code as actions and execution feedback as\nobservations. Our framework is language and platform agnostic, uses\nself-contained Docker environments to provide safe and reproducible execution,\nand is compatible out-of-the-box with traditional seq2seq coding methods, while\nenabling the development of new methods for interactive code generation. We use\nInterCode to create two interactive code environments with Bash and SQL as\naction spaces, leveraging data from the static Spider and NL2Bash datasets. We\ndemonstrate InterCode's viability as a testbed by evaluating multiple\nstate-of-the-art LLMs configured with different prompting strategies such as\nReAct and Plan & Solve. Our results showcase the benefits of interactive code\ngeneration and demonstrate that InterCode can serve as a challenging benchmark\nfor advancing code understanding and generation capabilities. InterCode is\ndesigned to be easily extensible and can even be used to incorporate new tasks\nsuch as Capture the Flag, a popular coding puzzle that is inherently multi-step\nand involves multiple programming languages. Project site with code and data:\nhttps://intercode-benchmark.github.io\n","authors":["John Yang","Akshara Prabhakar","Karthik Narasimhan","Shunyu Yao"],"pdf_url":"https://arxiv.org/pdf/2306.14898v2.pdf","comment":"Project site with code and data:\n  https://intercode-benchmark.github.io"},{"id":"http://arxiv.org/abs/2212.09553v2","updated":"2023-06-27T01:18:45Z","published":"2022-12-19T15:45:36Z","title":"Mu$^{2}$SLAM: Multitask, Multilingual Speech and Language Models","summary":"  We present Mu$^{2}$SLAM, a multilingual sequence-to-sequence model\npre-trained jointly on unlabeled speech, unlabeled text and supervised data\nspanning Automatic Speech Recognition (ASR), Automatic Speech Translation (AST)\nand Machine Translation (MT), in over 100 languages. By leveraging a quantized\nrepresentation of speech as a target, Mu$^{2}$SLAM trains the speech-text\nmodels with a sequence-to-sequence masked denoising objective similar to T5 on\nthe decoder and a masked language modeling (MLM) objective on the encoder, for\nboth unlabeled speech and text, while utilizing the supervised tasks to improve\ncross-lingual and cross-modal representation alignment within the model. On\nCoVoST AST, Mu$^{2}$SLAM establishes a new state-of-the-art for models trained\non public datasets, improving on xx-en translation over the previous best by\n1.9 BLEU points and on en-xx translation by 1.1 BLEU points. On Voxpopuli ASR,\nour model matches the performance of an mSLAM model fine-tuned with an RNN-T\ndecoder, despite using a relatively weaker sequence-to-sequence architecture.\nOn text understanding tasks, our model improves by more than 6\\% over mSLAM on\nXNLI, getting closer to the performance of mT5 models of comparable capacity on\nXNLI and TydiQA, paving the way towards a single model for all speech and text\nunderstanding tasks.\n","authors":["Yong Cheng","Yu Zhang","Melvin Johnson","Wolfgang Macherey","Ankur Bapna"],"pdf_url":"https://arxiv.org/pdf/2212.09553v2.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2210.17017v2","updated":"2023-06-27T00:39:38Z","published":"2022-10-31T02:12:51Z","title":"Blank Collapse: Compressing CTC emission for the faster decoding","summary":"  Connectionist Temporal Classification (CTC) model is a very efficient method\nfor modeling sequences, especially for speech data. In order to use CTC model\nas an Automatic Speech Recognition (ASR) task, the beam search decoding with an\nexternal language model like n-gram LM is necessary to obtain reasonable\nresults. In this paper we analyze the blank label in CTC beam search deeply and\npropose a very simple method to reduce the amount of calculation resulting in\nfaster beam search decoding speed. With this method, we can get up to 78%\nfaster decoding speed than ordinary beam search decoding with a very small loss\nof accuracy in LibriSpeech datasets. We prove this method is effective not only\npractically by experiments but also theoretically by mathematical reasoning. We\nalso observe that this reduction is more obvious if the accuracy of the model\nis higher.\n","authors":["Minkyu Jung","Ohhyeok Kwon","Seunghyun Seo","Soonshin Seo"],"pdf_url":"https://arxiv.org/pdf/2210.17017v2.pdf","comment":"Accepted in Interspeech 2023"},{"id":"http://arxiv.org/abs/2306.15123v1","updated":"2023-06-27T00:23:35Z","published":"2023-06-27T00:23:35Z","title":"Investigating Cross-Domain Behaviors of BERT in Review Understanding","summary":"  Review score prediction requires review text understanding, a critical\nreal-world application of natural language processing. Due to dissimilar text\ndomains in product reviews, a common practice is fine-tuning BERT models upon\nreviews of differing domains. However, there has not yet been an empirical\nstudy of cross-domain behaviors of BERT models in the various tasks of product\nreview understanding. In this project, we investigate text classification BERT\nmodels fine-tuned on single-domain and multi-domain Amazon review data. In our\nfindings, though single-domain models achieved marginally improved performance\non their corresponding domain compared to multi-domain models, multi-domain\nmodels outperformed single-domain models when evaluated on multi-domain data,\nsingle-domain data the single-domain model was not fine-tuned on, and on\naverage when considering all tests. Though slight increases in accuracy can be\nachieved through single-domain model fine-tuning, computational resources and\ncosts can be reduced by utilizing multi-domain models that perform well across\ndomains.\n","authors":["Albert Lu","Meng Jiang"],"pdf_url":"https://arxiv.org/pdf/2306.15123v1.pdf","comment":"9 pages, 1 figure, 2 tables"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2306.15670v1","updated":"2023-06-27T17:59:46Z","published":"2023-06-27T17:59:46Z","title":"Symphonize 3D Semantic Scene Completion with Contextual Instance Queries","summary":"  3D Semantic Scene Completion (SSC) has emerged as a nascent and pivotal task\nfor autonomous driving, as it involves predicting per-voxel occupancy within a\n3D scene from partial LiDAR or image inputs. Existing methods primarily focus\non the voxel-wise feature aggregation, while neglecting the instance-centric\nsemantics and broader context. In this paper, we present a novel paradigm\ntermed Symphonies (Scene-from-Insts) for SSC, which completes the scene volume\nfrom a sparse set of instance queries derived from the input with context\nawareness. By incorporating the queries as the instance feature representations\nwithin the scene, Symphonies dynamically encodes the instance-centric semantics\nto interact with the image and volume features while avoiding the dense\nvoxel-wise modeling. Simultaneously, it orchestrates a more comprehensive\nunderstanding of the scenario by capturing context throughout the entire scene,\ncontributing to alleviating the geometric ambiguity derived from occlusion and\nperspective errors. Symphonies achieves a state-of-the-art result of 13.02 mIoU\non the challenging SemanticKITTI dataset, outperforming existing methods and\nshowcasing the promising advancements of the paradigm. The code is available at\n\\url{https://github.com/hustvl/Symphonies}.\n","authors":["Haoyi Jiang","Tianheng Cheng","Naiyu Gao","Haoyang Zhang","Wenyu Liu","Xinggang Wang"],"pdf_url":"https://arxiv.org/pdf/2306.15670v1.pdf","comment":"Technical report. Code and models at:\n  https://github.com/hustvl/Symphonies"},{"id":"http://arxiv.org/abs/2306.15669v1","updated":"2023-06-27T17:59:39Z","published":"2023-06-27T17:59:39Z","title":"Detector-Free Structure from Motion","summary":"  We propose a new structure-from-motion framework to recover accurate camera\nposes and point clouds from unordered images. Traditional SfM systems typically\nrely on the successful detection of repeatable keypoints across multiple views\nas the first step, which is difficult for texture-poor scenes, and poor\nkeypoint detection may break down the whole SfM system. We propose a new\ndetector-free SfM framework to draw benefits from the recent success of\ndetector-free matchers to avoid the early determination of keypoints, while\nsolving the multi-view inconsistency issue of detector-free matchers.\nSpecifically, our framework first reconstructs a coarse SfM model from\nquantized detector-free matches. Then, it refines the model by a novel\niterative refinement pipeline, which iterates between an attention-based\nmulti-view matching module to refine feature tracks and a geometry refinement\nmodule to improve the reconstruction accuracy. Experiments demonstrate that the\nproposed framework outperforms existing detector-based SfM systems on common\nbenchmark datasets. We also collect a texture-poor SfM dataset to demonstrate\nthe capability of our framework to reconstruct texture-poor scenes. Based on\nthis framework, we take $\\textit{first place}$ in Image Matching Challenge\n2023.\n","authors":["Xingyi He","Jiaming Sun","Yifan Wang","Sida Peng","Qixing Huang","Hujun Bao","Xiaowei Zhou"],"pdf_url":"https://arxiv.org/pdf/2306.15669v1.pdf","comment":"Project page: https://zju3dv.github.io/DetectorFreeSfM/"},{"id":"http://arxiv.org/abs/2306.15668v1","updated":"2023-06-27T17:59:33Z","published":"2023-06-27T17:59:33Z","title":"Physion++: Evaluating Physical Scene Understanding that Requires Online\n  Inference of Different Physical Properties","summary":"  General physical scene understanding requires more than simply localizing and\nrecognizing objects -- it requires knowledge that objects can have different\nlatent properties (e.g., mass or elasticity), and that those properties affect\nthe outcome of physical events. While there has been great progress in physical\nand video prediction models in recent years, benchmarks to test their\nperformance typically do not require an understanding that objects have\nindividual physical properties, or at best test only those properties that are\ndirectly observable (e.g., size or color). This work proposes a novel dataset\nand benchmark, termed Physion++, that rigorously evaluates visual physical\nprediction in artificial systems under circumstances where those predictions\nrely on accurate estimates of the latent physical properties of objects in the\nscene. Specifically, we test scenarios where accurate prediction relies on\nestimates of properties such as mass, friction, elasticity, and deformability,\nand where the values of those properties can only be inferred by observing how\nobjects move and interact with other objects or fluids. We evaluate the\nperformance of a number of state-of-the-art prediction models that span a\nvariety of levels of learning vs. built-in knowledge, and compare that\nperformance to a set of human predictions. We find that models that have been\ntrained using standard regimes and datasets do not spontaneously learn to make\ninferences about latent properties, but also that models that encode objectness\nand physical states tend to make better predictions. However, there is still a\nhuge gap between all models and human performance, and all models' predictions\ncorrelate poorly with those made by humans, suggesting that no state-of-the-art\nmodel is learning to make physical predictions in a human-like way. Project\npage: https://dingmyu.github.io/physion_v2/\n","authors":["Hsiao-Yu Tung","Mingyu Ding","Zhenfang Chen","Daniel Bear","Chuang Gan","Joshua B. Tenenbaum","Daniel LK Yamins","Judith E Fan","Kevin A. Smith"],"pdf_url":"https://arxiv.org/pdf/2306.15668v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15667v1","updated":"2023-06-27T17:59:07Z","published":"2023-06-27T17:59:07Z","title":"PoseDiffusion: Solving Pose Estimation via Diffusion-aided Bundle\n  Adjustment","summary":"  Camera pose estimation is a long-standing computer vision problem that to\ndate often relies on classical methods, such as handcrafted keypoint matching,\nRANSAC and bundle adjustment. In this paper, we propose to formulate the\nStructure from Motion (SfM) problem inside a probabilistic diffusion framework,\nmodelling the conditional distribution of camera poses given input images. This\nnovel view of an old problem has several advantages. (i) The nature of the\ndiffusion framework mirrors the iterative procedure of bundle adjustment. (ii)\nThe formulation allows a seamless integration of geometric constraints from\nepipolar geometry. (iii) It excels in typically difficult scenarios such as\nsparse views with wide baselines. (iv) The method can predict intrinsics and\nextrinsics for an arbitrary amount of images. We demonstrate that our method\nPoseDiffusion significantly improves over the classic SfM pipelines and the\nlearned approaches on two real-world datasets. Finally, it is observed that our\nmethod can generalize across datasets without further training. Project page:\nhttps://posediffusion.github.io/\n","authors":["Jianyuan Wang","Christian Rupprecht","David Novotny"],"pdf_url":"https://arxiv.org/pdf/2306.15667v1.pdf","comment":"9 pages, 8 figures"},{"id":"http://arxiv.org/abs/2306.15662v1","updated":"2023-06-27T17:55:33Z","published":"2023-06-27T17:55:33Z","title":"Measured Albedo in the Wild: Filling the Gap in Intrinsics Evaluation","summary":"  Intrinsic image decomposition and inverse rendering are long-standing\nproblems in computer vision. To evaluate albedo recovery, most algorithms\nreport their quantitative performance with a mean Weighted Human Disagreement\nRate (WHDR) metric on the IIW dataset. However, WHDR focuses only on relative\nalbedo values and often fails to capture overall quality of the albedo. In\norder to comprehensively evaluate albedo, we collect a new dataset, Measured\nAlbedo in the Wild (MAW), and propose three new metrics that complement WHDR:\nintensity, chromaticity and texture metrics. We show that existing algorithms\noften improve WHDR metric but perform poorly on other metrics. We then finetune\ndifferent algorithms on our MAW dataset to significantly improve the quality of\nthe reconstructed albedo both quantitatively and qualitatively. Since the\nproposed intensity, chromaticity, and texture metrics and the WHDR are all\ncomplementary we further introduce a relative performance measure that captures\naverage performance. By analysing existing algorithms we show that there is\nsignificant room for improvement. Our dataset and evaluation metrics will\nenable researchers to develop algorithms that improve albedo reconstruction.\nCode and Data available at: https://measuredalbedo.github.io/\n","authors":["Jiaye Wu","Sanjoy Chowdhury","Hariharmano Shanmugaraja","David Jacobs","Soumyadip Sengupta"],"pdf_url":"https://arxiv.org/pdf/2306.15662v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15658v1","updated":"2023-06-27T17:51:06Z","published":"2023-06-27T17:51:06Z","title":"CLIPA-v2: Scaling CLIP Training with 81.1% Zero-shot ImageNet Accuracy\n  within a \\$10,000 Budget; An Extra \\$4,000 Unlocks 81.8% Accuracy","summary":"  The recent work CLIPA presents an inverse scaling law for CLIP training --\nwhereby the larger the image/text encoders used, the shorter the sequence\nlength of image/text tokens that can be applied in training. This finding\nenables us to train high-performance CLIP models with significantly reduced\ncomputations. Building upon this work, we hereby present CLIPA-v2 with two key\ncontributions. Technically, we find this inverse scaling law is also applicable\nin the finetuning stage, enabling further reduction in computational needs.\nEmpirically, we explore CLIPA at scale, extending the experiments up to the\nH/14 model with ~13B image-text pairs seen during training.\n  Our results are exciting -- by only allocating a budget of \\$10,000, our CLIP\nmodel achieves an impressive zero-shot ImageNet accuracy of 81.1%, surpassing\nthe prior best CLIP model (from OpenCLIP, 80.1%) by 1.0% and meanwhile reducing\nthe computational cost by ~39X. Moreover, with an additional investment of\n$4,000, we can further elevate the zero-shot ImageNet accuracy to 81.8%. Our\ncode and models are available at https://github.com/UCSC-VLAA/CLIPA.\n","authors":["Xianhang Li","Zeyu Wang","Cihang Xie"],"pdf_url":"https://arxiv.org/pdf/2306.15658v1.pdf","comment":"Tech Report. Code is available at https://github.com/UCSC-VLAA/CLIPA"},{"id":"http://arxiv.org/abs/2306.15628v1","updated":"2023-06-27T17:08:52Z","published":"2023-06-27T17:08:52Z","title":"Machine-learning based noise characterization and correction on neutral\n  atoms NISQ devices","summary":"  Neutral atoms devices represent a promising technology that uses optical\ntweezers to geometrically arrange atoms and modulated laser pulses to control\nthe quantum states. A neutral atoms Noisy Intermediate Scale Quantum (NISQ)\ndevice is developed by Pasqal with rubidium atoms that will allow to work with\nup to 100 qubits. All NISQ devices are affected by noise that have an impact on\nthe computations results. Therefore it is important to better understand and\ncharacterize the noise sources and possibly to correct them. Here, two\napproaches are proposed to characterize and correct noise parameters on neutral\natoms NISQ devices. In particular the focus is on Pasqal devices and Machine\nLearning (ML) techniques are adopted to pursue those objectives. To\ncharacterize the noise parameters, several ML models are trained, using as\ninput only the measurements of the final quantum state of the atoms, to predict\nlaser intensity fluctuation and waist, temperature and false positive and\nnegative measurement rate. Moreover, an analysis is provided with the scaling\non the number of atoms in the system and on the number of measurements used as\ninput. Also, we compare on real data the values predicted with ML with the a\npriori estimated parameters. Finally, a Reinforcement Learning (RL) framework\nis employed to design a pulse in order to correct the effect of the noise in\nthe measurements. It is expected that the analysis performed in this work will\nbe useful for a better understanding of the quantum dynamic in neutral atoms\ndevices and for the widespread adoption of this class of NISQ devices.\n","authors":["Ettore Canonici","Stefano Martina","Riccardo Mengoni","Daniele Ottaviani","Filippo Caruso"],"pdf_url":"https://arxiv.org/pdf/2306.15628v1.pdf","comment":"11 pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2303.12782v2","updated":"2023-06-27T17:02:40Z","published":"2023-03-22T17:52:11Z","title":"Tube-Link: A Flexible Cross Tube Baseline for Universal Video\n  Segmentation","summary":"  The goal of video segmentation is to accurately segment and track every pixel\nin diverse scenarios. In this paper, we present Tube-Link, a versatile\nframework that addresses multiple core tasks of video segmentation with a\nunified architecture. Our framework is a near-online approach that takes a\nshort subclip as input and outputs the corresponding spatial-temporal tube\nmasks. To enhance the modeling of cross-tube relationships, we propose an\neffective way to perform tube-level linking via attention along the queries. In\naddition, we introduce temporal contrastive learning to instance-wise\ndiscriminative features for tube-level association. Our approach offers\nflexibility and efficiency for both short and long video inputs, as the length\nof each subclip can be varied according to the needs of datasets or scenarios.\nTube-Link outperforms existing specialized architectures by a significant\nmargin on five video segmentation datasets. Specifically, it achieves almost\n13% relative improvements on VIPSeg and 4% improvements on KITTI-STEP over the\nstrong baseline Video K-Net. When using a ResNet50 backbone on Youtube-VIS-2019\nand 2021, Tube-Link boosts IDOL by 3% and 4%, respectively. Code will be\navailable.\n","authors":["Xiangtai Li","Haobo Yuan","Wenwei Zhang","Guangliang Cheng","Jiangmiao Pang","Chen Change Loy"],"pdf_url":"https://arxiv.org/pdf/2303.12782v2.pdf","comment":"Project page: https://github.com/lxtGH/Tube-Link (fix typos and\n  errors)"},{"id":"http://arxiv.org/abs/2306.15620v1","updated":"2023-06-27T16:59:15Z","published":"2023-06-27T16:59:15Z","title":"SCENEREPLICA: Benchmarking Real-World Robot Manipulation by Creating\n  Reproducible Scenes","summary":"  We present a new reproducible benchmark for evaluating robot manipulation in\nthe real world, specifically focusing on pick-and-place. Our benchmark uses the\nYCB objects, a commonly used dataset in the robotics community, to ensure that\nour results are comparable to other studies. Additionally, the benchmark is\ndesigned to be easily reproducible in the real world, making it accessible to\nresearchers and practitioners. We also provide our experimental results and\nanalyzes for model-based and model-free 6D robotic grasping on the benchmark,\nwhere representative algorithms are evaluated for object perception, grasping\nplanning, and motion planning. We believe that our benchmark will be a valuable\ntool for advancing the field of robot manipulation. By providing a standardized\nevaluation framework, researchers can more easily compare different techniques\nand algorithms, leading to faster progress in developing robot manipulation\nmethods.\n","authors":["Ninad Khargonkar","Sai Haneesh Allu","Yangxiao Lu","Jishnu Jaykumar P","Balakrishnan Prabhakaran","Yu Xiang"],"pdf_url":"https://arxiv.org/pdf/2306.15620v1.pdf","comment":"12 pages, 10 figures, Project page is available at\n  https://irvlutd.github.io/SceneReplica"},{"id":"http://arxiv.org/abs/2306.15612v1","updated":"2023-06-27T16:53:35Z","published":"2023-06-27T16:53:35Z","title":"Rethinking Cross-Entropy Loss for Stereo Matching Networks","summary":"  Despite the great success of deep learning in stereo matching, recovering\naccurate and clearly-contoured disparity map is still challenging. Currently,\nL1 loss and cross-entropy loss are the two most widely used loss functions for\ntraining the stereo matching networks. Comparing with the former, the latter\ncan usually achieve better results thanks to its direct constraint to the the\ncost volume. However, how to generate reasonable ground-truth distribution for\nthis loss function remains largely under exploited. Existing works assume\nuni-modal distributions around the ground-truth for all of the pixels, which\nignores the fact that the edge pixels may have multi-modal distributions. In\nthis paper, we first experimentally exhibit the importance of correct edge\nsupervision to the overall disparity accuracy. Then a novel adaptive\nmulti-modal cross-entropy loss which encourages the network to generate\ndifferent distribution patterns for edge and non-edge pixels is proposed. We\nfurther optimize the disparity estimator in the inference stage to alleviate\nthe bleeding and misalignment artifacts at the edge. Our method is generic and\ncan help classic stereo matching models regain competitive performance. GANet\ntrained by our loss ranks 1st on the KITTI 2015 and 2012 benchmarks and\noutperforms state-of-the-art methods by a large margin. Meanwhile, our method\nalso exhibits superior cross-domain generalization ability and outperforms\nexisting generalization-specialized methods on four popular real-world\ndatasets.\n","authors":["Peng Xu","Zhiyu Xiang","Chenyu Qiao","Jingyun Fu","Xijun Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.15612v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15599v1","updated":"2023-06-27T16:37:37Z","published":"2023-06-27T16:37:37Z","title":"Recurrent Neural Network-coupled SPAD TCSPC System for Real-time\n  Fluorescence Lifetime Imaging","summary":"  Fluorescence lifetime imaging (FLI) has been receiving increased attention in\nrecent years as a powerful imaging technique in biological and medical\nresearch. However, existing FLI systems often suffer from a tradeoff between\nprocessing speed, accuracy, and robustness. In this paper, we propose a SPAD\nTCSPC system coupled to a recurrent neural network (RNN) for FLI that\naccurately estimates on the fly fluorescence lifetime directly from raw\ntimestamps instead of histograms, which drastically reduces the data transfer\nrate and hardware resource utilization. We train two variants of the RNN on a\nsynthetic dataset and compare the results to those obtained using the\ncenter-of-mass method (CMM) and least squares fitting (LS fitting) methods. The\nresults demonstrate that two RNN variants, gated recurrent unit (GRU) and long\nshort-term memory (LSTM), are comparable to CMM and LS fitting in terms of\naccuracy and outperform CMM and LS fitting by a large margin in the presence of\nbackground noise. We also look at the Cramer-Rao lower bound and detailed\nanalysis showed that the RNN models are close to the theoretical optima. The\nanalysis of experimental data shows that our model, which is purely trained on\nsynthetic datasets, works well on real-world data. We build a FLI microscope\nsetup for evaluation based on Piccolo, a 32$\\times$32 SPAD sensor developed in\nour lab. Four quantized GRU cores, capable of processing up to 4 million\nphotons per second, are deployed on a Xilinx Kintex-7 FPGA. Powered by the GRU,\nthe FLI setup can retrieve real-time fluorescence lifetime images at up to 10\nframes per second. The proposed FLI system is promising for many important\nbiomedical applications, ranging from biological imaging of fast-moving cells\nto fluorescence-assisted diagnosis and surgery.\n","authors":["Yang Lin","Paul Mos","Andrei Ardelean","Claudio Bruschini","Edoardo Charbon"],"pdf_url":"https://arxiv.org/pdf/2306.15599v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15593v1","updated":"2023-06-27T16:18:55Z","published":"2023-06-27T16:18:55Z","title":"Cardiac CT perfusion imaging of pericoronary adipose tissue (PCAT)\n  highlights potential confounds in coronary CTA","summary":"  Features of pericoronary adipose tissue (PCAT) assessed from coronary\ncomputed tomography angiography (CCTA) are associated with inflammation and\ncardiovascular risk. As PCAT is vascularly connected with coronary vasculature,\nthe presence of iodine is a potential confounding factor on PCAT HU and\ntextures that has not been adequately investigated. Use dynamic cardiac CT\nperfusion (CCTP) to inform contrast determinants of PCAT assessment. From CCTP,\nwe analyzed HU dynamics of territory-specific PCAT, myocardium, and other\nadipose depots in patients with coronary artery disease. HU, blood flow, and\nradiomics were assessed over time. Changes from peak aorta time, Pa, chosen to\nmodel the time of CCTA, were obtained. HU in PCAT increased more than in other\nadipose depots. The estimated blood flow in PCAT was ~23% of that in the\ncontiguous myocardium. Comparing PCAT distal and proximal to a significant\nstenosis, we found less enhancement and longer time-to-peak distally.\nTwo-second offsets [before, after] Pa resulted in [ 4-HU, 3-HU] differences in\nPCAT. Due to changes in HU, the apparent PCAT volume reduced ~15% from the\nfirst scan (P1) to Pa using a conventional fat window. Comparing radiomic\nfeatures over time, 78% of features changed >10% relative to P1. CCTP\nelucidates blood flow in PCAT and enables analysis of PCAT features over time.\nPCAT assessments (HU, apparent volume, and radiomics) are sensitive to\nacquisition timing and the presence of obstructive stenosis, which may confound\nthe interpretation of PCAT in CCTA images. Data normalization may be in order.\n","authors":["Hao Wu","Yingnan Song","Ammar Hoori","Ananya Subramaniam","Juhwan Lee","Justin Kim","Tao Hu","Sadeer Al-Kindi","Wei-Ming Huang","Chun-Ho Yun","Chung-Lieh Hung","Sanjay Rajagopalan","David L. Wilson"],"pdf_url":"https://arxiv.org/pdf/2306.15593v1.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2306.15574v1","updated":"2023-06-27T15:53:20Z","published":"2023-06-27T15:53:20Z","title":"See Through the Fog: Curriculum Learning with Progressive Occlusion in\n  Medical Imaging","summary":"  In recent years, deep learning models have revolutionized medical image\ninterpretation, offering substantial improvements in diagnostic accuracy.\nHowever, these models often struggle with challenging images where critical\nfeatures are partially or fully occluded, which is a common scenario in\nclinical practice. In this paper, we propose a novel curriculum learning-based\napproach to train deep learning models to handle occluded medical images\neffectively. Our method progressively introduces occlusion, starting from\nclear, unobstructed images and gradually moving to images with increasing\nocclusion levels. This ordered learning process, akin to human learning, allows\nthe model to first grasp simple, discernable patterns and subsequently build\nupon this knowledge to understand more complicated, occluded scenarios.\nFurthermore, we present three novel occlusion synthesis methods, namely\nWasserstein Curriculum Learning (WCL), Information Adaptive Learning (IAL), and\nGeodesic Curriculum Learning (GCL). Our extensive experiments on diverse\nmedical image datasets demonstrate substantial improvements in model robustness\nand diagnostic accuracy over conventional training methodologies.\n","authors":["Pradeep Singh","Kishore Babu Nampalle","Uppala Vivek Narayan","Balasubramanian Raman"],"pdf_url":"https://arxiv.org/pdf/2306.15574v1.pdf","comment":"20 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2306.15561v1","updated":"2023-06-27T15:36:22Z","published":"2023-06-27T15:36:22Z","title":"You Can Mask More For Extremely Low-Bitrate Image Compression","summary":"  Learned image compression (LIC) methods have experienced significant progress\nduring recent years. However, these methods are primarily dedicated to\noptimizing the rate-distortion (R-D) performance at medium and high bitrates (>\n0.1 bits per pixel (bpp)), while research on extremely low bitrates is limited.\nBesides, existing methods fail to explicitly explore the image structure and\ntexture components crucial for image compression, treating them equally\nalongside uninformative components in networks. This can cause severe\nperceptual quality degradation, especially under low-bitrate scenarios. In this\nwork, inspired by the success of pre-trained masked autoencoders (MAE) in many\ndownstream tasks, we propose to rethink its mask sampling strategy from\nstructure and texture perspectives for high redundancy reduction and\ndiscriminative feature representation, further unleashing the potential of LIC\nmethods. Therefore, we present a dual-adaptive masking approach (DA-Mask) that\nsamples visible patches based on the structure and texture distributions of\noriginal images. We combine DA-Mask and pre-trained MAE in masked image\nmodeling (MIM) as an initial compressor that abstracts informative semantic\ncontext and texture representations. Such a pipeline can well cooperate with\nLIC networks to achieve further secondary compression while preserving\npromising reconstruction quality. Consequently, we propose a simple yet\neffective masked compression model (MCM), the first framework that unifies MIM\nand LIC end-to-end for extremely low-bitrate image compression. Extensive\nexperiments have demonstrated that our approach outperforms recent\nstate-of-the-art methods in R-D performance, visual quality, and downstream\napplications, at very low bitrates. Our code is available at\nhttps://github.com/lianqi1008/MCM.git.\n","authors":["Anqi Li","Feng Li","Jiaxin Han","Huihui Bai","Runmin Cong","Chunjie Zhang","Meng Wang","Weisi Lin","Yao Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.15561v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2306.14269v2","updated":"2023-06-27T15:34:17Z","published":"2023-06-25T15:26:06Z","title":"Weakly Supervised Scene Text Generation for Low-resource Languages","summary":"  A large number of annotated training images is crucial for training\nsuccessful scene text recognition models. However, collecting sufficient\ndatasets can be a labor-intensive and costly process, particularly for\nlow-resource languages. To address this challenge, auto-generating text data\nhas shown promise in alleviating the problem. Unfortunately, existing scene\ntext generation methods typically rely on a large amount of paired data, which\nis difficult to obtain for low-resource languages. In this paper, we propose a\nnovel weakly supervised scene text generation method that leverages a few\nrecognition-level labels as weak supervision. The proposed method is able to\ngenerate a large amount of scene text images with diverse backgrounds and font\nstyles through cross-language generation. Our method disentangles the content\nand style features of scene text images, with the former representing textual\ninformation and the latter representing characteristics such as font,\nalignment, and background. To preserve the complete content structure of\ngenerated images, we introduce an integrated attention module. Furthermore, to\nbridge the style gap in the style of different languages, we incorporate a\npre-trained font classifier. We evaluate our method using state-of-the-art\nscene text recognition models. Experiments demonstrate that our generated scene\ntext significantly improves the scene text recognition accuracy and help\nachieve higher accuracy when complemented with other generative methods.\n","authors":["Yangchen Xie","Xinyuan Chen","Hongjian Zhan","Palaiahankote Shivakum","Bing Yin","Cong Liu","Yue Lu"],"pdf_url":"https://arxiv.org/pdf/2306.14269v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15548v1","updated":"2023-06-27T15:18:52Z","published":"2023-06-27T15:18:52Z","title":"Geometric Ultrasound Localization Microscopy","summary":"  Contrast-Enhanced Ultra-Sound (CEUS) has become a viable method for\nnon-invasive, dynamic visualization in medical diagnostics, yet Ultrasound\nLocalization Microscopy (ULM) has enabled a revolutionary breakthrough by\noffering ten times higher resolution. To date, Delay-And-Sum (DAS) beamformers\nare used to render ULM frames, ultimately determining the image resolution\ncapability. To take full advantage of ULM, this study questions whether\nbeamforming is the most effective processing step for ULM, suggesting an\nalternative approach that relies solely on Time-Difference-of-Arrival (TDoA)\ninformation. To this end, a novel geometric framework for micro bubble\nlocalization via ellipse intersections is proposed to overcome existing\nbeamforming limitations. We present a benchmark comparison based on a public\ndataset for which our geometric ULM outperforms existing baseline methods in\nterms of accuracy and reliability while only utilizing a portion of the\navailable transducer data.\n","authors":["Christopher Hahne","Raphael Sznitman"],"pdf_url":"https://arxiv.org/pdf/2306.15548v1.pdf","comment":"Pre-print accepted for MICCAI 2023"},{"id":"http://arxiv.org/abs/2306.15521v1","updated":"2023-06-27T14:47:43Z","published":"2023-06-27T14:47:43Z","title":"What a MESS: Multi-Domain Evaluation of Zero-Shot Semantic Segmentation","summary":"  While semantic segmentation has seen tremendous improvements in the past,\nthere is still significant labeling efforts necessary and the problem of\nlimited generalization to classes that have not been present during training.\nTo address this problem, zero-shot semantic segmentation makes use of large\nself-supervised vision-language models, allowing zero-shot transfer to unseen\nclasses. In this work, we build a benchmark for Multi-domain Evaluation of\nSemantic Segmentation (MESS), which allows a holistic analysis of performance\nacross a wide range of domain-specific datasets such as medicine, engineering,\nearth monitoring, biology, and agriculture. To do this, we reviewed 120\ndatasets, developed a taxonomy, and classified the datasets according to the\ndeveloped taxonomy. We select a representative subset consisting of 22 datasets\nand propose it as the MESS benchmark. We evaluate eight recently published\nmodels on the proposed MESS benchmark and analyze characteristics for the\nperformance of zero-shot transfer models. The toolkit is available at\nhttps://github.com/blumenstiel/MESS.\n","authors":["Benedikt Blumenstiel","Johannes Jakubik","Hilde Kühne","Michael Vössing"],"pdf_url":"https://arxiv.org/pdf/2306.15521v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15515v1","updated":"2023-06-27T14:41:18Z","published":"2023-06-27T14:41:18Z","title":"Meshes Meet Voxels: Abdominal Organ Segmentation via Diffeomorphic\n  Deformations","summary":"  Abdominal multi-organ segmentation from CT and MRI is an essential\nprerequisite for surgical planning and computer-aided navigation systems.\nThree-dimensional numeric representations of abdominal shapes are further\nimportant for quantitative and statistical analyses thereof. Existing methods\nin the field, however, are unable to extract highly accurate 3D representations\nthat are smooth, topologically correct, and match points on a template. In this\nwork, we present UNetFlow, a novel diffeomorphic shape deformation approach for\nabdominal organs. UNetFlow combines the advantages of voxel-based and\nmesh-based approaches for 3D shape extraction. Our results demonstrate high\naccuracy with respect to manually annotated CT data and better topological\ncorrectness compared to previous methods. In addition, we show the\ngeneralization of UNetFlow to MRI.\n","authors":["Fabian Bongratz","Anne-Marie Rickmann","Christian Wachinger"],"pdf_url":"https://arxiv.org/pdf/2306.15515v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2306.15507v1","updated":"2023-06-27T14:30:25Z","published":"2023-06-27T14:30:25Z","title":"Self-supervised Learning of Event-guided Video Frame Interpolation for\n  Rolling Shutter Frames","summary":"  This paper makes the first attempt to tackle the challenging task of\nrecovering arbitrary frame rate latent global shutter (GS) frames from two\nconsecutive rolling shutter (RS) frames, guided by the novel event camera data.\nAlthough events possess high temporal resolution, beneficial for video frame\ninterpolation (VFI), a hurdle in tackling this task is the lack of paired GS\nframes. Another challenge is that RS frames are susceptible to distortion when\ncapturing moving objects. To this end, we propose a novel self-supervised\nframework that leverages events to guide RS frame correction and VFI in a\nunified framework. Our key idea is to estimate the displacement field (DF)\nnon-linear dense 3D spatiotemporal information of all pixels during the\nexposure time, allowing for the reciprocal reconstruction between RS and GS\nframes as well as arbitrary frame rate VFI. Specifically, the displacement\nfield estimation (DFE) module is proposed to estimate the spatiotemporal motion\nfrom events to correct the RS distortion and interpolate the GS frames in one\nstep. We then combine the input RS frames and DF to learn a mapping for\nRS-to-GS frame interpolation. However, as the mapping is highly\nunder-constrained, we couple it with an inverse mapping (i.e., GS-to-RS) and RS\nframe warping (i.e., RS-to-RS) for self-supervision. As there is a lack of\nlabeled datasets for evaluation, we generate two synthetic datasets and collect\na real-world dataset to train and test our method. Experimental results show\nthat our method yields comparable or better performance with prior supervised\nmethods.\n","authors":["Yunfan Lu","Guoqiang Liang","Lin Wang"],"pdf_url":"https://arxiv.org/pdf/2306.15507v1.pdf","comment":"This paper has been submitted for review in March 2023"},{"id":"http://arxiv.org/abs/2301.04954v2","updated":"2023-06-27T14:30:23Z","published":"2023-01-12T11:51:11Z","title":"Reaching the Edge of the Edge: Image Analysis in Space","summary":"  Satellites have become more widely available due to the reduction in size and\ncost of their components. As a result, there has been an advent of smaller\norganizations having the ability to deploy satellites with a variety of\ndata-intensive applications to run on them. One popular application is image\nanalysis to detect, for example, land, ice, clouds, etc. for Earth observation.\nHowever, the resource-constrained nature of the devices deployed in satellites\ncreates additional challenges for this resource-intensive application.\n  In this paper, we present our work and lessons-learned on building an Image\nProcessing Unit (IPU) for a satellite. We first investigate the performance of\na variety of edge devices (comparing CPU, GPU, TPU, and VPU) for\ndeep-learning-based image processing on satellites. Our goal is to identify\ndevices that can achieve accurate results and are flexible when workload\nchanges while satisfying the power and latency constraints of satellites. Our\nresults demonstrate that hardware accelerators such as ASICs and GPUs are\nessential for meeting the latency requirements. However, state-of-the-art edge\ndevices with GPUs may draw too much power for deployment on a satellite. Then,\nwe use the findings gained from the performance analysis to guide the\ndevelopment of the IPU module for an upcoming satellite mission. We detail how\nto integrate such a module into an existing satellite architecture and the\nsoftware necessary to support various missions utilizing this module.\n","authors":["Robert Bayer","Julian Priest","Pınar Tözün"],"pdf_url":"https://arxiv.org/pdf/2301.04954v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15490v1","updated":"2023-06-27T14:11:48Z","published":"2023-06-27T14:11:48Z","title":"EVD Surgical Guidance with Retro-Reflective Tool Tracking and Spatial\n  Reconstruction using Head-Mounted Augmented Reality Device","summary":"  Augmented Reality (AR) has been used to facilitate surgical guidance during\nExternal Ventricular Drain (EVD) surgery, reducing the risks of misplacement in\nmanual operations. During this procedure, the pivotal challenge is the accurate\nestimation of spatial relationship between pre-operative images and actual\npatient anatomy in AR environment. In this research, we propose a novel\nframework utilizing Time of Flight (ToF) depth sensors integrated in\ncommercially available AR Head Mounted Devices (HMD) for precise EVD surgical\nguidance. As previous studies have proven depth errors for ToF sensors, we\nfirst conducted a comprehensive assessment for the properties of this error on\nAR-HMDs. Subsequently, a depth error model and patient-specific model parameter\nidentification method, is introduced for accurate surface information. After\nthat, a tracking procedure combining retro-reflective markers and point clouds\nis proposed for accurate head tracking, where head surface is reconstructed\nusing ToF sensor data for spatial registration, avoiding fixing tracking\ntargets rigidly on the patient's cranium. Firstly, $7.580\\pm 1.488 mm$ ToF\nsensor depth value error was revealed on human skin, indicating the\nsignificance of depth correction. Our results showed that the ToF sensor depth\nerror was reduced by over $85\\%$ using proposed depth correction method on head\nphantoms in different materials. Meanwhile, the head surface reconstructed with\ncorrected depth data achieved sub-millimeter accuracy. Experiment on a sheep\nhead revealed $0.79 mm$ reconstruction error. Furthermore, a user study was\nconducted for the performance of proposed framework in simulated EVD surgery,\nwhere 5 surgeons performed 9 k-wire injections on a head phantom with virtual\nguidance. Results of this study revealed $2.09 \\pm 0.16 mm$ translational\naccuracy and $2.97\\pm 0.91 ^\\circ$ orientational accuracy.\n","authors":["Haowei Li","Wenqing Yan","Du Liu","Long Qian","Yuxing Yang","Yihao Liu","Zhe Zhao","Hui Ding","Guangzhi Wang"],"pdf_url":"https://arxiv.org/pdf/2306.15490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15482v1","updated":"2023-06-27T14:02:10Z","published":"2023-06-27T14:02:10Z","title":"Cooperation or Competition: Avoiding Player Domination for Multi-Target\n  Robustness via Adaptive Budgets","summary":"  Despite incredible advances, deep learning has been shown to be susceptible\nto adversarial attacks. Numerous approaches have been proposed to train robust\nnetworks both empirically and certifiably. However, most of them defend against\nonly a single type of attack, while recent work takes steps forward in\ndefending against multiple attacks. In this paper, to understand multi-target\nrobustness, we view this problem as a bargaining game in which different\nplayers (adversaries) negotiate to reach an agreement on a joint direction of\nparameter updating. We identify a phenomenon named player domination in the\nbargaining game, namely that the existing max-based approaches, such as MAX and\nMSD, do not converge. Based on our theoretical analysis, we design a novel\nframework that adjusts the budgets of different adversaries to avoid any player\ndominance. Experiments on standard benchmarks show that employing the proposed\nframework to the existing approaches significantly advances multi-target\nrobustness.\n","authors":["Yimu Wang","Dinghuai Zhang","Yihan Wu","Heng Huang","Hongyang Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.15482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01742v3","updated":"2023-06-27T13:58:46Z","published":"2022-10-04T17:02:37Z","title":"CADet: Fully Self-Supervised Out-Of-Distribution Detection With\n  Contrastive Learning","summary":"  Handling out-of-distribution (OOD) samples has become a major stake in the\nreal-world deployment of machine learning systems. This work explores the use\nof self-supervised contrastive learning to the simultaneous detection of two\ntypes of OOD samples: unseen classes and adversarial perturbations. First, we\npair self-supervised contrastive learning with the maximum mean discrepancy\n(MMD) two-sample test. This approach enables us to robustly test whether two\nindependent sets of samples originate from the same distribution, and we\ndemonstrate its effectiveness by discriminating between CIFAR-10 and CIFAR-10.1\nwith higher confidence than previous work. Motivated by this success, we\nintroduce CADet (Contrastive Anomaly Detection), a novel method for OOD\ndetection of single samples. CADet draws inspiration from MMD, but leverages\nthe similarity between contrastive transformations of a same sample. CADet\noutperforms existing adversarial detection methods in identifying adversarially\nperturbed samples on ImageNet and achieves comparable performance to unseen\nlabel detection methods on two challenging benchmarks: ImageNet-O and\niNaturalist. Significantly, CADet is fully self-supervised and requires neither\nlabels for in-distribution samples nor access to OOD examples.\n","authors":["Charles Guille-Escuret","Pau Rodriguez","David Vazquez","Ioannis Mitliagkas","Joao Monteiro"],"pdf_url":"https://arxiv.org/pdf/2210.01742v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15472v1","updated":"2023-06-27T13:46:15Z","published":"2023-06-27T13:46:15Z","title":"Taming Detection Transformers for Medical Object Detection","summary":"  The accurate detection of suspicious regions in medical images is an\nerror-prone and time-consuming process required by many routinely performed\ndiagnostic procedures. To support clinicians during this difficult task,\nseveral automated solutions were proposed relying on complex methods with many\nhyperparameters. In this study, we investigate the feasibility of DEtection\nTRansformer (DETR) models for volumetric medical object detection. In contrast\nto previous works, these models directly predict a set of objects without\nrelying on the design of anchors or manual heuristics such as\nnon-maximum-suppression to detect objects. We show by conducting extensive\nexperiments with three models, namely DETR, Conditional DETR, and DINO DETR on\nfour data sets (CADA, RibFrac, KiTS19, and LIDC) that these set prediction\nmodels can perform on par with or even better than currently existing methods.\nDINO DETR, the best-performing model in our experiments demonstrates this by\noutperforming a strong anchor-based one-stage detector, Retina U-Net, on three\nout of four data sets.\n","authors":["Marc K. Ickler","Michael Baumgartner","Saikat Roy","Tassilo Wald","Klaus H. Maier-Hein"],"pdf_url":"https://arxiv.org/pdf/2306.15472v1.pdf","comment":"BVM 2023 Oral. Marc K. Ickler and Michael Baumgartner contributed\n  equally"},{"id":"http://arxiv.org/abs/2306.14250v2","updated":"2023-06-27T13:40:48Z","published":"2023-06-25T13:50:50Z","title":"Introducing A Novel Method For Adaptive Thresholding In Brain Tumor\n  Medical Image Segmentation","summary":"  One of the most significant challenges in the field of deep learning and\nmedical image segmentation is to determine an appropriate threshold for\nclassifying each pixel. This threshold is a value above which the model's\noutput is considered to belong to a specific class. Manual thresholding based\non personal experience is error-prone and time-consuming, particularly for\ncomplex problems such as medical images. Traditional methods for thresholding\nare not effective for determining the threshold value for such problems.\n  To tackle this challenge, automatic thresholding methods using deep learning\nhave been proposed. However, the main issue with these methods is that they\noften determine the threshold value statically without considering changes in\ninput data. Since input data can be dynamic and may change over time, threshold\ndetermination should be adaptive and consider input data and environmental\nconditions.\n","authors":["Ali Fayzi","Mohammad Fayzi","Mostafa Forotan"],"pdf_url":"https://arxiv.org/pdf/2306.14250v2.pdf","comment":"5 pages , 4 figures , 3 formula"},{"id":"http://arxiv.org/abs/2306.07980v2","updated":"2023-06-27T13:33:43Z","published":"2023-05-30T14:39:32Z","title":"Dark Web Activity Classification Using Deep Learning","summary":"  In contemporary times, people rely heavily on the internet and search engines\nto obtain information, either directly or indirectly. However, the information\naccessible to users constitutes merely 4% of the overall information present on\nthe internet, which is commonly known as the surface web. The remaining\ninformation that eludes search engines is called the deep web. The deep web\nencompasses deliberately hidden information, such as personal email accounts,\nsocial media accounts, online banking accounts, and other confidential data.\nThe deep web contains several critical applications, including databases of\nuniversities, banks, and civil records, which are off-limits and illegal to\naccess. The dark web is a subset of the deep web that provides an ideal\nplatform for criminals and smugglers to engage in illicit activities, such as\ndrug trafficking, weapon smuggling, selling stolen bank cards, and money\nlaundering. In this article, we propose a search engine that employs deep\nlearning to detect the titles of activities on the dark web. We focus on five\ncategories of activities, including drug trading, weapon trading, selling\nstolen bank cards, selling fake IDs, and selling illegal currencies. Our aim is\nto extract relevant images from websites with a \".onion\" extension and identify\nthe titles of websites without images by extracting keywords from the text of\nthe pages. Furthermore, we introduce a dataset of images called Darkoob, which\nwe have gathered and used to evaluate our proposed method. Our experimental\nresults demonstrate that the proposed method achieves an accuracy rate of 94%\non the test dataset.\n","authors":["Ali Fayzi","Mohammad Fayzi","Kourosh Ahmadi"],"pdf_url":"https://arxiv.org/pdf/2306.07980v2.pdf","comment":"11 pages , 16 figures , 2 tables , New Dataset For DarkWeb Activity\n  Classification"},{"id":"http://arxiv.org/abs/2306.15464v1","updated":"2023-06-27T13:31:33Z","published":"2023-06-27T13:31:33Z","title":"Large-scale unsupervised audio pre-training for video-to-speech\n  synthesis","summary":"  Video-to-speech synthesis is the task of reconstructing the speech signal\nfrom a silent video of a speaker. Most established approaches to date involve a\ntwo-step process, whereby an intermediate representation from the video, such\nas a spectrogram, is extracted first and then passed to a vocoder to produce\nthe raw audio. Some recent work has focused on end-to-end synthesis, whereby\nthe generation of raw audio and any intermediate representations is performed\njointly. All such approaches involve training on data from almost exclusively\naudio-visual datasets, i.e. every audio sample has a corresponding video\nsample. This precludes the use of abundant audio-only datasets which may not\nhave a corresponding visual modality (e.g. audiobooks, radio podcasts, speech\nrecognition datasets etc.), as well as audio-only architectures that have been\ndeveloped by the audio machine learning community over the years. In this paper\nwe propose to train encoder-decoder models on more than 3,500 hours of audio\ndata at 24kHz, and then use the pre-trained decoders to initialize the audio\ndecoders for the video-to-speech synthesis task. The pre-training step uses\naudio samples only and does not require labels or corresponding samples from\nother modalities (visual, text). We demonstrate that this pre-training step\nimproves the reconstructed speech and that it is an unexplored way to improve\nthe quality of the generator in a cross-modal task while only requiring samples\nfrom one of the modalities. We conduct experiments using both raw audio and mel\nspectrograms as target outputs and benchmark our models with existing work.\n","authors":["Triantafyllos Kefalas","Yannis Panagakis","Maja Pantic"],"pdf_url":"https://arxiv.org/pdf/2306.15464v1.pdf","comment":"Submitted to IEEE"},{"id":"http://arxiv.org/abs/2306.15457v1","updated":"2023-06-27T13:22:19Z","published":"2023-06-27T13:22:19Z","title":"Robust Proxy: Improving Adversarial Robustness by Robust Proxy Learning","summary":"  Recently, it has been widely known that deep neural networks are highly\nvulnerable and easily broken by adversarial attacks. To mitigate the\nadversarial vulnerability, many defense algorithms have been proposed.\nRecently, to improve adversarial robustness, many works try to enhance feature\nrepresentation by imposing more direct supervision on the discriminative\nfeature. However, existing approaches lack an understanding of learning\nadversarially robust feature representation. In this paper, we propose a novel\ntraining framework called Robust Proxy Learning. In the proposed method, the\nmodel explicitly learns robust feature representations with robust proxies. To\nthis end, firstly, we demonstrate that we can generate class-representative\nrobust features by adding class-wise robust perturbations. Then, we use the\nclass representative features as robust proxies. With the class-wise robust\nfeatures, the model explicitly learns adversarially robust features through the\nproposed robust proxy learning framework. Through extensive experiments, we\nverify that we can manually generate robust features, and our proposed learning\nframework could increase the robustness of the DNNs.\n","authors":["Hong Joo Lee","Yong Man Ro"],"pdf_url":"https://arxiv.org/pdf/2306.15457v1.pdf","comment":"Accepted at IEEE Transactions on Information Forensics and Security\n  (TIFS)"},{"id":"http://arxiv.org/abs/2306.15451v1","updated":"2023-06-27T13:12:25Z","published":"2023-06-27T13:12:25Z","title":"Advancing Adversarial Training by Injecting Booster Signal","summary":"  Recent works have demonstrated that deep neural networks (DNNs) are highly\nvulnerable to adversarial attacks. To defend against adversarial attacks, many\ndefense strategies have been proposed, among which adversarial training has\nbeen demonstrated to be the most effective strategy. However, it has been known\nthat adversarial training sometimes hurts natural accuracy. Then, many works\nfocus on optimizing model parameters to handle the problem. Different from the\nprevious approaches, in this paper, we propose a new approach to improve the\nadversarial robustness by using an external signal rather than model\nparameters. In the proposed method, a well-optimized universal external signal\ncalled a booster signal is injected into the outside of the image which does\nnot overlap with the original content. Then, it boosts both adversarial\nrobustness and natural accuracy. The booster signal is optimized in parallel to\nmodel parameters step by step collaboratively. Experimental results show that\nthe booster signal can improve both the natural and robust accuracies over the\nrecent state-of-the-art adversarial training methods. Also, optimizing the\nbooster signal is general and flexible enough to be adopted on any existing\nadversarial training methods.\n","authors":["Hong Joo Lee","Youngjoon Yu","Yong Man Ro"],"pdf_url":"https://arxiv.org/pdf/2306.15451v1.pdf","comment":"Accepted at IEEE Transactions on Neural Networks and Learning Systems"},{"id":"http://arxiv.org/abs/2306.15445v1","updated":"2023-06-27T13:02:24Z","published":"2023-06-27T13:02:24Z","title":"UniUD Submission to the EPIC-Kitchens-100 Multi-Instance Retrieval\n  Challenge 2023","summary":"  In this report, we present the technical details of our submission to the\nEPIC-Kitchens-100 Multi-Instance Retrieval Challenge 2023. To participate in\nthe challenge, we ensembled two models trained with two different loss\nfunctions on 25% of the training data. Our submission, visible on the public\nleaderboard, obtains an average score of 56.81% nDCG and 42.63% mAP.\n","authors":["Alex Falcon","Giuseppe Serra"],"pdf_url":"https://arxiv.org/pdf/2306.15445v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15442v1","updated":"2023-06-27T12:58:16Z","published":"2023-06-27T12:58:16Z","title":"No-Service Rail Surface Defect Segmentation via Normalized Attention and\n  Dual-scale Interaction","summary":"  No-service rail surface defect (NRSD) segmentation is an essential way for\nperceiving the quality of no-service rails. However, due to the complex and\ndiverse outlines and low-contrast textures of no-service rails, existing\nnatural image segmentation methods cannot achieve promising performance in NRSD\nimages, especially in some unique and challenging NRSD scenes. To this end, in\nthis paper, we propose a novel segmentation network for NRSDs based on\nNormalized Attention and Dual-scale Interaction, named NaDiNet. Specifically,\nNaDiNet follows the enhancement-interaction paradigm. The Normalized\nChannel-wise Self-Attention Module (NAM) and the Dual-scale Interaction Block\n(DIB) are two key components of NaDiNet. NAM is a specific extension of the\nchannel-wise self-attention mechanism (CAM) to enhance features extracted from\nlow-contrast NRSD images. The softmax layer in CAM will produce very small\ncorrelation coefficients which are not conducive to low-contrast feature\nenhancement. Instead, in NAM, we directly calculate the normalized correlation\ncoefficient between channels to enlarge the feature differentiation. DIB is\nspecifically designed for the feature interaction of the enhanced features. It\nhas two interaction branches with dual scales, one for fine-grained clues and\nthe other for coarse-grained clues. With both branches working together, DIB\ncan perceive defect regions of different granularities. With these modules\nworking together, our NaDiNet can generate accurate segmentation map. Extensive\nexperiments on the public NRSD-MN dataset with man-made and natural NRSDs\ndemonstrate that our proposed NaDiNet with various backbones (i.e., VGG,\nResNet, and DenseNet) consistently outperforms 10 state-of-the-art methods. The\ncode and results of our method are available at\nhttps://github.com/monxxcn/NaDiNet.\n","authors":["Gongyang Li","Chengjun Han","Zhi Liu"],"pdf_url":"https://arxiv.org/pdf/2306.15442v1.pdf","comment":"10 pages, 6 figures, Accepted by IEEE Transactions on Instrumentation\n  and Measurement 2023"},{"id":"http://arxiv.org/abs/2306.15425v1","updated":"2023-06-27T12:37:21Z","published":"2023-06-27T12:37:21Z","title":"Phase Space Analysis of Cardiac Spectra","summary":"  Cardiac diseases are one of the main reasons of mortality in modern,\nindustrialized societies, and they cause high expenses in public health\nsystems. Therefore, it is important to develop analytical methods to improve\ncardiac diagnostics. Electric activity of heart was first modeled by using a\nset of nonlinear differential equations. Latter, variations of cardiac spectra\noriginated from deterministic dynamics are investigated. Analyzing the power\nspectra of a normal human heart presents His-Purkinje network, possessing a\nfractal like structure. Phase space trajectories are extracted from the time\nseries graph of ECG. Lower values of fractal dimension, D indicate dynamics\nthat are more coherent. If D has non-integer values greater than two when the\nsystem becomes chaotic or strange attractor. Recently, the development of a\nfast and robust method, which can be applied to multichannel physiologic\nsignals, was reported. This manuscript investigates two different ECG systems\nproduced from normal and abnormal human hearts to introduce an auxiliary phase\nspace method in conjunction with ECG signals for diagnoses of heart diseases.\nHere, the data for each person includes two signals based on V_4 and modified\nlead III (MLIII) respectively. Fractal analysis method is employed on the\ntrajectories constructed in phase space, from which the fractal dimension D is\nobtained using the box counting method. It is observed that, MLIII signals have\nlarger D values than the first signals (V_4), predicting more randomness yet\nmore information. The lowest value of D (1.708) indicates the perfect\noscillation of the normal heart and the highest value of D (1.863) presents the\nrandomness of the abnormal heart. Our significant finding is that the phase\nspace picture presents the distribution of the peak heights from the ECG\nspectra, giving valuable information about heart activities in conjunction with\nECG.\n","authors":["Onder Pekcan","Taner Arsan"],"pdf_url":"https://arxiv.org/pdf/2306.15425v1.pdf","comment":"10 pages, 8 figures, 1 table. arXiv admin note: text overlap with\n  arXiv:2305.10450"},{"id":"http://arxiv.org/abs/2306.15419v1","updated":"2023-06-27T12:23:04Z","published":"2023-06-27T12:23:04Z","title":"Free-style and Fast 3D Portrait Synthesis","summary":"  Efficiently generating a free-style 3D portrait with high quality and\nconsistency is a promising yet challenging task. The portrait styles generated\nby most existing methods are usually restricted by their 3D generators, which\nare learned in specific facial datasets, such as FFHQ. To get a free-style 3D\nportrait, one can build a large-scale multi-style database to retrain the 3D\ngenerator, or use a off-the-shelf tool to do the style translation. However,\nthe former is time-consuming due to data collection and training process, the\nlatter may destroy the multi-view consistency. To tackle this problem, we\npropose a fast 3D portrait synthesis framework in this paper, which enable one\nto use text prompts to specify styles. Specifically, for a given portrait\nstyle, we first leverage two generative priors, a 3D-aware GAN generator (EG3D)\nand a text-guided image editor (Ip2p), to quickly construct a few-shot training\nset, where the inference process of Ip2p is optimized to make editing more\nstable. Then we replace original triplane generator of EG3D with a\nImage-to-Triplane (I2T) module for two purposes: 1) getting rid of the style\nconstraints of pre-trained EG3D by fine-tuning I2T on the few-shot dataset; 2)\nimproving training efficiency by fixing all parts of EG3D except I2T.\nFurthermore, we construct a multi-style and multi-identity 3D portrait database\nto demonstrate the scalability and generalization of our method. Experimental\nresults show that our method is capable of synthesizing high-quality 3D\nportraits with specified styles in a few minutes, outperforming the\nstate-of-the-art.\n","authors":["Tianxiang Ma","Kang Zhao","Jianxin Sun","Jing Dong","Tieniu Tan"],"pdf_url":"https://arxiv.org/pdf/2306.15419v1.pdf","comment":"project website: https://tianxiangma.github.io/FF3D"},{"id":"http://arxiv.org/abs/2306.15416v1","updated":"2023-06-27T12:22:25Z","published":"2023-06-27T12:22:25Z","title":"Irregular Change Detection in Sparse Bi-Temporal Point Clouds using\n  Learned Place Recognition Descriptors and Point-to-Voxel Comparison","summary":"  Change detection and irregular object extraction in 3D point clouds is a\nchallenging task that is of high importance not only for autonomous navigation\nbut also for updating existing digital twin models of various industrial\nenvironments. This article proposes an innovative approach for change detection\nin 3D point clouds using deep learned place recognition descriptors and\nirregular object extraction based on voxel-to-point comparison. The proposed\nmethod first aligns the bi-temporal point clouds using a map-merging algorithm\nin order to establish a common coordinate frame. Then, it utilizes deep\nlearning techniques to extract robust and discriminative features from the 3D\npoint cloud scans, which are used to detect changes between consecutive point\ncloud frames and therefore find the changed areas. Finally, the altered areas\nare sampled and compared between the two time instances to extract any\nobstructions that caused the area to change. The proposed method was\nsuccessfully evaluated in real-world field experiments, where it was able to\ndetect different types of changes in 3D point clouds, such as object or\nmuck-pile addition and displacement, showcasing the effectiveness of the\napproach. The results of this study demonstrate important implications for\nvarious applications, including safety and security monitoring in construction\nsites, mapping and exploration and suggests potential future research\ndirections in this field.\n","authors":["Nikolaos Stathoulopoulos","Anton Koval","George Nikolakopoulos"],"pdf_url":"https://arxiv.org/pdf/2306.15416v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15410v1","updated":"2023-06-27T12:11:22Z","published":"2023-06-27T12:11:22Z","title":"AutoGraph: Predicting Lane Graphs from Traffic Observations","summary":"  Lane graph estimation is a long-standing problem in the context of autonomous\ndriving. Previous works aimed at solving this problem by relying on\nlarge-scale, hand-annotated lane graphs, introducing a data bottleneck for\ntraining models to solve this task. To overcome this limitation, we propose to\nuse the motion patterns of traffic participants as lane graph annotations. In\nour AutoGraph approach, we employ a pre-trained object tracker to collect the\ntracklets of traffic participants such as vehicles and trucks. Based on the\nlocation of these tracklets, we predict the successor lane graph from an\ninitial position using overhead RGB images only, not requiring any human\nsupervision. In a subsequent stage, we show how the individual successor\npredictions can be aggregated into a consistent lane graph. We demonstrate the\nefficacy of our approach on the UrbanLaneGraph dataset and perform extensive\nquantitative and qualitative evaluations, indicating that AutoGraph is on par\nwith models trained on hand-annotated graph data. Model and dataset will be\nmade available at redacted-for-review.\n","authors":["Jannik Zürn","Ingmar Posner","Wolfram Burgard"],"pdf_url":"https://arxiv.org/pdf/2306.15410v1.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2305.12140v2","updated":"2023-06-27T11:42:44Z","published":"2023-05-20T08:43:51Z","title":"Movie101: A New Movie Understanding Benchmark","summary":"  To help the visually impaired enjoy movies, automatic movie narrating systems\nare expected to narrate accurate, coherent, and role-aware plots when there are\nno speaking lines of actors. Existing works benchmark this challenge as a\nnormal video captioning task via some simplifications, such as removing role\nnames and evaluating narrations with ngram-based metrics, which makes it\ndifficult for automatic systems to meet the needs of real application\nscenarios. To narrow this gap, we construct a large-scale Chinese movie\nbenchmark, named Movie101. Closer to real scenarios, the Movie Clip Narrating\n(MCN) task in our benchmark asks models to generate role-aware narration\nparagraphs for complete movie clips where no actors are speaking. External\nknowledge, such as role information and movie genres, is also provided for\nbetter movie understanding. Besides, we propose a new metric called Movie\nNarration Score (MNScore) for movie narrating evaluation, which achieves the\nbest correlation with human evaluation. Our benchmark also supports the\nTemporal Narration Grounding (TNG) task to investigate clip localization given\ntext descriptions. For both two tasks, our proposed methods well leverage\nexternal knowledge and outperform carefully designed baselines. The dataset and\ncodes are released at https://github.com/yuezih/Movie101.\n","authors":["Zihao Yue","Qi Zhang","Anwen Hu","Liang Zhang","Ziheng Wang","Qin Jin"],"pdf_url":"https://arxiv.org/pdf/2305.12140v2.pdf","comment":"Accepted to ACL 2023"},{"id":"http://arxiv.org/abs/2306.14435v2","updated":"2023-06-27T11:30:16Z","published":"2023-06-26T06:04:09Z","title":"DragDiffusion: Harnessing Diffusion Models for Interactive Point-based\n  Image Editing","summary":"  Precise and controllable image editing is a challenging task that has\nattracted significant attention. Recently, DragGAN enables an interactive\npoint-based image editing framework and achieves impressive editing results\nwith pixel-level precision. However, since this method is based on generative\nadversarial networks (GAN), its generality is upper-bounded by the capacity of\nthe pre-trained GAN models. In this work, we extend such an editing framework\nto diffusion models and propose DragDiffusion. By leveraging large-scale\npretrained diffusion models, we greatly improve the applicability of\ninteractive point-based editing in real world scenarios. While most existing\ndiffusion-based image editing methods work on text embeddings, DragDiffusion\noptimizes the diffusion latent to achieve precise spatial control. Although\ndiffusion models generate images in an iterative manner, we empirically show\nthat optimizing diffusion latent at one single step suffices to generate\ncoherent results, enabling DragDiffusion to complete high-quality editing\nefficiently. Extensive experiments across a wide range of challenging cases\n(e.g., multi-objects, diverse object categories, various styles, etc.)\ndemonstrate the versatility and generality of DragDiffusion.\n","authors":["Yujun Shi","Chuhui Xue","Jiachun Pan","Wenqing Zhang","Vincent Y. F. Tan","Song Bai"],"pdf_url":"https://arxiv.org/pdf/2306.14435v2.pdf","comment":"Preliminary version. Work in Progress"},{"id":"http://arxiv.org/abs/2306.15390v1","updated":"2023-06-27T11:28:29Z","published":"2023-06-27T11:28:29Z","title":"DCP-NAS: Discrepant Child-Parent Neural Architecture Search for 1-bit\n  CNNs","summary":"  Neural architecture search (NAS) proves to be among the effective approaches\nfor many tasks by generating an application-adaptive neural architecture, which\nis still challenged by high computational cost and memory consumption. At the\nsame time, 1-bit convolutional neural networks (CNNs) with binary weights and\nactivations show their potential for resource-limited embedded devices. One\nnatural approach is to use 1-bit CNNs to reduce the computation and memory cost\nof NAS by taking advantage of the strengths of each in a unified framework,\nwhile searching the 1-bit CNNs is more challenging due to the more complicated\nprocesses involved. In this paper, we introduce Discrepant Child-Parent Neural\nArchitecture Search (DCP-NAS) to efficiently search 1-bit CNNs, based on a new\nframework of searching the 1-bit model (Child) under the supervision of a\nreal-valued model (Parent). Particularly, we first utilize a Parent model to\ncalculate a tangent direction, based on which the tangent propagation method is\nintroduced to search the optimized 1-bit Child. We further observe a coupling\nrelationship between the weights and architecture parameters existing in such\ndifferentiable frameworks. To address the issue, we propose a decoupled\noptimization method to search an optimized architecture. Extensive experiments\ndemonstrate that our DCP-NAS achieves much better results than prior arts on\nboth CIFAR-10 and ImageNet datasets. In particular, the backbones achieved by\nour DCP-NAS achieve strong generalization performance on person\nre-identification and object detection.\n","authors":["Yanjing Li","Sheng Xu","Xianbin Cao","Li'an Zhuo","Baochang Zhang","Tian Wang","Guodong Guo"],"pdf_url":"https://arxiv.org/pdf/2306.15390v1.pdf","comment":"Accepted by International Journal of Computer Vision"},{"id":"http://arxiv.org/abs/2306.13361v2","updated":"2023-06-27T10:54:27Z","published":"2023-06-23T08:27:32Z","title":"Neural 360$^\\circ$ Structured Light with Learned Metasurfaces","summary":"  Structured light has proven instrumental in 3D imaging, LiDAR, and\nholographic light projection. Metasurfaces, comprised of sub-wavelength-sized\nnanostructures, facilitate 180$^\\circ$ field-of-view (FoV) structured light,\ncircumventing the restricted FoV inherent in traditional optics like\ndiffractive optical elements. However, extant metasurface-facilitated\nstructured light exhibits sub-optimal performance in downstream tasks, due to\nheuristic pattern designs such as periodic dots that do not consider the\nobjectives of the end application. In this paper, we present neural 360$^\\circ$\nstructured light, driven by learned metasurfaces. We propose a differentiable\nframework, that encompasses a computationally-efficient 180$^\\circ$ wave\npropagation model and a task-specific reconstructor, and exploits both\ntransmission and reflection channels of the metasurface. Leveraging a\nfirst-order optimizer within our differentiable framework, we optimize the\nmetasurface design, thereby realizing neural 360$^\\circ$ structured light. We\nhave utilized neural 360$^\\circ$ structured light for holographic light\nprojection and 3D imaging. Specifically, we demonstrate the first 360$^\\circ$\nlight projection of complex patterns, enabled by our propagation model that can\nbe computationally evaluated 50,000$\\times$ faster than the Rayleigh-Sommerfeld\npropagation. For 3D imaging, we improve depth-estimation accuracy by\n5.09$\\times$ in RMSE compared to the heuristically-designed structured light.\nNeural 360$^\\circ$ structured light promises robust 360$^\\circ$ imaging and\ndisplay for robotics, extended-reality systems, and human-computer\ninteractions.\n","authors":["Eunsue Choi","Gyeongtae Kim","Jooyeong Yun","Yujin Jeon","Junsuk Rho","Seung-Hwan Baek"],"pdf_url":"https://arxiv.org/pdf/2306.13361v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15377v1","updated":"2023-06-27T10:54:08Z","published":"2023-06-27T10:54:08Z","title":"TrickVOS: A Bag of Tricks for Video Object Segmentation","summary":"  Space-time memory (STM) network methods have been dominant in semi-supervised\nvideo object segmentation (SVOS) due to their remarkable performance. In this\nwork, we identify three key aspects where we can improve such methods; i)\nsupervisory signal, ii) pretraining and iii) spatial awareness. We then propose\nTrickVOS; a generic, method-agnostic bag of tricks addressing each aspect with\ni) a structure-aware hybrid loss, ii) a simple decoder pretraining regime and\niii) a cheap tracker that imposes spatial constraints in model predictions.\nFinally, we propose a lightweight network and show that when trained with\nTrickVOS, it achieves competitive results to state-of-the-art methods on DAVIS\nand YouTube benchmarks, while being one of the first STM-based SVOS methods\nthat can run in real-time on a mobile device.\n","authors":["Evangelos Skartados","Konstantinos Georgiadis","Mehmet Kerim Yucel","Koskinas Ioannis","Armando Domi","Anastasios Drosou","Bruno Manganelli","Albert Sa`a-Garriga"],"pdf_url":"https://arxiv.org/pdf/2306.15377v1.pdf","comment":"Accepted to ICIP 2023"},{"id":"http://arxiv.org/abs/2306.15350v1","updated":"2023-06-27T10:03:15Z","published":"2023-06-27T10:03:15Z","title":"CellViT: Vision Transformers for Precise Cell Segmentation and\n  Classification","summary":"  Nuclei detection and segmentation in hematoxylin and eosin-stained (H&E)\ntissue images are important clinical tasks and crucial for a wide range of\napplications. However, it is a challenging task due to nuclei variances in\nstaining and size, overlapping boundaries, and nuclei clustering. While\nconvolutional neural networks have been extensively used for this task, we\nexplore the potential of Transformer-based networks in this domain. Therefore,\nwe introduce a new method for automated instance segmentation of cell nuclei in\ndigitized tissue samples using a deep learning architecture based on Vision\nTransformer called CellViT. CellViT is trained and evaluated on the PanNuke\ndataset, which is one of the most challenging nuclei instance segmentation\ndatasets, consisting of nearly 200,000 annotated Nuclei into 5 clinically\nimportant classes in 19 tissue types. We demonstrate the superiority of\nlarge-scale in-domain and out-of-domain pre-trained Vision Transformers by\nleveraging the recently published Segment Anything Model and a ViT-encoder\npre-trained on 104 million histological image patches - achieving\nstate-of-the-art nuclei detection and instance segmentation performance on the\nPanNuke dataset with a mean panoptic quality of 0.51 and an F1-detection score\nof 0.83. The code is publicly available at https://github.com/TIO-IKIM/CellViT\n","authors":["Fabian Hörst","Moritz Rempe","Lukas Heine","Constantin Seibold","Julius Keyl","Giulia Baldini","Selma Ugurel","Jens Siveke","Barbara Grünwald","Jan Egger","Jens Kleesiek"],"pdf_url":"https://arxiv.org/pdf/2306.15350v1.pdf","comment":"13 pages, 5 figures, appendix included"},{"id":"http://arxiv.org/abs/2306.15349v1","updated":"2023-06-27T10:02:45Z","published":"2023-06-27T10:02:45Z","title":"SSC-RS: Elevate LiDAR Semantic Scene Completion with Representation\n  Separation and BEV Fusion","summary":"  Semantic scene completion (SSC) jointly predicts the semantics and geometry\nof the entire 3D scene, which plays an essential role in 3D scene understanding\nfor autonomous driving systems. SSC has achieved rapid progress with the help\nof semantic context in segmentation. However, how to effectively exploit the\nrelationships between the semantic context in semantic segmentation and\ngeometric structure in scene completion remains under exploration. In this\npaper, we propose to solve outdoor SSC from the perspective of representation\nseparation and BEV fusion. Specifically, we present the network, named SSC-RS,\nwhich uses separate branches with deep supervision to explicitly disentangle\nthe learning procedure of the semantic and geometric representations. And a BEV\nfusion network equipped with the proposed Adaptive Representation Fusion (ARF)\nmodule is presented to aggregate the multi-scale features effectively and\nefficiently. Due to the low computational burden and powerful representation\nability, our model has good generality while running in real-time. Extensive\nexperiments on SemanticKITTI demonstrate our SSC-RS achieves state-of-the-art\nperformance.\n","authors":["Jianbiao Mei","Yu Yang","Mengmeng Wang","Tianxin Huang","Xuemeng Yang","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2306.15349v1.pdf","comment":"8 pages, 5 figures, IROS2023"},{"id":"http://arxiv.org/abs/2306.15348v1","updated":"2023-06-27T10:02:28Z","published":"2023-06-27T10:02:28Z","title":"PANet: LiDAR Panoptic Segmentation with Sparse Instance Proposal and\n  Aggregation","summary":"  Reliable LiDAR panoptic segmentation (LPS), including both semantic and\ninstance segmentation, is vital for many robotic applications, such as\nautonomous driving. This work proposes a new LPS framework named PANet to\neliminate the dependency on the offset branch and improve the performance on\nlarge objects, which are always over-segmented by clustering algorithms.\nFirstly, we propose a non-learning Sparse Instance Proposal (SIP) module with\nthe ``sampling-shifting-grouping\" scheme to directly group thing points into\ninstances from the raw point cloud efficiently. More specifically, balanced\npoint sampling is introduced to generate sparse seed points with more uniform\npoint distribution over the distance range. And a shift module, termed bubble\nshifting, is proposed to shrink the seed points to the clustered centers. Then\nwe utilize the connected component label algorithm to generate instance\nproposals. Furthermore, an instance aggregation module is devised to integrate\npotentially fragmented instances, improving the performance of the SIP module\non large objects. Extensive experiments show that PANet achieves\nstate-of-the-art performance among published works on the SemanticKITII\nvalidation and nuScenes validation for the panoptic segmentation task.\n","authors":["Jianbiao Mei","Yu Yang","Mengmeng Wang","Xiaojun Hou","Laijian Li","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2306.15348v1.pdf","comment":"8 pages, 3 figures, IROS2023"},{"id":"http://arxiv.org/abs/2305.07663v2","updated":"2023-06-27T09:56:30Z","published":"2023-04-30T13:53:39Z","title":"Revealing Similar Semantics Inside CNNs: An Interpretable Concept-based\n  Comparison of Feature Spaces","summary":"  Safety-critical applications require transparency in artificial intelligence\n(AI) components, but widely used convolutional neural networks (CNNs) widely\nused for perception tasks lack inherent interpretability. Hence, insights into\nwhat CNNs have learned are primarily based on performance metrics, because\nthese allow, e.g., for cross-architecture CNN comparison. However, these\nneglect how knowledge is stored inside. To tackle this yet unsolved problem,\nour work proposes two methods for estimating the layer-wise similarity between\nsemantic information inside CNN latent spaces. These allow insights into both\nthe flow and likeness of semantic information within CNN layers, and into the\ndegree of their similarity between different network architectures. As a basis,\nwe use two renowned explainable artificial intelligence (XAI) techniques, which\nare used to obtain concept activation vectors, i.e., global vector\nrepresentations in the latent space. These are compared with respect to their\nactivation on test inputs. When applied to three diverse object detectors and\ntwo datasets, our methods reveal that (1) similar semantic concepts are learned\nregardless of the CNN architecture, and (2) similar concepts emerge in similar\nrelative layer depth, independent of the total number of layers. Finally, our\napproach poses a promising step towards semantic model comparability and\ncomprehension of how different CNNs process semantic information.\n","authors":["Georgii Mikriukov","Gesina Schwalbe","Christian Hellert","Korinna Bade"],"pdf_url":"https://arxiv.org/pdf/2305.07663v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15341v1","updated":"2023-06-27T09:51:20Z","published":"2023-06-27T09:51:20Z","title":"Novel Hybrid-Learning Algorithms for Improved Millimeter-Wave Imaging\n  Systems","summary":"  Increasing attention is being paid to millimeter-wave (mmWave), 30 GHz to 300\nGHz, and terahertz (THz), 300 GHz to 10 THz, sensing applications including\nsecurity sensing, industrial packaging, medical imaging, and non-destructive\ntesting. Traditional methods for perception and imaging are challenged by novel\ndata-driven algorithms that offer improved resolution, localization, and\ndetection rates. Over the past decade, deep learning technology has garnered\nsubstantial popularity, particularly in perception and computer vision\napplications. Whereas conventional signal processing techniques are more easily\ngeneralized to various applications, hybrid approaches where signal processing\nand learning-based algorithms are interleaved pose a promising compromise\nbetween performance and generalizability. Furthermore, such hybrid algorithms\nimprove model training by leveraging the known characteristics of radio\nfrequency (RF) waveforms, thus yielding more efficiently trained deep learning\nalgorithms and offering higher performance than conventional methods. This\ndissertation introduces novel hybrid-learning algorithms for improved mmWave\nimaging systems applicable to a host of problems in perception and sensing.\nVarious problem spaces are explored, including static and dynamic gesture\nclassification; precise hand localization for human computer interaction;\nhigh-resolution near-field mmWave imaging using forward synthetic aperture\nradar (SAR); SAR under irregular scanning geometries; mmWave image\nsuper-resolution using deep neural network (DNN) and Vision Transformer (ViT)\narchitectures; and data-level multiband radar fusion using a novel\nhybrid-learning architecture. Furthermore, we introduce several novel\napproaches for deep learning model training and dataset synthesis.\n","authors":["Josiah Smith"],"pdf_url":"https://arxiv.org/pdf/2306.15341v1.pdf","comment":"PhD Dissertation Submitted to UTD ECE Department"},{"id":"http://arxiv.org/abs/2306.15333v1","updated":"2023-06-27T09:39:42Z","published":"2023-06-27T09:39:42Z","title":"Shoggoth: Towards Efficient Edge-Cloud Collaborative Real-Time Video\n  Inference via Adaptive Online Learning","summary":"  This paper proposes Shoggoth, an efficient edge-cloud collaborative\narchitecture, for boosting inference performance on real-time video of changing\nscenes. Shoggoth uses online knowledge distillation to improve the accuracy of\nmodels suffering from data drift and offloads the labeling process to the\ncloud, alleviating constrained resources of edge devices. At the edge, we\ndesign adaptive training using small batches to adapt models under limited\ncomputing power, and adaptive sampling of training frames for robustness and\nreducing bandwidth. The evaluations on the realistic dataset show 15%-20% model\naccuracy improvement compared to the edge-only strategy and fewer network costs\nthan the cloud-only strategy.\n","authors":["Liang Wang","Kai Lu","Nan Zhang","Xiaoyang Qu","Jianzong Wang","Jiguang Wan","Guokuan Li","Jing Xiao"],"pdf_url":"https://arxiv.org/pdf/2306.15333v1.pdf","comment":"Accepted by 60th ACM/IEEE Design Automation Conference (DAC2023)"},{"id":"http://arxiv.org/abs/2302.04841v2","updated":"2023-06-27T09:30:19Z","published":"2023-02-09T18:49:13Z","title":"Is This Loss Informative? Faster Text-to-Image Customization by Tracking\n  Objective Dynamics","summary":"  Text-to-image generation models represent the next step of evolution in image\nsynthesis, offering a natural way to achieve flexible yet fine-grained control\nover the result. One emerging area of research is the fast adaptation of large\ntext-to-image models to smaller datasets or new visual concepts. However, many\nefficient methods of adaptation have a long training time, which limits their\npractical applications, slows down research experiments, and spends excessive\nGPU resources. In this work, we study the training dynamics of popular\ntext-to-image personalization methods (such as Textual Inversion or\nDreamBooth), aiming to speed them up. We observe that most concepts are learned\nat early stages and do not improve in quality later, but standard model\nconvergence metrics fail to indicate that. Instead, we propose a simple drop-in\nearly stopping criterion that only requires computing the regular training\nobjective on a fixed set of inputs for all training iterations. Our experiments\non Stable Diffusion for a range of concepts and for three personalization\nmethods demonstrate the competitive performance of our approach, making\nadaptation up to 8 times faster with no significant drops in quality.\n","authors":["Anton Voronov","Mikhail Khoroshikh","Artem Babenko","Max Ryabinin"],"pdf_url":"https://arxiv.org/pdf/2302.04841v2.pdf","comment":"Code: https://github.com/yandex-research/DVAR. 19 pages, 14 figures"},{"id":"http://arxiv.org/abs/2306.15321v1","updated":"2023-06-27T09:23:36Z","published":"2023-06-27T09:23:36Z","title":"Multi-Dimensional Refinement Graph Convolutional Network with Robust\n  Decouple Loss for Fine-Grained Skeleton-Based Action Recognition","summary":"  Graph convolutional networks have been widely used in skeleton-based action\nrecognition. However, existing approaches are limited in fine-grained action\nrecognition due to the similarity of inter-class data. Moreover, the noisy data\nfrom pose extraction increases the challenge of fine-grained recognition. In\nthis work, we propose a flexible attention block called Channel-Variable\nSpatial-Temporal Attention (CVSTA) to enhance the discriminative power of\nspatial-temporal joints and obtain a more compact intra-class feature\ndistribution. Based on CVSTA, we construct a Multi-Dimensional Refinement Graph\nConvolutional Network (MDR-GCN), which can improve the discrimination among\nchannel-, joint- and frame-level features for fine-grained actions.\nFurthermore, we propose a Robust Decouple Loss (RDL), which significantly\nboosts the effect of the CVSTA and reduces the impact of noise. The proposed\nmethod combining MDR-GCN with RDL outperforms the known state-of-the-art\nskeleton-based approaches on fine-grained datasets, FineGym99 and FSD-10, and\nalso on the coarse dataset NTU-RGB+D X-view version.\n","authors":["Sheng-Lan Liu","Yu-Ning Ding","Jin-Rong Zhang","Kai-Yuan Liu","Si-Fan Zhang","Fei-Long Wang","Gao Huang"],"pdf_url":"https://arxiv.org/pdf/2306.15321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.14845v3","updated":"2023-06-27T09:22:05Z","published":"2023-03-26T23:00:00Z","title":"Multi-task Learning of Histology and Molecular Markers for Classifying\n  Diffuse Glioma","summary":"  Most recently, the pathology diagnosis of cancer is shifting to integrating\nmolecular makers with histology features. It is a urgent need for digital\npathology methods to effectively integrate molecular markers with histology,\nwhich could lead to more accurate diagnosis in the real world scenarios. This\npaper presents a first attempt to jointly predict molecular markers and\nhistology features and model their interactions for classifying diffuse glioma\nbases on whole slide images. Specifically, we propose a hierarchical multi-task\nmulti-instance learning framework to jointly predict histology and molecular\nmarkers. Moreover, we propose a co-occurrence probability-based label\ncorrection graph network to model the co-occurrence of molecular markers.\nLastly, we design an inter-omic interaction strategy with the dynamical\nconfidence constraint loss to model the interactions of histology and molecular\nmarkers. Our experiments show that our method outperforms other\nstate-of-the-art methods in classifying diffuse glioma,as well as related\nhistology and molecular markers on a multi-institutional dataset.\n","authors":["Xiaofei Wang","Stephen Price","Chao Li"],"pdf_url":"https://arxiv.org/pdf/2303.14845v3.pdf","comment":"Early Accept by MICCAI 2023"},{"id":"http://arxiv.org/abs/2306.15319v1","updated":"2023-06-27T09:18:40Z","published":"2023-06-27T09:18:40Z","title":"Nano1D: An accurate Computer Vision model for segmentation and analysis\n  of low-dimensional objects","summary":"  Microscopy images are usually analyzed qualitatively or manually and there is\na need for autonomous quantitative analysis of objects. In this paper, we\npresent a physics-based computational model for accurate segmentation and\ngeometrical analysis of one-dimensional irregular and deformable objects from\nmicroscopy images. This model, named Nano1D, has four steps of preprocessing,\nsegmentation, separating overlapped objects and geometrical measurements. The\nmodel is tested on Ag nanowires, and successfully segments and analyzes their\ngeometrical characteristics including length, width and distributions. The\nfunction of the algorithm is not undermined by the size, number, density,\norientation and overlapping of objects in images. The main strength of the\nmodel is shown to be its ability to segment and analyze overlapping objects\nsuccessfully with more than 99% accuracy, while current machine learning and\ncomputational models suffer from inaccuracy and inability to segment\noverlapping objects. Nano1D can analyze one-dimensional (1D) nanoparticles\nincluding nanowires, nanotubes, nanorods in addition to other 1D features of\nmicrostructures like microcracks, dislocations etc.\n","authors":["Ehsan Moradpur-Tari","Sergei Vlassov","Sven Oras","Mart Ernits","Elyad Damerchi","Andreas Kyritsakis","Veronika Zadin"],"pdf_url":"https://arxiv.org/pdf/2306.15319v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15318v1","updated":"2023-06-27T09:15:52Z","published":"2023-06-27T09:15:52Z","title":"Towards predicting Pedestrian Evacuation Time and Density from\n  Floorplans using a Vision Transformer","summary":"  Conventional pedestrian simulators are inevitable tools in the design process\nof a building, as they enable project engineers to prevent overcrowding\nsituations and plan escape routes for evacuation. However, simulation runtime\nand the multiple cumbersome steps in generating simulation results are\npotential bottlenecks during the building design process. Data-driven\napproaches have demonstrated their capability to outperform conventional\nmethods in speed while delivering similar or even better results across many\ndisciplines. In this work, we present a deep learning-based approach based on a\nVision Transformer to predict density heatmaps over time and total evacuation\ntime from a given floorplan. Specifically, due to limited availability of\npublic datasets, we implement a parametric data generation pipeline including a\nconventional simulator. This enables us to build a large synthetic dataset that\nwe use to train our architecture. Furthermore, we seamlessly integrate our\nmodel into a BIM-authoring tool to generate simulation results instantly and\nautomatically.\n","authors":["Patrick Berggold","Stavros Nousias","Rohit K. Dubey","André Borrmann"],"pdf_url":"https://arxiv.org/pdf/2306.15318v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14824v2","updated":"2023-06-27T09:11:34Z","published":"2023-06-26T16:32:47Z","title":"Kosmos-2: Grounding Multimodal Large Language Models to the World","summary":"  We introduce Kosmos-2, a Multimodal Large Language Model (MLLM), enabling new\ncapabilities of perceiving object descriptions (e.g., bounding boxes) and\ngrounding text to the visual world. Specifically, we represent refer\nexpressions as links in Markdown, i.e., ``[text span](bounding boxes)'', where\nobject descriptions are sequences of location tokens. Together with multimodal\ncorpora, we construct large-scale data of grounded image-text pairs (called\nGrIT) to train the model. In addition to the existing capabilities of MLLMs\n(e.g., perceiving general modalities, following instructions, and performing\nin-context learning), Kosmos-2 integrates the grounding capability into\ndownstream applications. We evaluate Kosmos-2 on a wide range of tasks,\nincluding (i) multimodal grounding, such as referring expression comprehension,\nand phrase grounding, (ii) multimodal referring, such as referring expression\ngeneration, (iii) perception-language tasks, and (iv) language understanding\nand generation. This work lays out the foundation for the development of\nEmbodiment AI and sheds light on the big convergence of language, multimodal\nperception, action, and world modeling, which is a key step toward artificial\ngeneral intelligence. Data, demo, and pretrained models are available at\nhttps://aka.ms/kosmos-2.\n","authors":["Zhiliang Peng","Wenhui Wang","Li Dong","Yaru Hao","Shaohan Huang","Shuming Ma","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2306.14824v2.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2306.14221v2","updated":"2023-06-27T09:03:32Z","published":"2023-06-25T12:05:46Z","title":"Feature Adversarial Distillation for Point Cloud Classification","summary":"  Due to the point cloud's irregular and unordered geometry structure,\nconventional knowledge distillation technology lost a lot of information when\ndirectly used on point cloud tasks. In this paper, we propose Feature\nAdversarial Distillation (FAD) method, a generic adversarial loss function in\npoint cloud distillation, to reduce loss during knowledge transfer. In the\nfeature extraction stage, the features extracted by the teacher are used as the\ndiscriminator, and the students continuously generate new features in the\ntraining stage. The feature of the student is obtained by attacking the\nfeedback from the teacher and getting a score to judge whether the student has\nlearned the knowledge well or not. In experiments on standard point cloud\nclassification on ModelNet40 and ScanObjectNN datasets, our method reduced the\ninformation loss of knowledge transfer in distillation in 40x model compression\nwhile maintaining competitive performance.\n","authors":["YuXing Lee","Wei Wu"],"pdf_url":"https://arxiv.org/pdf/2306.14221v2.pdf","comment":"Accepted to ICIP2023"},{"id":"http://arxiv.org/abs/2306.12010v2","updated":"2023-06-27T09:02:02Z","published":"2023-06-21T04:21:40Z","title":"Spiking Neural Network for Ultra-low-latency and High-accurate Object\n  Detection","summary":"  Spiking Neural Networks (SNNs) have garnered widespread interest for their\nenergy efficiency and brain-inspired event-driven properties. While recent\nmethods like Spiking-YOLO have expanded the SNNs to more challenging object\ndetection tasks, they often suffer from high latency and low detection\naccuracy, making them difficult to deploy on latency sensitive mobile\nplatforms. Furthermore, the conversion method from Artificial Neural Networks\n(ANNs) to SNNs is hard to maintain the complete structure of the ANNs,\nresulting in poor feature representation and high conversion errors. To address\nthese challenges, we propose two methods: timesteps compression and\nspike-time-dependent integrated (STDI) coding. The former reduces the timesteps\nrequired in ANN-SNN conversion by compressing information, while the latter\nsets a time-varying threshold to expand the information holding capacity. We\nalso present a SNN-based ultra-low latency and high accurate object detection\nmodel (SUHD) that achieves state-of-the-art performance on nontrivial datasets\nlike PASCAL VOC and MS COCO, with about remarkable 750x fewer timesteps and 30%\nmean average precision (mAP) improvement, compared to the Spiking-YOLO on MS\nCOCO datasets. To the best of our knowledge, SUHD is the deepest spike-based\nobject detection model to date that achieves ultra low timesteps to complete\nthe lossless conversion.\n","authors":["Jinye Qu","Zeyu Gao","Tielin Zhang","Yanfeng Lu","Huajin Tang","Hong Qiao"],"pdf_url":"https://arxiv.org/pdf/2306.12010v2.pdf","comment":"14 pages, 10 figures"},{"id":"http://arxiv.org/abs/2305.14243v3","updated":"2023-06-27T09:00:35Z","published":"2023-05-23T16:58:55Z","title":"Training Transitive and Commutative Multimodal Transformers with LoReTTa","summary":"  Collecting a multimodal dataset with two paired modalities A and B or B and C\nis difficult in practice. Obtaining a dataset with three aligned modalities A,\nB, and C is even more challenging. For example, some public medical datasets\nhave only genetic sequences and microscopic images for one patient, and only\ngenetic sequences and radiological images for another - but no dataset includes\nboth microscopic and radiological images for the same patient. This makes it\ndifficult to integrate and combine all modalities into a large pre-trained\nneural network. We introduce LoReTTa (Linking mOdalities with a tRansitive and\ncommutativE pre-Training sTrAtegy) to address this understudied problem. Our\nself-supervised framework combines causal masked modeling with the rules of\ncommutativity and transitivity to transition within and between different\nmodalities. Thus, it can model the relation A -> C with A -> B -> C. Given a\ndataset containing only the disjoint combinations (A, B) and (B, C), we show\nthat a transformer pre-trained with LoReTTa can handle any modality combination\nat inference time, including the never-seen pair (A, C) and the triplet (A, B,\nC). We evaluate our approach on a multimodal dataset derived from MNIST\ncontaining speech, vision, and language, as well as a real-world medical\ndataset containing mRNA, miRNA, and RPPA samples from TCGA. Compared to\ntraditional pre-training methods, we observe up to a 100-point reduction in\nperplexity for autoregressive generation tasks and up to a 15% improvement in\nclassification accuracy for previously unseen modality pairs during the\npre-training phase.\n","authors":["Manuel Tran","Amal Lahiani","Yashin Dicente Cid","Fabian J. Theis","Tingying Peng","Eldad Klaiman"],"pdf_url":"https://arxiv.org/pdf/2305.14243v3.pdf","comment":"Typo corrected and appendix added"},{"id":"http://arxiv.org/abs/2306.15308v1","updated":"2023-06-27T08:55:20Z","published":"2023-06-27T08:55:20Z","title":"Machine learning in solar physics","summary":"  The application of machine learning in solar physics has the potential to\ngreatly enhance our understanding of the complex processes that take place in\nthe atmosphere of the Sun. By using techniques such as deep learning, we are\nnow in the position to analyze large amounts of data from solar observations\nand identify patterns and trends that may not have been apparent using\ntraditional methods. This can help us improve our understanding of explosive\nevents like solar flares, which can have a strong effect on the Earth\nenvironment. Predicting hazardous events on Earth becomes crucial for our\ntechnological society. Machine learning can also improve our understanding of\nthe inner workings of the sun itself by allowing us to go deeper into the data\nand to propose more complex models to explain them. Additionally, the use of\nmachine learning can help to automate the analysis of solar data, reducing the\nneed for manual labor and increasing the efficiency of research in this field.\n","authors":["A. Asensio Ramos","M. C. M. Cheung","I. Chifu","R. Gafeira"],"pdf_url":"https://arxiv.org/pdf/2306.15308v1.pdf","comment":"100 pages, 13 figures, 286 references, accepted for publication as a\n  Living Review in Solar Physics (LRSP)"},{"id":"http://arxiv.org/abs/2306.15306v1","updated":"2023-06-27T08:49:31Z","published":"2023-06-27T08:49:31Z","title":"Transferability Metrics for Object Detection","summary":"  Transfer learning aims to make the most of existing pre-trained models to\nachieve better performance on a new task in limited data scenarios. However, it\nis unclear which models will perform best on which task, and it is\nprohibitively expensive to try all possible combinations. If transferability\nestimation offers a computation-efficient approach to evaluate the\ngeneralisation ability of models, prior works focused exclusively on\nclassification settings. To overcome this limitation, we extend transferability\nmetrics to object detection. We design a simple method to extract local\nfeatures corresponding to each object within an image using ROI-Align. We also\nintroduce TLogME, a transferability metric taking into account the coordinates\nregression task. In our experiments, we compare TLogME to state-of-the-art\nmetrics in the estimation of transfer performance of the Faster-RCNN object\ndetector. We evaluate all metrics on source and target selection tasks, for\nreal and synthetic datasets, and with different backbone architectures. We show\nthat, over different tasks, TLogME using the local extraction method provides a\nrobust correlation with transfer performance and outperforms other\ntransferability metrics on local and global level features.\n","authors":["Louis Fouquet","Simona Maggio","Léo Dreyfus-Schmidt"],"pdf_url":"https://arxiv.org/pdf/2306.15306v1.pdf","comment":"12 pages, 4 Figures"},{"id":"http://arxiv.org/abs/2305.13935v3","updated":"2023-06-27T08:45:06Z","published":"2023-05-08T08:38:22Z","title":"Distribution-aware Fairness Test Generation","summary":"  This work addresses how to validate group fairness in image recognition\nsoftware. We propose a distribution-aware fairness testing approach (called\nDistroFair) that systematically exposes class-level fairness violations in\nimage classifiers via a synergistic combination of out-of-distribution (OOD)\ntesting and semantic-preserving image mutation. DistroFair automatically learns\nthe distribution (e.g., number/orientation) of objects in a set of images. Then\nit systematically mutates objects in the images to become OOD using three\nsemantic-preserving image mutations -- object deletion, object insertion and\nobject rotation. We evaluate DistroFair using two well-known datasets\n(CityScapes and MS-COCO) and three major, commercial image recognition software\n(namely, Amazon Rekognition, Google Cloud Vision and Azure Computer Vision).\nResults show that about 21% of images generated by DistroFair reveal\nclass-level fairness violations using either ground truth or metamorphic\noracles. DistroFair is up to 2.3x more effective than two main baselines, i.e.,\n(a) an approach which focuses on generating images only within the distribution\n(ID) and (b) fairness analysis using only the original image dataset. We\nfurther observed that DistroFair is efficient, it generates 460 images per\nhour, on average. Finally, we evaluate the semantic validity of our approach\nvia a user study with 81 participants, using 30 real images and 30\ncorresponding mutated images generated by DistroFair. We found that images\ngenerated by DistroFair are 80% as realistic as real-world images.\n","authors":["Sai Sathiesh Rajan","Ezekiel Soremekun","Yves Le Traon","Sudipta Chattopadhyay"],"pdf_url":"https://arxiv.org/pdf/2305.13935v3.pdf","comment":"Paper submitted for review to TSE; 15 pages, 4 figures, LaTex;\n  Results and methodology have been updated"},{"id":"http://arxiv.org/abs/2306.09245v2","updated":"2023-06-27T08:31:27Z","published":"2023-06-02T08:37:14Z","title":"Image encryption for Offshore wind power based on 2D-LCLM and Zhou Yi\n  Eight Trigrams","summary":"  Offshore wind power is an important part of the new power system, due to the\ncomplex and changing situation at ocean, its normal operation and maintenance\ncannot be done without information such as images, therefore, it is especially\nimportant to transmit the correct image in the process of information\ntransmission. In this paper, we propose a new encryption algorithm for offshore\nwind power based on two-dimensional lagged complex logistic mapping (2D-LCLM)\nand Zhou Yi Eight Trigrams. Firstly, the initial value of the 2D-LCLM is\nconstructed by the Sha-256 to associate the 2D-LCLM with the plaintext.\nSecondly, a new encryption rule is proposed from the Zhou Yi Eight Trigrams to\nobfuscate the pixel values and generate the round key. Then, 2D-LCLM is\ncombined with the Zigzag to form an S-box. Finally, the simulation experiment\nof the algorithm is accomplished. The experimental results demonstrate that the\nalgorithm can resistant common attacks and has prefect encryption performance.\n","authors":["Lei Kou","Jinbo Wu","Fangfang Zhang","Peng Ji","Wende Ke","Junhe Wan","Hailin Liu","Yang Li","Quande Yuan"],"pdf_url":"https://arxiv.org/pdf/2306.09245v2.pdf","comment":"accepted by Int. J. of Bio-Inspired Computation"},{"id":"http://arxiv.org/abs/2306.15278v1","updated":"2023-06-27T08:10:20Z","published":"2023-06-27T08:10:20Z","title":"Hierarchical Dense Correlation Distillation for Few-Shot\n  Segmentation-Extended Abstract","summary":"  Few-shot semantic segmentation (FSS) aims to form class-agnostic models\nsegmenting unseen classes with only a handful of annotations. Previous methods\nlimited to the semantic feature and prototype representation suffer from coarse\nsegmentation granularity and train-set overfitting. In this work, we design\nHierarchically Decoupled Matching Network (HDMNet) mining pixel-level support\ncorrelation based on the transformer architecture. The self-attention modules\nare used to assist in establishing hierarchical dense features, as a means to\naccomplish the cascade matching between query and support features. Moreover,\nwe propose a matching module to reduce train-set overfitting and introduce\ncorrelation distillation leveraging semantic correspondence from coarse\nresolution to boost fine-grained segmentation. Our method performs decently in\nexperiments. We achieve 50.0% mIoU on COCO dataset one-shot setting and 56.0%\non five-shot segmentation, respectively. The code will be available on the\nproject website. We hope our work can benefit broader industrial applications\nwhere novel classes with limited annotations are required to be decently\nidentified.\n","authors":["Bohao Peng","Zhuotao Tian","Xiaoyang Wu","Chengyao Wang","Shu Liu","Jingyong Su","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2306.15278v1.pdf","comment":"Accepted to CVPR 2023 VISION Workshop, Oral. The extended abstract of\n  Hierarchical Dense Correlation Distillation for Few-Shot Segmentation. arXiv\n  admin note: substantial text overlap with arXiv:2303.14652"},{"id":"http://arxiv.org/abs/2306.14538v2","updated":"2023-06-27T07:51:16Z","published":"2023-06-26T09:21:13Z","title":"Learnable Differencing Center for Nighttime Depth Perception","summary":"  Depth completion is the task of recovering dense depth maps from sparse ones,\nusually with the help of color images. Existing image-guided methods perform\nwell on daytime depth perception self-driving benchmarks, but struggle in\nnighttime scenarios with poor visibility and complex illumination. To address\nthese challenges, we propose a simple yet effective framework called LDCNet.\nOur key idea is to use Recurrent Inter-Convolution Differencing (RICD) and\nIllumination-Affinitive Intra-Convolution Differencing (IAICD) to enhance the\nnighttime color images and reduce the negative effects of the varying\nillumination, respectively. RICD explicitly estimates global illumination by\ndifferencing two convolutions with different kernels, treating the\nsmall-kernel-convolution feature as the center of the large-kernel-convolution\nfeature in a new perspective. IAICD softly alleviates local relative light\nintensity by differencing a single convolution, where the center is dynamically\naggregated based on neighboring pixels and the estimated illumination map in\nRICD. On both nighttime depth completion and depth estimation tasks, extensive\nexperiments demonstrate the effectiveness of our LDCNet, reaching the state of\nthe art.\n","authors":["Zhiqiang Yan","Yupeng Zheng","Kun Wang","Xiang Li","Zhenyu Zhang","Shuo Chen","Jun Li","Jian Yang"],"pdf_url":"https://arxiv.org/pdf/2306.14538v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2305.11686v2","updated":"2023-06-27T07:50:51Z","published":"2023-05-19T14:08:15Z","title":"Domain Adaptive Sim-to-Real Segmentation of Oropharyngeal Organs Towards\n  Robot-assisted Intubation","summary":"  Robotic-assisted tracheal intubation requires the robot to distinguish\nanatomical features like an experienced physician using deep-learning\ntechniques. However, real datasets of oropharyngeal organs are limited due to\npatient privacy issues, making it challenging to train deep-learning models for\naccurate image segmentation. We hereby consider generating a new data modality\nthrough a virtual environment to assist the training process. Specifically,\nthis work introduces a virtual dataset generated by the Simulation Open\nFramework Architecture (SOFA) framework to overcome the limited availability of\nactual endoscopic images. We also propose a domain adaptive Sim-to-Real method\nfor oropharyngeal organ image segmentation, which employs an image blending\nstrategy called IoU-Ranking Blend (IRB) and style-transfer techniques to\naddress discrepancies between datasets. Experimental results demonstrate the\nsuperior performance of the proposed approach with domain adaptive models,\nimproving segmentation accuracy and training stability. In the practical\napplication, the trained segmentation model holds great promise for\nrobot-assisted intubation surgery and intelligent surgical navigation.\n","authors":["Guankun Wang","Tian-Ao Ren","Jiewen Lai","Long Bai","Hongliang Ren"],"pdf_url":"https://arxiv.org/pdf/2305.11686v2.pdf","comment":"Extended abstract in IEEE ICRA 2023 Workshop (New Evolutions in\n  Surgical Robotics: Embracing Multimodal Imaging Guidance, Intelligence, and\n  Bio-inspired Mechanisms)"},{"id":"http://arxiv.org/abs/2306.15255v1","updated":"2023-06-27T07:27:52Z","published":"2023-06-27T07:27:52Z","title":"GroundNLQ @ Ego4D Natural Language Queries Challenge 2023","summary":"  In this report, we present our champion solution for Ego4D Natural Language\nQueries (NLQ) Challenge in CVPR 2023. Essentially, to accurately ground in a\nvideo, an effective egocentric feature extractor and a powerful grounding model\nare required. Motivated by this, we leverage a two-stage pre-training strategy\nto train egocentric feature extractors and the grounding model on video\nnarrations, and further fine-tune the model on annotated data. In addition, we\nintroduce a novel grounding model GroundNLQ, which employs a multi-modal\nmulti-scale grounding module for effective video and text fusion and various\ntemporal intervals, especially for long videos. On the blind test set,\nGroundNLQ achieves 25.67 and 18.18 for R1@IoU=0.3 and R1@IoU=0.5, respectively,\nand surpasses all other teams by a noticeable margin. Our code will be released\nat\\url{https://github.com/houzhijian/GroundNLQ}.\n","authors":["Zhijian Hou","Lei Ji","Difei Gao","Wanjun Zhong","Kun Yan","Chao Li","Wing-Kwong Chan","Chong-Wah Ngo","Nan Duan","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2306.15255v1.pdf","comment":"5 pages, 2 figures, 4 tables, the champion solution for Ego4D Natural\n  Language Queries Challenge in CVPR 2023"},{"id":"http://arxiv.org/abs/2306.15244v1","updated":"2023-06-27T06:57:08Z","published":"2023-06-27T06:57:08Z","title":"Cutting-Edge Techniques for Depth Map Super-Resolution","summary":"  To overcome hardware limitations in commercially available depth sensors\nwhich result in low-resolution depth maps, depth map super-resolution (DMSR) is\na practical and valuable computer vision task. DMSR requires upscaling a\nlow-resolution (LR) depth map into a high-resolution (HR) space. Joint image\nfiltering for DMSR has been applied using spatially-invariant and\nspatially-variant convolutional neural network (CNN) approaches. In this\nproject, we propose a novel joint image filtering DMSR algorithm using a Swin\ntransformer architecture. Furthermore, we introduce a Nonlinear Activation Free\n(NAF) network based on a conventional CNN model used in cutting-edge image\nrestoration applications and compare the performance of the techniques. The\nproposed algorithms are validated through numerical studies and visual examples\ndemonstrating improvements to state-of-the-art performance while maintaining\ncompetitive computation time for noisy depth map super-resolution.\n","authors":["Ryan Peterson","Josiah Smith"],"pdf_url":"https://arxiv.org/pdf/2306.15244v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.08803v3","updated":"2023-06-27T06:51:25Z","published":"2022-04-19T10:51:00Z","title":"An Energy-Based Prior for Generative Saliency","summary":"  We propose a novel generative saliency prediction framework that adopts an\ninformative energy-based model as a prior distribution. The energy-based prior\nmodel is defined on the latent space of a saliency generator network that\ngenerates the saliency map based on a continuous latent variables and an\nobserved image. Both the parameters of saliency generator and the energy-based\nprior are jointly trained via Markov chain Monte Carlo-based maximum likelihood\nestimation, in which the sampling from the intractable posterior and prior\ndistributions of the latent variables are performed by Langevin dynamics. With\nthe generative saliency model, we can obtain a pixel-wise uncertainty map from\nan image, indicating model confidence in the saliency prediction. Different\nfrom existing generative models, which define the prior distribution of the\nlatent variables as a simple isotropic Gaussian distribution, our model uses an\nenergy-based informative prior which can be more expressive in capturing the\nlatent space of the data. With the informative energy-based prior, we extend\nthe Gaussian distribution assumption of generative models to achieve a more\nrepresentative distribution of the latent space, leading to more reliable\nuncertainty estimation. We apply the proposed frameworks to both RGB and RGB-D\nsalient object detection tasks with both transformer and convolutional neural\nnetwork backbones. We further propose an adversarial learning algorithm and a\nvariational inference algorithm as alternatives to train the proposed\ngenerative framework. Experimental results show that our generative saliency\nmodel with an energy-based prior can achieve not only accurate saliency\npredictions but also reliable uncertainty maps that are consistent with human\nperception. Results and code are available at\n\\url{https://github.com/JingZhang617/EBMGSOD}.\n","authors":["Jing Zhang","Jianwen Xie","Nick Barnes","Ping Li"],"pdf_url":"https://arxiv.org/pdf/2204.08803v3.pdf","comment":"Accepted to IEEE Transactions on Pattern Analysis and Machine\n  Intelligence 2023. arXiv admin note: text overlap with arXiv:2112.13528"},{"id":"http://arxiv.org/abs/2306.15242v1","updated":"2023-06-27T06:49:40Z","published":"2023-06-27T06:49:40Z","title":"SPDER: Semiperiodic Damping-Enabled Object Representation","summary":"  We present a neural network architecture designed to naturally learn a\npositional embedding and overcome the spectral bias towards lower frequencies\nfaced by conventional implicit neural representation networks. Our proposed\narchitecture, SPDER, is a simple MLP that uses an activation function composed\nof a sinusoidal multiplied by a sublinear function, called the damping\nfunction. The sinusoidal enables the network to automatically learn the\npositional embedding of an input coordinate while the damping passes on the\nactual coordinate value by preventing it from being projected down to within a\nfinite range of values. Our results indicate that SPDERs speed up training by\n10x and converge to losses 1,500-50,000x lower than that of the\nstate-of-the-art for image representation. SPDER is also state-of-the-art in\naudio representation. The superior representation capability allows SPDER to\nalso excel on multiple downstream tasks such as image super-resolution and\nvideo frame interpolation. We provide intuition as to why SPDER significantly\nimproves fitting compared to that of other INR methods while requiring no\nhyperparameter tuning or preprocessing.\n","authors":["Kathan Shah","Chawin Sitawarin"],"pdf_url":"https://arxiv.org/pdf/2306.15242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05745v3","updated":"2023-06-27T06:36:42Z","published":"2023-03-10T07:08:25Z","title":"Multi-site, Multi-domain Airway Tree Modeling (ATM'22): A Public\n  Benchmark for Pulmonary Airway Segmentation","summary":"  Open international challenges are becoming the de facto standard for\nassessing computer vision and image analysis algorithms. In recent years, new\nmethods have extended the reach of pulmonary airway segmentation that is closer\nto the limit of image resolution. Since EXACT'09 pulmonary airway segmentation,\nlimited effort has been directed to quantitative comparison of newly emerged\nalgorithms driven by the maturity of deep learning based approaches and\nclinical drive for resolving finer details of distal airways for early\nintervention of pulmonary diseases. Thus far, public annotated datasets are\nextremely limited, hindering the development of data-driven methods and\ndetailed performance evaluation of new algorithms. To provide a benchmark for\nthe medical imaging community, we organized the Multi-site, Multi-domain Airway\nTree Modeling (ATM'22), which was held as an official challenge event during\nthe MICCAI 2022 conference. ATM'22 provides large-scale CT scans with detailed\npulmonary airway annotation, including 500 CT scans (300 for training, 50 for\nvalidation, and 150 for testing). The dataset was collected from different\nsites and it further included a portion of noisy COVID-19 CTs with ground-glass\nopacity and consolidation. Twenty-three teams participated in the entire phase\nof the challenge and the algorithms for the top ten teams are reviewed in this\npaper. Quantitative and qualitative results revealed that deep learning models\nembedded with the topological continuity enhancement achieved superior\nperformance in general. ATM'22 challenge holds as an open-call design, the\ntraining data and the gold standard evaluation are available upon successful\nregistration via its homepage.\n","authors":["Minghui Zhang","Yangqian Wu","Hanxiao Zhang","Yulei Qin","Hao Zheng","Wen Tang","Corey Arnold","Chenhao Pei","Pengxin Yu","Yang Nan","Guang Yang","Simon Walsh","Dominic C. Marshall","Matthieu Komorowski","Puyang Wang","Dazhou Guo","Dakai Jin","Ya'nan Wu","Shuiqing Zhao","Runsheng Chang","Boyu Zhang","Xing Lv","Abdul Qayyum","Moona Mazher","Qi Su","Yonghuang Wu","Ying'ao Liu","Yufei Zhu","Jiancheng Yang","Ashkan Pakzad","Bojidar Rangelov","Raul San Jose Estepar","Carlos Cano Espinosa","Jiayuan Sun","Guang-Zhong Yang","Yun Gu"],"pdf_url":"https://arxiv.org/pdf/2303.05745v3.pdf","comment":"32 pages, 16 figures. Homepage: https://atm22.grand-challenge.org/.\n  Submitted"},{"id":"http://arxiv.org/abs/2305.02074v2","updated":"2023-06-27T06:27:49Z","published":"2023-05-03T12:25:01Z","title":"A Vision Transformer Approach for Efficient Near-Field Irregular SAR\n  Super-Resolution","summary":"  In this paper, we develop a novel super-resolution algorithm for near-field\nsynthetic-aperture radar (SAR) under irregular scanning geometries. As\nfifth-generation (5G) millimeter-wave (mmWave) devices are becoming\nincreasingly affordable and available, high-resolution SAR imaging is feasible\nfor end-user applications and non-laboratory environments. Emerging\napplications such freehand imaging, wherein a handheld radar is scanned\nthroughout space by a user, unmanned aerial vehicle (UAV) imaging, and\nautomotive SAR face several unique challenges for high-resolution imaging.\nFirst, recovering a SAR image requires knowledge of the array positions\nthroughout the scan. While recent work has introduced camera-based positioning\nsystems capable of adequately estimating the position, recovering the algorithm\nefficiently is a requirement to enable edge and Internet of Things (IoT)\ntechnologies. Efficient algorithms for non-cooperative near-field SAR sampling\nhave been explored in recent work, but suffer image defocusing under position\nestimation error and can only produce medium-fidelity images. In this paper, we\nintroduce a mobile-friend vision transformer (ViT) architecture to address\nposition estimation error and perform SAR image super-resolution (SR) under\nirregular sampling geometries. The proposed algorithm, Mobile-SRViT, is the\nfirst to employ a ViT approach for SAR image enhancement and is validated in\nsimulation and via empirical studies.\n","authors":["Josiah Smith","Yusef Alimam","Geetika Vedula","Murat Torlak"],"pdf_url":"https://arxiv.org/pdf/2305.02074v2.pdf","comment":"Accepted to Proc. IEEE WMCS"},{"id":"http://arxiv.org/abs/2306.15218v1","updated":"2023-06-27T05:43:16Z","published":"2023-06-27T05:43:16Z","title":"Semantic Segmentation Using Super Resolution Technique as Pre-Processing","summary":"  Combining high-level and low-level visual tasks is a common technique in the\nfield of computer vision. This work integrates the technique of image super\nresolution to semantic segmentation for document image binarization. It\ndemonstrates that using image super-resolution as a preprocessing step can\neffectively enhance the results and performance of semantic segmentation.\n","authors":["Chih-Chia Chen","Wei-Han Chen","Jen-Shiun Chiang","Chun-Tse Chien","Tingkai Chang"],"pdf_url":"https://arxiv.org/pdf/2306.15218v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12686v2","updated":"2023-06-27T05:35:24Z","published":"2023-01-30T06:27:48Z","title":"GibbsDDRM: A Partially Collapsed Gibbs Sampler for Solving Blind Inverse\n  Problems with Denoising Diffusion Restoration","summary":"  Pre-trained diffusion models have been successfully used as priors in a\nvariety of linear inverse problems, where the goal is to reconstruct a signal\nfrom noisy linear measurements. However, existing approaches require knowledge\nof the linear operator. In this paper, we propose GibbsDDRM, an extension of\nDenoising Diffusion Restoration Models (DDRM) to a blind setting in which the\nlinear measurement operator is unknown. GibbsDDRM constructs a joint\ndistribution of the data, measurements, and linear operator by using a\npre-trained diffusion model for the data prior, and it solves the problem by\nposterior sampling with an efficient variant of a Gibbs sampler. The proposed\nmethod is problem-agnostic, meaning that a pre-trained diffusion model can be\napplied to various inverse problems without fine-tuning. In experiments, it\nachieved high performance on both blind image deblurring and vocal\ndereverberation tasks, despite the use of simple generic priors for the\nunderlying linear operators.\n","authors":["Naoki Murata","Koichi Saito","Chieh-Hsin Lai","Yuhta Takida","Toshimitsu Uesaka","Yuki Mitsufuji","Stefano Ermon"],"pdf_url":"https://arxiv.org/pdf/2301.12686v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15203v1","updated":"2023-06-27T04:50:58Z","published":"2023-06-27T04:50:58Z","title":"Unsupervised Polychromatic Neural Representation for CT Metal Artifact\n  Reduction","summary":"  Emerging neural reconstruction techniques based on tomography (e.g., NeRF,\nNeAT, and NeRP) have started showing unique capabilities in medical imaging. In\nthis work, we present a novel Polychromatic neural representation (Polyner) to\ntackle the challenging problem of CT imaging when metallic implants exist\nwithin the human body. The artifacts arise from the drastic variation of\nmetal's attenuation coefficients at various energy levels of the X-ray\nspectrum, leading to a nonlinear metal effect in CT measurements.\nReconstructing CT images from metal-affected measurements hence poses a\ncomplicated nonlinear inverse problem where empirical models adopted in\nprevious metal artifact reduction (MAR) approaches lead to signal loss and\nstrongly aliased reconstructions. Polyner instead models the MAR problem from a\nnonlinear inverse problem perspective. Specifically, we first derive a\npolychromatic forward model to accurately simulate the nonlinear CT acquisition\nprocess. Then, we incorporate our forward model into the implicit neural\nrepresentation to accomplish reconstruction. Lastly, we adopt a regularizer to\npreserve the physical properties of the CT images across different energy\nlevels while effectively constraining the solution space. Our Polyner is an\nunsupervised method and does not require any external training data.\nExperimenting with multiple datasets shows that our Polyner achieves comparable\nor better performance than supervised methods on in-domain datasets while\ndemonstrating significant performance improvements on out-of-domain datasets.\nTo the best of our knowledge, our Polyner is the first unsupervised MAR method\nthat outperforms its supervised counterparts.\n","authors":["Qing Wu","Lixuan Chen","Ce Wang","Hongjiang Wei","S. Kevin Zhou","Jingyi Yu","Yuyao Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.15203v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2306.15195v1","updated":"2023-06-27T04:31:52Z","published":"2023-06-27T04:31:52Z","title":"Shikra: Unleashing Multimodal LLM's Referential Dialogue Magic","summary":"  In human conversations, individuals can indicate relevant regions within a\nscene while addressing others. In turn, the other person can then respond by\nreferring to specific regions if necessary. This natural referential ability in\ndialogue remains absent in current Multimodal Large Language Models (MLLMs). To\nfill this gap, this paper proposes an MLLM called Shikra, which can handle\nspatial coordinate inputs and outputs in natural language. Its architecture\nconsists of a vision encoder, an alignment layer, and a LLM. It is designed to\nbe straightforward and simple, without the need for extra vocabularies,\nposition encoder, pre-/post-detection modules, or external plug-in models. All\ninputs and outputs are in natural language form. Referential dialogue is a\nsuperset of various vision-language (VL) tasks. Shikra can naturally handle\nlocation-related tasks like REC and PointQA, as well as conventional VL tasks\nsuch as Image Captioning and VQA. Experimental results showcase Shikra's\npromising performance. Furthermore, it enables numerous exciting applications,\nlike providing mentioned objects' coordinates in chains of thoughts and\ncomparing user-pointed regions similarities. Our code and model are accessed at\nhttps://github.com/shikras/shikra.\n","authors":["Keqin Chen","Zhao Zhang","Weili Zeng","Richong Zhang","Feng Zhu","Rui Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.15195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15189v1","updated":"2023-06-27T04:14:50Z","published":"2023-06-27T04:14:50Z","title":"FBA-Net: Foreground and Background Aware Contrastive Learning for\n  Semi-Supervised Atrium Segmentation","summary":"  Medical image segmentation of gadolinium enhancement magnetic resonance\nimaging (GE MRI) is an important task in clinical applications. However, manual\nannotation is time-consuming and requires specialized expertise.\nSemi-supervised segmentation methods that leverage both labeled and unlabeled\ndata have shown promise, with contrastive learning emerging as a particularly\neffective approach. In this paper, we propose a contrastive learning strategy\nof foreground and background representations for semi-supervised 3D medical\nimage segmentation (FBA-Net). Specifically, we leverage the contrastive loss to\nlearn representations of both the foreground and background regions in the\nimages. By training the network to distinguish between foreground-background\npairs, we aim to learn a representation that can effectively capture the\nanatomical structures of interest. Experiments on three medical segmentation\ndatasets demonstrate state-of-the-art performance. Notably, our method achieves\na Dice score of 91.31% with only 20% labeled data, which is remarkably close to\nthe 91.62% score of the fully supervised method that uses 100% labeled data on\nthe left atrium dataset. Our framework has the potential to advance the field\nof semi-supervised 3D medical image segmentation and enable more efficient and\naccurate analysis of medical images with a limited amount of annotated labels.\n","authors":["Yunsung Chung","Chanho Lim","Chao Huang","Nassir Marrouche","Jihun Hamm"],"pdf_url":"https://arxiv.org/pdf/2306.15189v1.pdf","comment":"11 pages, 2 figures"},{"id":"http://arxiv.org/abs/2306.15172v1","updated":"2023-06-27T03:12:58Z","published":"2023-06-27T03:12:58Z","title":"Delving into Crispness: Guided Label Refinement for Crisp Edge Detection","summary":"  Learning-based edge detection usually suffers from predicting thick edges.\nThrough extensive quantitative study with a new edge crispness measure, we find\nthat noisy human-labeled edges are the main cause of thick predictions. Based\non this observation, we advocate that more attention should be paid on label\nquality than on model design to achieve crisp edge detection. To this end, we\npropose an effective Canny-guided refinement of human-labeled edges whose\nresult can be used to train crisp edge detectors. Essentially, it seeks for a\nsubset of over-detected Canny edges that best align human labels. We show that\nseveral existing edge detectors can be turned into a crisp edge detector\nthrough training on our refined edge maps. Experiments demonstrate that deep\nmodels trained with refined edges achieve significant performance boost of\ncrispness from 17.4% to 30.6%. With the PiDiNet backbone, our method improves\nODS and OIS by 12.2% and 12.6% on the Multicue dataset, respectively, without\nrelying on non-maximal suppression. We further conduct experiments and show the\nsuperiority of our crisp edge detection for optical flow estimation and image\nsegmentation.\n","authors":["Yunfan Ye","Renjiao Yi","Zhirui Gao","Zhiping Cai","Kai Xu"],"pdf_url":"https://arxiv.org/pdf/2306.15172v1.pdf","comment":"Accepted by TIP"},{"id":"http://arxiv.org/abs/2306.15162v1","updated":"2023-06-27T02:44:07Z","published":"2023-06-27T02:44:07Z","title":"YouTube-ASL: A Large-Scale, Open-Domain American Sign Language-English\n  Parallel Corpus","summary":"  Machine learning for sign languages is bottlenecked by data. In this paper,\nwe present YouTube-ASL, a large-scale, open-domain corpus of American Sign\nLanguage (ASL) videos and accompanying English captions drawn from YouTube.\nWith ~1000 hours of videos and >2500 unique signers, YouTube-ASL is ~3x as\nlarge and has ~10x as many unique signers as the largest prior ASL dataset. We\ntrain baseline models for ASL to English translation on YouTube-ASL and\nevaluate them on How2Sign, where we achieve a new finetuned state of the art of\n12.39 BLEU and, for the first time, report zero-shot results.\n","authors":["David Uthus","Garrett Tanzer","Manfred Georg"],"pdf_url":"https://arxiv.org/pdf/2306.15162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15142v1","updated":"2023-06-27T02:03:46Z","published":"2023-06-27T02:03:46Z","title":"Efficient and Accurate Scene Text Detection with Low-Rank Approximation\n  Network","summary":"  Recently, regression-based methods, which predict parameter curves for\nlocalizing texts, are popular in scene text detection. However, these methods\nstruggle to balance concise structure and fast post-processing, and the\nexisting parameter curves are still not ideal for modeling arbitrary-shaped\ntexts, leading to a challenge in balancing speed and accuracy. To tackle these\nchallenges, we firstly propose a dual matching scheme for positive samples,\nwhich accelerates inference speed through sparse matching scheme and\naccelerates model convergence through dense matching scheme. Then, we propose a\nnovel text contour representation method based on low-rank approximation by\nexploiting the shape correlation between different text contours, which is\ncomplete, compact, simplicity and robustness. Based on these designs, we\nimplement an efficient and accurate arbitrary-shaped text detector, named\nLRANet. Extensive experiments are conducted on three challenging datasets,\nwhich demonstrate the accuracy and efficiency of our LRANet over\nstate-of-the-art methods. The code will be released soon.\n","authors":["Yuchen Su"],"pdf_url":"https://arxiv.org/pdf/2306.15142v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.14718v4","updated":"2023-06-27T01:43:10Z","published":"2022-06-29T15:36:02Z","title":"LViT: Language meets Vision Transformer in Medical Image Segmentation","summary":"  Deep learning has been widely used in medical image segmentation and other\naspects. However, the performance of existing medical image segmentation models\nhas been limited by the challenge of obtaining sufficient high-quality labeled\ndata due to the prohibitive data annotation cost. To alleviate this limitation,\nwe propose a new text-augmented medical image segmentation model LViT (Language\nmeets Vision Transformer). In our LViT model, medical text annotation is\nincorporated to compensate for the quality deficiency in image data. In\naddition, the text information can guide to generate pseudo labels of improved\nquality in the semi-supervised learning. We also propose an Exponential Pseudo\nlabel Iteration mechanism (EPI) to help the Pixel-Level Attention Module (PLAM)\npreserve local image features in semi-supervised LViT setting. In our model, LV\n(Language-Vision) loss is designed to supervise the training of unlabeled\nimages using text information directly. For evaluation, we construct three\nmultimodal medical segmentation datasets (image + text) containing X-rays and\nCT images. Experimental results show that our proposed LViT has superior\nsegmentation performance in both fully-supervised and semi-supervised setting.\nThe code and datasets are available at https://github.com/HUANGLIZI/LViT.\n","authors":["Zihan Li","Yunxiang Li","Qingde Li","Puyang Wang","Dazhou Guo","Le Lu","Dakai Jin","You Zhang","Qingqi Hong"],"pdf_url":"https://arxiv.org/pdf/2206.14718v4.pdf","comment":"Accepted by IEEE Transactions on Medical Imaging (TMI)"},{"id":"http://arxiv.org/abs/2304.01508v3","updated":"2023-06-27T01:06:25Z","published":"2023-04-04T03:36:14Z","title":"EPVT: Environment-aware Prompt Vision Transformer for Domain\n  Generalization in Skin Lesion Recognition","summary":"  Skin lesion recognition using deep learning has made remarkable progress, and\nthere is an increasing need for deploying these systems in real-world\nscenarios. However, recent research has revealed that deep neural networks for\nskin lesion recognition may overly depend on disease-irrelevant image artifacts\n(i.e., dark corners, dense hairs), leading to poor generalization in unseen\nenvironments. To address this issue, we propose a novel domain generalization\nmethod called EPVT, which involves embedding prompts into the vision\ntransformer to collaboratively learn knowledge from diverse domains.\nConcretely, EPVT leverages a set of domain prompts, each of which plays as a\ndomain expert, to capture domain-specific knowledge; and a shared prompt for\ngeneral knowledge over the entire dataset. To facilitate knowledge sharing and\nthe interaction of different prompts, we introduce a domain prompt generator\nthat enables low-rank multiplicative updates between domain prompts and the\nshared prompt. A domain mixup strategy is additionally devised to reduce the\nco-occurring artifacts in each domain, which allows for more flexible decision\nmargins and mitigates the issue of incorrectly assigned domain labels.\nExperiments on four out-of-distribution datasets and six different biased ISIC\ndatasets demonstrate the superior generalization ability of EPVT in skin lesion\nrecognition across various environments. Code is avaliable at\nhttps://github.com/SiyuanYan1/EPVT.\n","authors":["Siyuan Yan","Chi Liu","Zhen Yu","Lie Ju","Dwarikanath Mahapatrainst","Victoria Mar","Monika Janda","Peter Soyer","Zongyuan Ge"],"pdf_url":"https://arxiv.org/pdf/2304.01508v3.pdf","comment":"Accepted by MICCAI 2023"},{"id":"http://arxiv.org/abs/2306.15128v1","updated":"2023-06-27T00:40:12Z","published":"2023-06-27T00:40:12Z","title":"MIMIC: Masked Image Modeling with Image Correspondences","summary":"  Many pixelwise dense prediction tasks-depth estimation and semantic\nsegmentation in computer vision today rely on pretrained image representations.\nTherefore, curating effective pretraining datasets is vital. Unfortunately, the\neffective pretraining datasets are those with multi-view scenes and have only\nbeen curated using annotated 3D meshes, point clouds, and camera parameters\nfrom simulated environments. We propose a dataset-curation mechanism that does\nnot require any annotations. We mine two datasets: MIMIC-1M with 1.3M and\nMIMIC-3M with 3.1M multi-view image pairs from open-sourced video datasets and\nfrom synthetic 3D environments. We train multiple self-supervised models with\ndifferent masked image modeling objectives to showcase the following findings:\nRepresentations trained on MIMIC-3M outperform those mined using annotations on\nmultiple downstream tasks, including depth estimation, semantic segmentation,\nsurface normals, and pose estimation. They also outperform representations that\nare frozen and when downstream training data is limited to few-shot. Larger\ndataset (MIMIC-3M) significantly improves performance, which is promising since\nour curation method can arbitrarily scale to produce even larger datasets.\nMIMIC code, dataset, and pretrained models are open-sourced at\nhttps://github.com/RAIVNLab/MIMIC.\n","authors":["Kalyani Marathe","Mahtab Bigverdi","Nishat Khan","Tuhin Kundu","Aniruddha Kembhavi","Linda G. Shapiro","Ranjay Krishna"],"pdf_url":"https://arxiv.org/pdf/2306.15128v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.11861v2","updated":"2023-06-27T00:19:14Z","published":"2023-02-23T08:59:56Z","title":"Out-of-Domain Robustness via Targeted Augmentations","summary":"  Models trained on one set of domains often suffer performance drops on unseen\ndomains, e.g., when wildlife monitoring models are deployed in new camera\nlocations. In this work, we study principles for designing data augmentations\nfor out-of-domain (OOD) generalization. In particular, we focus on real-world\nscenarios in which some domain-dependent features are robust, i.e., some\nfeatures that vary across domains are predictive OOD. For example, in the\nwildlife monitoring application above, image backgrounds vary across camera\nlocations but indicate habitat type, which helps predict the species of\nphotographed animals. Motivated by theoretical analysis on a linear setting, we\npropose targeted augmentations, which selectively randomize spurious\ndomain-dependent features while preserving robust ones. We prove that targeted\naugmentations improve OOD performance, allowing models to generalize better\nwith fewer domains. In contrast, existing approaches such as generic\naugmentations, which fail to randomize domain-dependent features, and\ndomain-invariant augmentations, which randomize all domain-dependent features,\nboth perform poorly OOD. In experiments on three real-world datasets, we show\nthat targeted augmentations set new states-of-the-art for OOD performance by\n3.2-15.2%.\n","authors":["Irena Gao","Shiori Sagawa","Pang Wei Koh","Tatsunori Hashimoto","Percy Liang"],"pdf_url":"https://arxiv.org/pdf/2302.11861v2.pdf","comment":"ICML camera ready"},{"id":"http://arxiv.org/abs/2207.06965v4","updated":"2023-06-27T00:10:00Z","published":"2022-07-14T14:49:32Z","title":"AutoMerge: A Framework for Map Assembling and Smoothing in City-scale\n  Environments","summary":"  We present AutoMerge, a LiDAR data processing framework for assembling a\nlarge number of map segments into a complete map. Traditional large-scale map\nmerging methods are fragile to incorrect data associations, and are primarily\nlimited to working only offline. AutoMerge utilizes multi-perspective fusion\nand adaptive loop closure detection for accurate data associations, and it uses\nincremental merging to assemble large maps from individual trajectory segments\ngiven in random order and with no initial estimations. Furthermore, after\nassembling the segments, AutoMerge performs fine matching and pose-graph\noptimization to globally smooth the merged map. We demonstrate AutoMerge on\nboth city-scale merging (120km) and campus-scale repeated merging (4.5km x 8).\nThe experiments show that AutoMerge (i) surpasses the second- and third- best\nmethods by 14% and 24% recall in segment retrieval, (ii) achieves comparable 3D\nmapping accuracy for 120 km large-scale map assembly, (iii) and it is robust to\ntemporally-spaced revisits. To the best of our knowledge, AutoMerge is the\nfirst mapping approach that can merge hundreds of kilometers of individual\nsegments without the aid of GPS.\n","authors":["Peng Yin","Haowen Lai","Shiqi Zhao","Ruohai Ge","Ji Zhang","Howie Choset","Sebastian Scherer"],"pdf_url":"https://arxiv.org/pdf/2207.06965v4.pdf","comment":"19 pages, 20 figures, IEEE Transactions on Robotics (T-RO) 2023"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2306.10946v2","updated":"2023-06-27T17:14:02Z","published":"2023-06-19T14:06:28Z","title":"Tourist Attractions Recommendation based on Attention Knowledge Graph\n  Convolution Network","summary":"  The recommendation algorithm based on knowledge graphs is at a relatively\nmature stage. However, there are still some problems in the recommendation of\nspecific areas. For example, in the tourism field, selecting suitable tourist\nattraction attributes process is complicated as the recommendation basis for\ntourist attractions. In this paper, we propose the improved Attention Knowledge\nGraph Convolution Network model, named (Att-KGCN), which automatically\ndiscovers the neighboring entities of the target scenic spot semantically. The\nattention layer aggregates relatively similar locations and represents them\nwith an adjacent vector. Then, according to the tourist's preferred choices,\nthe model predicts the probability of similar spots as a recommendation system.\nA knowledge graph dataset of tourist attractions used based on tourism data on\nSocotra Island-Yemen. Through experiments, it is verified that the Attention\nKnowledge Graph Convolution Network has a good effect on the recommendation of\ntourist attractions and can make more recommendations for tourists' choices.\n","authors":["Ahmad A. Mubarak","Afifa Kahled"],"pdf_url":"https://arxiv.org/pdf/2306.10946v2.pdf","comment":"I have incorrect information"},{"id":"http://arxiv.org/abs/2306.15541v1","updated":"2023-06-27T15:10:57Z","published":"2023-06-27T15:10:57Z","title":"Unleashing the Power of User Reviews: Exploring Airline Choices at\n  Catania Airport, Italy","summary":"  This study aims to investigate the possible relationship between the\nmechanisms of social influence and the choice of airline, through the use of\nnew tools, with the aim of understanding whether they can contribute to a\nbetter understanding of the factors influencing the decisions of consumers in\nthe aviation sector. We have chosen to extract user reviews from well-known\nplatforms: Trustpilot, Google, and Twitter. By combining web scraping\ntechniques, we have been able to collect a comprehensive dataset comprising a\nwide range of user opinions, feedback, and ratings. We then refined the BERT\nmodel to focus on insightful sentiment in the context of airline reviews.\nThrough our analysis, we observed an intriguing trend of average negative\nsentiment scores across various airlines, giving us deeper insight into the\ndynamics between airlines and helping us identify key partnerships, popular\nroutes, and airlines that play a central role in the aeronautical ecosystem of\nCatania airport during the specified period. Our investigation led us to find\nthat, despite an airline having received prestigious awards as a low-cost\nleader in Europe for two consecutive years 2021 and 2022, the \"Catanese\" user\ntends to suffer the dominant position of other companies. Understanding the\nimpact of positive reviews and leveraging sentiment analysis can help airlines\nimprove their reputation, attract more customers, and ultimately gain a\ncompetitive edge in the marketplace.\n","authors":["Vincenzo Miracula","Antonio Picone"],"pdf_url":"https://arxiv.org/pdf/2306.15541v1.pdf","comment":"arXiv admin note: text overlap with arXiv:1311.3475 by other authors"},{"id":"http://arxiv.org/abs/2305.05257v3","updated":"2023-06-27T13:58:48Z","published":"2023-05-09T08:26:48Z","title":"Survey of Federated Learning Models for Spatial-Temporal Mobility\n  Applications","summary":"  Federated learning involves training statistical models over edge devices\nsuch as mobile phones such that the training data is kept local. Federated\nLearning (FL) can serve as an ideal candidate for training spatial temporal\nmodels that rely on heterogeneous and potentially massive numbers of\nparticipants while preserving the privacy of highly sensitive location data.\nHowever, there are unique challenges involved with transitioning existing\nspatial temporal models to decentralized learning. In this survey paper, we\nreview the existing literature that has proposed FL-based models for predicting\nhuman mobility, traffic prediction, community detection, location-based\nrecommendation systems, and other spatial-temporal tasks. We describe the\nmetrics and datasets these works have been using and create a baseline of these\napproaches in comparison to the centralized settings. Finally, we discuss the\nchallenges of applying spatial-temporal models in a decentralized setting and\nby highlighting the gaps in the literature we provide a road map and\nopportunities for the research community.\n","authors":["Yacine Belal","Sonia Ben Mokhtar","Hamed Haddadi","Jaron Wang","Afra Mashhadi"],"pdf_url":"https://arxiv.org/pdf/2305.05257v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.07980v2","updated":"2023-06-27T13:33:43Z","published":"2023-05-30T14:39:32Z","title":"Dark Web Activity Classification Using Deep Learning","summary":"  In contemporary times, people rely heavily on the internet and search engines\nto obtain information, either directly or indirectly. However, the information\naccessible to users constitutes merely 4% of the overall information present on\nthe internet, which is commonly known as the surface web. The remaining\ninformation that eludes search engines is called the deep web. The deep web\nencompasses deliberately hidden information, such as personal email accounts,\nsocial media accounts, online banking accounts, and other confidential data.\nThe deep web contains several critical applications, including databases of\nuniversities, banks, and civil records, which are off-limits and illegal to\naccess. The dark web is a subset of the deep web that provides an ideal\nplatform for criminals and smugglers to engage in illicit activities, such as\ndrug trafficking, weapon smuggling, selling stolen bank cards, and money\nlaundering. In this article, we propose a search engine that employs deep\nlearning to detect the titles of activities on the dark web. We focus on five\ncategories of activities, including drug trading, weapon trading, selling\nstolen bank cards, selling fake IDs, and selling illegal currencies. Our aim is\nto extract relevant images from websites with a \".onion\" extension and identify\nthe titles of websites without images by extracting keywords from the text of\nthe pages. Furthermore, we introduce a dataset of images called Darkoob, which\nwe have gathered and used to evaluate our proposed method. Our experimental\nresults demonstrate that the proposed method achieves an accuracy rate of 94%\non the test dataset.\n","authors":["Ali Fayzi","Mohammad Fayzi","Kourosh Ahmadi"],"pdf_url":"https://arxiv.org/pdf/2306.07980v2.pdf","comment":"11 pages , 16 figures , 2 tables , New Dataset For DarkWeb Activity\n  Classification"},{"id":"http://arxiv.org/abs/1706.00178v4","updated":"2023-06-27T12:42:15Z","published":"2017-06-01T06:46:30Z","title":"Network Capacity Bound for Personalized PageRank in Multimodal Networks","summary":"  In a former paper the concept of Bipartite PageRank was introduced and a\ntheorem on the limit of authority flowing between nodes for personalized\nPageRank has been generalized. In this paper we want to extend those results to\nmultimodal networks. In particular we deal with a hypergraph type that may be\nused for describing multimodal network where a hyperlink connects nodes from\neach of the modalities. We introduce a generalisation of PageRank for such\ngraphs and define the respective random walk model that can be used for\ncomputations. We state and prove theorems on the limit of outflow of authority\nfor cases where individual modalities have identical and distinct damping\nfactors.\n","authors":["M. A. Kłopotek","S. T. Wierzchoń","R. A. Kłopotek"],"pdf_url":"https://arxiv.org/pdf/1706.00178v4.pdf","comment":"21 pages. 2 tables, 30 bibliography positions"},{"id":"http://arxiv.org/abs/2306.11182v2","updated":"2023-06-27T10:37:34Z","published":"2023-06-19T22:12:37Z","title":"Co-design Hardware and Algorithm for Vector Search","summary":"  Vector search has emerged as the foundation for large-scale information\nretrieval and machine learning systems, with search engines like Google and\nBing processing tens of thousands of queries per second on petabyte-scale\ndocument datasets by evaluating vector similarities between encoded query texts\nand web documents. As performance demands for vector search systems surge,\naccelerated hardware offers a promising solution in the post-Moore's Law era.\nWe introduce \\textit{FANNS}, an end-to-end and scalable vector search framework\non FPGAs. Given a user-provided recall requirement on a dataset and a hardware\nresource budget, \\textit{FANNS} automatically co-designs hardware and\nalgorithm, subsequently generating the corresponding accelerator. The framework\nalso supports scale-out by incorporating a hardware TCP/IP stack in the\naccelerator. \\textit{FANNS} attains up to 23.0$\\times$ and 37.2$\\times$ speedup\ncompared to FPGA and CPU baselines, respectively, and demonstrates superior\nscalability to GPUs, achieving 5.5$\\times$ and 7.6$\\times$ speedup in median\nand 95\\textsuperscript{th} percentile (P95) latency within an eight-accelerator\nconfiguration. The remarkable performance of \\textit{FANNS} lays a robust\ngroundwork for future FPGA integration in data centers and AI supercomputers.\n","authors":["Wenqi Jiang","Shigang Li","Yu Zhu","Johannes de Fine Licht","Zhenhao He","Runbin Shi","Cedric Renggli","Shuai Zhang","Theodoros Rekatsinas","Torsten Hoefler","Gustavo Alonso"],"pdf_url":"https://arxiv.org/pdf/2306.11182v2.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2306.05817v3","updated":"2023-06-27T06:03:57Z","published":"2023-06-09T11:31:50Z","title":"How Can Recommender Systems Benefit from Large Language Models: A Survey","summary":"  Recommender systems (RS) play important roles to match users' information\nneeds for Internet applications. In natural language processing (NLP) domains,\nlarge language model (LLM) has shown astonishing emergent abilities (e.g.,\ninstruction following, reasoning), thus giving rise to the promising research\ndirection of adapting LLM to RS for performance enhancements and user\nexperience improvements. In this paper, we conduct a comprehensive survey on\nthis research direction from an application-oriented view. We first summarize\nexisting research works from two orthogonal perspectives: where and how to\nadapt LLM to RS. For the \"WHERE\" question, we discuss the roles that LLM could\nplay in different stages of the recommendation pipeline, i.e., feature\nengineering, feature encoder, scoring/ranking function, and pipeline\ncontroller. For the \"HOW\" question, we investigate the training and inference\nstrategies, resulting in two fine-grained taxonomy criteria, i.e., whether to\ntune LLMs or not, and whether to involve conventional recommendation model\n(CRM) for inference. Detailed analysis and general development trajectories are\nprovided for both questions, respectively. Then, we highlight key challenges in\nadapting LLM to RS from three aspects, i.e., efficiency, effectiveness, and\nethics. Finally, we summarize the survey and discuss the future prospects. We\nalso actively maintain a GitHub repository for papers and other related\nresources in this rising direction:\nhttps://github.com/CHIANGEL/Awesome-LLM-for-RecSys.\n","authors":["Jianghao Lin","Xinyi Dai","Yunjia Xi","Weiwen Liu","Bo Chen","Xiangyang Li","Chenxu Zhu","Huifeng Guo","Yong Yu","Ruiming Tang","Weinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.05817v3.pdf","comment":"15 pages; 3 figures; summarization table in appendix;"},{"id":"http://arxiv.org/abs/2306.15222v1","updated":"2023-06-27T05:48:14Z","published":"2023-06-27T05:48:14Z","title":"Learning to Rank in Generative Retrieval","summary":"  Generative retrieval is a promising new paradigm in text retrieval that\ngenerates identifier strings of relevant passages as the retrieval target. This\nparadigm leverages powerful generation models and represents a new paradigm\ndistinct from traditional learning-to-rank methods. However, despite its rapid\ndevelopment, current generative retrieval methods are still limited. They\ntypically rely on a heuristic function to transform predicted identifiers into\na passage rank list, which creates a gap between the learning objective of\ngenerative retrieval and the desired passage ranking target. Moreover, the\ninherent exposure bias problem of text generation also persists in generative\nretrieval. To address these issues, we propose a novel framework, called LTRGR,\nthat combines generative retrieval with the classical learning-to-rank\nparadigm. Our approach involves training an autoregressive model using a\npassage rank loss, which directly optimizes the autoregressive model toward the\noptimal passage ranking. This framework only requires an additional training\nstep to enhance current generative retrieval systems and does not add any\nburden to the inference stage. We conducted experiments on three public\ndatasets, and our results demonstrate that LTRGR achieves state-of-the-art\nperformance among generative retrieval methods, indicating its effectiveness\nand robustness.\n","authors":["Yongqi Li","Nan Yang","Liang Wang","Furu Wei","Wenjie Li"],"pdf_url":"https://arxiv.org/pdf/2306.15222v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2006.10909v2","updated":"2023-06-27T05:32:12Z","published":"2020-06-19T00:43:23Z","title":"Neural Topic Modeling with Continual Lifelong Learning","summary":"  Lifelong learning has recently attracted attention in building machine\nlearning systems that continually accumulate and transfer knowledge to help\nfuture learning. Unsupervised topic modeling has been popularly used to\ndiscover topics from document collections. However, the application of topic\nmodeling is challenging due to data sparsity, e.g., in a small collection of\n(short) documents and thus, generate incoherent topics and sub-optimal document\nrepresentations. To address the problem, we propose a lifelong learning\nframework for neural topic modeling that can continuously process streams of\ndocument collections, accumulate topics and guide future topic modeling tasks\nby knowledge transfer from several sources to better deal with the sparse data.\nIn the lifelong process, we particularly investigate jointly: (1) sharing\ngenerative homologies (latent topics) over lifetime to transfer prior\nknowledge, and (2) minimizing catastrophic forgetting to retain the past\nlearning via novel selective data augmentation, co-training and topic\nregularization approaches. Given a stream of document collections, we apply the\nproposed Lifelong Neural Topic Modeling (LNTM) framework in modeling three\nsparse document collections as future tasks and demonstrate improved\nperformance quantified by perplexity, topic coherence and information retrieval\ntask.\n","authors":["Pankaj Gupta","Yatin Chaudhary","Thomas Runkler","Hinrich Schütze"],"pdf_url":"https://arxiv.org/pdf/2006.10909v2.pdf","comment":"Accepted at ICML2020 (13 pages, 11 figures, 9 tables)"},{"id":"http://arxiv.org/abs/2302.01115v3","updated":"2023-06-27T03:50:53Z","published":"2023-02-02T14:15:36Z","title":"PEPNet: Parameter and Embedding Personalized Network for Infusing with\n  Personalized Prior Information","summary":"  With the increase of content pages and interactive buttons in online services\nsuch as online-shopping and video-watching websites, industrial-scale\nrecommender systems face challenges in multi-domain and multi-task\nrecommendations. The core of multi-task and multi-domain recommendation is to\naccurately capture user interests in multiple scenarios given multiple user\nbehaviors. In this paper, we propose a plug-and-play \\textit{\\textbf{P}arameter\nand \\textbf{E}mbedding \\textbf{P}ersonalized \\textbf{Net}work\n(\\textbf{PEPNet})} for multi-domain and multi-task recommendation. PEPNet takes\npersonalized prior information as input and dynamically scales the bottom-level\nEmbedding and top-level DNN hidden units through gate mechanisms.\n\\textit{Embedding Personalized Network (EPNet)} performs personalized selection\non Embedding to fuse features with different importance for different users in\nmultiple domains. \\textit{Parameter Personalized Network (PPNet)} executes\npersonalized modification on DNN parameters to balance targets with different\nsparsity for different users in multiple tasks. We have made a series of\nspecial engineering optimizations combining the Kuaishou training framework and\nthe online deployment environment. By infusing personalized selection of\nEmbedding and personalized modification of DNN parameters, PEPNet tailored to\nthe interests of each individual obtains significant performance gains, with\nonline improvements exceeding 1\\% in multiple task metrics across multiple\ndomains. We have deployed PEPNet in Kuaishou apps, serving over 300 million\nusers every day.\n","authors":["Jianxin Chang","Chenbin Zhang","Yiqun Hui","Dewei Leng","Yanan Niu","Yang Song","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2302.01115v3.pdf","comment":"Accepted by KDD 2023"},{"id":"http://arxiv.org/abs/2302.02352v2","updated":"2023-06-27T03:29:32Z","published":"2023-02-05T10:04:45Z","title":"TWIN: TWo-stage Interest Network for Lifelong User Behavior Modeling in\n  CTR Prediction at Kuaishou","summary":"  Life-long user behavior modeling, i.e., extracting a user's hidden interests\nfrom rich historical behaviors in months or even years, plays a central role in\nmodern CTR prediction systems. Conventional algorithms mostly follow two\ncascading stages: a simple General Search Unit (GSU) for fast and coarse search\nover tens of thousands of long-term behaviors and an Exact Search Unit (ESU)\nfor effective Target Attention (TA) over the small number of finalists from\nGSU. Although efficient, existing algorithms mostly suffer from a crucial\nlimitation: the \\textit{inconsistent} target-behavior relevance metrics between\nGSU and ESU. As a result, their GSU usually misses highly relevant behaviors\nbut retrieves ones considered irrelevant by ESU. In such case, the TA in ESU,\nno matter how attention is allocated, mostly deviates from the real user\ninterests and thus degrades the overall CTR prediction accuracy. To address\nsuch inconsistency, we propose \\textbf{TWo-stage Interest Network (TWIN)},\nwhere our Consistency-Preserved GSU (CP-GSU) adopts the identical\ntarget-behavior relevance metric as the TA in ESU, making the two stages twins.\nSpecifically, to break TA's computational bottleneck and extend it from ESU to\nGSU, or namely from behavior length $10^2$ to length $10^4-10^5$, we build a\nnovel attention mechanism by behavior feature splitting. For the video inherent\nfeatures of a behavior, we calculate their linear projection by efficient\npre-computing \\& caching strategies. And for the user-item cross features, we\ncompress each into a one-dimentional bias term in the attention score\ncalculation to save the computational cost. The consistency between two stages,\ntogether with the effective TA-based relevance metric in CP-GSU, contributes to\nsignificant performance gain in CTR prediction.\n","authors":["Jianxin Chang","Chenbin Zhang","Zhiyi Fu","Xiaoxue Zang","Lin Guan","Jing Lu","Yiqun Hui","Dewei Leng","Yanan Niu","Yang Song","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2302.02352v2.pdf","comment":"Accepted by KDD 2023"},{"id":"http://arxiv.org/abs/2305.12837v3","updated":"2023-06-27T03:06:16Z","published":"2023-05-22T09:00:34Z","title":"Capturing Conversion Rate Fluctuation during Sales Promotions: A Novel\n  Historical Data Reuse Approach","summary":"  Conversion rate (CVR) prediction is one of the core components in online\nrecommender systems, and various approaches have been proposed to obtain\naccurate and well-calibrated CVR estimation. However, we observe that a\nwell-trained CVR prediction model often performs sub-optimally during sales\npromotions. This can be largely ascribed to the problem of the data\ndistribution shift, in which the conventional methods no longer work. To this\nend, we seek to develop alternative modeling techniques for CVR prediction.\nObserving similar purchase patterns across different promotions, we propose\nreusing the historical promotion data to capture the promotional conversion\npatterns. Herein, we propose a novel \\textbf{H}istorical \\textbf{D}ata\n\\textbf{R}euse (\\textbf{HDR}) approach that first retrieves historically\nsimilar promotion data and then fine-tunes the CVR prediction model with the\nacquired data for better adaptation to the promotion mode. HDR consists of\nthree components: an automated data retrieval module that seeks similar data\nfrom historical promotions, a distribution shift correction module that\nre-weights the retrieved data for better aligning with the target promotion,\nand a TransBlock module that quickly fine-tunes the original model for better\nadaptation to the promotion mode. Experiments conducted with real-world data\ndemonstrate the effectiveness of HDR, as it improves both ranking and\ncalibration metrics to a large extent. HDR has also been deployed on the\ndisplay advertising system in Alibaba, bringing a lift of $9\\%$ RPM and $16\\%$\nCVR during Double 11 Sales in 2022.\n","authors":["Zhangming Chan","Yu Zhang","Shuguang Han","Yong Bai","Xiang-Rong Sheng","Siyuan Lou","Jiacen Hu","Baolin Liu","Yuning Jiang","Jian Xu","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2305.12837v3.pdf","comment":"Accepted at KDD 2023. This work has already been deployed on the\n  display advertising system in Alibaba, bringing substantial economic gains"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2306.15661v1","updated":"2023-06-27T17:55:31Z","published":"2023-06-27T17:55:31Z","title":"Enhancing Representation Learning on High-Dimensional, Small-Size\n  Tabular Data: A Divide and Conquer Method with Ensembled VAEs","summary":"  Variational Autoencoders and their many variants have displayed impressive\nability to perform dimensionality reduction, often achieving state-of-the-art\nperformance. Many current methods however, struggle to learn good\nrepresentations in High Dimensional, Low Sample Size (HDLSS) tasks, which is an\ninherently challenging setting. We address this challenge by using an ensemble\nof lightweight VAEs to learn posteriors over subsets of the feature-space,\nwhich get aggregated into a joint posterior in a novel divide-and-conquer\napproach. Specifically, we present an alternative factorisation of the joint\nposterior that induces a form of implicit data augmentation that yields greater\nsample efficiency. Through a series of experiments on eight real-world\ndatasets, we show that our method learns better latent representations in HDLSS\nsettings, which leads to higher accuracy in a downstream classification task.\nFurthermore, we verify that our approach has a positive effect on\ndisentanglement and achieves a lower estimated Total Correlation on learnt\nrepresentations. Finally, we show that our approach is robust to partial\nfeatures at inference, exhibiting little performance degradation even with most\nfeatures missing.\n","authors":["Navindu Leelarathna","Andrei Margeloiu","Mateja Jamnik","Nikola Simidjievski"],"pdf_url":"https://arxiv.org/pdf/2306.15661v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15656v1","updated":"2023-06-27T17:50:26Z","published":"2023-06-27T17:50:26Z","title":"SparseOptimizer: Sparsify Language Models through Moreau-Yosida\n  Regularization and Accelerate through Compiler Co-design","summary":"  This paper introduces SparseOptimizer, a novel deep learning optimizer that\nexploits Moreau-Yosida regularization to naturally induce sparsity in large\nlanguage models such as BERT, ALBERT and GPT. Key to the design of\nSparseOptimizer is an embedded shrinkage operator, which imparts sparsity\ndirectly within the optimization process. This operator, backed by a sound\ntheoretical framework, includes an analytical solution, thereby reinforcing the\noptimizer's robustness and efficacy. Crucially, SparseOptimizer's plug-and-play\nfunctionality eradicates the need for code modifications, making it a\nuniversally adaptable tool for a wide array of large language models. Empirical\nevaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2\nconfirm that SparseBERT and SparseALBERT, when sparsified using\nSparseOptimizer, achieve performance comparable to their dense counterparts,\nBERT and ALBERT, while significantly reducing their parameter count. Further,\nthis work proposes an innovative optimizer-compiler co-design strategy,\ndemonstrating the potential of inference acceleration (\\textbf{3.37x},\n\\textbf{6.30x}, and \\textbf{7.15x} in comparison with Pytorch, TensorFlow, and\nLLVM generic compile, respectively) in SparseBERT when paired with an\nappropriately designed compiler. This study represents a significant step\nforward in the evolution of efficient, scalable, and high-performing large\nlanguage models, setting a precedent for future exploration and optimization in\nthis domain. The SparseOptimizer code and SparseALBERT model will be made\navailable upon paper acceptance.\n","authors":["Fu-Ming Guo"],"pdf_url":"https://arxiv.org/pdf/2306.15656v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15651v1","updated":"2023-06-27T17:47:12Z","published":"2023-06-27T17:47:12Z","title":"Dental CLAIRES: Contrastive LAnguage Image REtrieval Search for Dental\n  Research","summary":"  Learning about diagnostic features and related clinical information from\ndental radiographs is important for dental research. However, the lack of\nexpert-annotated data and convenient search tools poses challenges. Our primary\nobjective is to design a search tool that uses a user's query for oral-related\nresearch. The proposed framework, Contrastive LAnguage Image REtrieval Search\nfor dental research, Dental CLAIRES, utilizes periapical radiographs and\nassociated clinical details such as periodontal diagnosis, demographic\ninformation to retrieve the best-matched images based on the text query. We\napplied a contrastive representation learning method to find images described\nby the user's text by maximizing the similarity score of positive pairs (true\npairs) and minimizing the score of negative pairs (random pairs). Our model\nachieved a hit@3 ratio of 96% and a Mean Reciprocal Rank (MRR) of 0.82. We also\ndesigned a graphical user interface that allows researchers to verify the\nmodel's performance with interactions.\n","authors":["Tanjida Kabir","Luyao Chen","Muhammad F Walji","Luca Giancardo","Xiaoqian Jiang","Shayan Shams"],"pdf_url":"https://arxiv.org/pdf/2306.15651v1.pdf","comment":"10 pages, 7 figures, 4 tables"},{"id":"http://arxiv.org/abs/2306.15649v1","updated":"2023-06-27T17:43:18Z","published":"2023-06-27T17:43:18Z","title":"Effective resistance in metric spaces","summary":"  Effective resistance (ER) is an attractive way to interrogate the structure\nof graphs. It is an alternative to computing the eigenvectors of the graph\nLaplacian.\n  One attractive application of ER is to point clouds, i.e. graphs whose\nvertices correspond to IID samples from a distribution over a metric space.\nUnfortunately, it was shown that the ER between any two points converges to a\ntrivial quantity that holds no information about the graph's structure as the\nsize of the sample increases to infinity.\n  In this study, we show that this trivial solution can be circumvented by\nconsidering a region-based ER between pairs of small regions rather than pairs\nof points and by scaling the edge weights appropriately with respect to the\nunderlying density in each region. By keeping the regions fixed, we show\nanalytically that the region-based ER converges to a non-trivial limit as the\nnumber of points increases to infinity. Namely the ER on a metric space. We\nsupport our theoretical findings with numerical experiments.\n","authors":["Robi Bhattacharjee","Alexander Cloninger","Yoav Freund","Andreas Oslandsbotn"],"pdf_url":"https://arxiv.org/pdf/2306.15649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15636v1","updated":"2023-06-27T17:26:23Z","published":"2023-06-27T17:26:23Z","title":"On the Usefulness of Synthetic Tabular Data Generation","summary":"  Despite recent advances in synthetic data generation, the scientific\ncommunity still lacks a unified consensus on its usefulness. It is commonly\nbelieved that synthetic data can be used for both data exchange and boosting\nmachine learning (ML) training. Privacy-preserving synthetic data generation\ncan accelerate data exchange for downstream tasks, but there is not enough\nevidence to show how or why synthetic data can boost ML training. In this\nstudy, we benchmarked ML performance using synthetic tabular data for four use\ncases: data sharing, data augmentation, class balancing, and data\nsummarization. We observed marginal improvements for the balancing use case on\nsome datasets. However, we conclude that there is not enough evidence to claim\nthat synthetic tabular data is useful for ML training.\n","authors":["Dionysis Manousakas","Sergül Aydöre"],"pdf_url":"https://arxiv.org/pdf/2306.15636v1.pdf","comment":"Data-centric Machine Learning Research (DMLR) Workshop at the 40th\n  International Conference on Machine Learning (ICML)"},{"id":"http://arxiv.org/abs/2211.16199v3","updated":"2023-06-27T17:17:50Z","published":"2022-11-26T22:13:06Z","title":"Latent Graph Inference using Product Manifolds","summary":"  Graph Neural Networks usually rely on the assumption that the graph topology\nis available to the network as well as optimal for the downstream task. Latent\ngraph inference allows models to dynamically learn the intrinsic graph\nstructure of problems where the connectivity patterns of data may not be\ndirectly accessible. In this work, we generalize the discrete Differentiable\nGraph Module (dDGM) for latent graph learning. The original dDGM architecture\nused the Euclidean plane to encode latent features based on which the latent\ngraphs were generated. By incorporating Riemannian geometry into the model and\ngenerating more complex embedding spaces, we can improve the performance of the\nlatent graph inference system. In particular, we propose a computationally\ntractable approach to produce product manifolds of constant curvature model\nspaces that can encode latent features of varying structure. The latent\nrepresentations mapped onto the inferred product manifold are used to compute\nricher similarity measures that are leveraged by the latent graph learning\nmodel to obtain optimized latent graphs. Moreover, the curvature of the product\nmanifold is learned during training alongside the rest of the network\nparameters and based on the downstream task, rather than it being a static\nembedding space. Our novel approach is tested on a wide range of datasets, and\noutperforms the original dDGM model.\n","authors":["Haitz Sáez de Ocáriz Borde","Anees Kazi","Federico Barbero","Pietro Liò"],"pdf_url":"https://arxiv.org/pdf/2211.16199v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.10946v2","updated":"2023-06-27T17:14:02Z","published":"2023-06-19T14:06:28Z","title":"Tourist Attractions Recommendation based on Attention Knowledge Graph\n  Convolution Network","summary":"  The recommendation algorithm based on knowledge graphs is at a relatively\nmature stage. However, there are still some problems in the recommendation of\nspecific areas. For example, in the tourism field, selecting suitable tourist\nattraction attributes process is complicated as the recommendation basis for\ntourist attractions. In this paper, we propose the improved Attention Knowledge\nGraph Convolution Network model, named (Att-KGCN), which automatically\ndiscovers the neighboring entities of the target scenic spot semantically. The\nattention layer aggregates relatively similar locations and represents them\nwith an adjacent vector. Then, according to the tourist's preferred choices,\nthe model predicts the probability of similar spots as a recommendation system.\nA knowledge graph dataset of tourist attractions used based on tourism data on\nSocotra Island-Yemen. Through experiments, it is verified that the Attention\nKnowledge Graph Convolution Network has a good effect on the recommendation of\ntourist attractions and can make more recommendations for tourists' choices.\n","authors":["Ahmad A. Mubarak","Afifa Kahled"],"pdf_url":"https://arxiv.org/pdf/2306.10946v2.pdf","comment":"I have incorrect information"},{"id":"http://arxiv.org/abs/2306.15632v1","updated":"2023-06-27T17:13:20Z","published":"2023-06-27T17:13:20Z","title":"Asynchronous Algorithmic Alignment with Cocycles","summary":"  State-of-the-art neural algorithmic reasoners make use of message passing in\ngraph neural networks (GNNs). But typical GNNs blur the distinction between the\ndefinition and invocation of the message function, forcing a node to send\nmessages to its neighbours at every layer, synchronously. When applying GNNs to\nlearn to execute dynamic programming algorithms, however, on most steps only a\nhandful of the nodes would have meaningful updates to send. One, hence, runs\nthe risk of inefficiencies by sending too much irrelevant data across the graph\n-- with many intermediate GNN steps having to learn identity functions. In this\nwork, we explicitly separate the concepts of node state update and message\nfunction invocation. With this separation, we obtain a mathematical formulation\nthat allows us to reason about asynchronous computation in both algorithms and\nneural networks.\n","authors":["Andrew Dudzik","Tamara von Glehn","Razvan Pascanu","Petar Veličković"],"pdf_url":"https://arxiv.org/pdf/2306.15632v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15630v1","updated":"2023-06-27T17:12:28Z","published":"2023-06-27T17:12:28Z","title":"Coupling parameter and particle dynamics for adaptive sampling in Neural\n  Galerkin schemes","summary":"  Training nonlinear parametrizations such as deep neural networks to\nnumerically approximate solutions of partial differential equations is often\nbased on minimizing a loss that includes the residual, which is analytically\navailable in limited settings only. At the same time, empirically estimating\nthe training loss is challenging because residuals and related quantities can\nhave high variance, especially for transport-dominated and high-dimensional\nproblems that exhibit local features such as waves and coherent structures.\nThus, estimators based on data samples from un-informed, uniform distributions\nare inefficient. This work introduces Neural Galerkin schemes that estimate the\ntraining loss with data from adaptive distributions, which are empirically\nrepresented via ensembles of particles. The ensembles are actively adapted by\nevolving the particles with dynamics coupled to the nonlinear parametrizations\nof the solution fields so that the ensembles remain informative for estimating\nthe training loss. Numerical experiments indicate that few dynamic particles\nare sufficient for obtaining accurate empirical estimates of the training loss,\neven for problems with local features and with high-dimensional spatial\ndomains.\n","authors":["Yuxiao Wen","Eric Vanden-Eijnden","Benjamin Peherstorfer"],"pdf_url":"https://arxiv.org/pdf/2306.15630v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.07446v2","updated":"2023-06-27T17:10:50Z","published":"2021-09-15T17:29:30Z","title":"When Does Translation Require Context? A Data-driven, Multilingual\n  Exploration","summary":"  Although proper handling of discourse significantly contributes to the\nquality of machine translation (MT), these improvements are not adequately\nmeasured in common translation quality metrics. Recent works in context-aware\nMT attempt to target a small set of discourse phenomena during evaluation,\nhowever not in a fully systematic way. In this paper, we develop the\nMultilingual Discourse-Aware (MuDA) benchmark, a series of taggers that\nidentify and evaluate model performance on discourse phenomena in any given\ndataset. The choice of phenomena is inspired by a novel methodology to\nsystematically identify translations requiring context. We confirm the\ndifficulty of previously studied phenomena while uncovering others that were\npreviously unaddressed. We find that common context-aware MT models make only\nmarginal improvements over context-agnostic models, which suggests these models\ndo not handle these ambiguities effectively. We release code and data for 14\nlanguage pairs to encourage the MT community to focus on accurately capturing\ndiscourse phenomena.\n","authors":["Patrick Fernandes","Kayo Yin","Emmy Liu","André F. T. Martins","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2109.07446v2.pdf","comment":"Accepted at ACL2023"},{"id":"http://arxiv.org/abs/2306.15628v1","updated":"2023-06-27T17:08:52Z","published":"2023-06-27T17:08:52Z","title":"Machine-learning based noise characterization and correction on neutral\n  atoms NISQ devices","summary":"  Neutral atoms devices represent a promising technology that uses optical\ntweezers to geometrically arrange atoms and modulated laser pulses to control\nthe quantum states. A neutral atoms Noisy Intermediate Scale Quantum (NISQ)\ndevice is developed by Pasqal with rubidium atoms that will allow to work with\nup to 100 qubits. All NISQ devices are affected by noise that have an impact on\nthe computations results. Therefore it is important to better understand and\ncharacterize the noise sources and possibly to correct them. Here, two\napproaches are proposed to characterize and correct noise parameters on neutral\natoms NISQ devices. In particular the focus is on Pasqal devices and Machine\nLearning (ML) techniques are adopted to pursue those objectives. To\ncharacterize the noise parameters, several ML models are trained, using as\ninput only the measurements of the final quantum state of the atoms, to predict\nlaser intensity fluctuation and waist, temperature and false positive and\nnegative measurement rate. Moreover, an analysis is provided with the scaling\non the number of atoms in the system and on the number of measurements used as\ninput. Also, we compare on real data the values predicted with ML with the a\npriori estimated parameters. Finally, a Reinforcement Learning (RL) framework\nis employed to design a pulse in order to correct the effect of the noise in\nthe measurements. It is expected that the analysis performed in this work will\nbe useful for a better understanding of the quantum dynamic in neutral atoms\ndevices and for the widespread adoption of this class of NISQ devices.\n","authors":["Ettore Canonici","Stefano Martina","Riccardo Mengoni","Daniele Ottaviani","Filippo Caruso"],"pdf_url":"https://arxiv.org/pdf/2306.15628v1.pdf","comment":"11 pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2306.15626v1","updated":"2023-06-27T17:05:32Z","published":"2023-06-27T17:05:32Z","title":"LeanDojo: Theorem Proving with Retrieval-Augmented Language Models","summary":"  Large language models (LLMs) have shown promise in proving formal theorems\nusing proof assistants such as Lean. However, existing methods are difficult to\nreproduce or build on, due to private code, data, and large compute\nrequirements. This has created substantial barriers to research on machine\nlearning methods for theorem proving. This paper removes these barriers by\nintroducing LeanDojo: an open-source Lean playground consisting of toolkits,\ndata, models, and benchmarks. LeanDojo extracts data from Lean and enables\ninteraction with the proof environment programmatically. It contains\nfine-grained annotations of premises in proofs, providing valuable data for\npremise selection: a key bottleneck in theorem proving. Using this data, we\ndevelop ReProver (Retrieval-Augmented Prover): the first LLM-based prover that\nis augmented with retrieval for selecting premises from a vast math library. It\nis inexpensive and needs only one GPU week of training. Our retriever leverages\nLeanDojo's program analysis capability to identify accessible premises and hard\nnegative examples, which makes retrieval much more effective. Furthermore, we\nconstruct a new benchmark consisting of 96,962 theorems and proofs extracted\nfrom Lean's math library. It features challenging data split requiring the\nprover to generalize to theorems relying on novel premises that are never used\nin training. We use this benchmark for training and evaluation, and\nexperimental results demonstrate the effectiveness of ReProver over\nnon-retrieval baselines and GPT-4. We thus provide the first set of open-source\nLLM-based theorem provers without any proprietary datasets and release it under\na permissive MIT license to facilitate further research.\n","authors":["Kaiyu Yang","Aidan M. Swope","Alex Gu","Rahul Chalamala","Peiyang Song","Shixing Yu","Saad Godil","Ryan Prenger","Anima Anandkumar"],"pdf_url":"https://arxiv.org/pdf/2306.15626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15625v1","updated":"2023-06-27T17:05:22Z","published":"2023-06-27T17:05:22Z","title":"Value-aware Importance Weighting for Off-policy Reinforcement Learning","summary":"  Importance sampling is a central idea underlying off-policy prediction in\nreinforcement learning. It provides a strategy for re-weighting samples from a\ndistribution to obtain unbiased estimates under another distribution. However,\nimportance sampling weights tend to exhibit extreme variance, often leading to\nstability issues in practice. In this work, we consider a broader class of\nimportance weights to correct samples in off-policy learning. We propose the\nuse of $\\textit{value-aware importance weights}$ which take into account the\nsample space to provide lower variance, but still unbiased, estimates under a\ntarget distribution. We derive how such weights can be computed, and detail key\nproperties of the resulting importance weights. We then extend several\nreinforcement learning prediction algorithms to the off-policy setting with\nthese weights, and evaluate them empirically.\n","authors":["Kristopher De Asis","Eric Graves","Richard S. Sutton"],"pdf_url":"https://arxiv.org/pdf/2306.15625v1.pdf","comment":"CoLLAs 2023"},{"id":"http://arxiv.org/abs/2306.15620v1","updated":"2023-06-27T16:59:15Z","published":"2023-06-27T16:59:15Z","title":"SCENEREPLICA: Benchmarking Real-World Robot Manipulation by Creating\n  Reproducible Scenes","summary":"  We present a new reproducible benchmark for evaluating robot manipulation in\nthe real world, specifically focusing on pick-and-place. Our benchmark uses the\nYCB objects, a commonly used dataset in the robotics community, to ensure that\nour results are comparable to other studies. Additionally, the benchmark is\ndesigned to be easily reproducible in the real world, making it accessible to\nresearchers and practitioners. We also provide our experimental results and\nanalyzes for model-based and model-free 6D robotic grasping on the benchmark,\nwhere representative algorithms are evaluated for object perception, grasping\nplanning, and motion planning. We believe that our benchmark will be a valuable\ntool for advancing the field of robot manipulation. By providing a standardized\nevaluation framework, researchers can more easily compare different techniques\nand algorithms, leading to faster progress in developing robot manipulation\nmethods.\n","authors":["Ninad Khargonkar","Sai Haneesh Allu","Yangxiao Lu","Jishnu Jaykumar P","Balakrishnan Prabhakaran","Yu Xiang"],"pdf_url":"https://arxiv.org/pdf/2306.15620v1.pdf","comment":"12 pages, 10 figures, Project page is available at\n  https://irvlutd.github.io/SceneReplica"},{"id":"http://arxiv.org/abs/2306.15619v1","updated":"2023-06-27T16:59:06Z","published":"2023-06-27T16:59:06Z","title":"DCID: Deep Canonical Information Decomposition","summary":"  We consider the problem of identifying the signal shared between two\none-dimensional target variables, in the presence of additional multivariate\nobservations. Canonical Correlation Analysis (CCA)-based methods have\ntraditionally been used to identify shared variables, however, they were\ndesigned for multivariate targets and only offer trivial solutions for\nunivariate cases. In the context of Multi-Task Learning (MTL), various models\nwere postulated to learn features that are sparse and shared across multiple\ntasks. However, these methods were typically evaluated by their predictive\nperformance. To the best of our knowledge, no prior studies systematically\nevaluated models in terms of correctly recovering the shared signal. Here, we\nformalize the setting of univariate shared information retrieval, and propose\nICM, an evaluation metric which can be used in the presence of ground-truth\nlabels, quantifying 3 aspects of the learned shared features. We further\npropose Deep Canonical Information Decomposition (DCID) - a simple, yet\neffective approach for learning the shared variables. We benchmark the models\non a range of scenarios on synthetic data with known ground-truths and observe\nDCID outperforming the baselines in a wide range of settings. Finally, we\ndemonstrate a real-life application of DCID on brain Magnetic Resonance Imaging\n(MRI) data, where we are able to extract more accurate predictors of changes in\nbrain regions and obesity. The code for our experiments as well as the\nsupplementary materials are available at https://github.com/alexrakowski/dcid\n","authors":["Alexander Rakowski","Christoph Lippert"],"pdf_url":"https://arxiv.org/pdf/2306.15619v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15618v1","updated":"2023-06-27T16:58:26Z","published":"2023-06-27T16:58:26Z","title":"Learning Nonautonomous Systems via Dynamic Mode Decomposition","summary":"  We present a data-driven learning approach for unknown nonautonomous\ndynamical systems with time-dependent inputs based on dynamic mode\ndecomposition (DMD). To circumvent the difficulty of approximating the\ntime-dependent Koopman operators for nonautonomous systems, a modified system\nderived from local parameterization of the external time-dependent inputs is\nemployed as an approximation to the original nonautonomous system. The modified\nsystem comprises a sequence of local parametric systems, which can be well\napproximated by a parametric surrogate model using our previously proposed\nframework for dimension reduction and interpolation in parameter space (DRIPS).\nThe offline step of DRIPS relies on DMD to build a linear surrogate model,\nendowed with reduced-order bases (ROBs), for the observables mapped from\ntraining data. Then the offline step constructs a sequence of iterative\nparametric surrogate models from interpolations on suitable manifolds, where\nthe target/test parameter points are specified by the local parameterization of\nthe test external time-dependent inputs. We present a number of numerical\nexamples to demonstrate the robustness of our method and compare its\nperformance with deep neural networks in the same settings.\n","authors":["Hannah Lu","Daniel M. Tartakovsky"],"pdf_url":"https://arxiv.org/pdf/2306.15618v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2006.02392 by other authors"},{"id":"http://arxiv.org/abs/2305.15284v3","updated":"2023-06-27T16:41:19Z","published":"2023-05-24T16:05:15Z","title":"Replicable Reinforcement Learning","summary":"  The replicability crisis in the social, behavioral, and data sciences has led\nto the formulation of algorithm frameworks for replicability -- i.e., a\nrequirement that an algorithm produce identical outputs (with high probability)\nwhen run on two different samples from the same underlying distribution. While\nstill in its infancy, provably replicable algorithms have been developed for\nmany fundamental tasks in machine learning and statistics, including\nstatistical query learning, the heavy hitters problem, and distribution\ntesting. In this work we initiate the study of replicable reinforcement\nlearning, providing a provably replicable algorithm for parallel value\niteration, and a provably replicable version of R-max in the episodic setting.\nThese are the first formal replicability results for control problems, which\npresent different challenges for replication than batch learning settings.\n","authors":["Eric Eaton","Marcel Hussing","Michael Kearns","Jessica Sorrell"],"pdf_url":"https://arxiv.org/pdf/2305.15284v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15595v1","updated":"2023-06-27T16:26:26Z","published":"2023-06-27T16:26:26Z","title":"Extending Context Window of Large Language Models via Positional\n  Interpolation","summary":"  We present Position Interpolation (PI) that extends the context window sizes\nof RoPE-based pretrained LLMs such as LLaMA models to up to 32768 with minimal\nfine-tuning (within 1000 steps), while demonstrating strong empirical results\non various tasks that require long context, including passkey retrieval,\nlanguage modeling, and long document summarization from LLaMA 7B to 65B.\nMeanwhile, the extended model by Position Interpolation preserve quality\nrelatively well on tasks within its original context window. To achieve this\ngoal, Position Interpolation linearly down-scales the input position indices to\nmatch the original context window size, rather than extrapolating beyond the\ntrained context length which may lead to catastrophically high attention scores\nthat completely ruin the self-attention mechanism. Our theoretical study shows\nthat the upper bound of interpolation is at least $\\sim 600 \\times$ smaller\nthan that of extrapolation, further demonstrating its stability. Models\nextended via Position Interpolation retain its original architecture and can\nreuse most pre-existing optimization and infrastructure.\n","authors":["Shouyuan Chen","Sherman Wong","Liangjian Chen","Yuandong Tian"],"pdf_url":"https://arxiv.org/pdf/2306.15595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.11330v2","updated":"2023-06-27T16:21:32Z","published":"2023-06-20T06:57:24Z","title":"Low Latency Edge Classification GNN for Particle Trajectory Tracking on\n  FPGAs","summary":"  In-time particle trajectory reconstruction in the Large Hadron Collider is\nchallenging due to the high collision rate and numerous particle hits. Using\nGNN (Graph Neural Network) on FPGA has enabled superior accuracy with flexible\ntrajectory classification. However, existing GNN architectures have inefficient\nresource usage and insufficient parallelism for edge classification. This paper\nintroduces a resource-efficient GNN architecture on FPGAs for low latency\nparticle tracking. The modular architecture facilitates design scalability to\nsupport large graphs. Leveraging the geometric properties of hit detectors\nfurther reduces graph complexity and resource usage. Our results on Xilinx\nUltraScale+ VU9P demonstrate 1625x and 1574x performance improvement over CPU\nand GPU respectively.\n","authors":["Shi-Yu Huang","Yun-Chen Yang","Yu-Ru Su","Bo-Cheng Lai","Javier Duarte","Scott Hauck","Shih-Chieh Hsu","Jin-Xuan Hu","Mark S. Neubauer"],"pdf_url":"https://arxiv.org/pdf/2306.11330v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15591v1","updated":"2023-06-27T16:15:15Z","published":"2023-06-27T16:15:15Z","title":"Learning to Sail Dynamic Networks: The MARLIN Reinforcement Learning\n  Framework for Congestion Control in Tactical Environments","summary":"  Conventional Congestion Control (CC) algorithms,such as TCP Cubic, struggle\nin tactical environments as they misinterpret packet loss and fluctuating\nnetwork performance as congestion symptoms. Recent efforts, including our own\nMARLIN, have explored the use of Reinforcement Learning (RL) for CC, but they\noften fall short of generalization, particularly in competitive, unstable, and\nunforeseen scenarios. To address these challenges, this paper proposes an RL\nframework that leverages an accurate and parallelizable emulation environment\nto reenact the conditions of a tactical network. We also introduce refined RL\nformulation and performance evaluation methods tailored for agents operating in\nsuch intricate scenarios. We evaluate our RL learning framework by training a\nMARLIN agent in conditions replicating a bottleneck link transition between a\nSatellite Communication (SATCOM) and an UHF Wide Band (UHF) radio link.\nFinally, we compared its performance in file transfer tasks against\nTransmission Control Protocol (TCP) Cubic and the default strategy implemented\nin the Mockets tactical communication middleware. The results demonstrate that\nthe MARLIN RL agent outperforms both TCP and Mockets under different\nperspectives and highlight the effectiveness of specialized RL solutions in\noptimizing CC for tactical network environments.\n","authors":["Raffaele Galliera","Mattia Zaccarini","Alessandro Morelli","Roberto Fronteddu","Filippo Poltronieri","Niranjan Suri","Mauro Tortonesi"],"pdf_url":"https://arxiv.org/pdf/2306.15591v1.pdf","comment":"6 pages, 4 figures, IEEE conference"},{"id":"http://arxiv.org/abs/2208.11069v2","updated":"2023-06-27T16:13:22Z","published":"2022-08-23T16:25:48Z","title":"Asynchronous Execution of Heterogeneous Tasks in ML-driven HPC Workflows","summary":"  Heterogeneous scientific workflows consist of numerous types of tasks that\nrequire executing on heterogeneous resources. Asynchronous execution of those\ntasks is crucial to improve resource utilization, task throughput and reduce\nworkflows' makespan. Therefore, middleware capable of scheduling and executing\ndifferent task types across heterogeneous resources must enable asynchronous\nexecution of tasks. In this paper, we investigate the requirements and\nproperties of the asynchronous task execution of machine learning (ML)-driven\nhigh performance computing (HPC) workflows. We model the degree of\nasynchronicity permitted for arbitrary workflows and propose key metrics that\ncan be used to determine qualitative benefits when employing asynchronous\nexecution. Our experiments represent relevant scientific drivers, we perform\nthem at scale on Summit, and we show that the performance enhancements due to\nasynchronous execution are consistent with our model.\n","authors":["Vincent R. Pascuzzi","Ozgur O. Kilic","Matteo Turilli","Shantenu Jha"],"pdf_url":"https://arxiv.org/pdf/2208.11069v2.pdf","comment":"Publised on 26th edition of the workshop on Job Scheduling Strategies\n  for Parallel Processing. JSSPP23"},{"id":"http://arxiv.org/abs/2306.15585v1","updated":"2023-06-27T16:10:36Z","published":"2023-06-27T16:10:36Z","title":"Optimizing Credit Limit Adjustments Under Adversarial Goals Using\n  Reinforcement Learning","summary":"  Reinforcement learning has been explored for many problems, from video games\nwith deterministic environments to portfolio and operations management in which\nscenarios are stochastic; however, there have been few attempts to test these\nmethods in banking problems. In this study, we sought to find and automatize an\noptimal credit card limit adjustment policy by employing reinforcement learning\ntechniques. In particular, because of the historical data available, we\nconsidered two possible actions per customer, namely increasing or maintaining\nan individual's current credit limit. To find this policy, we first formulated\nthis decision-making question as an optimization problem in which the expected\nprofit was maximized; therefore, we balanced two adversarial goals: maximizing\nthe portfolio's revenue and minimizing the portfolio's provisions. Second,\ngiven the particularities of our problem, we used an offline learning strategy\nto simulate the impact of the action based on historical data from a super-app\n(i.e., a mobile application that offers various services from goods deliveries\nto financial products) in Latin America to train our reinforcement learning\nagent. Our results show that a Double Q-learning agent with optimized\nhyperparameters can outperform other strategies and generate a non-trivial\noptimal policy reflecting the complex nature of this decision. Our research not\nonly establishes a conceptual structure for applying reinforcement learning\nframework to credit limit adjustment, presenting an objective technique to make\nthese decisions primarily based on data-driven methods rather than relying only\non expert-driven systems but also provides insights into the effect of\nalternative data usage for determining these modifications.\n","authors":["Sherly Alfonso-Sánchez","Jesús Solano","Alejandro Correa-Bahnsen","Kristina P. Sendova","Cristián Bravo"],"pdf_url":"https://arxiv.org/pdf/2306.15585v1.pdf","comment":"29 pages, 16 figures"},{"id":"http://arxiv.org/abs/2306.10983v2","updated":"2023-06-27T16:09:11Z","published":"2023-06-19T14:50:24Z","title":"Effect-Invariant Mechanisms for Policy Generalization","summary":"  Policy learning is an important component of many real-world learning\nsystems. A major challenge in policy learning is how to adapt efficiently to\nunseen environments or tasks. Recently, it has been suggested to exploit\ninvariant conditional distributions to learn models that generalize better to\nunseen environments. However, assuming invariance of entire conditional\ndistributions (which we call full invariance) may be too strong of an\nassumption in practice. In this paper, we introduce a relaxation of full\ninvariance called effect-invariance (e-invariance for short) and prove that it\nis sufficient, under suitable assumptions, for zero-shot policy generalization.\nWe also discuss an extension that exploits e-invariance when we have a small\nsample from the test environment, enabling few-shot policy generalization. Our\nwork does not assume an underlying causal graph or that the data are generated\nby a structural causal model; instead, we develop testing procedures to test\ne-invariance directly from data. We present empirical results using simulated\ndata and a mobile health intervention dataset to demonstrate the effectiveness\nof our approach.\n","authors":["Sorawit Saengkyongam","Niklas Pfister","Predrag Klasnja","Susan Murphy","Jonas Peters"],"pdf_url":"https://arxiv.org/pdf/2306.10983v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15580v1","updated":"2023-06-27T16:03:56Z","published":"2023-06-27T16:03:56Z","title":"Approximate Message Passing for the Matrix Tensor Product Model","summary":"  We propose and analyze an approximate message passing (AMP) algorithm for the\nmatrix tensor product model, which is a generalization of the standard spiked\nmatrix models that allows for multiple types of pairwise observations over a\ncollection of latent variables. A key innovation for this algorithm is a method\nfor optimally weighing and combining multiple estimates in each iteration.\nBuilding upon an AMP convergence theorem for non-separable functions, we prove\na state evolution for non-separable functions that provides an asymptotically\nexact description of its performance in the high-dimensional limit. We leverage\nthis state evolution result to provide necessary and sufficient conditions for\nrecovery of the signal of interest. Such conditions depend on the singular\nvalues of a linear operator derived from an appropriate generalization of a\nsignal-to-noise ratio for our model. Our results recover as special cases a\nnumber of recently proposed methods for contextual models (e.g., covariate\nassisted clustering) as well as inhomogeneous noise models.\n","authors":["Riccardo Rossetti","Galen Reeves"],"pdf_url":"https://arxiv.org/pdf/2306.15580v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15576v1","updated":"2023-06-27T15:54:44Z","published":"2023-06-27T15:54:44Z","title":"PyBADS: Fast and robust black-box optimization in Python","summary":"  PyBADS is a Python implementation of the Bayesian Adaptive Direct Search\n(BADS) algorithm for fast and robust black-box optimization (Acerbi and Ma\n2017). BADS is an optimization algorithm designed to efficiently solve\ndifficult optimization problems where the objective function is rough\n(non-convex, non-smooth), mildly expensive (e.g., the function evaluation\nrequires more than 0.1 seconds), possibly noisy, and gradient information is\nunavailable. With BADS, these issues are well addressed, making it an excellent\nchoice for fitting computational models using methods such as\nmaximum-likelihood estimation. The algorithm scales efficiently to black-box\nfunctions with up to $D \\approx 20$ continuous input parameters and supports\nbounds or no constraints. PyBADS comes along with an easy-to-use Pythonic\ninterface for running the algorithm and inspecting its results. PyBADS only\nrequires the user to provide a Python function for evaluating the target\nfunction, and optionally other constraints.\n  Extensive benchmarks on both artificial test problems and large real\nmodel-fitting problems models drawn from cognitive, behavioral and\ncomputational neuroscience, show that BADS performs on par with or better than\nmany other common and state-of-the-art optimizers (Acerbi and Ma 2017), making\nit a general model-fitting tool which provides fast and robust solutions.\n","authors":["Gurjeet Sangra Singh","Luigi Acerbi"],"pdf_url":"https://arxiv.org/pdf/2306.15576v1.pdf","comment":"7 pages, 1 figure. Documentation is available at\n  https://acerbilab.github.io/pybads/ and source code is available at\n  https://github.com/acerbilab/pybads"},{"id":"http://arxiv.org/abs/2306.15574v1","updated":"2023-06-27T15:53:20Z","published":"2023-06-27T15:53:20Z","title":"See Through the Fog: Curriculum Learning with Progressive Occlusion in\n  Medical Imaging","summary":"  In recent years, deep learning models have revolutionized medical image\ninterpretation, offering substantial improvements in diagnostic accuracy.\nHowever, these models often struggle with challenging images where critical\nfeatures are partially or fully occluded, which is a common scenario in\nclinical practice. In this paper, we propose a novel curriculum learning-based\napproach to train deep learning models to handle occluded medical images\neffectively. Our method progressively introduces occlusion, starting from\nclear, unobstructed images and gradually moving to images with increasing\nocclusion levels. This ordered learning process, akin to human learning, allows\nthe model to first grasp simple, discernable patterns and subsequently build\nupon this knowledge to understand more complicated, occluded scenarios.\nFurthermore, we present three novel occlusion synthesis methods, namely\nWasserstein Curriculum Learning (WCL), Information Adaptive Learning (IAL), and\nGeodesic Curriculum Learning (GCL). Our extensive experiments on diverse\nmedical image datasets demonstrate substantial improvements in model robustness\nand diagnostic accuracy over conventional training methodologies.\n","authors":["Pradeep Singh","Kishore Babu Nampalle","Uppala Vivek Narayan","Balasubramanian Raman"],"pdf_url":"https://arxiv.org/pdf/2306.15574v1.pdf","comment":"20 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2306.15572v1","updated":"2023-06-27T15:48:40Z","published":"2023-06-27T15:48:40Z","title":"Generating Elementary Integrable Expressions","summary":"  There has been an increasing number of applications of machine learning to\nthe field of Computer Algebra in recent years, including to the prominent\nsub-field of Symbolic Integration. However, machine learning models require an\nabundance of data for them to be successful and there exist few benchmarks on\nthe scale required. While methods to generate new data already exist, they are\nflawed in several ways which may lead to bias in machine learning models\ntrained upon them. In this paper, we describe how to use the Risch Algorithm\nfor symbolic integration to create a dataset of elementary integrable\nexpressions. Further, we show that data generated this way alleviates some of\nthe flaws found in earlier methods.\n","authors":["Rashid Barket","Matthew England","Jürgen Gerhard"],"pdf_url":"https://arxiv.org/pdf/2306.15572v1.pdf","comment":"To appear in proceedings of CASC 2023. This version of the\n  contribution has been accepted for publication, after peer review but is not\n  the Version of Record and does not reflect post-acceptance improvements, or\n  any corrections"},{"id":"http://arxiv.org/abs/2306.15567v1","updated":"2023-06-27T15:46:22Z","published":"2023-06-27T15:46:22Z","title":"A Three-Way Knot: Privacy, Fairness, and Predictive Performance Dynamics","summary":"  As the frontier of machine learning applications moves further into human\ninteraction, multiple concerns arise regarding automated decision-making. Two\nof the most critical issues are fairness and data privacy. On the one hand, one\nmust guarantee that automated decisions are not biased against certain groups,\nespecially those unprotected or marginalized. On the other hand, one must\nensure that the use of personal information fully abides by privacy regulations\nand that user identities are kept safe. The balance between privacy, fairness,\nand predictive performance is complex. However, despite their potential\nsocietal impact, we still demonstrate a poor understanding of the dynamics\nbetween these optimization vectors. In this paper, we study this three-way\ntension and how the optimization of each vector impacts others, aiming to\ninform the future development of safe applications. In light of claims that\npredictive performance and fairness can be jointly optimized, we find this is\nonly possible at the expense of data privacy. Overall, experimental results\nshow that one of the vectors will be penalized regardless of which of the three\nwe optimize. Nonetheless, we find promising avenues for future work in joint\noptimization solutions, where smaller trade-offs are observed between the three\nvectors.\n","authors":["Tânia Carvalho","Nuno Moniz","Luís Antunes"],"pdf_url":"https://arxiv.org/pdf/2306.15567v1.pdf","comment":"12, 6 figures and 2 tables"},{"id":"http://arxiv.org/abs/2306.15559v1","updated":"2023-06-27T15:36:12Z","published":"2023-06-27T15:36:12Z","title":"RansomAI: AI-powered Ransomware for Stealthy Encryption","summary":"  Cybersecurity solutions have shown promising performance when detecting\nransomware samples that use fixed algorithms and encryption rates. However, due\nto the current explosion of Artificial Intelligence (AI), sooner than later,\nransomware (and malware in general) will incorporate AI techniques to\nintelligently and dynamically adapt its encryption behavior to be undetected.\nIt might result in ineffective and obsolete cybersecurity solutions, but the\nliterature lacks AI-powered ransomware to verify it. Thus, this work proposes\nRansomAI, a Reinforcement Learning-based framework that can be integrated into\nexisting ransomware samples to adapt their encryption behavior and stay\nstealthy while encrypting files. RansomAI presents an agent that learns the\nbest encryption algorithm, rate, and duration that minimizes its detection\n(using a reward mechanism and a fingerprinting intelligent detection system)\nwhile maximizing its damage function. The proposed framework was validated in a\nransomware, Ransomware-PoC, that infected a Raspberry Pi 4, acting as a\ncrowdsensor. A pool of experiments with Deep Q-Learning and Isolation Forest\n(deployed on the agent and detection system, respectively) has demonstrated\nthat RansomAI evades the detection of Ransomware-PoC affecting the Raspberry Pi\n4 in a few minutes with >90% accuracy.\n","authors":["Jan von der Assen","Alberto Huertas Celdrán","Janik Luechinger","Pedro Miguel Sánchez Sánchez","Gérôme Bovet","Gregorio Martínez Pérez","Burkhard Stiller"],"pdf_url":"https://arxiv.org/pdf/2306.15559v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15557v1","updated":"2023-06-27T15:35:22Z","published":"2023-06-27T15:35:22Z","title":"Simple Steps to Success: Axiomatics of Distance-Based Algorithmic\n  Recourse","summary":"  We propose a novel data-driven framework for algorithmic recourse that offers\nusers interventions to change their predicted outcome. Existing approaches to\ncompute recourse find a set of points that satisfy some desiderata -- e.g. an\nintervention in the underlying causal graph, or minimizing a cost function.\nSatisfying these criteria, however, requires extensive knowledge of the\nunderlying model structure, often an unrealistic amount of information in\nseveral domains. We propose a data-driven, computationally efficient approach\nto computing algorithmic recourse. We do so by suggesting directions in the\ndata manifold that users can take to change their predicted outcome. We present\nStepwise Explainable Paths (StEP), an axiomatically justified framework to\ncompute direction-based algorithmic recourse. We offer a thorough empirical and\ntheoretical investigation of StEP. StEP offers provable privacy and robustness\nguarantees, and outperforms the state-of-the-art on several established\nrecourse desiderata.\n","authors":["Jenny Hamer","Jake Valladares","Vignesh Viswanathan","Yair Zick"],"pdf_url":"https://arxiv.org/pdf/2306.15557v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15552v1","updated":"2023-06-27T15:24:24Z","published":"2023-06-27T15:24:24Z","title":"A Survey on Deep Learning Hardware Accelerators for Heterogeneous HPC\n  Platforms","summary":"  Recent trends in deep learning (DL) imposed hardware accelerators as the most\nviable solution for several classes of high-performance computing (HPC)\napplications such as image classification, computer vision, and speech\nrecognition. This survey summarizes and classifies the most recent advances in\ndesigning DL accelerators suitable to reach the performance requirements of HPC\napplications. In particular, it highlights the most advanced approaches to\nsupport deep learning accelerations including not only GPU and TPU-based\naccelerators but also design-specific hardware accelerators such as FPGA-based\nand ASIC-based accelerators, Neural Processing Units, open hardware\nRISC-V-based accelerators and co-processors. The survey also describes\naccelerators based on emerging memory technologies and computing paradigms,\nsuch as 3D-stacked Processor-In-Memory, non-volatile memories (mainly,\nResistive RAM and Phase Change Memories) to implement in-memory computing,\nNeuromorphic Processing Units, and accelerators based on Multi-Chip Modules.\nThe survey classifies the most influential architectures and technologies\nproposed in the last years, with the purpose of offering the reader a\ncomprehensive perspective in the rapidly evolving field of deep learning.\nFinally, it provides some insights into future challenges in DL accelerators\nsuch as quantum accelerators and photonics.\n","authors":["Cristina Silvano","Daniele Ielmini","Fabrizio Ferrandi","Leandro Fiorin","Serena Curzel","Luca Benini","Francesco Conti","Angelo Garofalo","Cristian Zambelli","Enrico Calore","Sebastiano Fabio Schifano","Maurizio Palesi","Giuseppe Ascia","Davide Patti","Stefania Perri","Nicola Petra","Davide De Caro","Luciano Lavagno","Teodoro Urso","Valeria Cardellini","Gian Carlo Cardarilli","Robert Birke"],"pdf_url":"https://arxiv.org/pdf/2306.15552v1.pdf","comment":"Preprint version of our manuscript submitted to the journal @ ACM\n  CSUR (35 pages plus Appendix) on June 22nd, 2023"},{"id":"http://arxiv.org/abs/2306.15551v1","updated":"2023-06-27T15:23:42Z","published":"2023-06-27T15:23:42Z","title":"CrunchGPT: A chatGPT assisted framework for scientific machine learning","summary":"  Scientific Machine Learning (SciML) has advanced recently across many\ndifferent areas in computational science and engineering. The objective is to\nintegrate data and physics seamlessly without the need of employing elaborate\nand computationally taxing data assimilation schemes. However, preprocessing,\nproblem formulation, code generation, postprocessing and analysis are still\ntime consuming and may prevent SciML from wide applicability in industrial\napplications and in digital twin frameworks. Here, we integrate the various\nstages of SciML under the umbrella of ChatGPT, to formulate CrunchGPT, which\nplays the role of a conductor orchestrating the entire workflow of SciML based\non simple prompts by the user. Specifically, we present two examples that\ndemonstrate the potential use of CrunchGPT in optimizing airfoils in\naerodynamics, and in obtaining flow fields in various geometries in interactive\nmode, with emphasis on the validation stage. To demonstrate the flow of the\nCrunchGPT, and create an infrastructure that can facilitate a broader vision,\nwe built a webapp based guided user interface, that includes options for a\ncomprehensive summary report. The overall objective is to extend CrunchGPT to\nhandle diverse problems in computational mechanics, design, optimization and\ncontrols, and general scientific computing tasks involved in SciML, hence using\nit as a research assistant tool but also as an educational tool. While here the\nexamples focus in fluid mechanics, future versions will target solid mechanics\nand materials science, geophysics, systems biology and bioinformatics.\n","authors":["Varun Kumar","Leonard Gleyzer","Adar Kahana","Khemraj Shukla","George Em Karniadakis"],"pdf_url":"https://arxiv.org/pdf/2306.15551v1.pdf","comment":"20 pages, 26 figures"},{"id":"http://arxiv.org/abs/2306.15548v1","updated":"2023-06-27T15:18:52Z","published":"2023-06-27T15:18:52Z","title":"Geometric Ultrasound Localization Microscopy","summary":"  Contrast-Enhanced Ultra-Sound (CEUS) has become a viable method for\nnon-invasive, dynamic visualization in medical diagnostics, yet Ultrasound\nLocalization Microscopy (ULM) has enabled a revolutionary breakthrough by\noffering ten times higher resolution. To date, Delay-And-Sum (DAS) beamformers\nare used to render ULM frames, ultimately determining the image resolution\ncapability. To take full advantage of ULM, this study questions whether\nbeamforming is the most effective processing step for ULM, suggesting an\nalternative approach that relies solely on Time-Difference-of-Arrival (TDoA)\ninformation. To this end, a novel geometric framework for micro bubble\nlocalization via ellipse intersections is proposed to overcome existing\nbeamforming limitations. We present a benchmark comparison based on a public\ndataset for which our geometric ULM outperforms existing baseline methods in\nterms of accuracy and reliability while only utilizing a portion of the\navailable transducer data.\n","authors":["Christopher Hahne","Raphael Sznitman"],"pdf_url":"https://arxiv.org/pdf/2306.15548v1.pdf","comment":"Pre-print accepted for MICCAI 2023"},{"id":"http://arxiv.org/abs/2306.15546v1","updated":"2023-06-27T15:15:55Z","published":"2023-06-27T15:15:55Z","title":"When Foundation Model Meets Federated Learning: Motivations, Challenges,\n  and Future Directions","summary":"  The intersection of the Foundation Model (FM) and Federated Learning (FL)\nprovides mutual benefits, presents a unique opportunity to unlock new\npossibilities in AI research, and address critical challenges in AI and\nreal-world applications. FL expands the availability of data for FMs and\nenables computation sharing, distributing the training process and reducing the\nburden on FL participants. It promotes collaborative FM development,\ndemocratizing the process and fostering inclusivity and innovation. On the\nother hand, FM, with its enormous size, pre-trained knowledge, and exceptional\nperformance, serves as a robust starting point for FL, facilitating faster\nconvergence and better performance under non-iid data. Additionally, leveraging\nFM to generate synthetic data enriches data diversity, reduces overfitting, and\npreserves privacy. By examining the interplay between FL and FM, this paper\naims to deepen the understanding of their synergistic relationship,\nhighlighting the motivations, challenges, and future directions. Through an\nexploration of the challenges faced by FL and FM individually and their\ninterconnections, we aim to inspire future research directions that can further\nenhance both fields, driving advancements and propelling the development of\nprivacy-preserving and scalable AI systems.\n","authors":["Weiming Zhuang","Chen Chen","Lingjuan Lyu"],"pdf_url":"https://arxiv.org/pdf/2306.15546v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15538v1","updated":"2023-06-27T15:07:20Z","published":"2023-06-27T15:07:20Z","title":"DataCI: A Platform for Data-Centric AI on Streaming Data","summary":"  We introduce DataCI, a comprehensive open-source platform designed\nspecifically for data-centric AI in dynamic streaming data settings. DataCI\nprovides 1) an infrastructure with rich APIs for seamless streaming dataset\nmanagement, data-centric pipeline development and evaluation on streaming\nscenarios, 2) an carefully designed versioning control function to track the\npipeline lineage, and 3) an intuitive graphical interface for a better\ninteractive user experience. Preliminary studies and demonstrations attest to\nthe easy-to-use and effectiveness of DataCI, highlighting its potential to\nrevolutionize the practice of data-centric AI in streaming data contexts.\n","authors":["Huaizheng Zhang","Yizheng Huang","Yuanming Li"],"pdf_url":"https://arxiv.org/pdf/2306.15538v1.pdf","comment":"3 pages, 4 figures"},{"id":"http://arxiv.org/abs/2306.15526v1","updated":"2023-06-27T14:54:39Z","published":"2023-06-27T14:54:39Z","title":"Higher-order Graph Attention Network for Stock Selection with Joint\n  Analysis","summary":"  Stock selection is important for investors to construct profitable\nportfolios. Graph neural networks (GNNs) are increasingly attracting\nresearchers for stock prediction due to their strong ability of relation\nmodelling and generalisation. However, the existing GNN methods only focus on\nsimple pairwise stock relation and do not capture complex higher-order\nstructures modelling relations more than two nodes. In addition, they only\nconsider factors of technical analysis and overlook factors of fundamental\nanalysis that can affect the stock trend significantly. Motivated by them, we\npropose higher-order graph attention network with joint analysis (H-GAT). H-GAT\nis able to capture higher-order structures and jointly incorporate factors of\nfundamental analysis with factors of technical analysis. Specifically, the\nsequential layer of H-GAT take both types of factors as the input of a\nlong-short term memory model. The relation embedding layer of H-GAT constructs\na higher-order graph and learn node embedding with GAT. We then predict the\nranks of stock return. Extensive experiments demonstrate the superiority of our\nH-GAT method on the profitability test and Sharp ratio over both NSDAQ and NYSE\ndatasets\n","authors":["Yang Qiao","Yiping Xia","Xiang Li","Zheng Li","Yan Ge"],"pdf_url":"https://arxiv.org/pdf/2306.15526v1.pdf","comment":"12 pages, 6 figures,"},{"id":"http://arxiv.org/abs/2306.12873v2","updated":"2023-06-27T14:39:31Z","published":"2023-06-22T13:34:26Z","title":"FuXi: A cascade machine learning forecasting system for 15-day global\n  weather forecast","summary":"  Over the past few years, due to the rapid development of machine learning\n(ML) models for weather forecasting, state-of-the-art ML models have shown\nsuperior performance compared to the European Centre for Medium-Range Weather\nForecasts (ECMWF)'s high-resolution forecast (HRES) in 10-day forecasts at a\nspatial resolution of 0.25 degree. However, the challenge remains to perform\ncomparably to the ECMWF ensemble mean (EM) in 15-day forecasts. Previous\nstudies have demonstrated the importance of mitigating the accumulation of\nforecast errors for effective long-term forecasts. Despite numerous efforts to\nreduce accumulation errors, including autoregressive multi-time step loss,\nusing a single model is found to be insufficient to achieve optimal performance\nin both short and long lead times. Therefore, we present FuXi, a cascaded ML\nweather forecasting system that provides 15-day global forecasts with a\ntemporal resolution of 6 hours and a spatial resolution of 0.25 degree. FuXi is\ndeveloped using 39 years of the ECMWF ERA5 reanalysis dataset. The performance\nevaluation, based on latitude-weighted root mean square error (RMSE) and\nanomaly correlation coefficient (ACC), demonstrates that FuXi has comparable\nforecast performance to ECMWF EM in 15-day forecasts, making FuXi the first\nML-based weather forecasting system to accomplish this achievement.\n","authors":["Lei Chen","Xiaohui Zhong","Feng Zhang","Yuan Cheng","Yinghui Xu","Yuan Qi","Hao Li"],"pdf_url":"https://arxiv.org/pdf/2306.12873v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.10790v3","updated":"2023-06-27T14:37:42Z","published":"2022-08-23T07:50:52Z","title":"Event-Triggered Time-Varying Bayesian Optimization","summary":"  We consider the problem of sequentially optimizing a time-varying objective\nfunction using time-varying Bayesian optimization (TVBO). Here, the key\nchallenge is the exploration-exploitation trade-off under time variations.\nCurrent approaches to TVBO require prior knowledge of a constant rate of\nchange. However, in practice, the rate of change is usually unknown. We propose\nan event-triggered algorithm, ET-GP-UCB, that treats the optimization problem\nas static until it detects changes in the objective function online and then\nresets the dataset. This allows the algorithm to adapt to realized temporal\nchanges without the need for prior knowledge. The event-trigger is based on\nprobabilistic uniform error bounds used in Gaussian process regression. We\nprovide regret bounds for ET-GP-UCB and show in numerical experiments that it\noutperforms state-of-the-art algorithms on synthetic and real-world data.\nFurthermore, these results demonstrate that ET-GP-UCB is readily applicable to\nvarious settings without tuning hyperparameters.\n","authors":["Paul Brunzema","Alexander von Rohr","Friedrich Solowjow","Sebastian Trimpe"],"pdf_url":"https://arxiv.org/pdf/2208.10790v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.04954v2","updated":"2023-06-27T14:30:23Z","published":"2023-01-12T11:51:11Z","title":"Reaching the Edge of the Edge: Image Analysis in Space","summary":"  Satellites have become more widely available due to the reduction in size and\ncost of their components. As a result, there has been an advent of smaller\norganizations having the ability to deploy satellites with a variety of\ndata-intensive applications to run on them. One popular application is image\nanalysis to detect, for example, land, ice, clouds, etc. for Earth observation.\nHowever, the resource-constrained nature of the devices deployed in satellites\ncreates additional challenges for this resource-intensive application.\n  In this paper, we present our work and lessons-learned on building an Image\nProcessing Unit (IPU) for a satellite. We first investigate the performance of\na variety of edge devices (comparing CPU, GPU, TPU, and VPU) for\ndeep-learning-based image processing on satellites. Our goal is to identify\ndevices that can achieve accurate results and are flexible when workload\nchanges while satisfying the power and latency constraints of satellites. Our\nresults demonstrate that hardware accelerators such as ASICs and GPUs are\nessential for meeting the latency requirements. However, state-of-the-art edge\ndevices with GPUs may draw too much power for deployment on a satellite. Then,\nwe use the findings gained from the performance analysis to guide the\ndevelopment of the IPU module for an upcoming satellite mission. We detail how\nto integrate such a module into an existing satellite architecture and the\nsoftware necessary to support various missions utilizing this module.\n","authors":["Robert Bayer","Julian Priest","Pınar Tözün"],"pdf_url":"https://arxiv.org/pdf/2301.04954v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15503v1","updated":"2023-06-27T14:29:44Z","published":"2023-06-27T14:29:44Z","title":"Prioritized Trajectory Replay: A Replay Memory for Data-driven\n  Reinforcement Learning","summary":"  In recent years, data-driven reinforcement learning (RL), also known as\noffline RL, have gained significant attention. However, the role of data\nsampling techniques in offline RL has been overlooked despite its potential to\nenhance online RL performance. Recent research suggests applying sampling\ntechniques directly to state-transitions does not consistently improve\nperformance in offline RL. Therefore, in this study, we propose a memory\ntechnique, (Prioritized) Trajectory Replay (TR/PTR), which extends the sampling\nperspective to trajectories for more comprehensive information extraction from\nlimited data. TR enhances learning efficiency by backward sampling of\ntrajectories that optimizes the use of subsequent state information. Building\non TR, we build the weighted critic target to avoid sampling unseen actions in\noffline training, and Prioritized Trajectory Replay (PTR) that enables more\nefficient trajectory sampling, prioritized by various trajectory priority\nmetrics. We demonstrate the benefits of integrating TR and PTR with existing\noffline RL algorithms on D4RL. In summary, our research emphasizes the\nsignificance of trajectory-based data sampling techniques in enhancing the\nefficiency and performance of offline RL algorithms.\n","authors":["Jinyi Liu","Yi Ma","Jianye Hao","Yujing Hu","Yan Zheng","Tangjie Lv","Changjie Fan"],"pdf_url":"https://arxiv.org/pdf/2306.15503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15500v1","updated":"2023-06-27T14:24:02Z","published":"2023-06-27T14:24:02Z","title":"A novel structured argumentation framework for improved explainability\n  of classification tasks","summary":"  This paper presents a novel framework for structured argumentation, named\nextend argumentative decision graph ($xADG$). It is an extension of\nargumentative decision graphs built upon Dung's abstract argumentation graphs.\nThe $xADG$ framework allows for arguments to use boolean logic operators and\nmultiple premises (supports) within their internal structure, resulting in more\nconcise argumentation graphs that may be easier for users to understand. The\nstudy presents a methodology for construction of $xADGs$ and evaluates their\nsize and predictive capacity for classification tasks of varying magnitudes.\nResulting $xADGs$ achieved strong (balanced) accuracy, which was accomplished\nthrough an input decision tree, while also reducing the average number of\nsupports needed to reach a conclusion. The results further indicated that it is\npossible to construct plausibly understandable $xADGs$ that outperform other\ntechniques for building $ADGs$ in terms of predictive capacity and overall\nsize. In summary, the study suggests that $xADG$ represents a promising\nframework to developing more concise argumentative models that can be used for\nclassification tasks and knowledge discovery, acquisition, and refinement.\n","authors":["Lucas Rizzo","Luca Longo"],"pdf_url":"https://arxiv.org/pdf/2306.15500v1.pdf","comment":"Submitted to the The World Conference on eXplainable Artificial\n  Intelligence (xAI 2023)"},{"id":"http://arxiv.org/abs/2306.10592v2","updated":"2023-06-27T14:21:15Z","published":"2023-06-18T16:11:40Z","title":"Conditional expectation using compactification operators","summary":"  The separate tasks of denoising, conditional expectation and manifold\nlearning can often be posed in a common setting of finding the conditional\nexpectations arising from a product of two random variables. This paper focuses\non this more general problem and describes an operator theoretic approach to\nestimating the conditional expectation. Kernel integral operators are used as a\ncompactification tool, to set up the estimation problem as a linear inverse\nproblem in a reproducing kernel Hilbert space. This equation is shown to have\nsolutions that are stable to numerical approximation, thus guaranteeing the\nconvergence of data-driven implementations. The overall technique is easy to\nimplement, and their successful application to some real-world problems are\nalso shown.\n","authors":["Suddhasattwa Das"],"pdf_url":"https://arxiv.org/pdf/2306.10592v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.13892v2","updated":"2023-06-27T14:19:56Z","published":"2023-04-27T00:34:24Z","title":"Discovering Object-Centric Generalized Value Functions From Pixels","summary":"  Deep Reinforcement Learning has shown significant progress in extracting\nuseful representations from high-dimensional inputs albeit using hand-crafted\nauxiliary tasks and pseudo rewards. Automatically learning such representations\nin an object-centric manner geared towards control and fast adaptation remains\nan open research problem. In this paper, we introduce a method that tries to\ndiscover meaningful features from objects, translating them to temporally\ncoherent \"question\" functions and leveraging the subsequent learned general\nvalue functions for control. We compare our approach with state-of-the-art\ntechniques alongside other ablations and show competitive performance in both\nstationary and non-stationary settings. Finally, we also investigate the\ndiscovered general value functions and through qualitative analysis show that\nthe learned representations are not only interpretable but also, centered\naround objects that are invariant to changes across tasks facilitating fast\nadaptation.\n","authors":["Somjit Nath","Gopeshh Raaj Subbaraj","Khimya Khetarpal","Samira Ebrahimi Kahou"],"pdf_url":"https://arxiv.org/pdf/2304.13892v2.pdf","comment":"Accepted at ICML 2023"},{"id":"http://arxiv.org/abs/2304.10726v2","updated":"2023-06-27T14:19:05Z","published":"2023-04-21T03:45:10Z","title":"Smart Learning to Find Dumb Contracts (Extended Version)","summary":"  We introduce the Deep Learning Vulnerability Analyzer (DLVA) for Ethereum\nsmart contracts based on neural networks. We train DLVA to judge bytecode even\nthough the supervising oracle can only judge source. DLVA's training algorithm\nis general: we extend a source code analysis to bytecode without any manual\nfeature engineering, predefined patterns, or expert rules. DLVA's training\nalgorithm is also robust: it overcame a 1.25% error rate mislabeled contracts,\nand--the student surpassing the teacher--found vulnerable contracts that\nSlither mislabeled. DLVA is much faster than other smart contract vulnerability\ndetectors: DLVA checks contracts for 29 vulnerabilities in 0.2 seconds, a\n10-1,000x speedup. DLVA has three key components. First, Smart Contract to\nVector (SC2V) uses neural networks to map smart contract bytecode to a\nhigh-dimensional floating-point vector. We benchmark SC2V against 4\nstate-of-the-art graph neural networks and show that it improves model\ndifferentiation by 2.2%. Second, Sibling Detector (SD) classifies contracts\nwhen a target contract's vector is Euclidian-close to a labeled contract's\nvector in a training set; although only able to judge 55.7% of the contracts in\nour test set, it has a Slither-predictive accuracy of 97.4% with a false\npositive rate of only 0.1%. Third, Core Classifier (CC) uses neural networks to\ninfer vulnerable contracts regardless of vector distance. We benchmark DLVA's\nCC with 10 ML techniques and show that the CC improves accuracy by 11.3%.\nOverall, DLVA predicts Slither's labels with an overall accuracy of 92.7% and\nassociated false positive rate of 7.2%. Lastly, we benchmark DLVA against nine\nwell-known smart contract analysis tools. Despite using much less analysis\ntime, DLVA completed every query, leading the pack with an average accuracy of\n99.7%, pleasingly balancing high true positive rates with low false positive\nrates.\n","authors":["Tamer Abdelaziz","Aquinas Hobor"],"pdf_url":"https://arxiv.org/pdf/2304.10726v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15482v1","updated":"2023-06-27T14:02:10Z","published":"2023-06-27T14:02:10Z","title":"Cooperation or Competition: Avoiding Player Domination for Multi-Target\n  Robustness via Adaptive Budgets","summary":"  Despite incredible advances, deep learning has been shown to be susceptible\nto adversarial attacks. Numerous approaches have been proposed to train robust\nnetworks both empirically and certifiably. However, most of them defend against\nonly a single type of attack, while recent work takes steps forward in\ndefending against multiple attacks. In this paper, to understand multi-target\nrobustness, we view this problem as a bargaining game in which different\nplayers (adversaries) negotiate to reach an agreement on a joint direction of\nparameter updating. We identify a phenomenon named player domination in the\nbargaining game, namely that the existing max-based approaches, such as MAX and\nMSD, do not converge. Based on our theoretical analysis, we design a novel\nframework that adjusts the budgets of different adversaries to avoid any player\ndominance. Experiments on standard benchmarks show that employing the proposed\nframework to the existing approaches significantly advances multi-target\nrobustness.\n","authors":["Yimu Wang","Dinghuai Zhang","Yihan Wu","Heng Huang","Hongyang Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.15482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12814v2","updated":"2023-06-27T14:01:09Z","published":"2023-02-24T18:49:10Z","title":"GraphSR: A Data Augmentation Algorithm for Imbalanced Node\n  Classification","summary":"  Graph neural networks (GNNs) have achieved great success in node\nclassification tasks. However, existing GNNs naturally bias towards the\nmajority classes with more labelled data and ignore those minority classes with\nrelatively few labelled ones. The traditional techniques often resort\nover-sampling methods, but they may cause overfitting problem. More recently,\nsome works propose to synthesize additional nodes for minority classes from the\nlabelled nodes, however, there is no any guarantee if those generated nodes\nreally stand for the corresponding minority classes. In fact, improperly\nsynthesized nodes may result in insufficient generalization of the algorithm.\nTo resolve the problem, in this paper we seek to automatically augment the\nminority classes from the massive unlabelled nodes of the graph. Specifically,\nwe propose \\textit{GraphSR}, a novel self-training strategy to augment the\nminority classes with significant diversity of unlabelled nodes, which is based\non a Similarity-based selection module and a Reinforcement Learning(RL)\nselection module. The first module finds a subset of unlabelled nodes which are\nmost similar to those labelled minority nodes, and the second one further\ndetermines the representative and reliable nodes from the subset via RL\ntechnique. Furthermore, the RL-based module can adaptively determine the\nsampling scale according to current training data. This strategy is general and\ncan be easily combined with different GNNs models. Our experiments demonstrate\nthe proposed approach outperforms the state-of-the-art baselines on various\nclass-imbalanced datasets.\n","authors":["Mengting Zhou","Zhiguo Gong"],"pdf_url":"https://arxiv.org/pdf/2302.12814v2.pdf","comment":"Accepted by AAAI2023"},{"id":"http://arxiv.org/abs/2305.05257v3","updated":"2023-06-27T13:58:48Z","published":"2023-05-09T08:26:48Z","title":"Survey of Federated Learning Models for Spatial-Temporal Mobility\n  Applications","summary":"  Federated learning involves training statistical models over edge devices\nsuch as mobile phones such that the training data is kept local. Federated\nLearning (FL) can serve as an ideal candidate for training spatial temporal\nmodels that rely on heterogeneous and potentially massive numbers of\nparticipants while preserving the privacy of highly sensitive location data.\nHowever, there are unique challenges involved with transitioning existing\nspatial temporal models to decentralized learning. In this survey paper, we\nreview the existing literature that has proposed FL-based models for predicting\nhuman mobility, traffic prediction, community detection, location-based\nrecommendation systems, and other spatial-temporal tasks. We describe the\nmetrics and datasets these works have been using and create a baseline of these\napproaches in comparison to the centralized settings. Finally, we discuss the\nchallenges of applying spatial-temporal models in a decentralized setting and\nby highlighting the gaps in the literature we provide a road map and\nopportunities for the research community.\n","authors":["Yacine Belal","Sonia Ben Mokhtar","Hamed Haddadi","Jaron Wang","Afra Mashhadi"],"pdf_url":"https://arxiv.org/pdf/2305.05257v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01742v3","updated":"2023-06-27T13:58:46Z","published":"2022-10-04T17:02:37Z","title":"CADet: Fully Self-Supervised Out-Of-Distribution Detection With\n  Contrastive Learning","summary":"  Handling out-of-distribution (OOD) samples has become a major stake in the\nreal-world deployment of machine learning systems. This work explores the use\nof self-supervised contrastive learning to the simultaneous detection of two\ntypes of OOD samples: unseen classes and adversarial perturbations. First, we\npair self-supervised contrastive learning with the maximum mean discrepancy\n(MMD) two-sample test. This approach enables us to robustly test whether two\nindependent sets of samples originate from the same distribution, and we\ndemonstrate its effectiveness by discriminating between CIFAR-10 and CIFAR-10.1\nwith higher confidence than previous work. Motivated by this success, we\nintroduce CADet (Contrastive Anomaly Detection), a novel method for OOD\ndetection of single samples. CADet draws inspiration from MMD, but leverages\nthe similarity between contrastive transformations of a same sample. CADet\noutperforms existing adversarial detection methods in identifying adversarially\nperturbed samples on ImageNet and achieves comparable performance to unseen\nlabel detection methods on two challenging benchmarks: ImageNet-O and\niNaturalist. Significantly, CADet is fully self-supervised and requires neither\nlabels for in-distribution samples nor access to OOD examples.\n","authors":["Charles Guille-Escuret","Pau Rodriguez","David Vazquez","Ioannis Mitliagkas","Joao Monteiro"],"pdf_url":"https://arxiv.org/pdf/2210.01742v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15479v1","updated":"2023-06-27T13:57:16Z","published":"2023-06-27T13:57:16Z","title":"Causal Inference via Predictive Coding","summary":"  Bayesian and causal inference are fundamental processes for intelligence.\nBayesian inference models observations: what can be inferred about y if we\nobserve a related variable x? Causal inference models interventions: if we\ndirectly change x, how will y change? Predictive coding is a\nneuroscience-inspired method for performing Bayesian inference on continuous\nstate variables using local information only. In this work, we go beyond\nBayesian inference, and show how a simple change in the inference process of\npredictive coding enables interventional and counterfactual inference in\nscenarios where the causal graph is known. We then extend our results, and show\nhow predictive coding can be generalized to cases where this graph is unknown,\nand has to be inferred from data, hence performing causal discovery. What\nresults is a novel and straightforward technique that allows us to perform\nend-to-end causal inference on predictive-coding-based structural causal\nmodels, and demonstrate its utility for potential applications in machine\nlearning.\n","authors":["Tommaso Salvatori","Luca Pinchetti","Amine M'Charrak","Beren Millidge","Thomas Lukasiewicz"],"pdf_url":"https://arxiv.org/pdf/2306.15479v1.pdf","comment":"44 Pages, 24 Figures"},{"id":"http://arxiv.org/abs/2305.10272v2","updated":"2023-06-27T13:55:55Z","published":"2023-05-17T15:03:58Z","title":"Demonstrating Large-Scale Package Manipulation via Learned Metrics of\n  Pick Success","summary":"  Automating warehouse operations can reduce logistics overhead costs,\nultimately driving down the final price for consumers, increasing the speed of\ndelivery, and enhancing the resiliency to workforce fluctuations. The past few\nyears have seen increased interest in automating such repeated tasks but mostly\nin controlled settings. Tasks such as picking objects from unstructured,\ncluttered piles have only recently become robust enough for large-scale\ndeployment with minimal human intervention.\n  This paper demonstrates a large-scale package manipulation from unstructured\npiles in Amazon Robotics' Robot Induction (Robin) fleet, which utilizes a pick\nsuccess predictor trained on real production data. Specifically, the system was\ntrained on over 394K picks. It is used for singulating up to 5 million packages\nper day and has manipulated over 200 million packages during this paper's\nevaluation period.\n  The developed learned pick quality measure ranks various pick alternatives in\nreal-time and prioritizes the most promising ones for execution. The pick\nsuccess predictor aims to estimate from prior experience the success\nprobability of a desired pick by the deployed industrial robotic arms in\ncluttered scenes containing deformable and rigid objects with partially known\nproperties. It is a shallow machine learning model, which allows us to evaluate\nwhich features are most important for the prediction. An online pick ranker\nleverages the learned success predictor to prioritize the most promising picks\nfor the robotic arm, which are then assessed for collision avoidance. This\nlearned ranking process is demonstrated to overcome the limitations and\noutperform the performance of manually engineered and heuristic alternatives.\n  To the best of the authors' knowledge, this paper presents the first\nlarge-scale deployment of learned pick quality estimation methods in a real\nproduction system.\n","authors":["Shuai Li","Azarakhsh Keipour","Kevin Jamieson","Nicolas Hudson","Charles Swan","Kostas Bekris"],"pdf_url":"https://arxiv.org/pdf/2305.10272v2.pdf","comment":"Robotics: Science and Systems (RSS 2023) conference, July 10 - 14,\n  2023, Daegu, Republic of Korea"},{"id":"http://arxiv.org/abs/2306.05437v2","updated":"2023-06-27T13:52:15Z","published":"2023-06-08T02:52:24Z","title":"One-step Multi-view Clustering with Diverse Representation","summary":"  Multi-view clustering has attracted broad attention due to its capacity to\nutilize consistent and complementary information among views. Although\ntremendous progress has been made recently, most existing methods undergo high\ncomplexity, preventing them from being applied to large-scale tasks. Multi-view\nclustering via matrix factorization is a representative to address this issue.\nHowever, most of them map the data matrices into a fixed dimension, limiting\nthe model's expressiveness. Moreover, a range of methods suffers from a\ntwo-step process, i.e., multimodal learning and the subsequent $k$-means,\ninevitably causing a sub-optimal clustering result. In light of this, we\npropose a one-step multi-view clustering with diverse representation method,\nwhich incorporates multi-view learning and $k$-means into a unified framework.\nSpecifically, we first project original data matrices into various latent\nspaces to attain comprehensive information and auto-weight them in a\nself-supervised manner. Then we directly use the information matrices under\ndiverse dimensions to obtain consensus discrete clustering labels. The unified\nwork of representation learning and clustering boosts the quality of the final\nresults. Furthermore, we develop an efficient optimization algorithm with\nproven convergence to solve the resultant problem. Comprehensive experiments on\nvarious datasets demonstrate the promising clustering performance of our\nproposed method.\n","authors":["Xinhang Wan","Jiyuan Liu","Xinwang Liu","Siwei Wang","Yi Wen","Tianjiao Wan","Li Shen","En Zhu"],"pdf_url":"https://arxiv.org/pdf/2306.05437v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15464v1","updated":"2023-06-27T13:31:33Z","published":"2023-06-27T13:31:33Z","title":"Large-scale unsupervised audio pre-training for video-to-speech\n  synthesis","summary":"  Video-to-speech synthesis is the task of reconstructing the speech signal\nfrom a silent video of a speaker. Most established approaches to date involve a\ntwo-step process, whereby an intermediate representation from the video, such\nas a spectrogram, is extracted first and then passed to a vocoder to produce\nthe raw audio. Some recent work has focused on end-to-end synthesis, whereby\nthe generation of raw audio and any intermediate representations is performed\njointly. All such approaches involve training on data from almost exclusively\naudio-visual datasets, i.e. every audio sample has a corresponding video\nsample. This precludes the use of abundant audio-only datasets which may not\nhave a corresponding visual modality (e.g. audiobooks, radio podcasts, speech\nrecognition datasets etc.), as well as audio-only architectures that have been\ndeveloped by the audio machine learning community over the years. In this paper\nwe propose to train encoder-decoder models on more than 3,500 hours of audio\ndata at 24kHz, and then use the pre-trained decoders to initialize the audio\ndecoders for the video-to-speech synthesis task. The pre-training step uses\naudio samples only and does not require labels or corresponding samples from\nother modalities (visual, text). We demonstrate that this pre-training step\nimproves the reconstructed speech and that it is an unexplored way to improve\nthe quality of the generator in a cross-modal task while only requiring samples\nfrom one of the modalities. We conduct experiments using both raw audio and mel\nspectrograms as target outputs and benchmark our models with existing work.\n","authors":["Triantafyllos Kefalas","Yannis Panagakis","Maja Pantic"],"pdf_url":"https://arxiv.org/pdf/2306.15464v1.pdf","comment":"Submitted to IEEE"},{"id":"http://arxiv.org/abs/2305.13108v3","updated":"2023-06-27T13:19:19Z","published":"2023-05-22T15:09:27Z","title":"Debiased Automatic Speech Recognition for Dysarthric Speech via Sample\n  Reweighting with Sample Affinity Test","summary":"  Automatic speech recognition systems based on deep learning are mainly\ntrained under empirical risk minimization (ERM). Since ERM utilizes the\naveraged performance on the data samples regardless of a group such as healthy\nor dysarthric speakers, ASR systems are unaware of the performance disparities\nacross the groups. This results in biased ASR systems whose performance\ndifferences among groups are severe. In this study, we aim to improve the ASR\nsystem in terms of group robustness for dysarthric speakers. To achieve our\ngoal, we present a novel approach, sample reweighting with sample affinity test\n(Re-SAT). Re-SAT systematically measures the debiasing helpfulness of the given\ndata sample and then mitigates the bias by debiasing helpfulness-based sample\nreweighting. Experimental results demonstrate that Re-SAT contributes to\nimproved ASR performance on dysarthric speech without performance degradation\non healthy speech.\n","authors":["Eungbeom Kim","Yunkee Chae","Jaeheon Sim","Kyogu Lee"],"pdf_url":"https://arxiv.org/pdf/2305.13108v3.pdf","comment":"Accepted by Interspeech 2023"},{"id":"http://arxiv.org/abs/2305.17760v3","updated":"2023-06-27T13:16:42Z","published":"2023-05-28T16:04:48Z","title":"Language Models are Bounded Pragmatic Speakers","summary":"  How do language models \"think\"? This paper formulates a probabilistic\ncognitive model called the bounded pragmatic speaker, which can characterize\nthe operation of different variations of language models. Specifically, we\ndemonstrate that large language models fine-tuned with reinforcement learning\nfrom human feedback (Ouyang et al., 2022) embody a model of thought that\nconceptually resembles a fast-and-slow model (Kahneman, 2011), which\npsychologists have attributed to humans. We discuss the limitations of\nreinforcement learning from human feedback as a fast-and-slow model of thought\nand propose avenues for expanding this framework. In essence, our research\nhighlights the value of adopting a cognitive probabilistic modeling approach to\ngain insights into the comprehension, evaluation, and advancement of language\nmodels.\n","authors":["Khanh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2305.17760v3.pdf","comment":"Proceedings of the First Workshop on Theory of Mind in Communicating\n  Agents at (TOM @ ICML 2023)"},{"id":"http://arxiv.org/abs/2302.04658v2","updated":"2023-06-27T13:09:05Z","published":"2023-02-09T14:20:14Z","title":"The Sample Complexity of Approximate Rejection Sampling with\n  Applications to Smoothed Online Learning","summary":"  Suppose we are given access to $n$ independent samples from distribution\n$\\mu$ and we wish to output one of them with the goal of making the output\ndistributed as close as possible to a target distribution $\\nu$. In this work\nwe show that the optimal total variation distance as a function of $n$ is given\nby $\\tilde\\Theta(\\frac{D}{f'(n)})$ over the class of all pairs $\\nu,\\mu$ with a\nbounded $f$-divergence $D_f(\\nu\\|\\mu)\\leq D$. Previously, this question was\nstudied only for the case when the Radon-Nikodym derivative of $\\nu$ with\nrespect to $\\mu$ is uniformly bounded. We then consider an application in the\nseemingly very different field of smoothed online learning, where we show that\nrecent results on the minimax regret and the regret of oracle-efficient\nalgorithms still hold even under relaxed constraints on the adversary (to have\nbounded $f$-divergence, as opposed to bounded Radon-Nikodym derivative).\nFinally, we also study efficacy of importance sampling for mean estimates\nuniform over a function class and compare importance sampling with rejection\nsampling.\n","authors":["Adam Block","Yury Polyanskiy"],"pdf_url":"https://arxiv.org/pdf/2302.04658v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13442v2","updated":"2023-06-27T13:01:26Z","published":"2023-06-23T11:12:33Z","title":"Minibatch training of neural network ensembles via trajectory sampling","summary":"  Most iterative neural network training methods use estimates of the loss\nfunction over small random subsets (or minibatches) of the data to update the\nparameters, which aid in decoupling the training time from the (often very\nlarge) size of the training datasets. Here, we show that a minibatch approach\ncan also be used to train neural network ensembles (NNEs) via trajectory\nmethods in a highly efficient manner. We illustrate this approach by training\nNNEs to classify images in the MNIST datasets. This method gives an improvement\nto the training times, allowing it to scale as the ratio of the size of the\ndataset to that of the average minibatch size which, in the case of MNIST,\ngives a computational improvement typically of two orders of magnitude. We\nhighlight the advantage of using longer trajectories to represent NNEs, both\nfor improved accuracy in inference and reduced update cost in terms of the\nsamples needed in minibatch updates.\n","authors":["Jamie F. Mair","Luke Causer","Juan P. Garrahan"],"pdf_url":"https://arxiv.org/pdf/2306.13442v2.pdf","comment":"11 pages, 4 figures, 1 algorithm"},{"id":"http://arxiv.org/abs/2306.15444v1","updated":"2023-06-27T12:59:56Z","published":"2023-06-27T12:59:56Z","title":"Limited-Memory Greedy Quasi-Newton Method with Non-asymptotic\n  Superlinear Convergence Rate","summary":"  Non-asymptotic convergence analysis of quasi-Newton methods has gained\nattention with a landmark result establishing an explicit superlinear rate of\nO$((1/\\sqrt{t})^t)$. The methods that obtain this rate, however, exhibit a\nwell-known drawback: they require the storage of the previous Hessian\napproximation matrix or instead storing all past curvature information to form\nthe current Hessian inverse approximation. Limited-memory variants of\nquasi-Newton methods such as the celebrated L-BFGS alleviate this issue by\nleveraging a limited window of past curvature information to construct the\nHessian inverse approximation. As a result, their per iteration complexity and\nstorage requirement is O$(\\tau d)$ where $\\tau \\le d$ is the size of the window\nand $d$ is the problem dimension reducing the O$(d^2)$ computational cost and\nmemory requirement of standard quasi-Newton methods. However, to the best of\nour knowledge, there is no result showing a non-asymptotic superlinear\nconvergence rate for any limited-memory quasi-Newton method. In this work, we\nclose this gap by presenting a limited-memory greedy BFGS (LG-BFGS) method that\nachieves an explicit non-asymptotic superlinear rate. We incorporate\ndisplacement aggregation, i.e., decorrelating projection, in post-processing\ngradient variations, together with a basis vector selection scheme on variable\nvariations, which greedily maximizes a progress measure of the Hessian estimate\nto the true Hessian. Their combination allows past curvature information to\nremain in a sparse subspace while yielding a valid representation of the full\nhistory. Interestingly, our established non-asymptotic superlinear convergence\nrate demonstrates a trade-off between the convergence speed and memory\nrequirement, which to our knowledge, is the first of its kind. Numerical\nresults corroborate our theoretical findings and demonstrate the effectiveness\nof our method.\n","authors":["Zhan Gao","Aryan Mokhtari","Alec Koppel"],"pdf_url":"https://arxiv.org/pdf/2306.15444v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06561v2","updated":"2023-06-27T12:58:29Z","published":"2023-06-11T02:25:15Z","title":"Learning World Models with Identifiable Factorization","summary":"  Extracting a stable and compact representation of the environment is crucial\nfor efficient reinforcement learning in high-dimensional, noisy, and\nnon-stationary environments. Different categories of information coexist in\nsuch environments -- how to effectively extract and disentangle these\ninformation remains a challenging problem. In this paper, we propose IFactor, a\ngeneral framework to model four distinct categories of latent state variables\nthat capture various aspects of information within the RL system, based on\ntheir interactions with actions and rewards. Our analysis establishes\nblock-wise identifiability of these latent variables, which not only provides a\nstable and compact representation but also discloses that all reward-relevant\nfactors are significant for policy learning. We further present a practical\napproach to learning the world model with identifiable blocks, ensuring the\nremoval of redundants but retaining minimal and sufficient information for\npolicy optimization. Experiments in synthetic worlds demonstrate that our\nmethod accurately identifies the ground-truth latent variables, substantiating\nour theoretical findings. Moreover, experiments in variants of the DeepMind\nControl Suite and RoboDesk showcase the superior performance of our approach\nover baselines.\n","authors":["Yu-Ren Liu","Biwei Huang","Zhengmao Zhu","Honglong Tian","Mingming Gong","Yang Yu","Kun Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.06561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05866v3","updated":"2023-06-27T12:57:25Z","published":"2022-12-12T13:09:46Z","title":"Measuring the Driving Forces of Predictive Performance: Application to\n  Credit Scoring","summary":"  In credit scoring, machine learning models are known to outperform standard\nparametric models. As they condition access to credit, banking supervisors and\ninternal model validation teams need to monitor their predictive performance\nand to identify the features with the highest impact on performance. To\nfacilitate this, we introduce the XPER methodology to decompose a performance\nmetric (e.g., AUC, $R^2$) into specific contributions associated with the\nvarious features of a classification or regression model. XPER is theoretically\ngrounded on Shapley values and is both model-agnostic and performance\nmetric-agnostic. Furthermore, it can be implemented either at the model level\nor at the individual level. Using a novel dataset of car loans, we decompose\nthe AUC of a machine-learning model trained to forecast the default probability\nof loan applicants. We show that a small number of features can explain a\nsurprisingly large part of the model performance. Furthermore, we find that the\nfeatures that contribute the most to the predictive performance of the model\nmay not be the ones that contribute the most to individual forecasts (SHAP). We\nalso show how XPER can be used to deal with heterogeneity issues and\nsignificantly boost out-of-sample performance.\n","authors":["Hué Sullivan","Hurlin Christophe","Pérignon Christophe","Saurin Sébastien"],"pdf_url":"https://arxiv.org/pdf/2212.05866v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15437v1","updated":"2023-06-27T12:53:14Z","published":"2023-06-27T12:53:14Z","title":"On-device modeling of user's social context and familiar places from\n  smartphone-embedded sensor data","summary":"  Context modeling and recognition are crucial for adaptive mobile and\nubiquitous computing. Context-awareness in mobile environments relies on prompt\nreactions to context changes. However, current solutions focus on limited\ncontext information processed on centralized architectures, risking privacy\nleakage and lacking personalization. On-device context modeling and recognition\nare emerging research trends, addressing these concerns. Social interactions\nand visited locations play significant roles in characterizing daily life\nscenarios. This paper proposes an unsupervised and lightweight approach to\nmodel the user's social context and locations directly on the mobile device.\nLeveraging the ego-network model, the system extracts high-level, semantic-rich\ncontext features from smartphone-embedded sensor data. For the social context,\nthe approach utilizes data on physical and cyber social interactions among\nusers and their devices. Regarding location, it prioritizes modeling the\nfamiliarity degree of specific locations over raw location data, such as GPS\ncoordinates and proximity devices. The effectiveness of the proposed approach\nis demonstrated through three sets of experiments, employing five real-world\ndatasets. These experiments evaluate the structure of social and location ego\nnetworks, provide a semantic evaluation of the proposed models, and assess\nmobile computing performance. Finally, the relevance of the extracted features\nis showcased by the improved performance of three machine learning models in\nrecognizing daily-life situations. Compared to using only features related to\nphysical context, the proposed approach achieves a 3% improvement in AUROC, 9%\nin Precision, and 5% in Recall.\n","authors":["Mattia Giovanni Campana","Franca Delmastro"],"pdf_url":"https://arxiv.org/pdf/2306.15437v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15427v1","updated":"2023-06-27T12:38:11Z","published":"2023-06-27T12:38:11Z","title":"Adversarial Training for Graph Neural Networks","summary":"  Despite its success in the image domain, adversarial training does not (yet)\nstand out as an effective defense for Graph Neural Networks (GNNs) against\ngraph structure perturbations. In the pursuit of fixing adversarial training\n(1) we show and overcome fundamental theoretical as well as practical\nlimitations of the adopted graph learning setting in prior work; (2) we reveal\nthat more flexible GNNs based on learnable graph diffusion are able to adjust\nto adversarial perturbations, while the learned message passing scheme is\nnaturally interpretable; (3) we introduce the first attack for structure\nperturbations that, while targeting multiple nodes at once, is capable of\nhandling global (graph-level) as well as local (node-level) constraints.\nIncluding these contributions, we demonstrate that adversarial training is a\nstate-of-the-art defense against adversarial structure perturbations.\n","authors":["Lukas Gosch","Simon Geisler","Daniel Sturm","Bertrand Charpentier","Daniel Zügner","Stephan Günnemann"],"pdf_url":"https://arxiv.org/pdf/2306.15427v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00773v3","updated":"2023-06-27T12:36:32Z","published":"2023-02-01T22:05:04Z","title":"Toward Physically Plausible Data-Driven Models: A Novel Neural Network\n  Approach to Symbolic Regression","summary":"  Many real-world systems can be described by mathematical models that are\nhuman-comprehensible, easy to analyze and help explain the system's behavior.\nSymbolic regression is a method that can automatically generate such models\nfrom data. Historically, symbolic regression has been predominantly realized by\ngenetic programming, a method that evolves populations of candidate solutions\nthat are subsequently modified by genetic operators crossover and mutation.\nHowever, this approach suffers from several deficiencies: it does not scale\nwell with the number of variables and samples in the training data - models\ntend to grow in size and complexity without an adequate accuracy gain, and it\nis hard to fine-tune the model coefficients using just genetic operators.\nRecently, neural networks have been applied to learn the whole analytic model,\ni.e., its structure and the coefficients, using gradient-based optimization\nalgorithms. This paper proposes a novel neural network-based symbolic\nregression method that constructs physically plausible models based on even\nvery small training data sets and prior knowledge about the system. The method\nemploys an adaptive weighting scheme to effectively deal with multiple loss\nfunction terms and an epoch-wise learning process to reduce the chance of\ngetting stuck in poor local optima. Furthermore, we propose a parameter-free\nmethod for choosing the model with the best interpolation and extrapolation\nperformance out of all the models generated throughout the whole learning\nprocess. We experimentally evaluate the approach on four test systems: the\nTurtleBot 2 mobile robot, the magnetic manipulation system, the equivalent\nresistance of two resistors in parallel, and the longitudinal force of the\nanti-lock braking system. The results clearly show the potential of the method\nto find parsimonious models that comply with the prior knowledge provided.\n","authors":["Jiří Kubalík","Erik Derner","Robert Babuška"],"pdf_url":"https://arxiv.org/pdf/2302.00773v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00615v2","updated":"2023-06-27T12:10:38Z","published":"2023-02-01T17:29:43Z","title":"GFlowNets for AI-Driven Scientific Discovery","summary":"  Tackling the most pressing problems for humanity, such as the climate crisis\nand the threat of global pandemics, requires accelerating the pace of\nscientific discovery. While science has traditionally relied on trial and error\nand even serendipity to a large extent, the last few decades have seen a surge\nof data-driven scientific discoveries. However, in order to truly leverage\nlarge-scale data sets and high-throughput experimental setups, machine learning\nmethods will need to be further improved and better integrated in the\nscientific discovery pipeline. A key challenge for current machine learning\nmethods in this context is the efficient exploration of very large search\nspaces, which requires techniques for estimating reducible (epistemic)\nuncertainty and generating sets of diverse and informative experiments to\nperform. This motivated a new probabilistic machine learning framework called\nGFlowNets, which can be applied in the modeling, hypotheses generation and\nexperimental design stages of the experimental science loop. GFlowNets learn to\nsample from a distribution given indirectly by a reward function corresponding\nto an unnormalized probability, which enables sampling diverse, high-reward\ncandidates. GFlowNets can also be used to form efficient and amortized Bayesian\nposterior estimators for causal models conditioned on the already acquired\nexperimental data. Having such posterior models can then provide estimators of\nepistemic uncertainty and information gain that can drive an experimental\ndesign policy. Altogether, here we will argue that GFlowNets can become a\nvaluable tool for AI-driven scientific discovery, especially in scenarios of\nvery large candidate spaces where we have access to cheap but inaccurate\nmeasurements or to expensive but accurate measurements. This is a common\nsetting in the context of drug and material discovery, which we use as examples\nthroughout the paper.\n","authors":["Moksh Jain","Tristan Deleu","Jason Hartford","Cheng-Hao Liu","Alex Hernandez-Garcia","Yoshua Bengio"],"pdf_url":"https://arxiv.org/pdf/2302.00615v2.pdf","comment":"31 pages, 5 figures. Updated with camera-ready changes"},{"id":"http://arxiv.org/abs/2306.15403v1","updated":"2023-06-27T12:02:25Z","published":"2023-06-27T12:02:25Z","title":"Verifying Safety of Neural Networks from Topological Perspectives","summary":"  Neural networks (NNs) are increasingly applied in safety-critical systems\nsuch as autonomous vehicles. However, they are fragile and are often\nill-behaved. Consequently, their behaviors should undergo rigorous guarantees\nbefore deployment in practice. In this paper, we propose a set-boundary\nreachability method to investigate the safety verification problem of NNs from\na topological perspective. Given an NN with an input set and a safe set, the\nsafety verification problem is to determine whether all outputs of the NN\nresulting from the input set fall within the safe set. In our method, the\nhomeomorphism property and the open map property of NNs are mainly exploited,\nwhich establish rigorous guarantees between the boundaries of the input set and\nthe boundaries of the output set. The exploitation of these two properties\nfacilitates reachability computations via extracting subsets of the input set\nrather than the entire input set, thus controlling the wrapping effect in\nreachability analysis and facilitating the reduction of computation burdens for\nsafety verification. The homeomorphism property exists in some widely used NNs\nsuch as invertible residual networks (i-ResNets) and Neural ordinary\ndifferential equations (Neural ODEs), and the open map is a less strict\nproperty and easier to satisfy compared with the homeomorphism property. For\nNNs establishing either of these properties, our set-boundary reachability\nmethod only needs to perform reachability analysis on the boundary of the input\nset. Moreover, for NNs that do not feature these properties with respect to the\ninput set, we explore subsets of the input set for establishing the local\nhomeomorphism property and then abandon these subsets for reachability\ncomputations. Finally, some examples demonstrate the performance of the\nproposed method.\n","authors":["Zhen Liang","Dejin Ren","Bai Xue","Ji Wang","Wenjing Yang","Wanwei Liu"],"pdf_url":"https://arxiv.org/pdf/2306.15403v1.pdf","comment":"25 pages, 11 figures. arXiv admin note: substantial text overlap with\n  arXiv:2210.04175"},{"id":"http://arxiv.org/abs/2306.11375v3","updated":"2023-06-27T12:02:21Z","published":"2023-06-20T08:31:24Z","title":"Top-down machine learning of coarse-grained protein force-fields","summary":"  Developing accurate and efficient coarse-grained representations of proteins\nis crucial for understanding their folding, function, and interactions over\nextended timescales. Our methodology involves simulating proteins with\nmolecular dynamics and utilizing the resulting trajectories to train a neural\nnetwork potential through differentiable trajectory reweighting. Remarkably,\nthis method requires only the native conformation of proteins, eliminating the\nneed for labeled data derived from extensive simulations or memory-intensive\nend-to-end differentiable simulations. Once trained, the model can be employed\nto run parallel molecular dynamics simulations and sample folding events for\nproteins both within and beyond the training distribution, showcasing its\nextrapolation capabilities. By applying Markov State Models, native-like\nconformations of the simulated proteins can be predicted from the\ncoarse-grained simulations. Owing to its theoretical transferability and\nability to use solely experimental static structures as training data, we\nanticipate that this approach will prove advantageous for developing new\nprotein force fields and further advancing the study of protein dynamics,\nfolding, and interactions.\n","authors":["Carles Navarro","Maciej Majewski","Gianni de Fabritiis"],"pdf_url":"https://arxiv.org/pdf/2306.11375v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15400v1","updated":"2023-06-27T11:53:25Z","published":"2023-06-27T11:53:25Z","title":"Length Generalization in Arithmetic Transformers","summary":"  We examine how transformers cope with two challenges: learning basic integer\narithmetic, and generalizing to longer sequences than seen during training. We\nfind that relative position embeddings enable length generalization for simple\ntasks, such as addition: models trained on $5$-digit numbers can perform\n$15$-digit sums. However, this method fails for multiplication, and we propose\ntrain set priming: adding a few ($10$ to $50$) long sequences to the training\nset. We show that priming allows models trained on $5$-digit $\\times$ $3$-digit\nmultiplications to generalize to $35\\times 3$ examples. We also show that\nmodels can be primed for different generalization lengths, and that the priming\nsample size scales as the logarithm of the training set size. Finally, we\ndiscuss potential applications of priming beyond arithmetic.\n","authors":["Samy Jelassi","Stéphane d'Ascoli","Carles Domingo-Enrich","Yuhuai Wu","Yuanzhi Li","François Charton"],"pdf_url":"https://arxiv.org/pdf/2306.15400v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15392v1","updated":"2023-06-27T11:33:31Z","published":"2023-06-27T11:33:31Z","title":"Assessing Dataset Quality Through Decision Tree Characteristics in\n  Autoencoder-Processed Spaces","summary":"  In this paper, we delve into the critical aspect of dataset quality\nassessment in machine learning classification tasks. Leveraging a variety of\nnine distinct datasets, each crafted for classification tasks with varying\ncomplexity levels, we illustrate the profound impact of dataset quality on\nmodel training and performance. We further introduce two additional datasets\ndesigned to represent specific data conditions - one maximizing entropy and the\nother demonstrating high redundancy. Our findings underscore the importance of\nappropriate feature selection, adequate data volume, and data quality in\nachieving high-performing machine learning models. To aid researchers and\npractitioners, we propose a comprehensive framework for dataset quality\nassessment, which can help evaluate if the dataset at hand is sufficient and of\nthe required quality for specific tasks. This research offers valuable insights\ninto data assessment practices, contributing to the development of more\naccurate and robust machine learning models.\n","authors":["Szymon Mazurek","Maciej Wielgosz"],"pdf_url":"https://arxiv.org/pdf/2306.15392v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14435v2","updated":"2023-06-27T11:30:16Z","published":"2023-06-26T06:04:09Z","title":"DragDiffusion: Harnessing Diffusion Models for Interactive Point-based\n  Image Editing","summary":"  Precise and controllable image editing is a challenging task that has\nattracted significant attention. Recently, DragGAN enables an interactive\npoint-based image editing framework and achieves impressive editing results\nwith pixel-level precision. However, since this method is based on generative\nadversarial networks (GAN), its generality is upper-bounded by the capacity of\nthe pre-trained GAN models. In this work, we extend such an editing framework\nto diffusion models and propose DragDiffusion. By leveraging large-scale\npretrained diffusion models, we greatly improve the applicability of\ninteractive point-based editing in real world scenarios. While most existing\ndiffusion-based image editing methods work on text embeddings, DragDiffusion\noptimizes the diffusion latent to achieve precise spatial control. Although\ndiffusion models generate images in an iterative manner, we empirically show\nthat optimizing diffusion latent at one single step suffices to generate\ncoherent results, enabling DragDiffusion to complete high-quality editing\nefficiently. Extensive experiments across a wide range of challenging cases\n(e.g., multi-objects, diverse object categories, various styles, etc.)\ndemonstrate the versatility and generality of DragDiffusion.\n","authors":["Yujun Shi","Chuhui Xue","Jiachun Pan","Wenqing Zhang","Vincent Y. F. Tan","Song Bai"],"pdf_url":"https://arxiv.org/pdf/2306.14435v2.pdf","comment":"Preliminary version. Work in Progress"},{"id":"http://arxiv.org/abs/2306.15389v1","updated":"2023-06-27T11:27:55Z","published":"2023-06-27T11:27:55Z","title":"Multi-perspective Information Fusion Res2Net with RandomSpecmix for Fake\n  Speech Detection","summary":"  In this paper, we propose the multi-perspective information fusion (MPIF)\nRes2Net with random Specmix for fake speech detection (FSD). The main purpose\nof this system is to improve the model's ability to learn precise forgery\ninformation for FSD task in low-quality scenarios. The task of random Specmix,\na data augmentation, is to improve the generalization ability of the model and\nenhance the model's ability to locate discriminative information. Specmix cuts\nand pastes the frequency dimension information of the spectrogram in the same\nbatch of samples without introducing other data, which helps the model to\nlocate the really useful information. At the same time, we randomly select\nsamples for augmentation to reduce the impact of data augmentation directly\nchanging all the data. Once the purpose of helping the model to locate\ninformation is achieved, it is also important to reduce unnecessary\ninformation. The role of MPIF-Res2Net is to reduce redundant interference\ninformation. Deceptive information from a single perspective is always similar,\nso the model learning this similar information will produce redundant spoofing\nclues and interfere with truly discriminative information. The proposed\nMPIF-Res2Net fuses information from different perspectives, making the\ninformation learned by the model more diverse, thereby reducing the redundancy\ncaused by similar information and avoiding interference with the learning of\ndiscriminative information. The results on the ASVspoof 2021 LA dataset\ndemonstrate the effectiveness of our proposed method, achieving EER and\nmin-tDCF of 3.29% and 0.2557, respectively.\n","authors":["Shunbo Dong","Jun Xue","Cunhang Fan","Kang Zhu","Yujie Chen","Zhao Lv"],"pdf_url":"https://arxiv.org/pdf/2306.15389v1.pdf","comment":"Accepted by DADA2023"},{"id":"http://arxiv.org/abs/2306.15374v1","updated":"2023-06-27T10:46:36Z","published":"2023-06-27T10:46:36Z","title":"LeCo: Lightweight Compression via Learning Serial Correlations","summary":"  Lightweight data compression is a key technique that allows column stores to\nexhibit superior performance for analytical queries. Despite a comprehensive\nstudy on dictionary-based encodings to approach Shannon's entropy, few prior\nworks have systematically exploited the serial correlation in a column for\ncompression. In this paper, we propose LeCo (i.e., Learned Compression), a\nframework that uses machine learning to remove the serial redundancy in a value\nsequence automatically to achieve an outstanding compression ratio and\ndecompression performance simultaneously. LeCo presents a general approach to\nthis end, making existing (ad-hoc) algorithms such as Frame-of-Reference (FOR),\nDelta Encoding, and Run-Length Encoding (RLE) special cases under our\nframework. Our microbenchmark with three synthetic and six real-world data sets\nshows that a prototype of LeCo achieves a Pareto improvement on both\ncompression ratio and random access speed over the existing solutions. When\nintegrating LeCo into widely-used applications, we observe up to 3.9x speed up\nin filter-scanning a Parquet file and a 16% increase in Rocksdb's throughput.\n","authors":["Yihao Liu","Xinyu Zeng","Huanchen Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.15374v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.10404v3","updated":"2023-06-27T10:37:55Z","published":"2023-06-17T18:16:51Z","title":"The RL Perceptron: Generalisation Dynamics of Policy Learning in High\n  Dimensions","summary":"  Reinforcement learning (RL) algorithms have proven transformative in a range\nof domains. To tackle real-world domains, these systems often use neural\nnetworks to learn policies directly from pixels or other high-dimensional\nsensory input. By contrast, much theory of RL has focused on discrete state\nspaces or worst-case analysis, and fundamental questions remain about the\ndynamics of policy learning in high-dimensional settings. Here, we propose a\nsolvable high-dimensional model of RL that can capture a variety of learning\nprotocols, and derive its typical dynamics as a set of closed-form ordinary\ndifferential equations (ODEs). We derive optimal schedules for the learning\nrates and task difficulty - analogous to annealing schemes and curricula during\ntraining in RL - and show that the model exhibits rich behaviour, including\ndelayed learning under sparse rewards; a variety of learning regimes depending\non reward baselines; and a speed-accuracy trade-off driven by reward\nstringency. Experiments on variants of the Procgen game \"Bossfight\" and Arcade\nLearning Environment game \"Pong\" also show such a speed-accuracy trade-off in\npractice. Together, these results take a step towards closing the gap between\ntheory and practice in high-dimensional RL.\n","authors":["Nishil Patel","Sebastian Lee","Stefano Sarao Mannelli","Sebastian Goldt","Adrew Saxe"],"pdf_url":"https://arxiv.org/pdf/2306.10404v3.pdf","comment":"10 pages, 7 figures, Preprint"},{"id":"http://arxiv.org/abs/2306.11182v2","updated":"2023-06-27T10:37:34Z","published":"2023-06-19T22:12:37Z","title":"Co-design Hardware and Algorithm for Vector Search","summary":"  Vector search has emerged as the foundation for large-scale information\nretrieval and machine learning systems, with search engines like Google and\nBing processing tens of thousands of queries per second on petabyte-scale\ndocument datasets by evaluating vector similarities between encoded query texts\nand web documents. As performance demands for vector search systems surge,\naccelerated hardware offers a promising solution in the post-Moore's Law era.\nWe introduce \\textit{FANNS}, an end-to-end and scalable vector search framework\non FPGAs. Given a user-provided recall requirement on a dataset and a hardware\nresource budget, \\textit{FANNS} automatically co-designs hardware and\nalgorithm, subsequently generating the corresponding accelerator. The framework\nalso supports scale-out by incorporating a hardware TCP/IP stack in the\naccelerator. \\textit{FANNS} attains up to 23.0$\\times$ and 37.2$\\times$ speedup\ncompared to FPGA and CPU baselines, respectively, and demonstrates superior\nscalability to GPUs, achieving 5.5$\\times$ and 7.6$\\times$ speedup in median\nand 95\\textsuperscript{th} percentile (P95) latency within an eight-accelerator\nconfiguration. The remarkable performance of \\textit{FANNS} lays a robust\ngroundwork for future FPGA integration in data centers and AI supercomputers.\n","authors":["Wenqi Jiang","Shigang Li","Yu Zhu","Johannes de Fine Licht","Zhenhao He","Runbin Shi","Cedric Renggli","Shuai Zhang","Theodoros Rekatsinas","Torsten Hoefler","Gustavo Alonso"],"pdf_url":"https://arxiv.org/pdf/2306.11182v2.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2306.15369v1","updated":"2023-06-27T10:35:18Z","published":"2023-06-27T10:35:18Z","title":"A Meta-analytical Comparison of Naive Bayes and Random Forest for\n  Software Defect Prediction","summary":"  Is there a statistical difference between Naive Bayes and Random Forest in\nterms of recall, f-measure, and precision for predicting software defects? By\nutilizing systematic literature review and meta-analysis, we are answering this\nquestion. We conducted a systematic literature review by establishing criteria\nto search and choose papers, resulting in five studies. After that, using the\nmeta-data and forest-plots of five chosen papers, we conducted a meta-analysis\nto compare the two models. The results have shown that there is no significant\nstatistical evidence that Naive Bayes perform differently from Random Forest in\nterms of recall, f-measure, and precision.\n","authors":["Ch Muhammad Awais","Wei Gu","Gcinizwe Dlamini","Zamira Kholmatova","Giancarlo Succi"],"pdf_url":"https://arxiv.org/pdf/2306.15369v1.pdf","comment":"11 pages, 8 figures, Conference Paper"},{"id":"http://arxiv.org/abs/2306.15368v1","updated":"2023-06-27T10:33:37Z","published":"2023-06-27T10:33:37Z","title":"Mean Field Theory in Deep Metric Learning","summary":"  In this paper, we explore the application of mean field theory, a technique\nfrom statistical physics, to deep metric learning and address the high training\ncomplexity commonly associated with conventional metric learning loss\nfunctions. By adapting mean field theory for deep metric learning, we develop\nan approach to design classification-based loss functions from pair-based ones,\nwhich can be considered complementary to the proxy-based approach. Applying the\nmean field theory to two pair-based loss functions, we derive two new loss\nfunctions, MeanFieldContrastive and MeanFieldClassWiseMultiSimilarity losses,\nwith reduced training complexity. We extensively evaluate these derived loss\nfunctions on three image-retrieval datasets and demonstrate that our loss\nfunctions outperform baseline methods in two out of the three datasets.\n","authors":["Takuya Furusawa"],"pdf_url":"https://arxiv.org/pdf/2306.15368v1.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2305.16945v2","updated":"2023-06-27T10:21:43Z","published":"2023-05-26T14:00:12Z","title":"Levin Tree Search with Context Models","summary":"  Levin Tree Search (LTS) is a search algorithm that makes use of a policy (a\nprobability distribution over actions) and comes with a theoretical guarantee\non the number of expansions before reaching a goal node, depending on the\nquality of the policy. This guarantee can be used as a loss function, which we\ncall the LTS loss, to optimize neural networks representing the policy\n(LTS+NN). In this work we show that the neural network can be substituted with\nparameterized context models originating from the online compression literature\n(LTS+CM). We show that the LTS loss is convex under this new model, which\nallows for using standard convex optimization tools, and obtain convergence\nguarantees to the optimal parameters in an online setting for a given set of\nsolution trajectories -- guarantees that cannot be provided for neural\nnetworks. The new LTS+CM algorithm compares favorably against LTS+NN on several\nbenchmarks: Sokoban (Boxoban), The Witness, and the 24-Sliding Tile puzzle\n(STP). The difference is particularly large on STP, where LTS+NN fails to solve\nmost of the test instances while LTS+CM solves each test instance in a fraction\nof a second. Furthermore, we show that LTS+CM is able to learn a policy that\nsolves the Rubik's cube in only a few hundred expansions, which considerably\nimproves upon previous machine learning techniques.\n","authors":["Laurent Orseau","Marcus Hutter","Levi H. S. Lelis"],"pdf_url":"https://arxiv.org/pdf/2305.16945v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15363v1","updated":"2023-06-27T10:21:27Z","published":"2023-06-27T10:21:27Z","title":"Your Attack Is Too DUMB: Formalizing Attacker Scenarios for Adversarial\n  Transferability","summary":"  Evasion attacks are a threat to machine learning models, where adversaries\nattempt to affect classifiers by injecting malicious samples. An alarming\nside-effect of evasion attacks is their ability to transfer among different\nmodels: this property is called transferability. Therefore, an attacker can\nproduce adversarial samples on a custom model (surrogate) to conduct the attack\non a victim's organization later. Although literature widely discusses how\nadversaries can transfer their attacks, their experimental settings are limited\nand far from reality. For instance, many experiments consider both attacker and\ndefender sharing the same dataset, balance level (i.e., how the ground truth is\ndistributed), and model architecture.\n  In this work, we propose the DUMB attacker model. This framework allows\nanalyzing if evasion attacks fail to transfer when the training conditions of\nsurrogate and victim models differ. DUMB considers the following conditions:\nDataset soUrces, Model architecture, and the Balance of the ground truth. We\nthen propose a novel testbed to evaluate many state-of-the-art evasion attacks\nwith DUMB; the testbed consists of three computer vision tasks with two\ndistinct datasets each, four types of balance levels, and three model\narchitectures. Our analysis, which generated 13K tests over 14 distinct\nattacks, led to numerous novel findings in the scope of transferable attacks\nwith surrogate models. In particular, mismatches between attackers and victims\nin terms of dataset source, balance levels, and model architecture lead to\nnon-negligible loss of attack performance.\n","authors":["Marco Alecci","Mauro Conti","Francesco Marchiori","Luca Martinelli","Luca Pajola"],"pdf_url":"https://arxiv.org/pdf/2306.15363v1.pdf","comment":"Accepted at RAID 2023"},{"id":"http://arxiv.org/abs/2010.07154v4","updated":"2023-06-27T10:20:45Z","published":"2020-10-14T15:14:49Z","title":"Learning Deep Features in Instrumental Variable Regression","summary":"  Instrumental variable (IV) regression is a standard strategy for learning\ncausal relationships between confounded treatment and outcome variables from\nobservational data by utilizing an instrumental variable, which affects the\noutcome only through the treatment. In classical IV regression, learning\nproceeds in two stages: stage 1 performs linear regression from the instrument\nto the treatment; and stage 2 performs linear regression from the treatment to\nthe outcome, conditioned on the instrument. We propose a novel method, deep\nfeature instrumental variable regression (DFIV), to address the case where\nrelations between instruments, treatments, and outcomes may be nonlinear. In\nthis case, deep neural nets are trained to define informative nonlinear\nfeatures on the instruments and treatments. We propose an alternating training\nregime for these features to ensure good end-to-end performance when composing\nstages 1 and 2, thus obtaining highly flexible feature maps in a\ncomputationally efficient manner. DFIV outperforms recent state-of-the-art\nmethods on challenging IV benchmarks, including settings involving high\ndimensional image data. DFIV also exhibits competitive performance in\noff-policy policy evaluation for reinforcement learning, which can be\nunderstood as an IV regression task.\n","authors":["Liyuan Xu","Yutian Chen","Siddarth Srinivasan","Nando de Freitas","Arnaud Doucet","Arthur Gretton"],"pdf_url":"https://arxiv.org/pdf/2010.07154v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15350v1","updated":"2023-06-27T10:03:15Z","published":"2023-06-27T10:03:15Z","title":"CellViT: Vision Transformers for Precise Cell Segmentation and\n  Classification","summary":"  Nuclei detection and segmentation in hematoxylin and eosin-stained (H&E)\ntissue images are important clinical tasks and crucial for a wide range of\napplications. However, it is a challenging task due to nuclei variances in\nstaining and size, overlapping boundaries, and nuclei clustering. While\nconvolutional neural networks have been extensively used for this task, we\nexplore the potential of Transformer-based networks in this domain. Therefore,\nwe introduce a new method for automated instance segmentation of cell nuclei in\ndigitized tissue samples using a deep learning architecture based on Vision\nTransformer called CellViT. CellViT is trained and evaluated on the PanNuke\ndataset, which is one of the most challenging nuclei instance segmentation\ndatasets, consisting of nearly 200,000 annotated Nuclei into 5 clinically\nimportant classes in 19 tissue types. We demonstrate the superiority of\nlarge-scale in-domain and out-of-domain pre-trained Vision Transformers by\nleveraging the recently published Segment Anything Model and a ViT-encoder\npre-trained on 104 million histological image patches - achieving\nstate-of-the-art nuclei detection and instance segmentation performance on the\nPanNuke dataset with a mean panoptic quality of 0.51 and an F1-detection score\nof 0.83. The code is publicly available at https://github.com/TIO-IKIM/CellViT\n","authors":["Fabian Hörst","Moritz Rempe","Lukas Heine","Constantin Seibold","Julius Keyl","Giulia Baldini","Selma Ugurel","Jens Siveke","Barbara Grünwald","Jan Egger","Jens Kleesiek"],"pdf_url":"https://arxiv.org/pdf/2306.15350v1.pdf","comment":"13 pages, 5 figures, appendix included"},{"id":"http://arxiv.org/abs/2306.15347v1","updated":"2023-06-27T10:00:06Z","published":"2023-06-27T10:00:06Z","title":"FedET: A Communication-Efficient Federated Class-Incremental Learning\n  Framework Based on Enhanced Transformer","summary":"  Federated Learning (FL) has been widely concerned for it enables\ndecentralized learning while ensuring data privacy. However, most existing\nmethods unrealistically assume that the classes encountered by local clients\nare fixed over time. After learning new classes, this assumption will make the\nmodel's catastrophic forgetting of old classes significantly severe. Moreover,\ndue to the limitation of communication cost, it is challenging to use\nlarge-scale models in FL, which will affect the prediction accuracy. To address\nthese challenges, we propose a novel framework, Federated Enhanced Transformer\n(FedET), which simultaneously achieves high accuracy and low communication\ncost. Specifically, FedET uses Enhancer, a tiny module, to absorb and\ncommunicate new knowledge, and applies pre-trained Transformers combined with\ndifferent Enhancers to ensure high precision on various tasks. To address local\nforgetting caused by new classes of new tasks and global forgetting brought by\nnon-i.i.d (non-independent and identically distributed) class imbalance across\ndifferent local clients, we proposed an Enhancer distillation method to modify\nthe imbalance between old and new knowledge and repair the non-i.i.d. problem.\nExperimental results demonstrate that FedET's average accuracy on\nrepresentative benchmark datasets is 14.1% higher than the state-of-the-art\nmethod, while FedET saves 90% of the communication cost compared to the\nprevious method.\n","authors":["Chenghao Liu","Xiaoyang Qu","Jianzong Wang","Jing Xiao"],"pdf_url":"https://arxiv.org/pdf/2306.15347v1.pdf","comment":"Accepted by 2023 International Joint Conference on Artificial\n  Intelligence (IJCAI2023)"},{"id":"http://arxiv.org/abs/2306.13793v2","updated":"2023-06-27T09:59:31Z","published":"2023-06-23T21:40:24Z","title":"QNNRepair: Quantized Neural Network Repair","summary":"  We present QNNRepair, the first method in the literature for repairing\nquantized neural networks (QNNs). QNNRepair aims to improve the accuracy of a\nneural network model after quantization. It accepts the full-precision and\nweight-quantized neural networks and a repair dataset of passing and failing\ntests. At first, QNNRepair applies a software fault localization method to\nidentify the neurons that cause performance degradation during neural network\nquantization. Then, it formulates the repair problem into a linear programming\nproblem of solving neuron weights parameters, which corrects the QNN's\nperformance on failing tests while not compromising its performance on passing\ntests. We evaluate QNNRepair with widely used neural network architectures such\nas MobileNetV2, ResNet, and VGGNet on popular datasets, including\nhigh-resolution images. We also compare QNNRepair with the state-of-the-art\ndata-free quantization method SQuant. According to the experiment results, we\nconclude that QNNRepair is effective in improving the quantized model's\nperformance in most cases. Its repaired models have 24% higher accuracy than\nSQuant's in the independent validation set, especially for the ImageNet\ndataset.\n","authors":["Xidan Song","Youcheng Sun","Mustafa A. Mustafa","Lucas C. Cordeiro"],"pdf_url":"https://arxiv.org/pdf/2306.13793v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.07663v2","updated":"2023-06-27T09:56:30Z","published":"2023-04-30T13:53:39Z","title":"Revealing Similar Semantics Inside CNNs: An Interpretable Concept-based\n  Comparison of Feature Spaces","summary":"  Safety-critical applications require transparency in artificial intelligence\n(AI) components, but widely used convolutional neural networks (CNNs) widely\nused for perception tasks lack inherent interpretability. Hence, insights into\nwhat CNNs have learned are primarily based on performance metrics, because\nthese allow, e.g., for cross-architecture CNN comparison. However, these\nneglect how knowledge is stored inside. To tackle this yet unsolved problem,\nour work proposes two methods for estimating the layer-wise similarity between\nsemantic information inside CNN latent spaces. These allow insights into both\nthe flow and likeness of semantic information within CNN layers, and into the\ndegree of their similarity between different network architectures. As a basis,\nwe use two renowned explainable artificial intelligence (XAI) techniques, which\nare used to obtain concept activation vectors, i.e., global vector\nrepresentations in the latent space. These are compared with respect to their\nactivation on test inputs. When applied to three diverse object detectors and\ntwo datasets, our methods reveal that (1) similar semantic concepts are learned\nregardless of the CNN architecture, and (2) similar concepts emerge in similar\nrelative layer depth, independent of the total number of layers. Finally, our\napproach poses a promising step towards semantic model comparability and\ncomprehension of how different CNNs process semantic information.\n","authors":["Georgii Mikriukov","Gesina Schwalbe","Christian Hellert","Korinna Bade"],"pdf_url":"https://arxiv.org/pdf/2305.07663v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15340v1","updated":"2023-06-27T09:50:47Z","published":"2023-06-27T09:50:47Z","title":"A Toolbox for Fast Interval Arithmetic in numpy with an Application to\n  Formal Verification of Neural Network Controlled Systems","summary":"  In this paper, we present a toolbox for interval analysis in numpy, with an\napplication to formal verification of neural network controlled systems. Using\nthe notion of natural inclusion functions, we systematically construct interval\nbounds for a general class of mappings. The toolbox offers efficient\ncomputation of natural inclusion functions using compiled C code, as well as a\nfamiliar interface in numpy with its canonical features, such as n-dimensional\narrays, matrix/vector operations, and vectorization. We then use this toolbox\nin formal verification of dynamical systems with neural network controllers,\nthrough the composition of their inclusion functions.\n","authors":["Akash Harapanahalli","Saber Jafarpour","Samuel Coogan"],"pdf_url":"https://arxiv.org/pdf/2306.15340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15337v1","updated":"2023-06-27T09:46:16Z","published":"2023-06-27T09:46:16Z","title":"Homological Neural Networks: A Sparse Architecture for Multivariate\n  Complexity","summary":"  The rapid progress of Artificial Intelligence research came with the\ndevelopment of increasingly complex deep learning models, leading to growing\nchallenges in terms of computational complexity, energy efficiency and\ninterpretability. In this study, we apply advanced network-based information\nfiltering techniques to design a novel deep neural network unit characterized\nby a sparse higher-order graphical architecture built over the homological\nstructure of underlying data. We demonstrate its effectiveness in two\napplication domains which are traditionally challenging for deep learning:\ntabular data and time series regression problems. Results demonstrate the\nadvantages of this novel design which can tie or overcome the results of\nstate-of-the-art machine learning and deep learning models using only a\nfraction of parameters.\n","authors":["Yuanrong Wang","Antonio Briola","Tomaso Aste"],"pdf_url":"https://arxiv.org/pdf/2306.15337v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.10828v4","updated":"2023-06-27T09:34:34Z","published":"2022-05-22T13:54:44Z","title":"What Do Compressed Multilingual Machine Translation Models Forget?","summary":"  Recently, very large pre-trained models achieve state-of-the-art results in\nvarious natural language processing (NLP) tasks, but their size makes it more\nchallenging to apply them in resource-constrained environments. Compression\ntechniques allow to drastically reduce the size of the models and therefore\ntheir inference time with negligible impact on top-tier metrics. However, the\ngeneral performance averaged across multiple tasks and/or languages may hide a\ndrastic performance drop on under-represented features, which could result in\nthe amplification of biases encoded by the models. In this work, we assess the\nimpact of compression methods on Multilingual Neural Machine Translation models\n(MNMT) for various language groups, gender, and semantic biases by extensive\nanalysis of compressed models on different machine translation benchmarks, i.e.\nFLORES-101, MT-Gender, and DiBiMT. We show that the performance of\nunder-represented languages drops significantly, while the average BLEU metric\nonly slightly decreases. Interestingly, the removal of noisy memorization with\ncompression leads to a significant improvement for some medium-resource\nlanguages. Finally, we demonstrate that compression amplifies intrinsic gender\nand semantic biases, even in high-resource languages. Code:\nhttps://github.com/alirezamshi/bias-compressedMT\n","authors":["Alireza Mohammadshahi","Vassilina Nikoulina","Alexandre Berard","Caroline Brun","James Henderson","Laurent Besacier"],"pdf_url":"https://arxiv.org/pdf/2205.10828v4.pdf","comment":"Accepted to Findings of EMNLP 2022, presented at WMT 2022"},{"id":"http://arxiv.org/abs/2306.15328v1","updated":"2023-06-27T09:34:32Z","published":"2023-06-27T09:34:32Z","title":"Simulating counterfactuals","summary":"  Counterfactual inference considers a hypothetical intervention in a parallel\nworld that shares some evidence with the factual world. If the evidence\nspecifies a conditional distribution on a manifold, counterfactuals may be\nanalytically intractable. We present an algorithm for simulating values from a\ncounterfactual distribution where conditions can be set on both discrete and\ncontinuous variables. We show that the proposed algorithm can be presented as a\nparticle filter leading to asymptotically valid inference. The algorithm is\napplied to fairness analysis in credit scoring.\n","authors":["Juha Karvanen","Santtu Tikka","Matti Vihola"],"pdf_url":"https://arxiv.org/pdf/2306.15328v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.04841v2","updated":"2023-06-27T09:30:19Z","published":"2023-02-09T18:49:13Z","title":"Is This Loss Informative? Faster Text-to-Image Customization by Tracking\n  Objective Dynamics","summary":"  Text-to-image generation models represent the next step of evolution in image\nsynthesis, offering a natural way to achieve flexible yet fine-grained control\nover the result. One emerging area of research is the fast adaptation of large\ntext-to-image models to smaller datasets or new visual concepts. However, many\nefficient methods of adaptation have a long training time, which limits their\npractical applications, slows down research experiments, and spends excessive\nGPU resources. In this work, we study the training dynamics of popular\ntext-to-image personalization methods (such as Textual Inversion or\nDreamBooth), aiming to speed them up. We observe that most concepts are learned\nat early stages and do not improve in quality later, but standard model\nconvergence metrics fail to indicate that. Instead, we propose a simple drop-in\nearly stopping criterion that only requires computing the regular training\nobjective on a fixed set of inputs for all training iterations. Our experiments\non Stable Diffusion for a range of concepts and for three personalization\nmethods demonstrate the competitive performance of our approach, making\nadaptation up to 8 times faster with no significant drops in quality.\n","authors":["Anton Voronov","Mikhail Khoroshikh","Artem Babenko","Max Ryabinin"],"pdf_url":"https://arxiv.org/pdf/2302.04841v2.pdf","comment":"Code: https://github.com/yandex-research/DVAR. 19 pages, 14 figures"},{"id":"http://arxiv.org/abs/2306.15324v1","updated":"2023-06-27T09:28:29Z","published":"2023-06-27T09:28:29Z","title":"Anomaly Detection in Networks via Score-Based Generative Models","summary":"  Node outlier detection in attributed graphs is a challenging problem for\nwhich there is no method that would work well across different datasets.\nMotivated by the state-of-the-art results of score-based models in graph\ngenerative modeling, we propose to incorporate them into the aforementioned\nproblem. Our method achieves competitive results on small-scale graphs. We\nprovide an empirical analysis of the Dirichlet energy, and show that generative\nmodels might struggle to accurately reconstruct it.\n","authors":["Dmitrii Gavrilev","Evgeny Burnaev"],"pdf_url":"https://arxiv.org/pdf/2306.15324v1.pdf","comment":"16 pages, 8 figures, ICML workshop on Structured Probabilistic\n  Inference & Generative Modeling"},{"id":"http://arxiv.org/abs/2302.10720v2","updated":"2023-06-27T09:25:32Z","published":"2023-02-21T15:16:12Z","title":"Learning to Play Text-based Adventure Games with Maximum Entropy\n  Reinforcement Learning","summary":"  Text-based games are a popular testbed for language-based reinforcement\nlearning (RL). In previous work, deep Q-learning is commonly used as the\nlearning agent. Q-learning algorithms are challenging to apply to complex\nreal-world domains due to, for example, their instability in training.\nTherefore, in this paper, we adapt the soft-actor-critic (SAC) algorithm to the\ntext-based environment. To deal with sparse extrinsic rewards from the\nenvironment, we combine it with a potential-based reward shaping technique to\nprovide more informative (dense) reward signals to the RL agent. We apply our\nmethod to play difficult text-based games. The SAC method achieves higher\nscores than the Q-learning methods on many games with only half the number of\ntraining steps. This shows that it is well-suited for text-based games.\nMoreover, we show that the reward shaping technique helps the agent to learn\nthe policy faster and achieve higher scores. In particular, we consider a\ndynamically learned value function as a potential function for shaping the\nlearner's original sparse reward signals.\n","authors":["Weichen Li","Rati Devidze","Sophie Fellenz"],"pdf_url":"https://arxiv.org/pdf/2302.10720v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14221v2","updated":"2023-06-27T09:03:32Z","published":"2023-06-25T12:05:46Z","title":"Feature Adversarial Distillation for Point Cloud Classification","summary":"  Due to the point cloud's irregular and unordered geometry structure,\nconventional knowledge distillation technology lost a lot of information when\ndirectly used on point cloud tasks. In this paper, we propose Feature\nAdversarial Distillation (FAD) method, a generic adversarial loss function in\npoint cloud distillation, to reduce loss during knowledge transfer. In the\nfeature extraction stage, the features extracted by the teacher are used as the\ndiscriminator, and the students continuously generate new features in the\ntraining stage. The feature of the student is obtained by attacking the\nfeedback from the teacher and getting a score to judge whether the student has\nlearned the knowledge well or not. In experiments on standard point cloud\nclassification on ModelNet40 and ScanObjectNN datasets, our method reduced the\ninformation loss of knowledge transfer in distillation in 40x model compression\nwhile maintaining competitive performance.\n","authors":["YuXing Lee","Wei Wu"],"pdf_url":"https://arxiv.org/pdf/2306.14221v2.pdf","comment":"Accepted to ICIP2023"},{"id":"http://arxiv.org/abs/2303.09901v2","updated":"2023-06-27T08:52:50Z","published":"2023-03-17T11:33:06Z","title":"mCPT at SemEval-2023 Task 3: Multilingual Label-Aware Contrastive\n  Pre-Training of Transformers for Few- and Zero-shot Framing Detection","summary":"  This paper presents the winning system for the zero-shot Spanish framing\ndetection task, which also achieves competitive places in eight additional\nlanguages. The challenge of the framing detection task lies in identifying a\nset of 14 frames when only a few or zero samples are available, i.e., a\nmultilingual multi-label few- or zero-shot setting. Our developed solution\nemploys a pre-training procedure based on multilingual Transformers using a\nlabel-aware contrastive loss function. In addition to describing the system, we\nperform an embedding space analysis and ablation study to demonstrate how our\npre-training procedure supports framing detection to advance computational\nframing analysis.\n","authors":["Markus Reiter-Haas","Alexander Ertl","Kevin Innerhofer","Elisabeth Lex"],"pdf_url":"https://arxiv.org/pdf/2303.09901v2.pdf","comment":"Accepted for publication at SemEval'23"},{"id":"http://arxiv.org/abs/2305.13935v3","updated":"2023-06-27T08:45:06Z","published":"2023-05-08T08:38:22Z","title":"Distribution-aware Fairness Test Generation","summary":"  This work addresses how to validate group fairness in image recognition\nsoftware. We propose a distribution-aware fairness testing approach (called\nDistroFair) that systematically exposes class-level fairness violations in\nimage classifiers via a synergistic combination of out-of-distribution (OOD)\ntesting and semantic-preserving image mutation. DistroFair automatically learns\nthe distribution (e.g., number/orientation) of objects in a set of images. Then\nit systematically mutates objects in the images to become OOD using three\nsemantic-preserving image mutations -- object deletion, object insertion and\nobject rotation. We evaluate DistroFair using two well-known datasets\n(CityScapes and MS-COCO) and three major, commercial image recognition software\n(namely, Amazon Rekognition, Google Cloud Vision and Azure Computer Vision).\nResults show that about 21% of images generated by DistroFair reveal\nclass-level fairness violations using either ground truth or metamorphic\noracles. DistroFair is up to 2.3x more effective than two main baselines, i.e.,\n(a) an approach which focuses on generating images only within the distribution\n(ID) and (b) fairness analysis using only the original image dataset. We\nfurther observed that DistroFair is efficient, it generates 460 images per\nhour, on average. Finally, we evaluate the semantic validity of our approach\nvia a user study with 81 participants, using 30 real images and 30\ncorresponding mutated images generated by DistroFair. We found that images\ngenerated by DistroFair are 80% as realistic as real-world images.\n","authors":["Sai Sathiesh Rajan","Ezekiel Soremekun","Yves Le Traon","Sudipta Chattopadhyay"],"pdf_url":"https://arxiv.org/pdf/2305.13935v3.pdf","comment":"Paper submitted for review to TSE; 15 pages, 4 figures, LaTex;\n  Results and methodology have been updated"},{"id":"http://arxiv.org/abs/2305.07499v2","updated":"2023-06-27T08:43:13Z","published":"2023-05-12T14:12:56Z","title":"Device-Robust Acoustic Scene Classification via Impulse Response\n  Augmentation","summary":"  The ability to generalize to a wide range of recording devices is a crucial\nperformance factor for audio classification models. The characteristics of\ndifferent types of microphones introduce distributional shifts in the digitized\naudio signals due to their varying frequency responses. If this domain shift is\nnot taken into account during training, the model's performance could degrade\nseverely when it is applied to signals recorded by unseen devices. In\nparticular, training a model on audio signals recorded with a small number of\ndifferent microphones can make generalization to unseen devices difficult. To\ntackle this problem, we convolve audio signals in the training set with\npre-recorded device impulse responses (DIRs) to artificially increase the\ndiversity of recording devices. We systematically study the effect of DIR\naugmentation on the task of Acoustic Scene Classification using CNNs and Audio\nSpectrogram Transformers. The results show that DIR augmentation in isolation\nperforms similarly to the state-of-the-art method Freq-MixStyle. However, we\nalso show that DIR augmentation and Freq-MixStyle are complementary, achieving\na new state-of-the-art performance on signals recorded by devices unseen during\ntraining.\n","authors":["Tobias Morocutti","Florian Schmid","Khaled Koutini","Gerhard Widmer"],"pdf_url":"https://arxiv.org/pdf/2305.07499v2.pdf","comment":"In Proceedings of the 31st European Signal Processing Conference,\n  EUSIPCO 2023. Source Code available at:\n  https://github.com/theMoro/DIRAugmentation/"},{"id":"http://arxiv.org/abs/2306.15299v1","updated":"2023-06-27T08:37:57Z","published":"2023-06-27T08:37:57Z","title":"FAIRER: Fairness as Decision Rationale Alignment","summary":"  Deep neural networks (DNNs) have made significant progress, but often suffer\nfrom fairness issues, as deep models typically show distinct accuracy\ndifferences among certain subgroups (e.g., males and females). Existing\nresearch addresses this critical issue by employing fairness-aware loss\nfunctions to constrain the last-layer outputs and directly regularize DNNs.\nAlthough the fairness of DNNs is improved, it is unclear how the trained\nnetwork makes a fair prediction, which limits future fairness improvements. In\nthis paper, we investigate fairness from the perspective of decision rationale\nand define the parameter parity score to characterize the fair decision process\nof networks by analyzing neuron influence in various subgroups. Extensive\nempirical studies show that the unfair issue could arise from the unaligned\ndecision rationales of subgroups. Existing fairness regularization terms fail\nto achieve decision rationale alignment because they only constrain last-layer\noutputs while ignoring intermediate neuron alignment. To address the issue, we\nformulate the fairness as a new task, i.e., decision rationale alignment that\nrequires DNNs' neurons to have consistent responses on subgroups at both\nintermediate processes and the final prediction. To make this idea practical\nduring optimization, we relax the naive objective function and propose\ngradient-guided parity alignment, which encourages gradient-weighted\nconsistency of neurons across subgroups. Extensive experiments on a variety of\ndatasets show that our method can significantly enhance fairness while\nsustaining a high level of accuracy and outperforming other approaches by a\nwide margin.\n","authors":["Tianlin Li","Qing Guo","Aishan Liu","Mengnan Du","Zhiming Li","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2306.15299v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15298v1","updated":"2023-06-27T08:36:35Z","published":"2023-06-27T08:36:35Z","title":"Gender Bias in BERT -- Measuring and Analysing Biases through Sentiment\n  Rating in a Realistic Downstream Classification Task","summary":"  Pretrained language models are publicly available and constantly finetuned\nfor various real-life applications. As they become capable of grasping complex\ncontextual information, harmful biases are likely increasingly intertwined with\nthose models. This paper analyses gender bias in BERT models with two main\ncontributions: First, a novel bias measure is introduced, defining biases as\nthe difference in sentiment valuation of female and male sample versions.\nSecond, we comprehensively analyse BERT's biases on the example of a realistic\nIMDB movie classifier. By systematically varying elements of the training\npipeline, we can conclude regarding their impact on the final model bias. Seven\ndifferent public BERT models in nine training conditions, i.e. 63 models in\ntotal, are compared. Almost all conditions yield significant gender biases.\nResults indicate that reflected biases stem from public BERT models rather than\ntask-specific data, emphasising the weight of responsible usage.\n","authors":["Sophie Jentzsch","Cigdem Turan"],"pdf_url":"https://arxiv.org/pdf/2306.15298v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13596v2","updated":"2023-06-27T08:28:40Z","published":"2023-06-23T16:35:46Z","title":"Max-Margin Token Selection in Attention Mechanism","summary":"  Attention mechanism is a central component of the transformer architecture\nwhich led to the phenomenal success of large language models. However, the\ntheoretical principles underlying the attention mechanism are poorly\nunderstood, especially its nonconvex optimization dynamics. In this work, we\nexplore the seminal softmax-attention model $f(\\boldsymbol{X})=\\langle\n\\boldsymbol{Xv}, \\texttt{softmax}(\\boldsymbol{XWp})\\rangle$, where\n$\\boldsymbol{X}$ is the token sequence and\n$(\\boldsymbol{v},\\boldsymbol{W},\\boldsymbol{p})$ are trainable parameters. We\nprove that running gradient descent on $\\boldsymbol{p}$, or equivalently\n$\\boldsymbol{W}$, converges in direction to a max-margin solution that\nseparates $\\textit{locally-optimal}$ tokens from non-optimal ones. This clearly\nformalizes attention as an optimal token selection mechanism. Remarkably, our\nresults are applicable to general data and precisely characterize\n$\\textit{optimality}$ of tokens in terms of the value embeddings\n$\\boldsymbol{Xv}$ and problem geometry. We also provide a broader\nregularization path analysis that establishes the margin maximizing nature of\nattention even for nonlinear prediction heads. When optimizing $\\boldsymbol{v}$\nand $\\boldsymbol{p}$ simultaneously with logistic loss, we identify conditions\nunder which the regularization paths directionally converge to their respective\nhard-margin SVM solutions where $\\boldsymbol{v}$ separates the input features\nbased on their labels. Interestingly, the SVM formulation of $\\boldsymbol{p}$\nis influenced by the support vector geometry of $\\boldsymbol{v}$. Finally, we\nverify our theoretical findings via numerical experiments and provide insights.\n","authors":["Davoud Ataee Tarzanagh","Yingcong Li","Xuechen Zhang","Samet Oymak"],"pdf_url":"https://arxiv.org/pdf/2306.13596v2.pdf","comment":"minor edits and title change"},{"id":"http://arxiv.org/abs/2306.15283v1","updated":"2023-06-27T08:15:28Z","published":"2023-06-27T08:15:28Z","title":"Adaptive Annealed Importance Sampling with Constant Rate Progress","summary":"  Annealed Importance Sampling (AIS) synthesizes weighted samples from an\nintractable distribution given its unnormalized density function. This\nalgorithm relies on a sequence of interpolating distributions bridging the\ntarget to an initial tractable distribution such as the well-known geometric\nmean path of unnormalized distributions which is assumed to be suboptimal in\ngeneral. In this paper, we prove that the geometric annealing corresponds to\nthe distribution path that minimizes the KL divergence between the current\nparticle distribution and the desired target when the feasible change in the\nparticle distribution is constrained. Following this observation, we derive the\nconstant rate discretization schedule for this annealing sequence, which\nadjusts the schedule to the difficulty of moving samples between the initial\nand the target distributions. We further extend our results to $f$-divergences\nand present the respective dynamics of annealing sequences based on which we\npropose the Constant Rate AIS (CR-AIS) algorithm and its efficient\nimplementation for $\\alpha$-divergences. We empirically show that CR-AIS\nperforms well on multiple benchmark distributions while avoiding the\ncomputationally expensive tuning loop in existing Adaptive AIS.\n","authors":["Shirin Goshtasbpour","Victor Cohen","Fernando Perez-Cruz"],"pdf_url":"https://arxiv.org/pdf/2306.15283v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15272v1","updated":"2023-06-27T07:54:18Z","published":"2023-06-27T07:54:18Z","title":"Delivering Inflated Explanations","summary":"  In the quest for Explainable Artificial Intelligence (XAI) one of the\nquestions that frequently arises given a decision made by an AI system is,\n``why was the decision made in this way?'' Formal approaches to explainability\nbuild a formal model of the AI system and use this to reason about the\nproperties of the system. Given a set of feature values for an instance to be\nexplained, and a resulting decision, a formal abductive explanation is a set of\nfeatures, such that if they take the given value will always lead to the same\ndecision. This explanation is useful, it shows that only some features were\nused in making the final decision. But it is narrow, it only shows that if the\nselected features take their given values the decision is unchanged. It's\npossible that some features may change values and still lead to the same\ndecision. In this paper we formally define inflated explanations which is a set\nof features, and for each feature of set of values (always including the value\nof the instance being explained), such that the decision will remain unchanged.\nInflated explanations are more informative than abductive explanations since\ne.g they allow us to see if the exact value of a feature is important, or it\ncould be any nearby value. Overall they allow us to better understand the role\nof each feature in the decision. We show that we can compute inflated\nexplanations for not that much greater cost than abductive explanations, and\nthat we can extend duality results for abductive explanations also to inflated\nexplanations.\n","authors":["Yacine Izza","Alexey Ignatiev","Peter Stuckey","Joao Marques-Silva"],"pdf_url":"https://arxiv.org/pdf/2306.15272v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.09036v6","updated":"2023-06-27T07:54:07Z","published":"2021-12-16T17:27:29Z","title":"The Dual PC Algorithm and the Role of Gaussianity for Structure Learning\n  of Bayesian Networks","summary":"  Learning the graphical structure of Bayesian networks is key to describing\ndata-generating mechanisms in many complex applications but poses considerable\ncomputational challenges. Observational data can only identify the equivalence\nclass of the directed acyclic graph underlying a Bayesian network model, and a\nvariety of methods exist to tackle the problem. Under certain assumptions, the\npopular PC algorithm can consistently recover the correct equivalence class by\nreverse-engineering the conditional independence (CI) relationships holding in\nthe variable distribution. The dual PC algorithm is a novel scheme to carry out\nthe CI tests within the PC algorithm by leveraging the inverse relationship\nbetween covariance and precision matrices. By exploiting block matrix\ninversions we can also perform tests on partial correlations of complementary\n(or dual) conditioning sets. The multiple CI tests of the dual PC algorithm\nproceed by first considering marginal and full-order CI relationships and\nprogressively moving to central-order ones. Simulation studies show that the\ndual PC algorithm outperforms the classic PC algorithm both in terms of run\ntime and in recovering the underlying network structure, even in the presence\nof deviations from Gaussianity. Additionally, we show that the dual PC\nalgorithm applies for Gaussian copula models, and demonstrate its performance\nin that setting.\n","authors":["Enrico Giudice","Jack Kuipers","Giusi Moffa"],"pdf_url":"https://arxiv.org/pdf/2112.09036v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15265v1","updated":"2023-06-27T07:49:35Z","published":"2023-06-27T07:49:35Z","title":"Hyper-parameter Adaptation of Conformer ASR Systems for Elderly and\n  Dysarthric Speech Recognition","summary":"  Automatic recognition of disordered and elderly speech remains highly\nchallenging tasks to date due to data scarcity. Parameter fine-tuning is often\nused to exploit the large quantities of non-aged and healthy speech pre-trained\nmodels, while neural architecture hyper-parameters are set using expert\nknowledge and remain unchanged. This paper investigates hyper-parameter\nadaptation for Conformer ASR systems that are pre-trained on the Librispeech\ncorpus before being domain adapted to the DementiaBank elderly and UASpeech\ndysarthric speech datasets. Experimental results suggest that hyper-parameter\nadaptation produced word error rate (WER) reductions of 0.45% and 0.67% over\nparameter-only fine-tuning on DBank and UASpeech tasks respectively. An\nintuitive correlation is found between the performance improvements by\nhyper-parameter domain adaptation and the relative utterance length ratio\nbetween the source and target domain data.\n","authors":["Tianzi Wang","Shoukang Hu","Jiajun Deng","Zengrui Jin","Mengzhe Geng","Yi Wang","Helen Meng","Xunying Liu"],"pdf_url":"https://arxiv.org/pdf/2306.15265v1.pdf","comment":"5 pages, 3 figures, 3 tables, accepted by Interspeech2023"},{"id":"http://arxiv.org/abs/2306.11380v2","updated":"2023-06-27T07:37:14Z","published":"2023-06-20T08:38:31Z","title":"A Bayesian Take on Gaussian Process Networks","summary":"  Gaussian Process Networks (GPNs) are a class of directed graphical models\nwhich employ Gaussian processes as priors for the conditional expectation of\neach variable given its parents in the network. The model allows describing\ncontinuous joint distributions in a compact but flexible manner with minimal\nparametric assumptions on the dependencies between variables. Bayesian\nstructure learning of GPNs requires computing the posterior over graphs of the\nnetwork and is computationally infeasible even in low dimensions. This work\nimplements Monte Carlo and Markov Chain Monte Carlo methods to sample from the\nposterior distribution of network structures. As such, the approach follows the\nBayesian paradigm, comparing models via their marginal likelihood and computing\nthe posterior probability of the GPN features. Simulation studies show that our\nmethod outperforms state-of-the-art algorithms in recovering the graphical\nstructure of the network and provides an accurate approximation of its\nposterior distribution.\n","authors":["Enrico Giudice","Jack Kuipers","Giusi Moffa"],"pdf_url":"https://arxiv.org/pdf/2306.11380v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.03853v4","updated":"2023-06-27T06:20:54Z","published":"2022-12-05T12:33:26Z","title":"Clustering with Neural Network and Index","summary":"  A new model called Clustering with Neural Network and Index (CNNI) is\nintroduced. CNNI uses a Neural Network to cluster data points. Training of the\nNeural Network mimics supervised learning, with an internal clustering\nevaluation index acting as the loss function. An experiment is conducted to\ntest the feasibility of the new model, and compared with results of other\nclustering models like K-means and Gaussian Mixture Model (GMM). The result\nshows CNNI can work properly for clustering data; CNNI equipped with MMJ-SC,\nachieves the first parametric (inductive) clustering model that can deal with\nnon-convex shaped (non-flat geometry) data.\n","authors":["Gangli Liu"],"pdf_url":"https://arxiv.org/pdf/2212.03853v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15221v1","updated":"2023-06-27T05:46:18Z","published":"2023-06-27T05:46:18Z","title":"[Re] Double Sampling Randomized Smoothing","summary":"  This paper is a contribution to the reproducibility challenge in the field of\nmachine learning, specifically addressing the issue of certifying the\nrobustness of neural networks (NNs) against adversarial perturbations. The\nproposed Double Sampling Randomized Smoothing (DSRS) framework overcomes the\nlimitations of existing methods by using an additional smoothing distribution\nto improve the robustness certification. The paper provides a clear\nmanifestation of DSRS for a generalized family of Gaussian smoothing and a\ncomputationally efficient method for implementation. The experiments on MNIST\nand CIFAR-10 demonstrate the effectiveness of DSRS, consistently certifying\nlarger robust radii compared to other methods. Also various ablations studies\nare conducted to further analyze the hyperparameters and effect of adversarial\ntraining methods on the certified radius by the proposed framework.\n","authors":["Aryan Gupta","Sarthak Gupta","Abhay Kumar","Harsh Dugar"],"pdf_url":"https://arxiv.org/pdf/2306.15221v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.06563v3","updated":"2023-06-27T05:45:20Z","published":"2023-05-11T04:42:35Z","title":"Manifold Regularized Tucker Decomposition Approach for Spatiotemporal\n  Traffic Data Imputation","summary":"  Spatiotemporal traffic data imputation (STDI), estimating the missing value\nfrom partially observed traffic data, is an inevitable and challenging task in\ndata-driven intelligent transportation systems (ITS). Due to the traffic data's\nmultidimensionality, we transform the traffic matrix into the 3rd-order tensor\nand propose an innovative manifold regularized Tucker decomposition (ManiRTD)\nmodel for STDI. ManiRTD considers the sparsity of the Tucker core tensor to\nconstrain the low rankness and employs manifold regularization and the Toeplitz\nmatrix to enhance the model performance. We address the ManiRTD model through a\nblock coordinate descent framework under alternating proximal gradient updating\nrules with convergence-guaranteed. Numerical experiments on real-world\nspatiotemporal traffic datasets (STDs) demonstrate that our proposed model is\nsuperior to the other baselines under various missing scenarios.\n","authors":["Wenwu Gong","Zhejun Huang","Lili Yang"],"pdf_url":"https://arxiv.org/pdf/2305.06563v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15220v1","updated":"2023-06-27T05:44:56Z","published":"2023-06-27T05:44:56Z","title":"S-TLLR: STDP-inspired Temporal Local Learning Rule for Spiking Neural\n  Networks","summary":"  Spiking Neural Networks (SNNs) are biologically plausible models that have\nbeen identified as potentially apt for the deployment for energy-efficient\nintelligence at the edge, particularly for sequential learning tasks. However,\ntraining of SNNs poses a significant challenge due to the necessity for precise\ntemporal and spatial credit assignment. Back-propagation through time (BPTT)\nalgorithm, whilst being the most widely used method for addressing these\nissues, incurs a high computational cost due to its temporal dependency.\nMoreover, BPTT and its approximations solely utilize causal information derived\nfrom the spiking activity to compute the synaptic updates, thus neglecting\nnon-causal relationships. In this work, we propose S-TLLR, a novel three-factor\ntemporal local learning rule inspired by the Spike-Timing Dependent Plasticity\n(STDP) mechanism, aimed at training SNNs on event-based learning tasks. S-TLLR\nconsiders both causal and non-causal relationships between pre and\npost-synaptic activities, achieving performance comparable to BPTT and\nenhancing performance relative to methods using only causal information.\nFurthermore, S-TLLR has low memory and time complexity, which is independent of\nthe number of time steps, rendering it suitable for online learning on\nlow-power devices. To demonstrate the scalability of our proposed method, we\nhave conducted extensive evaluations on event-based datasets spanning a wide\nrange of applications, such as image and gesture recognition, audio\nclassification, and optical flow estimation. In all the experiments, S-TLLR\nachieved high accuracy with a reduction in the number of computations between\n$1.1-10\\times$.\n","authors":["Marco Paul E. Apolinario","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2306.15220v1.pdf","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2306.15217v1","updated":"2023-06-27T05:37:23Z","published":"2023-06-27T05:37:23Z","title":"Unsupervised Episode Generation for Graph Meta-learning","summary":"  In this paper, we investigate Unsupervised Episode Generation methods to\nsolve Few-Shot Node-Classification (FSNC) problem via Meta-learning without\nlabels. Dominant meta-learning methodologies for FSNC were developed under the\nexistence of abundant labeled nodes for training, which however may not be\npossible to obtain in the real-world. Although few studies have been proposed\nto tackle the label-scarcity problem, they still rely on a limited amount of\nlabeled data, which hinders the full utilization of the information of all\nnodes in a graph. Despite the effectiveness of Self-Supervised Learning (SSL)\napproaches on FSNC without labels, they mainly learn generic node embeddings\nwithout consideration on the downstream task to be solved, which may limit its\nperformance. In this work, we propose unsupervised episode generation methods\nto benefit from their generalization ability for FSNC tasks while resolving\nlabel-scarcity problem. We first propose a method that utilizes graph\naugmentation to generate training episodes called g-UMTRA, which however has\nseveral drawbacks, i.e., 1) increased training time due to the computation of\naugmented features and 2) low applicability to existing baselines. Hence, we\npropose Neighbors as Queries (NaQ), which generates episodes from structural\nneighbors found by graph diffusion. Our proposed methods are model-agnostic,\nthat is, they can be plugged into any existing graph meta-learning models,\nwhile not sacrificing much of their performance or sometimes even improving\nthem. We provide theoretical insights to support why our unsupervised episode\ngeneration methodologies work, and extensive experimental results demonstrate\nthe potential of our unsupervised episode generation methods for graph\nmeta-learning towards FSNC problems.\n","authors":["Jihyeong Jung","Sangwoo Seo","Sungwon Kim","Chanyoung Park"],"pdf_url":"https://arxiv.org/pdf/2306.15217v1.pdf","comment":"11 pages, 9 figures, preprint"},{"id":"http://arxiv.org/abs/2301.12686v2","updated":"2023-06-27T05:35:24Z","published":"2023-01-30T06:27:48Z","title":"GibbsDDRM: A Partially Collapsed Gibbs Sampler for Solving Blind Inverse\n  Problems with Denoising Diffusion Restoration","summary":"  Pre-trained diffusion models have been successfully used as priors in a\nvariety of linear inverse problems, where the goal is to reconstruct a signal\nfrom noisy linear measurements. However, existing approaches require knowledge\nof the linear operator. In this paper, we propose GibbsDDRM, an extension of\nDenoising Diffusion Restoration Models (DDRM) to a blind setting in which the\nlinear measurement operator is unknown. GibbsDDRM constructs a joint\ndistribution of the data, measurements, and linear operator by using a\npre-trained diffusion model for the data prior, and it solves the problem by\nposterior sampling with an efficient variant of a Gibbs sampler. The proposed\nmethod is problem-agnostic, meaning that a pre-trained diffusion model can be\napplied to various inverse problems without fine-tuning. In experiments, it\nachieved high performance on both blind image deblurring and vocal\ndereverberation tasks, despite the use of simple generic priors for the\nunderlying linear operators.\n","authors":["Naoki Murata","Koichi Saito","Chieh-Hsin Lai","Yuhta Takida","Toshimitsu Uesaka","Yuki Mitsufuji","Stefano Ermon"],"pdf_url":"https://arxiv.org/pdf/2301.12686v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2006.10909v2","updated":"2023-06-27T05:32:12Z","published":"2020-06-19T00:43:23Z","title":"Neural Topic Modeling with Continual Lifelong Learning","summary":"  Lifelong learning has recently attracted attention in building machine\nlearning systems that continually accumulate and transfer knowledge to help\nfuture learning. Unsupervised topic modeling has been popularly used to\ndiscover topics from document collections. However, the application of topic\nmodeling is challenging due to data sparsity, e.g., in a small collection of\n(short) documents and thus, generate incoherent topics and sub-optimal document\nrepresentations. To address the problem, we propose a lifelong learning\nframework for neural topic modeling that can continuously process streams of\ndocument collections, accumulate topics and guide future topic modeling tasks\nby knowledge transfer from several sources to better deal with the sparse data.\nIn the lifelong process, we particularly investigate jointly: (1) sharing\ngenerative homologies (latent topics) over lifetime to transfer prior\nknowledge, and (2) minimizing catastrophic forgetting to retain the past\nlearning via novel selective data augmentation, co-training and topic\nregularization approaches. Given a stream of document collections, we apply the\nproposed Lifelong Neural Topic Modeling (LNTM) framework in modeling three\nsparse document collections as future tasks and demonstrate improved\nperformance quantified by perplexity, topic coherence and information retrieval\ntask.\n","authors":["Pankaj Gupta","Yatin Chaudhary","Thomas Runkler","Hinrich Schütze"],"pdf_url":"https://arxiv.org/pdf/2006.10909v2.pdf","comment":"Accepted at ICML2020 (13 pages, 11 figures, 9 tables)"},{"id":"http://arxiv.org/abs/2306.15212v1","updated":"2023-06-27T05:18:25Z","published":"2023-06-27T05:18:25Z","title":"TranssionADD: A multi-frame reinforcement based sequence tagging model\n  for audio deepfake detection","summary":"  Thanks to recent advancements in end-to-end speech modeling technology, it\nhas become increasingly feasible to imitate and clone a user`s voice. This\nleads to a significant challenge in differentiating between authentic and\nfabricated audio segments. To address the issue of user voice abuse and misuse,\nthe second Audio Deepfake Detection Challenge (ADD 2023) aims to detect and\nanalyze deepfake speech utterances. Specifically, Track 2, named the\nManipulation Region Location (RL), aims to pinpoint the location of manipulated\nregions in audio, which can be present in both real and generated audio\nsegments. We propose our novel TranssionADD system as a solution to the\nchallenging problem of model robustness and audio segment outliers in the trace\ncompetition. Our system provides three unique contributions: 1) we adapt\nsequence tagging task for audio deepfake detection; 2) we improve model\ngeneralization by various data augmentation techniques; 3) we incorporate\nmulti-frame detection (MFD) module to overcome limited representation provided\nby a single frame and use isolated-frame penalty (IFP) loss to handle outliers\nin segments. Our best submission achieved 2nd place in Track 2, demonstrating\nthe effectiveness and robustness of our proposed system.\n","authors":["Jie Liu","Zhiba Su","Hui Huang","Caiyan Wan","Quanxiu Wang","Jiangli Hong","Benlai Tang","Fengjie Zhu"],"pdf_url":"https://arxiv.org/pdf/2306.15212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2006.10632v3","updated":"2023-06-27T05:07:42Z","published":"2020-06-18T15:53:58Z","title":"Explainable and Discourse Topic-aware Neural Language Understanding","summary":"  Marrying topic models and language models exposes language understanding to a\nbroader source of document-level context beyond sentences via topics. While\nintroducing topical semantics in language models, existing approaches\nincorporate latent document topic proportions and ignore topical discourse in\nsentences of the document. This work extends the line of research by\nadditionally introducing an explainable topic representation in language\nunderstanding, obtained from a set of key terms correspondingly for each latent\ntopic of the proportion. Moreover, we retain sentence-topic associations along\nwith document-topic association by modeling topical discourse for every\nsentence in the document. We present a novel neural composite language model\nthat exploits both the latent and explainable topics along with topical\ndiscourse at sentence-level in a joint learning framework of topic and language\nmodels. Experiments over a range of tasks such as language modeling, word sense\ndisambiguation, document classification, retrieval and text generation\ndemonstrate ability of the proposed model in improving language understanding.\n","authors":["Yatin Chaudhary","Hinrich Schütze","Pankaj Gupta"],"pdf_url":"https://arxiv.org/pdf/2006.10632v3.pdf","comment":"Accepted at ICML2020 (13 pages, 2 figures)"},{"id":"http://arxiv.org/abs/2306.14468v2","updated":"2023-06-27T04:51:19Z","published":"2023-06-26T07:20:25Z","title":"A General Framework for Sequential Decision-Making under Adaptivity\n  Constraints","summary":"  We take the first step in studying general sequential decision-making under\ntwo adaptivity constraints: rare policy switch and batch learning. First, we\nprovide a general class called the Eluder Condition class, which includes a\nwide range of reinforcement learning classes. Then, for the rare policy switch\nconstraint, we provide a generic algorithm to achieve a\n$\\widetilde{\\mathcal{O}}(\\log K) $ switching cost with a\n$\\widetilde{\\mathcal{O}}(\\sqrt{K})$ regret on the EC class. For the batch\nlearning constraint, we provide an algorithm that provides a\n$\\widetilde{\\mathcal{O}}(\\sqrt{K}+K/B)$ regret with the number of batches $B.$\nThis paper is the first work considering rare policy switch and batch learning\nunder general function classes, which covers nearly all the models studied in\nthe previous works such as tabular MDP (Bai et al. 2019; Zhang et al. 2020),\nlinear MDP (Wang et al. 2021; Gao et al. 2021), low eluder dimension MDP (Kong\net al. 2021; Gao et al. 2021), generalized linear function approximation (Qiao\net al. 2023), and also some new classes such as the low $D_\\Delta$-type Bellman\neluder dimension problem, linear mixture MDP, kernelized nonlinear regulator\nand undercomplete partially observed Markov decision process (POMDP).\n","authors":["Nuoya Xiong","Zhaoran Wang","Zhuoran Yang"],"pdf_url":"https://arxiv.org/pdf/2306.14468v2.pdf","comment":"48 pages"},{"id":"http://arxiv.org/abs/2212.04612v2","updated":"2023-06-27T04:33:11Z","published":"2022-12-09T00:32:46Z","title":"Training Data Influence Analysis and Estimation: A Survey","summary":"  Good models require good training data. For overparameterized deep models,\nthe causal relationship between training data and model predictions is\nincreasingly opaque and poorly understood. Influence analysis partially\ndemystifies training's underlying interactions by quantifying the amount each\ntraining instance alters the final model. Measuring the training data's\ninfluence exactly can be provably hard in the worst case; this has led to the\ndevelopment and use of influence estimators, which only approximate the true\ninfluence. This paper provides the first comprehensive survey of training data\ninfluence analysis and estimation. We begin by formalizing the various, and in\nplaces orthogonal, definitions of training data influence. We then organize\nstate-of-the-art influence analysis methods into a taxonomy; we describe each\nof these methods in detail and compare their underlying assumptions, asymptotic\ncomplexities, and overall strengths and weaknesses. Finally, we propose future\nresearch directions to make influence analysis more useful in practice as well\nas more theoretically and empirically sound. A curated, up-to-date list of\nresources related to influence analysis is available at\nhttps://github.com/ZaydH/influence_analysis_papers.\n","authors":["Zayd Hammoudeh","Daniel Lowd"],"pdf_url":"https://arxiv.org/pdf/2212.04612v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15194v1","updated":"2023-06-27T04:28:52Z","published":"2023-06-27T04:28:52Z","title":"Chronic pain detection from resting-state raw EEG signals using improved\n  feature selection","summary":"  We present an automatic approach that works on resting-state raw EEG data for\nchronic pain detection. A new feature selection algorithm - modified Sequential\nFloating Forward Selection (mSFFS) - is proposed. The improved feature\nselection scheme is rather compact but displays better class separability as\nindicated by the Bhattacharyya distance measures and better visualization\nresults. It also outperforms selections generated by other benchmark methods,\nboosting the test accuracy to 97.5% and yielding a test accuracy of 81.4% on an\nexternal dataset that contains different types of chronic pain\n","authors":["Jean Li","Dirk De Ridder","Divya Adhia","Matthew Hall","Jeremiah D. Deng"],"pdf_url":"https://arxiv.org/pdf/2306.15194v1.pdf","comment":"9 pages, 4 figures, journal submission"},{"id":"http://arxiv.org/abs/2305.17583v2","updated":"2023-06-27T04:19:02Z","published":"2023-05-27T21:32:28Z","title":"On Neural Networks as Infinite Tree-Structured Probabilistic Graphical\n  Models","summary":"  Deep neural networks (DNNs) lack the precise semantics and definitive\nprobabilistic interpretation of probabilistic graphical models (PGMs). In this\npaper, we propose an innovative solution by constructing infinite\ntree-structured PGMs that correspond exactly to neural networks. Our research\nreveals that DNNs, during forward propagation, indeed perform approximations of\nPGM inference that are precise in this alternative PGM structure. Not only does\nour research complement existing studies that describe neural networks as\nkernel machines or infinite-sized Gaussian processes, it also elucidates a more\ndirect approximation that DNNs make to exact inference in PGMs. Potential\nbenefits include improved pedagogy and interpretation of DNNs, and algorithms\nthat can merge the strengths of PGMs and DNNs.\n","authors":["Boyao Li","Alexandar J. Thomson","Matthew M. Engelhard","David Page"],"pdf_url":"https://arxiv.org/pdf/2305.17583v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2103.00704v2","updated":"2023-06-27T04:18:06Z","published":"2021-03-01T02:33:20Z","title":"FedPower: Privacy-Preserving Distributed Eigenspace Estimation","summary":"  Eigenspace estimation is fundamental in machine learning and statistics,\nwhich has found applications in PCA, dimension reduction, and clustering, among\nothers. The modern machine learning community usually assumes that data come\nfrom and belong to different organizations. The low communication power and the\npossible privacy breaches of data make the computation of eigenspace\nchallenging. To address these challenges, we propose a class of algorithms\ncalled \\textsf{FedPower} within the federated learning (FL) framework.\n\\textsf{FedPower} leverages the well-known power method by alternating multiple\nlocal power iterations and a global aggregation step, thus improving\ncommunication efficiency. In the aggregation, we propose to weight each local\neigenvector matrix with {\\it Orthogonal Procrustes Transformation} (OPT) for\nbetter alignment. To ensure strong privacy protection, we add Gaussian noise in\neach iteration by adopting the notion of \\emph{differential privacy} (DP). We\nprovide convergence bounds for \\textsf{FedPower} that are composed of different\ninterpretable terms corresponding to the effects of Gaussian noise,\nparallelization, and random sampling of local machines. Additionally, we\nconduct experiments to demonstrate the effectiveness of our proposed\nalgorithms.\n","authors":["Xiao Guo","Xiang Li","Xiangyu Chang","Shusen Wang","Zhihua Zhang"],"pdf_url":"https://arxiv.org/pdf/2103.00704v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15188v1","updated":"2023-06-27T04:14:03Z","published":"2023-06-27T04:14:03Z","title":"One-class systems seamlessly fit in the forward-forward algorithm","summary":"  The forward-forward algorithm presents a new method of training neural\nnetworks by updating weights during an inference, performing parameter updates\nfor each layer individually. This immediately reduces memory requirements\nduring training and may lead to many more benefits, like seamless online\ntraining. This method relies on a loss (\"goodness\") function that can be\nevaluated on the activations of each layer, of which can have a varied\nparameter size, depending on the hyperparamaterization of the network. In the\nseminal paper, a goodness function was proposed to fill this need; however, if\nplaced in a one-class problem context, one need not pioneer a new loss because\nthese functions can innately handle dynamic network sizes. In this paper, we\ninvestigate the performance of deep one-class objective functions when trained\nin a forward-forward fashion. The code is available at\n\\url{https://github.com/MichaelHopwood/ForwardForwardOneclass}.\n","authors":["Michael Hopwood"],"pdf_url":"https://arxiv.org/pdf/2306.15188v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04265v2","updated":"2023-06-27T04:11:21Z","published":"2023-06-07T09:05:56Z","title":"Permutation Equivariant Graph Framelets for Heterophilous Graph Learning","summary":"  The nature of heterophilous graphs is significantly different with that of\nhomophilous graphs, which causes difficulties in early graph neural network\nmodels and suggests aggregations beyond 1-hop neighborhood. In this paper, we\ndevelop a new way to implement multi-scale extraction via constructing\nHaar-type graph framelets with desired properties of permutation equivariance,\nefficiency, and sparsity, for deep learning tasks on graphs. We further design\na graph framelet neural network model PEGFAN (Permutation Equivariant Graph\nFramelet Augmented Network) based on our constructed graph framelets. The\nexperiments are conducted on a synthetic dataset and 9 benchmark datasets to\ncompare performance with other state-of-the-art models. The result shows that\nour model can achieve best performance on certain datasets of heterophilous\ngraphs (including the majority of heterophilous datasets with relatively larger\nsizes and denser connections) and competitive performance on the remaining.\n","authors":["Jianfei Li","Ruigang Zheng","Han Feng","Ming Li","Xiaosheng Zhuang"],"pdf_url":"https://arxiv.org/pdf/2306.04265v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13629v2","updated":"2023-06-27T04:11:03Z","published":"2023-01-31T13:42:36Z","title":"DiffSTG: Probabilistic Spatio-Temporal Graph Forecasting with Denoising\n  Diffusion Models","summary":"  Spatio-temporal graph neural networks (STGNN) have emerged as the dominant\nmodel for spatio-temporal graph (STG) forecasting. Despite their success, they\nfail to model intrinsic uncertainties within STG data, which cripples their\npracticality in downstream tasks for decision-making. To this end, this paper\nfocuses on probabilistic STG forecasting, which is challenging due to the\ndifficulty in modeling uncertainties and complex ST dependencies. In this\nstudy, we present the first attempt to generalize the popular denoising\ndiffusion probabilistic models to STGs, leading to a novel non-autoregressive\nframework called DiffSTG, along with the first denoising network UGnet for STG\nin the framework. Our approach combines the spatio-temporal learning\ncapabilities of STGNNs with the uncertainty measurements of diffusion models.\nExtensive experiments validate that DiffSTG reduces the Continuous Ranked\nProbability Score (CRPS) by 4%-14%, and Root Mean Squared Error (RMSE) by 2%-7%\nover existing methods on three real-world datasets.\n","authors":["Haomin Wen","Youfang Lin","Yutong Xia","Huaiyu Wan","Qingsong Wen","Roger Zimmermann","Yuxuan Liang"],"pdf_url":"https://arxiv.org/pdf/2301.13629v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15182v1","updated":"2023-06-27T03:42:31Z","published":"2023-06-27T03:42:31Z","title":"Automatic Truss Design with Reinforcement Learning","summary":"  Truss layout design, namely finding a lightweight truss layout satisfying all\nthe physical constraints, is a fundamental problem in the building industry.\nGenerating the optimal layout is a challenging combinatorial optimization\nproblem, which can be extremely expensive to solve by exhaustive search.\nDirectly applying end-to-end reinforcement learning (RL) methods to truss\nlayout design is infeasible either, since only a tiny portion of the entire\nlayout space is valid under the physical constraints, leading to particularly\nsparse rewards for RL training. In this paper, we develop AutoTruss, a\ntwo-stage framework to efficiently generate both lightweight and valid truss\nlayouts. AutoTruss first adopts Monte Carlo tree search to discover a diverse\ncollection of valid layouts. Then RL is applied to iteratively refine the valid\nsolutions. We conduct experiments and ablation studies in popular truss layout\ndesign test cases in both 2D and 3D settings. AutoTruss outperforms the\nbest-reported layouts by 25.1% in the most challenging 3D test cases, resulting\nin the first effective deep-RL-based approach in the truss layout design\nliterature.\n","authors":["Weihua Du","Jinglun Zhao","Chao Yu","Xingcheng Yao","Zimeng Song","Siyang Wu","Ruifeng Luo","Zhiyuan Liu","Xianzhong Zhao","Yi Wu"],"pdf_url":"https://arxiv.org/pdf/2306.15182v1.pdf","comment":"IJCAI2023. The codes are available at\n  https://github.com/StigLidu/AutoTruss"},{"id":"http://arxiv.org/abs/2212.07551v3","updated":"2023-06-27T03:36:30Z","published":"2022-12-14T23:46:23Z","title":"Faster Maximum Inner Product Search in High Dimensions","summary":"  Maximum Inner Product Search (MIPS) is a ubiquitous task in machine learning\napplications such as recommendation systems. Given a query vector and $n$ atom\nvectors in $d$-dimensional space, the goal of MIPS is to find the atom that has\nthe highest inner product with the query vector. Existing MIPS algorithms scale\nat least as $O(\\sqrt{d})$, which becomes computationally prohibitive in\nhigh-dimensional settings. In this work, we present BanditMIPS, a novel\nrandomized MIPS algorithm whose complexity is independent of $d$. BanditMIPS\nestimates the inner product for each atom by subsampling coordinates and\nadaptively evaluates more coordinates for more promising atoms. The specific\nadaptive sampling strategy is motivated by multi-armed bandits. We provide\ntheoretical guarantees that BanditMIPS returns the correct answer with high\nprobability, while improving the complexity in $d$ from $O(\\sqrt{d})$ to\n$O(1)$. We also perform experiments on four synthetic and real-world datasets\nand demonstrate that BanditMIPS outperforms prior state-of-the-art algorithms.\nFor example, in the Movie Lens dataset ($n$=4,000, $d$=6,000), BanditMIPS is\n20$\\times$ faster than the next best algorithm while returning the same answer.\nBanditMIPS requires no preprocessing of the data and includes a hyperparameter\nthat practitioners may use to trade off accuracy and runtime. We also propose a\nvariant of our algorithm, named BanditMIPS-$\\alpha$, which achieves further\nspeedups by employing non-uniform sampling across coordinates. Finally, we\ndemonstrate how known preprocessing techniques can be used to further\naccelerate BanditMIPS, and discuss applications to Matching Pursuit and Fourier\nanalysis.\n","authors":["Mo Tiwari","Ryan Kang","Je-Yong Lee","Donghyun Lee","Chris Piech","Sebastian Thrun","Ilan Shomorony","Martin Jinye Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.07551v3.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2305.12837v3","updated":"2023-06-27T03:06:16Z","published":"2023-05-22T09:00:34Z","title":"Capturing Conversion Rate Fluctuation during Sales Promotions: A Novel\n  Historical Data Reuse Approach","summary":"  Conversion rate (CVR) prediction is one of the core components in online\nrecommender systems, and various approaches have been proposed to obtain\naccurate and well-calibrated CVR estimation. However, we observe that a\nwell-trained CVR prediction model often performs sub-optimally during sales\npromotions. This can be largely ascribed to the problem of the data\ndistribution shift, in which the conventional methods no longer work. To this\nend, we seek to develop alternative modeling techniques for CVR prediction.\nObserving similar purchase patterns across different promotions, we propose\nreusing the historical promotion data to capture the promotional conversion\npatterns. Herein, we propose a novel \\textbf{H}istorical \\textbf{D}ata\n\\textbf{R}euse (\\textbf{HDR}) approach that first retrieves historically\nsimilar promotion data and then fine-tunes the CVR prediction model with the\nacquired data for better adaptation to the promotion mode. HDR consists of\nthree components: an automated data retrieval module that seeks similar data\nfrom historical promotions, a distribution shift correction module that\nre-weights the retrieved data for better aligning with the target promotion,\nand a TransBlock module that quickly fine-tunes the original model for better\nadaptation to the promotion mode. Experiments conducted with real-world data\ndemonstrate the effectiveness of HDR, as it improves both ranking and\ncalibration metrics to a large extent. HDR has also been deployed on the\ndisplay advertising system in Alibaba, bringing a lift of $9\\%$ RPM and $16\\%$\nCVR during Double 11 Sales in 2022.\n","authors":["Zhangming Chan","Yu Zhang","Shuguang Han","Yong Bai","Xiang-Rong Sheng","Siyuan Lou","Jiacen Hu","Baolin Liu","Yuning Jiang","Jian Xu","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2305.12837v3.pdf","comment":"Accepted at KDD 2023. This work has already been deployed on the\n  display advertising system in Alibaba, bringing substantial economic gains"},{"id":"http://arxiv.org/abs/2306.15169v1","updated":"2023-06-27T03:01:43Z","published":"2023-06-27T03:01:43Z","title":"Exploiting Inferential Structure in Neural Processes","summary":"  Neural Processes (NPs) are appealing due to their ability to perform fast\nadaptation based on a context set. This set is encoded by a latent variable,\nwhich is often assumed to follow a simple distribution. However, in real-word\nsettings, the context set may be drawn from richer distributions having\nmultiple modes, heavy tails, etc. In this work, we provide a framework that\nallows NPs' latent variable to be given a rich prior defined by a graphical\nmodel. These distributional assumptions directly translate into an appropriate\naggregation strategy for the context set. Moreover, we describe a\nmessage-passing procedure that still allows for end-to-end optimization with\nstochastic gradients. We demonstrate the generality of our framework by using\nmixture and Student-t assumptions that yield improvements in function modelling\nand test-time robustness.\n","authors":["Dharmesh Tailor","Mohammad Emtiyaz Khan","Eric Nalisnick"],"pdf_url":"https://arxiv.org/pdf/2306.15169v1.pdf","comment":"Uncertainty in Artificial Intelligence (UAI) 2023"},{"id":"http://arxiv.org/abs/2302.13939v4","updated":"2023-06-27T02:55:23Z","published":"2023-02-27T16:43:04Z","title":"SpikeGPT: Generative Pre-trained Language Model with Spiking Neural\n  Networks","summary":"  As the size of large language models continue to scale, so does the\ncomputational resources required to run it. Spiking Neural Networks (SNNs) have\nemerged as an energy-efficient approach to deep learning that leverage sparse\nand event-driven activations to reduce the computational overhead associated\nwith model inference. While they have become competitive with non-spiking\nmodels on many computer vision tasks, SNNs have also proven to be more\nchallenging to train. As a result, their performance lags behind modern deep\nlearning, and we are yet to see the effectiveness of SNNs in language\ngeneration. In this paper, inspired by the Receptance Weighted Key Value (RWKV)\nlanguage model, we successfully implement `SpikeGPT', a generative language\nmodel with binary, event-driven spiking activation units. We train the proposed\nmodel on two model variants: 45M and 216M parameters. To the best of our\nknowledge, SpikeGPT is the largest backpropagation-trained SNN model to date,\nrendering it suitable for both the generation and comprehension of natural\nlanguage. We achieve this by modifying the transformer block to replace\nmulti-head self attention to reduce quadratic computational complexity O(N^2)\nto linear complexity O(N) with increasing sequence length. Input tokens are\ninstead streamed in sequentially to our attention mechanism (as with typical\nSNNs). Our preliminary experiments show that SpikeGPT remains competitive with\nnon-spiking models on tested benchmarks, while maintaining 20x fewer operations\nwhen processed on neuromorphic hardware that can leverage sparse, event-driven\nactivations.\n","authors":["Rui-Jie Zhu","Qihang Zhao","Guoqi Li","Jason K. Eshraghian"],"pdf_url":"https://arxiv.org/pdf/2302.13939v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15166v1","updated":"2023-06-27T02:47:59Z","published":"2023-06-27T02:47:59Z","title":"Learning from Invalid Data: On Constraint Satisfaction in Generative\n  Models","summary":"  Generative models have demonstrated impressive results in vision, language,\nand speech. However, even with massive datasets, they struggle with precision,\ngenerating physically invalid or factually incorrect data. This is particularly\nproblematic when the generated data must satisfy constraints, for example, to\nmeet product specifications in engineering design or to adhere to the laws of\nphysics in a natural scene. To improve precision while preserving diversity and\nfidelity, we propose a novel training mechanism that leverages datasets of\nconstraint-violating data points, which we consider invalid. Our approach\nminimizes the divergence between the generative distribution and the valid\nprior while maximizing the divergence with the invalid distribution. We\ndemonstrate how generative models like GANs and DDPMs that we augment to train\nwith invalid data vastly outperform their standard counterparts which solely\ntrain on valid data points. For example, our training procedure generates up to\n98 % fewer invalid samples on 2D densities, improves connectivity and stability\nfour-fold on a stacking block problem, and improves constraint satisfaction by\n15 % on a structural topology optimization benchmark in engineering design. We\nalso analyze how the quality of the invalid data affects the learning procedure\nand the generalization properties of models. Finally, we demonstrate\nsignificant improvements in sample efficiency, showing that a tenfold increase\nin valid samples leads to a negligible difference in constraint satisfaction,\nwhile less than 10 % invalid samples lead to a tenfold improvement. Our\nproposed mechanism offers a promising solution for improving precision in\ngenerative models while preserving diversity and fidelity, particularly in\ndomains where constraint satisfaction is critical and data is limited, such as\nengineering design, robotics, and medicine.\n","authors":["Giorgio Giannone","Lyle Regenwetter","Akash Srivastava","Dan Gutfreund","Faez Ahmed"],"pdf_url":"https://arxiv.org/pdf/2306.15166v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15164v1","updated":"2023-06-27T02:46:08Z","published":"2023-06-27T02:46:08Z","title":"DSRM: Boost Textual Adversarial Training with Distribution Shift Risk\n  Minimization","summary":"  Adversarial training is one of the best-performing methods in improving the\nrobustness of deep language models. However, robust models come at the cost of\nhigh time consumption, as they require multi-step gradient ascents or word\nsubstitutions to obtain adversarial samples. In addition, these generated\nsamples are deficient in grammatical quality and semantic consistency, which\nimpairs the effectiveness of adversarial training. To address these problems,\nwe introduce a novel, effective procedure for instead adversarial training with\nonly clean data. Our procedure, distribution shift risk minimization (DSRM),\nestimates the adversarial loss by perturbing the input data's probability\ndistribution rather than their embeddings. This formulation results in a robust\nmodel that minimizes the expected global loss under adversarial attacks. Our\napproach requires zero adversarial samples for training and reduces time\nconsumption by up to 70\\% compared to current best-performing adversarial\ntraining methods. Experiments demonstrate that DSRM considerably improves\nBERT's resistance to textual adversarial attacks and achieves state-of-the-art\nrobust accuracy on various benchmarks.\n","authors":["Songyang Gao","Shihan Dou","Yan Liu","Xiao Wang","Qi Zhang","Zhongyu Wei","Jin Ma","Ying Shan"],"pdf_url":"https://arxiv.org/pdf/2306.15164v1.pdf","comment":"Accepted by ACL2023"},{"id":"http://arxiv.org/abs/2306.15163v1","updated":"2023-06-27T02:44:54Z","published":"2023-06-27T02:44:54Z","title":"Wasserstein Generative Regression","summary":"  In this paper, we propose a new and unified approach for nonparametric\nregression and conditional distribution learning. Our approach simultaneously\nestimates a regression function and a conditional generator using a generative\nlearning framework, where a conditional generator is a function that can\ngenerate samples from a conditional distribution. The main idea is to estimate\na conditional generator that satisfies the constraint that it produces a good\nregression function estimator. We use deep neural networks to model the\nconditional generator. Our approach can handle problems with multivariate\noutcomes and covariates, and can be used to construct prediction intervals. We\nprovide theoretical guarantees by deriving non-asymptotic error bounds and the\ndistributional consistency of our approach under suitable assumptions. We also\nperform numerical experiments with simulated and real data to demonstrate the\neffectiveness and superiority of our approach over some existing approaches in\nvarious scenarios.\n","authors":["Shanshan Song","Tong Wang","Guohao Shen","Yuanyuan Lin","Jian Huang"],"pdf_url":"https://arxiv.org/pdf/2306.15163v1.pdf","comment":"50 pages, including appendix. 5 figures and 6 tables in the main\n  text. 1 figure and 7 tables in the appendix"},{"id":"http://arxiv.org/abs/2201.03225v2","updated":"2023-06-27T02:36:46Z","published":"2022-01-10T09:17:21Z","title":"Explainable AI Integrated Feature Selection for Landslide Susceptibility\n  Mapping using TreeSHAP","summary":"  Landslides have been a regular occurrence and an alarming threat to human\nlife and property in the era of anthropogenic global warming. An early\nprediction of landslide susceptibility using a data-driven approach is a demand\nof time. In this study, we explored the eloquent features that best describe\nlandslide susceptibility with state-of-the-art machine learning methods. In our\nstudy, we employed state-of-the-art machine learning algorithms including\nXgBoost, LR, KNN, SVM, and Adaboost for landslide susceptibility prediction. To\nfind the best hyperparameters of each individual classifier for optimized\nperformance, we have incorporated the Grid Search method, with 10 Fold\nCross-Validation. In this context, the optimized version of XgBoost\noutperformed all other classifiers with a Cross-validation Weighted F1 score of\n94.62 %. Followed by this empirical evidence, we explored the XgBoost\nclassifier by incorporating TreeSHAP, a game-theory-based statistical algorithm\nused to explain Machine Learning models, to identify eloquent features such as\nSLOPE, ELEVATION, TWI that complement the performance of the XGBoost classifier\nmostly and features such as LANDUSE, NDVI, SPI which has less effect on models\nperformance. According to the TreeSHAP explanation of features, we selected the\n9 most significant landslide causal factors out of 15. Evidently, an optimized\nversion of XgBoost along with feature reduction by 40 % has outperformed all\nother classifiers in terms of popular evaluation metrics with a\nCross-Validation Weighted F1 score of 95.01 % on the training and AUC score of\n97 %\n","authors":["Muhammad Sakib Khan Inan","Istiakur Rahman"],"pdf_url":"https://arxiv.org/pdf/2201.03225v2.pdf","comment":"Accepted for publication in SN Computer Science (Springer)"},{"id":"http://arxiv.org/abs/2306.15159v1","updated":"2023-06-27T02:35:25Z","published":"2023-06-27T02:35:25Z","title":"Evaluation of machine learning architectures on the quantification of\n  epistemic and aleatoric uncertainties in complex dynamical systems","summary":"  Machine learning methods for the construction of data-driven reduced order\nmodel models are used in an increasing variety of engineering domains,\nespecially as a supplement to expensive computational fluid dynamics for design\nproblems. An important check on the reliability of surrogate models is\nUncertainty Quantification (UQ), a self assessed estimate of the model error.\nAccurate UQ allows for cost savings by reducing both the required size of\ntraining data sets and the required safety factors, while poor UQ prevents\nusers from confidently relying on model predictions. We examine several machine\nlearning techniques, including both Gaussian processes and a family\nUQ-augmented neural networks: Ensemble neural networks (ENN), Bayesian neural\nnetworks (BNN), Dropout neural networks (D-NN), and Gaussian neural networks\n(G-NN). We evaluate UQ accuracy (distinct from model accuracy) using two\nmetrics: the distribution of normalized residuals on validation data, and the\ndistribution of estimated uncertainties. We apply these metrics to two model\ndata sets, representative of complex dynamical systems: an ocean engineering\nproblem in which a ship traverses irregular wave episodes, and a dispersive\nwave turbulence system with extreme events, the Majda-McLaughlin-Tabak model.\nWe present conclusions concerning model architecture and hyperparameter tuning.\n","authors":["Stephen Guth","Alireza Mojahed","Themistoklis P. Sapsis"],"pdf_url":"https://arxiv.org/pdf/2306.15159v1.pdf","comment":"Submitted for publication to \"Computer Methods in Applied Mechanics\n  and Engineering.\" 25 pages, 20 figures. arXiv admin note: text overlap with\n  arXiv:1505.05424 by other authors"},{"id":"http://arxiv.org/abs/2111.06171v5","updated":"2023-06-27T02:29:46Z","published":"2021-11-11T12:17:22Z","title":"Convergence and Stability of the Stochastic Proximal Point Algorithm\n  with Momentum","summary":"  Stochastic gradient descent with momentum (SGDM) is the dominant algorithm in\nmany optimization scenarios, including convex optimization instances and\nnon-convex neural network training. Yet, in the stochastic setting, momentum\ninterferes with gradient noise, often leading to specific step size and\nmomentum choices in order to guarantee convergence, set aside acceleration.\nProximal point methods, on the other hand, have gained much attention due to\ntheir numerical stability and elasticity against imperfect tuning. Their\nstochastic accelerated variants though have received limited attention: how\nmomentum interacts with the stability of (stochastic) proximal point methods\nremains largely unstudied. To address this, we focus on the convergence and\nstability of the stochastic proximal point algorithm with momentum (SPPAM), and\nshow that SPPAM allows a faster linear convergence to a neighborhood compared\nto the stochastic proximal point algorithm (SPPA) with a better contraction\nfactor, under proper hyperparameter tuning. In terms of stability, we show that\nSPPAM depends on problem constants more favorably than SGDM, allowing a wider\nrange of step size and momentum that lead to convergence.\n","authors":["Junhyung Lyle Kim","Panos Toulis","Anastasios Kyrillidis"],"pdf_url":"https://arxiv.org/pdf/2111.06171v5.pdf","comment":"24 pages, 2 figures, 4th Annual Conference on Learning for Dynamics\n  and Control"},{"id":"http://arxiv.org/abs/2306.15157v1","updated":"2023-06-27T02:26:07Z","published":"2023-06-27T02:26:07Z","title":"Revisiting Tropical Polynomial Division: Theory, Algorithms and\n  Application to Neural Networks","summary":"  Tropical geometry has recently found several applications in the analysis of\nneural networks with piecewise linear activation functions. This paper presents\na new look at the problem of tropical polynomial division and its application\nto the simplification of neural networks. We analyze tropical polynomials with\nreal coefficients, extending earlier ideas and methods developed for\npolynomials with integer coefficients. We first prove the existence of a unique\nquotient-remainder pair and characterize the quotient in terms of the convex\nbi-conjugate of a related function. Interestingly, the quotient of tropical\npolynomials with integer coefficients does not necessarily have integer\ncoefficients. Furthermore, we develop a relationship of tropical polynomial\ndivision with the computation of the convex hull of unions of convex polyhedra\nand use it to derive an exact algorithm for tropical polynomial division. An\napproximate algorithm is also presented, based on an alternation between data\npartition and linear programming. We also develop special techniques to divide\ncomposite polynomials, described as sums or maxima of simpler ones. Finally, we\npresent some numerical results to illustrate the efficiency of the algorithms\nproposed, using the MNIST handwritten digit and CIFAR-10 datasets.\n","authors":["Ioannis Kordonis","Petros Maragos"],"pdf_url":"https://arxiv.org/pdf/2306.15157v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15156v1","updated":"2023-06-27T02:26:01Z","published":"2023-06-27T02:26:01Z","title":"Learning non-Markovian Decision-Making from State-only Sequences","summary":"  Conventional imitation learning assumes access to the actions of\ndemonstrators, but these motor signals are often non-observable in naturalistic\nsettings. Additionally, sequential decision-making behaviors in these settings\ncan deviate from the assumptions of a standard Markov Decision Process (MDP).\nTo address these challenges, we explore deep generative modeling of state-only\nsequences with non-Markov Decision Process (nMDP), where the policy is an\nenergy-based prior in the latent space of the state transition generator. We\ndevelop maximum likelihood estimation to achieve model-based imitation, which\ninvolves short-run MCMC sampling from the prior and importance sampling for the\nposterior. The learned model enables \\textit{decision-making as inference}:\nmodel-free policy execution is equivalent to prior sampling, model-based\nplanning is posterior sampling initialized from the policy. We demonstrate the\nefficacy of the proposed method in a prototypical path planning task with\nnon-Markovian constraints and show that the learned model exhibits strong\nperformances in challenging domains from the MuJoCo suite.\n","authors":["Aoyang Qin","Feng Gao","Qing Li","Song-Chun Zhu","Sirui Xie"],"pdf_url":"https://arxiv.org/pdf/2306.15156v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.09790v2","updated":"2023-06-27T02:24:18Z","published":"2023-04-27T02:01:41Z","title":"Molecule-Morphology Contrastive Pretraining for Transferable Molecular\n  Representation","summary":"  Image-based profiling techniques have become increasingly popular over the\npast decade for their applications in target identification,\nmechanism-of-action inference, and assay development. These techniques have\ngenerated large datasets of cellular morphologies, which are typically used to\ninvestigate the effects of small molecule perturbagens. In this work, we extend\nthe impact of such dataset to improving quantitative structure-activity\nrelationship (QSAR) models by introducing Molecule-Morphology Contrastive\nPretraining (MoCoP), a framework for learning multi-modal representation of\nmolecular graphs and cellular morphologies. We scale MoCoP to approximately\n100K molecules and 600K morphological profiles using data from the JUMP-CP\nConsortium and show that MoCoP consistently improves performances of graph\nneural networks (GNNs) on molecular property prediction tasks in ChEMBL20\nacross all dataset sizes. The pretrained GNNs are also evaluated on internal\nGSK pharmacokinetic data and show an average improvement of 2.6% and 6.3% in\nAUPRC for full and low data regimes, respectively. Our findings suggest that\nintegrating cellular morphologies with molecular graphs using MoCoP can\nsignificantly improve the performance of QSAR models, ultimately expanding the\ndeep learning toolbox available for QSAR applications.\n","authors":["Cuong Q. Nguyen","Dante Pertusi","Kim M. Branson"],"pdf_url":"https://arxiv.org/pdf/2305.09790v2.pdf","comment":"ICML 2023 Workshop on Computational Biology"},{"id":"http://arxiv.org/abs/2306.15155v1","updated":"2023-06-27T02:24:05Z","published":"2023-06-27T02:24:05Z","title":"Input-sensitive dense-sparse primitive compositions for GNN acceleration","summary":"  Graph neural networks (GNN) have become an important class of neural network\nmodels that have gained popularity in domains such as social and financial\nnetwork analysis. Different phases of GNN computations can be modeled using\nboth dense and sparse matrix operations. There have been many frameworks and\noptimization techniques proposed in the literature to accelerate GNNs. However,\ngetting consistently high performance across many input graphs with different\nsparsity patterns and GNN embedding sizes has remained difficult.\n  In this paper, we propose different algebraic reassociations of GNN\ncomputations that lead to novel dense and sparse matrix primitive selections\nand compositions. We show that the profitability of these compositions depends\non the input graph, embedding size, and the target hardware. We developed\nSENSEi, a system that uses a data-driven adaptive strategy to select the best\ncomposition given the input graph and GNN embedding sizes. Our evaluations on a\nwide range of graphs and embedding sizes show that SENSEi achieves geomean\nspeedups of $1.105\\times$ (up to $2.959\\times$) and $1.187\\times$ (up to\n$1.99\\times$) on graph convolutional networks and geomean speedups of\n$2.307\\times$ (up to $35.866\\times$) and $1.44\\times$ (up to $5.69\\times$) on\ngraph attention networks on CPUs and GPUs respectively over the widely used\nDeep Graph Library. Further, we show that the compositions yield notable\nsynergistic performance benefits on top of other established sparse\noptimizations such as sparse matrix tiling by evaluating against a well-tuned\nbaseline.\n","authors":["Damitha Lenadora","Vimarsh Sathia","Gerasimos Gerogiannis","Serif Yesil","Josep Torrellas","Charith Mendis"],"pdf_url":"https://arxiv.org/pdf/2306.15155v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15154v1","updated":"2023-06-27T02:22:45Z","published":"2023-06-27T02:22:45Z","title":"Contrastive Meta-Learning for Few-shot Node Classification","summary":"  Few-shot node classification, which aims to predict labels for nodes on\ngraphs with only limited labeled nodes as references, is of great significance\nin real-world graph mining tasks. Particularly, in this paper, we refer to the\ntask of classifying nodes in classes with a few labeled nodes as the few-shot\nnode classification problem. To tackle such a label shortage issue, existing\nworks generally leverage the meta-learning framework, which utilizes a number\nof episodes to extract transferable knowledge from classes with abundant\nlabeled nodes and generalizes the knowledge to other classes with limited\nlabeled nodes. In essence, the primary aim of few-shot node classification is\nto learn node embeddings that are generalizable across different classes. To\naccomplish this, the GNN encoder must be able to distinguish node embeddings\nbetween different classes, while also aligning embeddings for nodes in the same\nclass. Thus, in this work, we propose to consider both the intra-class and\ninter-class generalizability of the model. We create a novel contrastive\nmeta-learning framework on graphs, named COSMIC, with two key designs. First,\nwe propose to enhance the intra-class generalizability by involving a\ncontrastive two-step optimization in each episode to explicitly align node\nembeddings in the same classes. Second, we strengthen the inter-class\ngeneralizability by generating hard node classes via a novel\nsimilarity-sensitive mix-up strategy. Extensive experiments on few-shot node\nclassification datasets verify the superiority of our framework over\nstate-of-the-art baselines. Our code is provided at\nhttps://github.com/SongW-SW/COSMIC.\n","authors":["Song Wang","Zhen Tan","Huan Liu","Jundong Li"],"pdf_url":"https://arxiv.org/pdf/2306.15154v1.pdf","comment":"SIGKDD 2023"},{"id":"http://arxiv.org/abs/2306.08158v2","updated":"2023-06-27T02:06:24Z","published":"2023-06-13T22:07:54Z","title":"Survey on Sociodemographic Bias in Natural Language Processing","summary":"  Deep neural networks often learn unintended biases during training, which\nmight have harmful effects when deployed in real-world settings. This paper\nsurveys 209 papers on bias in NLP models, most of which address\nsociodemographic bias. To better understand the distinction between bias and\nreal-world harm, we turn to ideas from psychology and behavioral economics to\npropose a definition for sociodemographic bias. We identify three main\ncategories of NLP bias research: types of bias, quantifying bias, and\ndebiasing. We conclude that current approaches on quantifying bias face\nreliability issues, that many of the bias metrics do not relate to real-world\nbiases, and that current debiasing techniques are superficial and hide bias\nrather than removing it. Finally, we provide recommendations for future work.\n","authors":["Vipul Gupta","Pranav Narayanan Venkit","Shomir Wilson","Rebecca J. Passonneau"],"pdf_url":"https://arxiv.org/pdf/2306.08158v2.pdf","comment":"23 pages, 1 figure"},{"id":"http://arxiv.org/abs/2306.14898v2","updated":"2023-06-27T01:51:57Z","published":"2023-06-26T17:59:50Z","title":"InterCode: Standardizing and Benchmarking Interactive Coding with\n  Execution Feedback","summary":"  Humans write code in a fundamentally interactive manner and rely on constant\nexecution feedback to correct errors, resolve ambiguities, and decompose tasks.\nWhile LLMs have recently exhibited promising coding capabilities, current\ncoding benchmarks mostly consider a static instruction-to-code sequence\ntransduction process, which has the potential for error propagation and a\ndisconnect between the generated code and its final execution environment. To\naddress this gap, we introduce InterCode, a lightweight, flexible, and\neasy-to-use framework of interactive coding as a standard reinforcement\nlearning (RL) environment, with code as actions and execution feedback as\nobservations. Our framework is language and platform agnostic, uses\nself-contained Docker environments to provide safe and reproducible execution,\nand is compatible out-of-the-box with traditional seq2seq coding methods, while\nenabling the development of new methods for interactive code generation. We use\nInterCode to create two interactive code environments with Bash and SQL as\naction spaces, leveraging data from the static Spider and NL2Bash datasets. We\ndemonstrate InterCode's viability as a testbed by evaluating multiple\nstate-of-the-art LLMs configured with different prompting strategies such as\nReAct and Plan & Solve. Our results showcase the benefits of interactive code\ngeneration and demonstrate that InterCode can serve as a challenging benchmark\nfor advancing code understanding and generation capabilities. InterCode is\ndesigned to be easily extensible and can even be used to incorporate new tasks\nsuch as Capture the Flag, a popular coding puzzle that is inherently multi-step\nand involves multiple programming languages. Project site with code and data:\nhttps://intercode-benchmark.github.io\n","authors":["John Yang","Akshara Prabhakar","Karthik Narasimhan","Shunyu Yao"],"pdf_url":"https://arxiv.org/pdf/2306.14898v2.pdf","comment":"Project site with code and data:\n  https://intercode-benchmark.github.io"},{"id":"http://arxiv.org/abs/2306.15138v1","updated":"2023-06-27T01:38:52Z","published":"2023-06-27T01:38:52Z","title":"A Restarted Large-Scale Spectral Clustering with Self-Guiding and Block\n  Diagonal Representation","summary":"  Spectral clustering is one of the most popular unsupervised machine learning\nmethods. Constructing similarity matrix is crucial to this type of method. In\nmost existing works, the similarity matrix is computed once for all or is\nupdated alternatively. However, the former is difficult to reflect\ncomprehensive relationships among data points, and the latter is time-consuming\nand is even infeasible for large-scale problems. In this work, we propose a\nrestarted clustering framework with self-guiding and block diagonal\nrepresentation. An advantage of the strategy is that some useful clustering\ninformation obtained from previous cycles could be preserved as much as\npossible. To the best of our knowledge, this is the first work that applies\nrestarting strategy to spectral clustering. The key difference is that we\nreclassify the samples in each cycle of our method, while they are classified\nonly once in existing methods. To further release the overhead, we introduce a\nblock diagonal representation with Nystr\\\"{o}m approximation for constructing\nthe similarity matrix. Theoretical results are established to show the\nrationality of inexact computations in spectral clustering. Comprehensive\nexperiments are performed on some benchmark databases, which show the\nsuperiority of our proposed algorithms over many state-of-the-art algorithms\nfor large-scale problems. Specifically, our framework has a potential boost for\nclustering algorithms and works well even using an initial guess chosen\nrandomly.\n","authors":["Yongyan Guo","Gang Wu"],"pdf_url":"https://arxiv.org/pdf/2306.15138v1.pdf","comment":"36 pages"},{"id":"http://arxiv.org/abs/2208.11361v2","updated":"2023-06-27T01:23:31Z","published":"2022-08-24T08:19:41Z","title":"Self-Supervised Exploration via Temporal Inconsistency in Reinforcement\n  Learning","summary":"  Under sparse extrinsic reward settings, reinforcement learning has remained\nchallenging, despite surging interests in this field. Previous attempts suggest\nthat intrinsic reward can alleviate the issue caused by sparsity. In this\narticle, we present a novel intrinsic reward that is inspired by human\nlearning, as humans evaluate curiosity by comparing current observations with\nhistorical knowledge. Our method involves training a self-supervised prediction\nmodel, saving snapshots of the model parameters, and using nuclear norm to\nevaluate the temporal inconsistency between the predictions of different\nsnapshots as intrinsic rewards. We also propose a variational weighting\nmechanism to assign weight to different snapshots in an adaptive manner. Our\nexperimental results on various benchmark environments demonstrate the efficacy\nof our method, which outperforms other intrinsic reward-based methods without\nadditional training costs and with higher noise tolerance. This work has been\nsubmitted to the IEEE for possible publication. Copyright may be transferred\nwithout notice, after which this version may no longer be accessible.\n","authors":["Zijian Gao","Kele Xu","Yuanzhao Zhai","Dawei Feng","Bo Ding","XinJun Mao","Huaimin Wang"],"pdf_url":"https://arxiv.org/pdf/2208.11361v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14759v2","updated":"2023-06-27T01:22:41Z","published":"2023-06-26T15:13:36Z","title":"PMaF: Deep Declarative Layers for Principal Matrix Features","summary":"  We explore two differentiable deep declarative layers, namely least squares\non sphere (LESS) and implicit eigen decomposition (IED), for learning the\nprincipal matrix features (PMaF). This can be used to represent data features\nwith a low-dimension vector containing dominant information from a\nhigh-dimension matrix. We first solve the problems with iterative optimization\nin the forward pass and then backpropagate the solution for implicit gradients\nunder a bi-level optimization framework. Particularly, adaptive descent steps\nwith the backtracking line search method and descent decay in the tangent space\nare studied to improve the forward pass efficiency of LESS. Meanwhile,\nexploited data structures are used to greatly reduce the computational\ncomplexity in the backward pass of LESS and IED. Empirically, we demonstrate\nthe superiority of our layers over the off-the-shelf baselines by comparing the\nsolution optimality and computational requirements.\n","authors":["Zhiwei Xu","Hao Wang","Yanbin Liu","Stephen Gould"],"pdf_url":"https://arxiv.org/pdf/2306.14759v2.pdf","comment":"Accepted to the Differentiable Almost Everything Workshop of the\n  International Conference on Machine Learning (ICML), 2023"},{"id":"http://arxiv.org/abs/2209.06800v3","updated":"2023-06-27T01:07:09Z","published":"2022-09-14T17:32:28Z","title":"MGG: Accelerating Graph Neural Networks with Fine-grained intra-kernel\n  Communication-Computation Pipelining on Multi-GPU Platforms","summary":"  The increasing size of input graphs for graph neural networks (GNNs)\nhighlights the demand for using multi-GPU platforms. However, existing\nmulti-GPU GNN systems optimize the computation and communication individually\nbased on the conventional practice of scaling dense DNNs. For irregularly\nsparse and fine-grained GNN workloads, such solutions miss the opportunity to\njointly schedule/optimize the computation and communication operations for\nhigh-performance delivery. To this end, we propose MGG, a novel system design\nto accelerate full-graph GNNs on multi-GPU platforms. The core of MGG is its\nnovel dynamic software pipeline to facilitate fine-grained\ncomputation-communication overlapping within a GPU kernel. Specifically, MGG\nintroduces GNN-tailored pipeline construction and GPU-aware pipeline mapping to\nfacilitate workload balancing and operation overlapping. MGG also incorporates\nan intelligent runtime design with analytical modeling and optimization\nheuristics to dynamically improve the execution performance. Extensive\nevaluation reveals that MGG outperforms state-of-the-art full-graph GNN systems\nacross various settings: on average 4.41X, 4.81X, and 10.83X faster than DGL,\nMGG-UVM, and ROC, respectively.\n","authors":["Yuke Wang","Boyuan Feng","Zheng Wang","Tong Geng","Kevin Barker","Ang Li","Yufei Ding"],"pdf_url":"https://arxiv.org/pdf/2209.06800v3.pdf","comment":"Paper is accepted to OSDI'23"},{"id":"http://arxiv.org/abs/2304.01508v3","updated":"2023-06-27T01:06:25Z","published":"2023-04-04T03:36:14Z","title":"EPVT: Environment-aware Prompt Vision Transformer for Domain\n  Generalization in Skin Lesion Recognition","summary":"  Skin lesion recognition using deep learning has made remarkable progress, and\nthere is an increasing need for deploying these systems in real-world\nscenarios. However, recent research has revealed that deep neural networks for\nskin lesion recognition may overly depend on disease-irrelevant image artifacts\n(i.e., dark corners, dense hairs), leading to poor generalization in unseen\nenvironments. To address this issue, we propose a novel domain generalization\nmethod called EPVT, which involves embedding prompts into the vision\ntransformer to collaboratively learn knowledge from diverse domains.\nConcretely, EPVT leverages a set of domain prompts, each of which plays as a\ndomain expert, to capture domain-specific knowledge; and a shared prompt for\ngeneral knowledge over the entire dataset. To facilitate knowledge sharing and\nthe interaction of different prompts, we introduce a domain prompt generator\nthat enables low-rank multiplicative updates between domain prompts and the\nshared prompt. A domain mixup strategy is additionally devised to reduce the\nco-occurring artifacts in each domain, which allows for more flexible decision\nmargins and mitigates the issue of incorrectly assigned domain labels.\nExperiments on four out-of-distribution datasets and six different biased ISIC\ndatasets demonstrate the superior generalization ability of EPVT in skin lesion\nrecognition across various environments. Code is avaliable at\nhttps://github.com/SiyuanYan1/EPVT.\n","authors":["Siyuan Yan","Chi Liu","Zhen Yu","Lie Ju","Dwarikanath Mahapatrainst","Victoria Mar","Monika Janda","Peter Soyer","Zongyuan Ge"],"pdf_url":"https://arxiv.org/pdf/2304.01508v3.pdf","comment":"Accepted by MICCAI 2023"},{"id":"http://arxiv.org/abs/2305.00152v2","updated":"2023-06-27T00:52:34Z","published":"2023-04-29T02:27:42Z","title":"Limits of Model Selection under Transfer Learning","summary":"  Theoretical studies on transfer learning or domain adaptation have so far\nfocused on situations with a known hypothesis class or model; however in\npractice, some amount of model selection is usually involved, often appearing\nunder the umbrella term of hyperparameter-tuning: for example, one may think of\nthe problem of tuning for the right neural network architecture towards a\ntarget task, while leveraging data from a related source task.\n  Now, in addition to the usual tradeoffs on approximation vs estimation errors\ninvolved in model selection, this problem brings in a new complexity term,\nnamely, the transfer distance between source and target distributions, which is\nknown to vary with the choice of hypothesis class.\n  We present a first study of this problem, focusing on classification; in\nparticular, the analysis reveals some remarkable phenomena: adaptive rates,\ni.e., those achievable with no distributional information, can be arbitrarily\nslower than oracle rates, i.e., when given knowledge on distances.\n","authors":["Steve Hanneke","Samory Kpotufe","Yasaman Mahdaviyeh"],"pdf_url":"https://arxiv.org/pdf/2305.00152v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15128v1","updated":"2023-06-27T00:40:12Z","published":"2023-06-27T00:40:12Z","title":"MIMIC: Masked Image Modeling with Image Correspondences","summary":"  Many pixelwise dense prediction tasks-depth estimation and semantic\nsegmentation in computer vision today rely on pretrained image representations.\nTherefore, curating effective pretraining datasets is vital. Unfortunately, the\neffective pretraining datasets are those with multi-view scenes and have only\nbeen curated using annotated 3D meshes, point clouds, and camera parameters\nfrom simulated environments. We propose a dataset-curation mechanism that does\nnot require any annotations. We mine two datasets: MIMIC-1M with 1.3M and\nMIMIC-3M with 3.1M multi-view image pairs from open-sourced video datasets and\nfrom synthetic 3D environments. We train multiple self-supervised models with\ndifferent masked image modeling objectives to showcase the following findings:\nRepresentations trained on MIMIC-3M outperform those mined using annotations on\nmultiple downstream tasks, including depth estimation, semantic segmentation,\nsurface normals, and pose estimation. They also outperform representations that\nare frozen and when downstream training data is limited to few-shot. Larger\ndataset (MIMIC-3M) significantly improves performance, which is promising since\nour curation method can arbitrarily scale to produce even larger datasets.\nMIMIC code, dataset, and pretrained models are open-sourced at\nhttps://github.com/RAIVNLab/MIMIC.\n","authors":["Kalyani Marathe","Mahtab Bigverdi","Nishat Khan","Tuhin Kundu","Aniruddha Kembhavi","Linda G. Shapiro","Ranjay Krishna"],"pdf_url":"https://arxiv.org/pdf/2306.15128v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.11861v2","updated":"2023-06-27T00:19:14Z","published":"2023-02-23T08:59:56Z","title":"Out-of-Domain Robustness via Targeted Augmentations","summary":"  Models trained on one set of domains often suffer performance drops on unseen\ndomains, e.g., when wildlife monitoring models are deployed in new camera\nlocations. In this work, we study principles for designing data augmentations\nfor out-of-domain (OOD) generalization. In particular, we focus on real-world\nscenarios in which some domain-dependent features are robust, i.e., some\nfeatures that vary across domains are predictive OOD. For example, in the\nwildlife monitoring application above, image backgrounds vary across camera\nlocations but indicate habitat type, which helps predict the species of\nphotographed animals. Motivated by theoretical analysis on a linear setting, we\npropose targeted augmentations, which selectively randomize spurious\ndomain-dependent features while preserving robust ones. We prove that targeted\naugmentations improve OOD performance, allowing models to generalize better\nwith fewer domains. In contrast, existing approaches such as generic\naugmentations, which fail to randomize domain-dependent features, and\ndomain-invariant augmentations, which randomize all domain-dependent features,\nboth perform poorly OOD. In experiments on three real-world datasets, we show\nthat targeted augmentations set new states-of-the-art for OOD performance by\n3.2-15.2%.\n","authors":["Irena Gao","Shiori Sagawa","Pang Wei Koh","Tatsunori Hashimoto","Percy Liang"],"pdf_url":"https://arxiv.org/pdf/2302.11861v2.pdf","comment":"ICML camera ready"},{"id":"http://arxiv.org/abs/2305.12334v3","updated":"2023-06-27T00:02:08Z","published":"2023-05-21T03:51:03Z","title":"Towards Complex Dynamic Physics System Simulation with Graph Neural ODEs","summary":"  The great learning ability of deep learning models facilitates us to\ncomprehend the real physical world, making learning to simulate complicated\nparticle systems a promising endeavour. However, the complex laws of the\nphysical world pose significant challenges to the learning based simulations,\nsuch as the varying spatial dependencies between interacting particles and\nvarying temporal dependencies between particle system states in different time\nstamps, which dominate particles' interacting behaviour and the physical\nsystems' evolution patterns. Existing learning based simulation methods fail to\nfully account for the complexities, making them unable to yield satisfactory\nsimulations. To better comprehend the complex physical laws, this paper\nproposes a novel learning based simulation model- Graph Networks with\nSpatial-Temporal neural Ordinary Equations (GNSTODE)- that characterizes the\nvarying spatial and temporal dependencies in particle systems using a united\nend-to-end framework. Through training with real-world particle-particle\ninteraction observations, GNSTODE is able to simulate any possible particle\nsystems with high precisions. We empirically evaluate GNSTODE's simulation\nperformance on two real-world particle systems, Gravity and Coulomb, with\nvarying levels of spatial and temporal dependencies. The results show that the\nproposed GNSTODE yields significantly better simulations than state-of-the-art\nlearning based simulation methods, which proves that GNSTODE can serve as an\neffective solution to particle simulations in real-world application.\n","authors":["Guangsi Shi","Daokun Zhang","Ming Jin","Shirui Pan"],"pdf_url":"https://arxiv.org/pdf/2305.12334v3.pdf","comment":"12 pages,5 figures, 6 tables, 49 references"}],"Multimedia":[{"id":"http://arxiv.org/abs/2306.15561v1","updated":"2023-06-27T15:36:22Z","published":"2023-06-27T15:36:22Z","title":"You Can Mask More For Extremely Low-Bitrate Image Compression","summary":"  Learned image compression (LIC) methods have experienced significant progress\nduring recent years. However, these methods are primarily dedicated to\noptimizing the rate-distortion (R-D) performance at medium and high bitrates (>\n0.1 bits per pixel (bpp)), while research on extremely low bitrates is limited.\nBesides, existing methods fail to explicitly explore the image structure and\ntexture components crucial for image compression, treating them equally\nalongside uninformative components in networks. This can cause severe\nperceptual quality degradation, especially under low-bitrate scenarios. In this\nwork, inspired by the success of pre-trained masked autoencoders (MAE) in many\ndownstream tasks, we propose to rethink its mask sampling strategy from\nstructure and texture perspectives for high redundancy reduction and\ndiscriminative feature representation, further unleashing the potential of LIC\nmethods. Therefore, we present a dual-adaptive masking approach (DA-Mask) that\nsamples visible patches based on the structure and texture distributions of\noriginal images. We combine DA-Mask and pre-trained MAE in masked image\nmodeling (MIM) as an initial compressor that abstracts informative semantic\ncontext and texture representations. Such a pipeline can well cooperate with\nLIC networks to achieve further secondary compression while preserving\npromising reconstruction quality. Consequently, we propose a simple yet\neffective masked compression model (MCM), the first framework that unifies MIM\nand LIC end-to-end for extremely low-bitrate image compression. Extensive\nexperiments have demonstrated that our approach outperforms recent\nstate-of-the-art methods in R-D performance, visual quality, and downstream\napplications, at very low bitrates. Our code is available at\nhttps://github.com/lianqi1008/MCM.git.\n","authors":["Anqi Li","Feng Li","Jiaxin Han","Huihui Bai","Runmin Cong","Chunjie Zhang","Meng Wang","Weisi Lin","Yao Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.15561v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2306.15401v1","updated":"2023-06-27T11:54:57Z","published":"2023-06-27T11:54:57Z","title":"Explainable Multimodal Emotion Reasoning","summary":"  Multimodal emotion recognition is an active research topic in the field of\nartificial intelligence. It aims to integrate multimodal clues (including\nacoustic, visual, and lexical clues) and recognize human emotional states from\nthese clues. Current works generally assume correct emotion labels for\nbenchmark datasets and focus on building more effective architectures to\nachieve better performance. But due to the ambiguity and subjectivity of\nemotion, existing datasets cannot achieve high annotation consistency (i.e.,\nlabels may be inaccurate), making it difficult for models developed on these\ndatasets to meet the demand of practical applications. To address this problem,\nthe core is to improve the reliability of emotion annotations. Therefore, we\npropose a new task called ``Explainable Multimodal Emotion Reasoning (EMER)''.\nUnlike previous works that only predict emotional states, EMER further explains\nthe reasons behind these predictions to enhance their reliability. In this\ntask, rationality is the only evaluation metric. As long as the emotional\nreasoning process for a given video is plausible, the prediction is correct. In\nthis paper, we make an initial attempt at this task and establish a benchmark\ndataset, baselines, and evaluation metrics. We aim to address the long-standing\nproblem of label ambiguity and point a way to the next-generation affective\ncomputing techniques. In addition, EMER can also be exploited to evaluate the\naudio-video-text understanding ability of recent multimodal large language\nmodels. Code and data:\nhttps://github.com/zeroQiaoba/Explainable-Multimodal-Emotion-Reasoning.\n","authors":["Zheng Lian","Licai Sun","Mingyu Xu","Haiyang Sun","Ke Xu","Zhuofan Wen","Shun Chen","Bin Liu","Jianhua Tao"],"pdf_url":"https://arxiv.org/pdf/2306.15401v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.12140v2","updated":"2023-06-27T11:42:44Z","published":"2023-05-20T08:43:51Z","title":"Movie101: A New Movie Understanding Benchmark","summary":"  To help the visually impaired enjoy movies, automatic movie narrating systems\nare expected to narrate accurate, coherent, and role-aware plots when there are\nno speaking lines of actors. Existing works benchmark this challenge as a\nnormal video captioning task via some simplifications, such as removing role\nnames and evaluating narrations with ngram-based metrics, which makes it\ndifficult for automatic systems to meet the needs of real application\nscenarios. To narrow this gap, we construct a large-scale Chinese movie\nbenchmark, named Movie101. Closer to real scenarios, the Movie Clip Narrating\n(MCN) task in our benchmark asks models to generate role-aware narration\nparagraphs for complete movie clips where no actors are speaking. External\nknowledge, such as role information and movie genres, is also provided for\nbetter movie understanding. Besides, we propose a new metric called Movie\nNarration Score (MNScore) for movie narrating evaluation, which achieves the\nbest correlation with human evaluation. Our benchmark also supports the\nTemporal Narration Grounding (TNG) task to investigate clip localization given\ntext descriptions. For both two tasks, our proposed methods well leverage\nexternal knowledge and outperform carefully designed baselines. The dataset and\ncodes are released at https://github.com/yuezih/Movie101.\n","authors":["Zihao Yue","Qi Zhang","Anwen Hu","Liang Zhang","Ziheng Wang","Qin Jin"],"pdf_url":"https://arxiv.org/pdf/2305.12140v2.pdf","comment":"Accepted to ACL 2023"},{"id":"http://arxiv.org/abs/2306.15246v1","updated":"2023-06-27T06:59:10Z","published":"2023-06-27T06:59:10Z","title":"Errorless Robust JPEG Steganography Using Steganographic Polar Codes","summary":"  Recently, a robust steganographic algorithm that achieves errorless\nrobustness against JPEG recompression is proposed. The method evaluates the\nbehavior of DCT coefficients after recompression using the local JPEG encoder\nto select robust coefficients and sets the other coefficients as wet cost.\nCombining the lattice embedding scheme, the method is errorless by\nconstruction. However, the authors only concern with the success rate under\ntheoretical embedding, while the success rate of the implementation with\npractical steganographic codes is not verified. In this letter, we implement\nthe method with two steganographic codes, i.e., steganographic polar code and\nsyndrome-trellis code. By analyzing the possibility of success embedding of two\nsteganographic codes under wet paper embedding, we discover that steganographic\npolar code achieves success embedding with a larger number of wet coefficients\ncompared with syndrome-trellis code, which makes steganographic polar code more\nsuitable under the errorless robust embedding paradigm. The experimental\nresults show that the combination of steganographic polar code and errorless\nrobust embedding achieves a higher success rate compared with the\nimplementation with syndrome-trellis code under close security performance.\n","authors":["Jimin Zhang","Xianfeng Zhao","Xiaolei He"],"pdf_url":"https://arxiv.org/pdf/2306.15246v1.pdf","comment":"5 pages, 6 figures, submitted to IEEE Signal Processing Letters"},{"id":"http://arxiv.org/abs/2305.13583v2","updated":"2023-06-27T05:48:46Z","published":"2023-05-23T01:24:15Z","title":"Cross-Attention is Not Enough: Incongruity-Aware Hierarchical Multimodal\n  Sentiment Analysis and Emotion Recognition","summary":"  Fusing multiple modalities for affective computing tasks has proven effective\nfor performance improvement. However, how multimodal fusion works is not well\nunderstood, and its use in the real world usually results in large model sizes.\nIn this work, on sentiment and emotion analysis, we first analyze how the\nsalient affective information in one modality can be affected by the other in\ncrossmodal attention. We find that inter-modal incongruity exists at the latent\nlevel due to crossmodal attention. Based on this finding, we propose a\nlightweight model via Hierarchical Crossmodal Transformer with Modality Gating\n(HCT-MG), which determines a primary modality according to its contribution to\nthe target task and then hierarchically incorporates auxiliary modalities to\nalleviate inter-modal incongruity and reduce information redundancy. The\nexperimental evaluation on three benchmark datasets: CMU-MOSI, CMU-MOSEI, and\nIEMOCAP verifies the efficacy of our approach, showing that it: 1) achieves\nbetter performance than prior work as well as manual selection of the primary\nmodality; 2) can recognize hard samples whose emotions are hard to tell; 3)\nmitigates the inter-modal incongruity at the latent level when modalities have\nmismatched affective tendencies; 4) reduces model size to less than 1M\nparameters while outperforming existing models of similar sizes.\n","authors":["Yaoting Wang","Yuanchao Li","Peter Bell","Catherine Lai"],"pdf_url":"https://arxiv.org/pdf/2305.13583v2.pdf","comment":"*Equal contribution"}]}}